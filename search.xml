<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[轻量级Kubernetes发行版k3s之部署metrics-server]]></title>
    <url>%2F2019%2F09%2F09%2Flightweight-kubernetes-release-k3s-hpa-metrics%2F</url>
    <content type="text"><![CDATA[安装从官方仓库下载项目文件： 1234567$ git clone https://github.com/kubernetes-incubator/metrics-server.git$ cd metrics-server/deploy/1.8+$ lsaggregated-metrics-reader.yaml auth-reader.yaml metrics-server-deployment.yaml resource-reader.yamlauth-delegator.yaml metrics-apiservice.yaml metrics-server-service.yaml 下载镜像需要使用的镜像为 k8s.gcr.io/metrics-server-amd64:v0.3.4 。 通过如下的脚本来下载： 创建文件 $ vim pull_images.sh 1234567#!/bin/bashimages=(metrics-server-amd64:v0.3.4)for imageName in $&#123;images[@]&#125; ; do docker pull gcr.azk8s.cn/google_containers/$imageName docker tag gcr.azk8s.cn/google_containers/$imageName k8s.gcr.io/$imageName docker rmi gcr.azk8s.cn/google_containers/$imageNamedone 执行 $ bash ./pull_images.sh 查看该镜像：1$ docker images 修改yaml文件修改 metrics-server-deployment.yaml 将其中 Deployment 中镜像的 imagePullPolicy: Always 改成 imagePullPolicy: IfNotPresent ,以使用本地下载的镜像。 编辑文件 $ vim metrics-server-deployment.yaml 部署安装123456789101112$ cd ../../$ kubectl apply -f deploy/1.8+clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader createdclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdserviceaccount/metrics-server createddeployment.extensions/metrics-server createdservice/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created 查看容器运行状态123$ kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEmetrics-server-5588fd886b-bcp7x 1/1 Running 0 44s 效果查看1234567891011121314151617$ kubectl top nodes -n kube-systemNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%k3s-agent 20m 2% 202Mi 20%k3s-master 50m 5% 543Mi 54%$ kubectl top pods -n kube-systemNAME CPU(cores) MEMORY(bytes)coredns-b7464766c-dbl29 3m 22Mimetrics-server-5588fd886b-bcp7x 1m 13Misvclb-traefik-rmwcp 0m 1Misvclb-traefik-t4gbn 0m 1Mitiller-deploy-749f694975-f9rft 1m 9Mitraefik-5c79b789c5-8jsvg 3m 21Mi# 查看所有Pods$ kubectl top pods --all-namespaces 相关参考 Configuration Info kubernetes-incubator/metrics-server 未完待续。。。]]></content>
      <categories>
        <category>轻量级云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>K3s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客置顶功能优化]]></title>
    <url>%2F2019%2F09%2F05%2Fhexo-top-optimize%2F</url>
    <content type="text"><![CDATA[今天一个朋友发微信跟我说：“你的博客该更新了，都长草了！” 我一想不对呀，这两天一直都有更新文章的呀！然后我才恍然明白原来他说的是我博客的“置顶”功能。 不过确实，某些文章设置了置顶后在博客中给人的感觉就是：一看前面几篇文章的发表时间还是好几个月前的甚至是几年前的，第一印象就是 “这个博客已经好久不更新了吧！”。那种感觉就像。。。你约女孩子见面结果三天没洗头一样。。。不仅仅是尴尬 在我之前的文章中也介绍过在Hexo博客中(nexT主题)添加文章“置顶”功能的方法：Hexo博客功能优化 | IT范儿 虽然只是在写文章时添加了一个 top: true 的标记，但确实实现了一个非常棒的功能。 对于博客作者来说，知道这样的文章是“置顶”的，但对于博客浏览者来说，他们却并不知情。那么最好的解决方法就是为 “置顶” 的文章加上一个“置顶”的标记。 置顶标记从网上简单的搜索了一下，找到了如下的代码段。修改博客文件目录中的 /themes/next/layout/_macro/post.swig 文件： 直接搜索 class=&quot;post-meta 在 &lt;div class=&quot;post-meta&quot;&gt; 和 &lt;span class=&quot;post-time&quot;&gt; 之间加入如下的代码段： 123456789&lt;div class=&quot;post-meta&quot;&gt; &#123;% if post.top %&#125; &lt;i class=&quot;fa fa-thumb-tack&quot;&gt;&lt;/i&gt; &lt;font color=7D26CD&gt;置顶&lt;/font&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt; &#123;% endif %&#125; &lt;span class=&quot;post-time&quot;&gt; 保存修改。执行 hexo s -g 查看效果。 颜色修改对于“置顶”两字的颜色，默认的颜色 7D26CD 我不是很喜欢，所以把它改成了稍微偏红的颜色 #f05050 ，当然你也可以随意更改，看个人喜好了。 # 号有没有无所谓，大小写随意不影响，不过为了符合标准建议写成这样：color=&quot;#f05050&quot;。 需要注意的是，修改后必须重新执行 hexo s -g 命令才能看到效果，并不是像文章更新的那样刷新页面就立即生效的。 扩展优化虽然按照上面的方法加上了 “置顶” 标记，不过感觉和自己想象的似乎有那么点差距，但差距在哪也不是很好说。。。 所以我就上网去找了一下，发现了下面的一个网站的置顶效果（其中的文字我做了替换）： 恩，就是这样！“置顶” 两个字放在标题前面，红底、白字，非常醒目。 当然，改起来其实也很简单。。。 不过可能有的朋友说了，“我也不会写代码呀，让我怎么改？”，或者 “我也不会nodejs呀？” 。。。 那这个问题其实非常好办，不会写你还不会改吗？不会改你还不会抄吗？照葫芦画瓢总可以吧！！！ 首先，查看网页的源代码，找到我们需要添加置顶标记的文章标题： 1234567&lt;header class=&quot;post-header&quot;&gt; &lt;h2 class=&quot;post-title&quot; itemprop=&quot;name headline&quot;&gt; &lt;a class=&quot;post-title-link&quot; href=&quot;/2019/07/11/run-drone-cicd-on-kubernetes/&quot; itemprop=&quot;url&quot;&gt; 在Kubernetes上执行Drone CI/CD&lt;/a&gt;&lt;/h2&gt; &lt;div class=&quot;post-meta&quot;&gt; 可以看到文章的标题是包裹在一个带有class标记的a链接中，class名称为post-title-link。 然后，我们再回到上面操作的 post.swig 文件中去搜索该class 标记，找到了如下的代码段：1234&#123;% endif %&#125;&lt;a class=&quot;post-title-link&quot; href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; itemprop=&quot;url&quot;&gt;&#123;##&#125; &#123;&#123; post.title | default(__(&apos;post.untitled&apos;))&#125;&#125;&#123;##&#125;&lt;/a&gt;&#123;# 通过单词可知其中的 post.title 就是文章的标题了。那其实我们只需要把 “置顶” 两个字加到a标签中，文章标题之前就可以了嘛。 然后，回去看我们上面的 “葫芦”：1&lt;font color=7D26CD&gt;置顶&lt;/font&gt; 我们只需稍微改一下，加上颜色，加上置顶条件：1&#123;% if post.top %&#125;&lt;font color=&quot;f05050&quot;&gt;[置顶] &lt;/font&gt; &#123;% endif %&#125; 然后放进去就可以了：1234&#123;% endif %&#125;&lt;a class=&quot;post-title-link&quot; href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; itemprop=&quot;url&quot;&gt;&#123;##&#125; &#123;% if post.top %&#125;&lt;font color=&quot;f05050&quot;&gt;[置顶] &lt;/font&gt; &#123;% endif %&#125; &#123;&#123; post.title | default(__(&apos;post.untitled&apos;))&#125;&#125;&#123;##&#125;&lt;/a&gt;&#123;# 最后的效果如下： 当然，前端能力强的，还可以再美化一下。 说点别的博客嘛，看的就是文章。重要的就是把你在工作、学习或者生活中遇到的问题、获得的经验、得到的收获去分享给别人，可能这就是我写博客的初衷所在吧。 看到好多朋友的博客搞得非常的“花哨”，什么动态背景啦，什么萌萌哒卡哇伊啦。我一直都不是很感冒。 可能更关键的原因是：每次我打开带有“动态背景”的博客时，我的MacBook的风扇就会进入 “狂浪” 模式，虽然我一直觉得这可能是Hexo的一个至今未被修复的bug。。。 你听，耳边想起了： 狂浪是一种态度 狂浪在起起伏伏 狂浪 狂浪 狂浪 狂浪 相关参考 Hexo博客彻底解决置顶问题 | wangwlj’s Blog]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome浏览器通过SwitchyOmega实现自动代理切换]]></title>
    <url>%2F2019%2F09%2F04%2Fautoproxy-by-shadowsocks-and-switchyomega%2F</url>
    <content type="text"><![CDATA[在之前使用ShadowSocks代理FQ时，一般情况下我就使用默认的 “自动代理模式”，遇到一些需要FQ的网站时再手动切换为 “全局模式”。而有时候忘了切换回来，访问国内的网站就特别的慢。而每次都需要手动的切换也是非常繁琐。 之前也曾使用过SwitchyOmega实现Chrome浏览器的代理切换，但当时只是进行了简单的设置，没有深入的去了解。所以遇到特殊的情况就很无奈，最后也就弃用了。 最近花了点时间看了看SwitchyOmega的设置，感觉是时候实现代理的自动切换了。 ShadowSocks默认情况下，ss在自动模式下有一个PAC文件，记录着一些需要FQ才能访问的站点。不过对于该文件中没有记录的网站，则需要手动的添加进去。在之前的文章 如何添加URL到shadowsocks的列表让其使用代理访问 | IT范儿 中我也介绍了相关的手动添加方法。但是，每次遇到一个新的需FQ的站点都需要这样来操作，也确实繁琐了一些。 关于ss的一些配置，这里就不详细的介绍了。所以在此之前，你应该有一个正常使用的ss客户端。 安装Proxy SwitchyOmega在线安装正常情况下，开启了ss就可以直接访问Chrome应用商店来安装了。搜索 “Proxy SwitchyOmega” 安装即可。 这里我也给出了 Proxy SwitchyOmega 的地址： Proxy SwitchyOmega - Chrome 网上应用店 离线安装当然，也可以通过离线的CRX包安装。从 Github 直接下载安装包： Releases · FelisCatus/SwitchyOmega 在 Chrome 地址栏输入 chrome://extensions 打开扩展程序，拖动 .crx 后缀的 SwitchyOmega 安装文件到扩展程序中按提示进行安装。 Proxy SwitchyOmega配置在 Proxy SwitchyOmega 安装完成后默认已设置好两个情景模式：auto switch 和proxy。 我下面的操作是将原来的默认设置删除后并重新添加的（因为之前有一些其他的设置），当然你可以直接按照我下面的方法来修改默认带的这两个模式。 新增代理模式安装完成后会在 Chrome 浏览器右上角显示扩展程序的图标，选择 “选项” 打开 SwitchyOmega 选项设置界面，点击 “新建情景模式”，这里我设置名称为 ss代理（同默认的proxy模式），情景类型选择 “代理服务器”，之后新增一项 SOCKS5的代理信息： 默认情况下，ss的 SOCKS5 代理端口为 1080 。 完成之后，点击 “应用选项” 保存设置。 新增智能切换模式再次点击 “新建情景模式”，我设置名称为 “智能切换”（同默认的auto switch模式），情景类型选择 “自动切换模式”，点击 “创建”。 在 “规则列表设置” 中，填写： 规则列表格式： AutoProxy规则列表网址： https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 然后点击 “立即更新情景模式”，之后会在 “规则列表正文” 中显示相应的规则列表。 在上面的 “切换规则” 中，将 “规则列表规则” 前面的框打√，后面选择上一步设置的 “ss代理”(同默认的proxy模式) ，下面的 “默认情景模式” 选择 “直接连接” 。点击左侧 “应用选项” 保存设置即可。 这样设置的意思表示：如果网址匹配到规则列表中的网址规则，则会走代理，如果没有匹配到规则及默认的情况下，则会直接访问。 体验自动代理切换将ss的代理模式更改为 “自动代理模式”：点击 SwitchyOmega 图标选择 “智能切换” (同默认的proxy模式) 选项即可。 然后在Chrome浏览器中打开 google.com 查看是否能正常访问。 设置本地Ip不走代理有时候在本地开发网站项目时，都会通过本地的Ip来访问调试。但某些情况下本地的Ip也会去走SwitchyOmega的代理模式，所以需要将本地的Ip给屏蔽掉。 如上面 “新增代理模式” 中的图片，在 “不代理地址列表” 中填写本地的Ip地址。 我本机的Ip为 192.168.5.*，之后不要忘了 “应用选项” 来保存设置。 新增自定义站点因为我们使用的自定义AutoProxy文件是公共的，所以不可能把所有需要的网址全都加进去。那么就需要来自动判断哪些网址需要添加进规则列表中。 比如访问 https://www.instagram.com/ 网址，可以发现通过默认的 “智能切换” 是不能正常浏览的。 不过，可以看到此时 SwitchyOmega 图标右下角多了一个数字 1。 依次点击 SwitchyOmega 图标 – 1个资源未加载 ，在新的窗口中选择相应的情景模式 ss代理 并点击 “添加条件”。 此时，可以看到网站刷新后页面能够正常的访问了。 之后，再次访问网站 https://www.instagram.com/ 时就会自动使用 ss代理 模式来实现科学上网了。 快速切换场景通过上面的设置后，在浏览网页时已经可以做到智能化的代理切换了：在规则列表中的走代理，其他的直接访问。没在规则列表中的手动添加一下即可。 不过，时间长了之后我们也会感觉到厌烦。如果将浏览网站的需求剥离到最简单： 一个网址，要么是正常浏览模式，要么是翻墙浏览模式。 所以，我们只需要在这两种模式之前切换就好了嘛，搞那么复杂干什么呢？ SwitchyOmega 中也已经为我们添加了这样的选项 – “快速切换” 模式。 在 “快速切换” 模式下，可以通过两种方式来切换情景模式： 通过点击 SwitchyOmega 的图标来循环切换 通过快捷键 Alt+Shift+O 来循环切换 设置要启用 “快速切换” 模式，点击： “选项” – “界面” –（最下方）“快速切换”，勾选即可启用 在 “循环切换以下情景模式” 中，加入 “直接连接” 和 “ss代理”（同默认的auto switch模式） 两项： 最后，点击左侧的 ”应用选项“ 保存设置。 使用在 ”快速切换“ 模式下，SwitchyOmega 图标点击就不会像之前一样弹出 代理列表菜单 了，而是在 “直连” 和 “代理” 之间循环切换。 如果需要打开 SwitchyOmega 的选项，可以右击该图标 – 选择 “选项”。 如果需要暂时停用 “快速切换” 模式，也可以右击该图标 – 将 “启用快速切换” 前面的 √ 去掉即可。 这样在浏览网站时，如果 “直连” 无法访问，点击一下图标或者快捷键就可以使用代理了。 不过，在一段时间的体验后个人感觉这种方式其实没有上面的 “自动切换模式” 来的方便。 虚拟情景模式如何理解默认情况下，我们在一个情景模式中只能添加一个代理服务器。如果你有多个代理服务器可用，那么就需要添加多个代理情景模式。 假如我有A、B、C三个代理。默认情况下，在 “自动切换模式” 下我选择的是A代理和直连。突然有一天，A代理挂掉了，连不上了，这时我就需要在 “自动切换模式” 中手动将B代理或者C代理设置为默认的代理服务器。 而 “虚拟情景模式” 就是针对于这种多个代理的情况而言的。你可以把它看成 “代理工具的集合” ，可以快速的使用其中一个代理来进行连接。而如果其中一个代理挂掉，又可以快速的切换到另一个代理来使用。 如何设置添加多个代理在开始设置之前，我们先添加多个代理。比如我这里添加了一个 ”B代理“ 和一个 ”C代理“ 。 新增虚情景模式点击 “新增情景模式” – 设置名称（我这里设置为 “虚拟代理”） – 选择 “虚情景模式” – 创建。 在 ”虚情景模式“ 的 ”目标“ 中，选择所有的 ”代理“ 模式其中的一项，表示默认使用的代理： 最后，别忘了点击左侧的 ”应用选项“ 保存设置。 使用虚情景代理选择 “自动代理模式” ：我这里是 “智能切换” 模式（同默认的auto switch模式）。 将 “规则列表规则” 后面的情景模式更改为我们新设置的 “虚拟情景模式” 代理。 最后，点击左侧的 ”应用选项“ 保存设置。 使用打开 google.com 页面，依旧选择 “智能切换” （同默认的auto switch模式）代理。 只是这时可以看到新增的 “虚拟代理” 选项后面多了一个下拉框，可以让我们在多个代理之间选择其中一个来使用。 相关参考 Proxy SwitchyOmega - 轻松快捷的管理和切换多个代理设置 SwitchyOmega代理设置 — 穿墙指南 1.0.0 文档 显示查询自己的IP地址 建议：换回proxyswitch的切换方式 · Issue #399 · FelisCatus/SwitchyOmega 如何通俗的理解 Switchy Omega 虚拟情景模式 - 黑冰技术站]]></content>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级Kubernetes发行版k3s之Helm安装及应用部署]]></title>
    <url>%2F2019%2F09%2F01%2Flightweight-kubernetes-release-k3s-helm%2F</url>
    <content type="text"><![CDATA[说明helm介绍Helm是Kubernetes生态系统中的一个软件包管理工具。 类似于Ubuntu下的ap-get或者CentOS下的yum，Helm是一个用于kubernetes的包管理器。 通过Helm可以对应用程序相关的Kubernetes资源文件进行打包，管理依赖及管理应用程序版本等功能。 helm组件 Helm: Kubernetes的应用打包工具，也是命令行工具客户端的名称 Tiller: Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令 Chart: Helm的打包格式，内部包含了一组相关的kubernetes资源 Release: 使用Helm install命令在Kubernetes集群中安装的Chart称为Release Repoistory: Helm的软件仓库 helm客户端安装helm使用的是和kubctl相同的配置文件，可以通过官方的说明了解： Helm will figure out where to install Tiller by reading your Kubernetes configuration file (usually $HOME/.kube/config). This is the same file that kubectl uses. 在安装有kubectl的服务器上安装helm客户端或者将k3s的配置文件 /etc/rancher/k3s/k3s.yaml 拷贝到指定设备的 ~/.kube/config 如果是其他指定设备，需要修改配置文件 ~/.kube/config ，将其中的 https://localhost:6443 替换为k3s的master节点的IP，如 https://192.168.5.17:6443 执行如下命令，测试kubectl是否能正常管理k3s集群：1kubectl get nodes 从 Releases · helm/helm 下载 heml的客户端安装包，解压后将其中的 helm 程序移动到 /usr/local/bin 目录下。 helm客户端验证可以通过如下命令来查看helm的信息：123➜ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125;Error: could not find tiller 此处可能会报出 dial tcp [::1]:8080: connect: connection refused 的错误，解决方法见下面。 helm服务端安装helm的服务端名为tiller，tiller需要部署在Kubernetes集群中并且需要设置相应的权限。 第一步：为Tiller创建一个Service Account：1kubectl -n kube-system create serviceaccount tiller 第二步：为Tiller赋予cluster-admin权限：1kubectl create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller 也可以直接创建下面的 tiller-rbac-config.yaml 文件来完成上面两步： 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 执行：1kubectl create -f tiller-rbac-config.yaml 安装Tiller:1helm init --service-account tiller tiller的镜像默认会去 gcr.io 镜像仓库中获取，而该地址在国内是无法访问的。此时可以通过 --tiller-image 来指定国内的镜像仓库源：12helm init --service-account tiller \--tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:&lt;tag&gt; 详细的解决方法说明见下面。 验证Tiller通过如下命令来验证helm服务端Tiller是否安装成功：1234$ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125; 如果同时显示出了helm的client和server的版本信息，则说明安装成功。 如果显示为 Error: could not find a ready tiller pod 则只需稍等一下，待tiller的Pod安装完成即可。 也可以通过 kubectl 命令来验证，执行如下命令：1$ kubectl get pods -n kube-system | grep tiller 如果看到一个前缀为 tiller-deploy 的Pod即说明Tiller安装成功了。 Tiller升级通过如下命令来升级Tiller版本：1helm init --upgrade Tiller卸载由于Tiller的数据保存在ConfigMaps中，所以无需担心数据丢失的问题。卸载Tiller推荐的方式是执行如下命令：123kubectl delete deployment tiller-deploy --namespace kube-systemkubectl delete svc tiller-deploy --namespace kube-system 或者使用下面的命令：1helm reset 通过Helm Chart部署应用这里，我通过一个简单的Chart来测试通过helm部署应用。 Chart执行如下命令来创建一个chart：1➜ helm create hello-chart 查看该chart目录下的文件：12➜ ls hello-chartcharts Chart.yaml templates values.yaml 其中，Chart.yaml 文件用于描述这个chart，其中包括chart的名称、描述信息以及版本等：123456➜ cat Chart.yamlapiVersion: v1appVersion: &quot;1.0&quot;description: A Helm chart for Kubernetesname: hello-chartversion: 0.1.0 values.yaml 用于存储templates目录中模板文件中用到的变量。模板文件就是Go模板，需要安装Go模板的规则来编写。 templates 目录下则是部署应用的相关模板文件。 部署修改 values.yaml 文件中下面部分： 123456789101112image: repository: nginx tag: stable pullPolicy: IfNotPresentimagePullSecrets: []nameOverride: &quot;&quot;fullnameOverride: &quot;&quot;service: type: ClusterIP port: 80 将其中的 image.tag 修改为 alpine ，将 service.type 修改为 NodePort 。即使用 nginx:alpine 镜像，并设置service类型为 NodePort，以便于访问。 修改完成后，在 hello-chart 目录同级，执行如下命令来部署helm：12345678910111213141516171819202122232425➜ helm install ./hello-chartNAME: truculent-wolverineLAST DEPLOYED: Sun Sep 1 23:51:47 2019NAMESPACE: defaultSTATUS: DEPLOYEDRESOURCES:==&gt; v1/DeploymentNAME READY UP-TO-DATE AVAILABLE AGEtruculent-wolverine-hello-chart 0/1 0 0 0s==&gt; v1/Pod(related)NAME READY STATUS RESTARTS AGEtruculent-wolverine-hello-chart-655545d645-72xg9 0/1 Pending 0 0s==&gt; v1/ServiceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEtruculent-wolverine-hello-chart NodePort 10.43.199.183 &lt;none&gt; 80:31337/TCP 0sNOTES:1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services truculent-wolverine-hello-chart) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;) echo http://$NODE_IP:$NODE_PORT 可以看到通过helm chart创建了一个随机名称的Release实例并输出了相关的 Deployment Pod 和 Service 信息。而且可以看到相应的Service端口为 31337 。通过浏览器访问k3s主机IP及端口 http://192.168.5.17:31337/ 查看是否能正常访问。 此时，可以通过 helm list 命令查看安装的Release信息：123➜ helm listNAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACEtruculent-wolverine 1 Sun Sep 1 23:51:47 2019 DEPLOYED hello-chart-0.1.0 1.0 default 如果需要删除Release，则可以通过指定Release的名称来实现：12➜ helm delete truculent-wolverinerelease &quot;truculent-wolverine&quot; deleted 关于Helm的更多信息可以参照官方文档了解。 问题汇总Install Tiller ImagePullBackOff在执行 helm init --service-account tiller 命令时安装的Pod会一直卡在 ImagePullBackOff 阶段，这是因为Triller的镜像默认是从 gcr.io 镜像仓库中拉取的，而该镜像地址在国内是无法访问的。 123456789Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 68s default-scheduler Successfully assigned kube-system/tiller-deploy-7f4d76c4b6-xxlng to k3s-agent Warning Failed 26s (x2 over 52s) kubelet, k3s-agent Failed to pull image &quot;gcr.io/kubernetes-helm/tiller:v2.14.3&quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers) Warning Failed 26s (x2 over 52s) kubelet, k3s-agent Error: ErrImagePull Normal BackOff 14s (x2 over 52s) kubelet, k3s-agent Back-off pulling image &quot;gcr.io/kubernetes-helm/tiller:v2.14.3&quot; Warning Failed 14s (x2 over 52s) kubelet, k3s-agent Error: ImagePullBackOff Normal Pulling 0s (x3 over 67s) kubelet, k3s-agent Pulling image &quot;gcr.io/kubernetes-helm/tiller:v2.14.3&quot; 可以通过 --tiller-image 参数来指定安装的镜像仓库地址。 12helm init --service-account tiller \--tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:&lt;tag&gt; 其中，Tiller 镜像版本与 helm 版本相同。 在执行该命令之前，可通过 kubectl delete deploy tiller-deploy -n kube-system 命令来删除上一步命令安装失败的Pod。 参考自 3. Initialize Helm (Install Tiller) helm 报错 connection refused123➜ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125;Error: Get http://localhost:8080/api/v1/namespaces/kube-system/pods?labelSelector=app%3Dhelm%2Cname%3Dtiller: dial tcp [::1]:8080: connect: connection refused 如果你直接在k3s的master节点上执行 helm version 命令的话，很容易会出现上面的错误信息。 这是因为helm默认会从 ~/.kube/config 中来载入kubernetes/k3s的集群信息，而k3s的默认配置文件是 /etc/rancher/k3s/k3s.yaml ，在k3s的master节点上的 ~/.kube 目录下并不存在一个 config 文件，也就导致了helm连接不上k3s集群，而获取不到集群的信息。 要解决这个问题，可以通过指定配置文件的方式，如下：123➜ KUBECONFIG=/etc/rancher/k3s/k3s.yaml helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125;Error: could not find tiller 即在 helm version 命令前指定k3s集群配置文件的地址 KUBECONFIG=/etc/rancher/k3s/k3s.yaml，这样就能正常执行了。 当然，如果觉得每条helm命令都加一个 KUBECONFIG 参数太麻烦，可以通过如下方式解决：12345➜ export KUBECONFIG=/etc/rancher/k3s/k3s.yaml➜ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.14.3&quot;, GitCommit:&quot;0e7f3b6637f7af8fcfddb3d2941fcc7cbebb0085&quot;, GitTreeState:&quot;clean&quot;&#125;Error: could not find tiller 如果觉得这种方法也很麻烦，那么可以将k3s的配置文件复制一份到 ~/.kube/config 下：1cp /etc/rancher/k3s/k3s.yaml ~/.kube/config 相关参考 3. Initialize Helm (Install Tiller) Helm helm/helm: The Kubernetes Package Manager]]></content>
      <categories>
        <category>轻量级云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>K3s</tag>
        <tag>Helm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级Kubernetes发行版k3s之配置问题汇总]]></title>
    <url>%2F2019%2F08%2F31%2Flightweight-kubernetes-release-k3s-issues%2F</url>
    <content type="text"><![CDATA[虽然上篇文章中提到k3s安装非常简单，但由于现在k3s的版本还是 v0.8.1，可能会出现不稳定的情况以及一些配置上的问题，还不推荐在生产环境中正式使用。 下面我总结了一些我在配置k3s集群过程中遇到的一些问题及解决方法。 关于容器引擎containerdk3s默认推荐使用 Containerd 作为容器引擎。通过用containderd替换Docker，K3s能够显著减少运行时占用空间，删除了libnetwork、swarm、Docker存储驱动程序和其他插件等功能。 k3s服务在安装时也默认设置了containerd容器管理工具 crictl。 关于containerd的详细内容，这里暂且不细说，后续我会单独用一篇文章来介绍。 dockerk3s 也支持使用docker来作为容器引擎。只需要在服务启动时指定参数 --docker 即可。 因为我平时习惯了使用docker，所以我就选择了docker作为默认的容器引擎。启动后如下，会在 CONTAINER-RUNTIME 一栏显示所用的容器引擎信息： 1234# kubectl get nodes -o wideNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEk3s-agent Ready worker 6m2s v1.14.6-k3s.1 192.168.5.18 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-957.10.1.el7.x86_64 docker://18.6.3k3s-master Ready master 4m38s v1.14.6-k3s.1 192.168.5.17 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-957.10.1.el7.x86_64 docker://18.6.3 docker版本我安装的k3s版本为 v0.8.1，对应的kubernetes版本为 v1.14.6。安装的docker版本为 v18.06。 一开始我使用的docker版本为 v18.09，配置k3s的master客户端时服务能正常启动，但当安装agent服务时，添加了 --docker 参数后k3s服务一直无法启动。于是我只好将docker版本从 v18.09 降级到了 v18.06 版本才正常启动。 我去查看了一下Kubernetes支持的docker版本，对于Kubernetes v1.14 版本支持的docker版本为 1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09。 至于我的 v18.09 为什么没有正常启动，后来推测可能是两方面的问题： k3s不稳定（可以尝试多次重启服务或者重启系统解决） 系统环境影响（可以通过重新搭建系统环境来解决） pause镜像Kubernetes集群在运行时需要获取一个基础镜像pause：k8s.gcr.io/pause:3.1，k3s中也不例外。但由于pause镜像的仓库为 k8s.gcr.io，在国内是无法正常拉取的，也就导致了你在创建Pod时一直处于 ImagePullBackOff 状态。 一般我们可以通过折中的方法来获取该镜像。 使用docker作为容器引擎时这种方法是相对来说比较简单的，只需要在k3s服务命令中添加 --docker 就可以指定k3s使用Docker容器引擎。pause镜像的获取可以按照之前搭建Kubernetes集群环境时 Kubernetes入门 – 一使用kubeadm部署Kubernetes集群v1.14.1 | IT范儿 中的步骤来操作。 我这里使用的是 azure中国 的镜像地址：123$ docker pull gcr.azk8s.cn/google_containers/pause:3.1$ docker tag gcr.azk8s.cn/google_containers/pause:3.1 k8s.gcr.io/pause:3.1$ docker rmi gcr.azk8s.cn/google_containers/pause:3.1 使用containerd作为容器引擎时k3s中默认使用containerd作为容器引擎，在运行Pod时也会先去获取pause镜像。 这里我总结了两种方法来为containerd提前下载pause镜像。 通过docker拉取我们可以通过docker把pause镜像拉取下来，然后转换成containerd可以使用的pause镜像： 1234567891011# 通过docker拉取镜像$ docker pull gcr.azk8s.cn/google_containers/pause:3.1# 通过tag重命名pause镜像$ docker tag gcr.azk8s.cn/google_containers/pause:3.1 k8s.gcr.io/pause:3.1# 保存镜像为tar包$ docker save k8s.gcr.io/pause:3.1 -o pause.tar# 让containerd加载该tar包$ ctr cri load pause.tar 通过air-gap安装k3s支持预加载containerd映像，方法是在启动之前将它们放在代理的images目录中。 先从 Releases · rancher/k3s 下载对应的 k3s-airgap-images-xxx.tar 安装包。 然后通过如下命令操作：12sudo mkdir -p /var/lib/rancher/k3s/agent/images/sudo cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/ 详见官方文档：Running K3S 启用端口一般情况下，在局域网内测试k3s集群为了测试方便都会选择关闭防火墙 systemctl stop firewalld &amp;&amp; systemctl disable firewalld 。但如果是在正式的生产环境中则需要启用防火墙并打开相关的端口。 按照k3s文档上的说明，需要启用 6443 和 8472 端口。 但是，不排除还有一些其他的潜在端口。这里我只找到了一篇相关的issues：k3s service cannot start in RHEL with firewall enabled · Issue #401 · rancher/k3s 扩展：Configuration Info Open Ports / Network Security 卸载k3s如果是通过 install.sh 脚本安装的k3s，默认会在服务中安装一个卸载的脚本文件： /usr/local/bin/k3s-uninstall.sh (or as k3s-agent-uninstall.sh). Running in Docker除了通过二进制的方式来部署k3s，还可以使用更简单的Docker容器方式来部署。k3s官方也给出了两种方法来通过Docker容器安装k3s。 docker-compose可以直接从k3s的github仓库中获取该 docker-compose.yaml 文件，或执行：1$ wget https://raw.githubusercontent.com/rancher/k3s/master/docker-compose.yml k3dk3d 可以理解成 k3s in docker ，是一个设计用于在Docker中轻松运行k3s的实用程序。 详见：rancher/k3d: Little helper to run Rancher Lab’s k3s in Docker 异常处理kube config permissions在通过非root账户配置好k3s-master 服务后，我想着通过 kubectl get node 查看一下节点的运行状态，结果却报出了如下的错误： 123➜ ~ k3s kubectl get nodeWARN[2019-08-30T12:14:50.841714144+08:00] Unable to read /etc/rancher/k3s/k3s.yaml, please start server with --write-kubeconfig-mode to modify kube config permissionserror: Error loading config file &quot;/etc/rancher/k3s/k3s.yaml&quot;: open /etc/rancher/k3s/k3s.yaml: permission denied 错误信息是：在加载配置文件 /etc/rancher/k3s/k3s.yaml 时没有权限。 让人欣喜的是在错误信息也给出了解决方法，通过设置 --write-kubeconfig-mode 参数来赋予权限。 只需在 k3s.service 中将 ExecStart 的值 ExecStart=/usr/local/bin/k3s server --docker 改成：1/usr/local/bin/k3s server --docker --write-kubeconfig-mode 644 之后，重启服务即可： 12➜ ~ sudo systemctl daemon-reload➜ ~ sudo systemctl restart k3s 具体关于这个问题的讨论可以参考：/etc/rancher/k3s/k3s.yaml is world readable · Issue #389 · rancher/k3s 这个issue讨论。 certificate has expired在安装 k3s-agent 过程中，发现启动服务后日志中一直报如下的错误：128月 30 17:07:00 node1 k3s[941]: time=&quot;2019-08-30T17:07:00.542226362+08:00&quot; level=error msg=&quot;server https://127.0.0.1:35556/cacerts is not trusted: Get https://127.0.0.1:35556/cacerts: x509: certificate has expired or is not yet valid&quot;8月 30 17:07:02 node1 k3s[941]: time=&quot;2019-08-30T17:07:02.547358146+08:00&quot; level=error msg=&quot;server https://127.0.0.1:35556/cacerts is not trusted: Get https://127.0.0.1:35556/cacerts: x509: certificate has expired or is not yet valid&quot; 看错误信息 x509: certificate has expired or is not yet valid&quot; 提示是证书过期了，但刚一安装证书怎么就过期了呢？多次重启服务后发现一直报这个错误。 后来才发现原来是master服务器和agent服务器两个主机的系统时间不一致导致的，我将agent服务器重启后就好了。]]></content>
      <categories>
        <category>轻量级云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>K3s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级Kubernetes发行版k3s之介绍]]></title>
    <url>%2F2019%2F08%2F30%2Flightweight-kubernetes-release-k3s-introduce%2F</url>
    <content type="text"><![CDATA[k3s 是一个轻量级 Kubernetes，它易于安装，二进制文件包小于 40 mb，只需要 512MB RAM 即可运行。 k3s介绍k3s 旨在成为完全兼容的 Kubernetes 发行版，相比 k8s 主要更改如下： 旧的、Alpha 版本的、非默认功能都已经删除。 删除了大多数内部云提供商和存储插件，可以用插件替换。 新增 SQLite3 作为默认存储机制，etcd3 仍然有效，但是不再是默认项。 封装在简单的启动器中，可以处理大量 LTS 复杂性和选项。 最小化到没有操作系统依赖，只需要一个内核和 cgroup 挂载。 K3s支持x86_64、ARM64和ARMv7架构，使K3s得以更加灵活地跨任何边缘基础架构工作。 使用场景： 边缘计算 与应用程序绑定使用 嵌入式设备 CI环境 k3s工作原理： k3s安装k3s的安装非常简单，可以直接按照官方给出的教程来操作。 通过 install.sh 脚本来安装，执行如下命令： 1curl -sfL https://get.k3s.io | sh - k3s的配置文件默认存储在 /etc/rancher/k3s/k3s.yaml 下。安装脚本默认会安装相关的工具，比如 kubectl 和卸载服务相关的 k3s-unstall.sh 脚本等。 配置k3s集群的token文件存在于server节点的 /var/lib/rancher/k3s/server/node-token 文件中。可以通过如下命令来安装worker节点： 1curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=XXX sh - 经测试，默认情况下安装的k3s服务为master节点，服务名称为 k3s.service ，在加上 K3S_URL 和 K3S_TOKEN 两个参数后，安装的服务名称为 k3s-agent.service ，看来官方也是直接做了区分。 当然，你也可以直接通过一条命令 curl -sfL https://get.k3s.io | sh - 来安装所有的master节点和agent节点，这样服务名称都会为 k3s.service 。然后在通过修改命令参数的方式来指定是master节点还是agent节点，以及一些其他参数。 总而言之，k3s的安装相比于k8s来说，还是非常简单的。 相关参考 rancher/k3s: Lightweight Kubernetes. 5 less than k8s. Quick-Start 这篇文章多少有点水，当然，硬货还在后面。。。]]></content>
      <categories>
        <category>轻量级云原生</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>K3s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo遇到的一个关于nodejs版本的问题]]></title>
    <url>%2F2019%2F08%2F24%2Fhexo-of-nodejs-version%2F</url>
    <content type="text"><![CDATA[自从升级了nodejs的版本到 v10.15.3 之后，每次执行 hexo 的命令都会报出一大串的错误信息。开始因为这个错误并不影响后续的命令执行，所以也就一直没有解决。但是每次看到这个错误就觉得头疼，所以花了一点时间研究了一下，没想到。。。问题的原因还真挺简单的。 问题现象1234567891011121314151617181920212223➜ hexo new &quot;ssh-faster&quot;Error: The module &apos;/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/build/Release/DTraceProviderBindings.node&apos;was compiled against a different Node.js version usingNODE_MODULE_VERSION 57. This version of Node.js requiresNODE_MODULE_VERSION 64. Please try re-compiling or re-installingthe module (for instance, using `npm rebuild` or `npm install`). at Object.Module._extensions..node (internal/modules/cjs/loader.js:730:18) at Module.load (internal/modules/cjs/loader.js:600:32) at tryModuleLoad (internal/modules/cjs/loader.js:539:12) at Function.Module._load (internal/modules/cjs/loader.js:531:3) at Module.require (internal/modules/cjs/loader.js:637:17) at require (internal/modules/cjs/helpers.js:22:18) at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/dtrace-provider.js:18:23) at Module._compile (internal/modules/cjs/loader.js:701:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:712:10) at Module.load (internal/modules/cjs/loader.js:600:32) at tryModuleLoad (internal/modules/cjs/loader.js:539:12) at Function.Module._load (internal/modules/cjs/loader.js:531:3) at Module.require (internal/modules/cjs/loader.js:637:17) at require (internal/modules/cjs/helpers.js:22:18) at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/hexo-cli/node_modules/bunyan/lib/bunyan.js:79:18) at Module._compile (internal/modules/cjs/loader.js:701:30)INFO Created: ~/Project/Leafney.github.io/source/_posts/ssh-faster.md 看上面的错误信息就可简单的知道这是关于 NODE_MODULE_VERSION 版本不一致的问题导致的。 解决先查看一下当前node及npm版本：12345➜ node -vv10.15.3➜ npm -v6.4.1 经查询，这个问题的原因就是 hexo-cli 的版本太低导致的。 执行命令：1➜ sudo npm i -g hexo-cli 可以看到 hexo-cli的版本进行了更新：1&gt; New minor version of npm available! 6.4.1 → 6.11.2 So，一条命令解决问题。 参考：解决NODEJS更新到8.0+后HEXO命令行报错 | 小明]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中加速SSH连接]]></title>
    <url>%2F2019%2F08%2F24%2Fssh-faster%2F</url>
    <content type="text"><![CDATA[服务器端修改配置文件 /etc/ssh/sshd_config，将以下两项 取消注释 且值均设置为 no: 1234# vim /etc/ssh/sshd_configUseDNS noGSSAPIAuthentication no UseDNS 会对客户端进行DNS反向解析，然后在比对正向解析的结果查看是否一致。 GSSAPIAuthentication 大多数情况下使用密码验证或者秘钥验证所以关闭GSSAPI验证即可 之后，重启sshd守护进程：1# systemctl restart sshd]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS应用软件网站推荐]]></title>
    <url>%2F2019%2F07%2F14%2Fmac-software-website%2F</url>
    <content type="text"><![CDATA[网站推荐 精品MAC应用分享 麦氪派(WaitsUn.com | 爱情守望者)_精品Mac应用分享 MacEnjoy-macOS破解资源分享站 ⭐️ 苹果/mac破解软件下载-常用必备软件推荐-MacSKY苹果软件园 修复TNT破解的Mac软件退出问题7月12日，Apple删除了TNT的证书，更新了T2芯片的安全模式。因此很多破解的应用程序在7月12日之后打开会崩溃。例如，CleanMyMac X，BetterZip，1Password，One Switch 等，目前的解决方案是需要自己手动签名，能解决大部份软件崩溃问题。 安装Xcode可以在App Store中下载安装，并且至少运行一次。 安装Command Line Tools 工具打开终端工具输入如下命令： 1xcode-select install 弹出后选择继续安装。 软件签名安装完成后可以利用 codesign 进行签名，打开终端输入如下命令： 1codesign --force --deep --sign - /Applications/name.app 注意后面的文件路径，你可以打开 访达(Finder) 找到 应用程序，找到要签名的软件，输入命令 codesign --force --deep --sign - 后把需要签名的软件拖拽到终端然后回车即可。 一键签署工具如果嫌以上的操作太复杂，也可以使用一键签署工具：CodeSigner For Mac打开时崩溃签署工具 V0.9.3 beta 4 - 特别 相关参考 修复TNT破解的Mac软件退出问题 – 黑苹果乐园 重要提醒：7月12号以后打开软件提示崩溃问题解决办法 - MacSKY苹果软件园 Mac 软件安装问题解决 - 支持 注意：推荐网站中涉及到的资源建议仅供学习和研究使用，请支持并购买正版软件。]]></content>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Kubernetes上执行Drone CI/CD]]></title>
    <url>%2F2019%2F07%2F11%2Frun-drone-cicd-on-kubernetes%2F</url>
    <content type="text"><![CDATA[介绍之前曾使用 docker run 和 docker-compose 的方式部署过Drone服务，方法比较简单。最近一段时间一直在学习Kubernetes，正好研究一下如何在Kubernetes上部署Drone实现CI/CD。 相比之前在Docker下部署的Drone server-agent 模式，在Kubernetes上运行Drone可以简化我们的部署，其中最大的改进就是不再需要单独的去维护 agent 服务了，Drone会创建一个Kubernetes Job来执行相应的Pipeline。 这个Kubernetes Job会生成一个Pipeline Controller容器。来负责编排管道步骤、收集结果、并向Drone服务器回调通知。 不过，目前在Kubernetes上运行Drone服务仍然是实验性的，官方并不推荐在正式的生产环境中来部署。 实践注意事项我通过 Deployment 在VBox虚拟机上的Kubernetes环境中分别部署Gitea和Drone服务。其中有几点需要注意： 为了便于测试，指定 Service 使用 type: NodePort 来绑定主机端口； 由于使用本地环境部署的原因，并没有使用 traefik + host 的方式来设置虚拟域名，关键是在本地环境下gitea的webhook无法通过虚拟域名来执行回调而触发Drone的Pipeline，所以只能使用IP方式； 先部署Gitea服务，其中的 nodePort 不需要手动指定，使用随机端口号即可； 部署Drone服务时，需要手动指定 nodePort 一项，因为在设置环境变量 DRONE_SERVER_HOST 时需要该端口； 执行gitea安装配置页面，以下几项需要注意： 创建一个简单的 .drone.yml 文件：12345678910111213kind: pipelinename: defaultclone: disable: truesteps:- name: test_drone image: alpine:3.9 commands: - echo &quot;show hello world by drone&quot; - echo $(pwd) - sleep 10 当执行git提交后，Drone容器中的部分日志记录如下： 12345&#123;&quot;commit&quot;:&quot;6ef0d3355007823ab03c6c1a8ca7ba41bb7c304e&quot;,&quot;event&quot;:&quot;push&quot;,&quot;level&quot;:&quot;debug&quot;,&quot;msg&quot;:&quot;webhook parsed&quot;,&quot;name&quot;:&quot;hello&quot;,&quot;namespace&quot;:&quot;abc&quot;,&quot;time&quot;:&quot;2019-07-10T13:08:24Z&quot;&#125;&#123;&quot;commit&quot;:&quot;6ef0d3355007823ab03c6c1a8ca7ba41bb7c304e&quot;,&quot;event&quot;:&quot;push&quot;,&quot;level&quot;:&quot;debug&quot;,&quot;msg&quot;:&quot;trigger: received&quot;,&quot;ref&quot;:&quot;refs/heads/master&quot;,&quot;repo&quot;:&quot;abc/hello&quot;,&quot;time&quot;:&quot;2019-07-10T13:08:24Z&quot;&#125;&#123;&quot;build-id&quot;:2,&quot;level&quot;:&quot;debug&quot;,&quot;msg&quot;:&quot;kubernetes: creating job&quot;,&quot;repo-id&quot;:1,&quot;stage-id&quot;:2,&quot;stage-name&quot;:&quot;default&quot;,&quot;stage-number&quot;:1,&quot;time&quot;:&quot;2019-07-10T13:08:24Z&quot;&#125;&#123;&quot;build-id&quot;:2,&quot;level&quot;:&quot;debug&quot;,&quot;msg&quot;:&quot;kubernetes: successfully created job&quot;,&quot;repo-id&quot;:1,&quot;stage-id&quot;:2,&quot;stage-name&quot;:&quot;default&quot;,&quot;stage-number&quot;:1,&quot;time&quot;:&quot;2019-07-10T13:08:25Z&quot;&#125;&#123;&quot;fields.time&quot;:&quot;2019-07-10T13:08:25Z&quot;,&quot;latency&quot;:351766213,&quot;level&quot;:&quot;debug&quot;,&quot;method&quot;:&quot;POST&quot;,&quot;msg&quot;:&quot;&quot;,&quot;remote&quot;:&quot;10.244.0.1:50176&quot;,&quot;request&quot;:&quot;/hook?secret=Gfz8OUgBscs2wySUiQZsTRdqDCqK6GBc&quot;,&quot;request-id&quot;:&quot;1Np3FAx2JZldpFOFBkNsnn2jgD1&quot;,&quot;time&quot;:&quot;2019-07-10T13:08:25Z&quot;&#125; 可以看到其中关键的两步： &quot;build-id&quot;:2 -- &quot;msg&quot;:&quot;kubernetes: creating job&quot; &quot;build-id&quot;:2 -- &quot;msg&quot;:&quot;kubernetes: successfully created job&quot; 查看自动创建的Job：123$ kubectl -n cicd get jobNAME COMPLETIONS DURATION AGEdrone-job-2-cnbmdfdlov2wqkcsg 1/1 43s 56s 查看相应的Pod:1234$ kubectl -n cicd get podsNAME READY STATUS RESTARTS AGEdrone-deploy-77fb9ff86d-w8q9s 1/1 Running 0 17mdrone-job-2-cnbmdfdlov2wqkcsg-c8m56 0/1 Completed 0 5m37s 查看Drone UI中的构建情况： 分析查看该Pod的详细描述：12345678910111213141516171819202122➜ kubectl -n cicd describe pods drone-job-2-cnbmdfdlov2wqkcsg-c8m56Name: drone-job-2-cnbmdfdlov2wqkcsg-c8m56Namespace: cicd......Status: SucceededIP: 10.244.1.121Controlled By: Job/drone-job-2-cnbmdfdlov2wqkcsgContainers: drone-controller: Container ID: docker://8a2e413b84fe6d9dd361cc17b82881f888ff7376605c83bea0714cd5e439523c Image: drone/controller:1.2.1 Image ID: docker-pullable://drone/controller@sha256:3a57ab277657525b1cfe464d8f38501a4454a5db3d20ca7e56052330df2ec523 Port: &lt;none&gt; Host Port: &lt;none&gt; State: Terminated Reason: Completed Exit Code: 0 Started: Wed, 10 Jul 2019 02:14:44 +0800 Finished: Wed, 10 Jul 2019 02:14:57 +0800...... 可以看到在该Pod内部自动创建了一个基于 drone/controller 镜像的容器来执行Pipeline。 自动移除Jobs默认情况下，执行完成后的Kubernetes Jobs不会自动从系统中清除，主要是为了便于对Pipeline执行过程中报错的故障排查。 如果需要实现自动清理，这里我找到了两种方式，可以深入的去了解一下： 设置Kubernetes的 TTLAfterFinished 特性，这也是Drone官方给出的解决方法 通过第三方的工具来实现：lwolf/kube-cleanup-operator: Kubernetes Operator to automatically delete completed Jobs and their Pods 注意事项需要为Drone创建相应的ServiceAccount权限。否则会报如下错误：1jobs.batch is forbidden: User &quot;system:serviceaccount:default:default&quot; cannot create resource &quot;jobs&quot; in API group &quot;batch&quot; in the namespace &quot;default&quot; 配置流程则直接按照Drone文档中的方法操作即可。 相关参考 gitea-Kubernetes Drone CI/CD Goes Kubernetes-Native]]></content>
      <categories>
        <category>CI/CD实践</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Drone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下从命令行快速打开VSCode]]></title>
    <url>%2F2019%2F07%2F03%2Flaunching-vscode-from-command-line%2F</url>
    <content type="text"><![CDATA[设置打开 VS Code 通过快捷键 Command + Shift + P 调出命令面板并输入 shell command ，选择 Shell Command: Install &#39;code&#39; command in PATH 一项即可。 重启终端窗口，并输入 code . 即可在当前目录下打开VS Code了。 也可以通过如下命令在VS Code中打开指定的文件：1$ code ~/Project/Leafney.github.io/pubblog/000Hexo模板.md 相关参考 Setting up Visual Studio Code Running Visual Studio Code on macOS]]></content>
      <categories>
        <category>工具技巧</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整理常用国内镜像软件源]]></title>
    <url>%2F2019%2F07%2F03%2Fmirror-software-sources%2F</url>
    <content type="text"><![CDATA[列表 Alpine Ubuntu/Debian CentOS Python/Pip Golang Docker Kubernetes 没有涉及到的可以在评论处补充完善。 Alpine设置多个环境注意：第一行中使用的是 &gt; 符号，这样会把原有的默认仓库源信息给覆盖掉，如果需要保留，请更换成 &gt;&gt; 。 123echo &quot;https://mirrors.aliyun.com/alpine/v3.9/main/&quot; &gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/v3.9/community/&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/edge/testing/&quot; &gt;&gt; /etc/apk/repositories 单独设置注意：根据所使用的alpine系统版本，更换其中的版本号。 123$ echo &quot;http://mirrors.ustc.edu.cn/alpine/v3.9/main/&quot; &gt;&gt; /etc/apk/repositories$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.4/main&quot; &gt;&gt; /etc/apk/repositories Ubuntu/Debian备份原始文件1$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 软件源编辑器打开：1/etc/apt/sources.list 替换默认的1http://archive.ubuntu.com/ 为1mirrors.aliyun.com 阿里云 http://mirrors.aliyun.com/ubuntu/ 网易163 http://mirrors.163.com/ubuntu/ 开源社：12345678910deb http://azure.archive.ubuntu.com/ubuntu/ bionic main restricted universe multiversedeb http://azure.archive.ubuntu.com/ubuntu/ bionic-security main restricted universe multiversedeb http://azure.archive.ubuntu.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://azure.archive.ubuntu.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://azure.archive.ubuntu.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://azure.archive.ubuntu.com/ubuntu/ bionic main restricted universe multiversedeb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-backports main restricted universe multiverse 待完善。 Debian网易163 http://mirrors.163.com/debian/ 待完善。 CentOS待完善。 Python/Pip选择国内镜像源从 PyPI Mirror Status 可以找到可用的国内PypI镜像源，这里我选择豆瓣的源地址 https://pypi.douban.com/ 。 常用的国内镜像源 pypi.douban.com 豆瓣源，北京 pypi.tuna.tsinghua.edu.cn 清华源，北京 mirrors.aliyun.com/pypi 阿里源，杭州 临时修改在安装软件时通过 -i 指令指定要使用的镜像源： easy_install：1$ easy_install -i https://&lt;mirror&gt;/simple &lt;package&gt; pip：1$ pip install -i https://&lt;mirror&gt;/simple &lt;package&gt; 如：pip install -i https://pypi.douban.com/simple ansible 全局更改通过在配置文件中指定来实现全局更改。 easy_install 更改全局镜像源在Unix系统下，配置文件位于 ~/.pydistutils.cfg 在Windows系统下，配置文件位于 ？？？ (待完善) 如果文件不存在，新建一个就可以。 然后在相应的配置文件中写入如下内容(这里使用豆瓣的镜像源为例)： 12[easy_install]index_url = https://pypi.douban.com/simple 注意： 源路径要包含 /simple 部分。 pip 更改全局镜像源在Unix和Mac OS系统下，对应的配置文件应该位于 $HOME/.pip/pip.conf 。$HOME 为 ~ 根目录。即 ~/.pip/pip.conf 。 在Windows系统下，配置文件应位于 %HOME%\pip\pip.ini 。%HOME% 为 C:\Users\&lt;your_name&gt;\ 目录，即 C:\Users\&lt;your_name&gt;\pip\pip.ini 。 如果文件不存在，新建一个就可以。 然后在相应的配置文件中写入如下内容(这里使用豆瓣的镜像源为例)： 12[global]index-url = https://pypi.douban.com/simple 升级pip1$ pip install --upgrade pip Golang通过 go module 管理的项目设置代理： 123export GO111MODULE=onexport GOPROXY=https://athens.azurefd.net Docker详见：配置Docker镜像加速器2019 | IT范儿 Kubernetes阿里云Debian / Ubuntu1234567apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF apt-get updateapt-get install -y kubelet kubeadm kubectl CentOS / RHEL / Fedora123456789101112cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFsetenforce 0yum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet 阿里巴巴开源镜像站 Azure China使用GCR Proxy Cache从gcr.io下载镜像:1docker pull gcr.azk8s.cn/google_containers/&lt;imagename&gt;:&lt;version&gt; GCR Proxy Cache 详见：Kubernetes入门 – 一使用kubeadm部署Kubernetes集群v1.14.1 | IT范儿]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>Docker</tag>
        <tag>Python</tag>
        <tag>Alpine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go test 禁用缓存]]></title>
    <url>%2F2019%2F06%2F27%2Fgo-test-disable-cached%2F</url>
    <content type="text"><![CDATA[每当执行 go test 时，如果功能代码和测试代码没有变动，则在下一次执行时，会直接读取缓存中的测试结果，并通过 (cached) 进行标记。 要禁用测试缓存，可以通过 -count=1 标志来实现。 如下示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:45:16]➜ go test -v ./... ? go_demo [no test files]=== RUN TestCreateUnixMillis--- PASS: TestCreateUnixMillis (0.00s) utils_test.go:7: 1561614325740PASSok go_demo/utils 0.006s# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:45:32]➜ go test -v ./...? go_demo [no test files]=== RUN TestCreateUnixMillis--- PASS: TestCreateUnixMillis (0.00s) utils_test.go:7: 1561614325740PASSok go_demo/utils (cached)# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:45:38]➜ go test -v ./...? go_demo [no test files]=== RUN TestCreateUnixMillis--- PASS: TestCreateUnixMillis (0.00s) utils_test.go:7: 1561614325740PASSok go_demo/utils (cached)# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:45:59]➜ go test -v ./... -count=1? go_demo [no test files]=== RUN TestCreateUnixMillis--- PASS: TestCreateUnixMillis (0.00s) utils_test.go:7: 1561614494115PASSok go_demo/utils 0.006s# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:48:14]➜ go test -v ./... -count=1? go_demo [no test files]=== RUN TestCreateUnixMillis--- PASS: TestCreateUnixMillis (0.00s) utils_test.go:7: 1561614508408PASSok go_demo/utils 0.006s# ~/test/hello-drone/go_demo [master ✗ (fe95bec)] [13:48:32]➜ 关于 -count=1 的解释，可以通过命令 go help testflag 来查看： 12345When &apos;go test&apos; runs in package list mode, &apos;go test&apos; caches successfulpackage test results to avoid unnecessary repeated running of tests. Todisable test caching, use any test flag or argument other than thecacheable flags. The idiomatic way to disable test caching explicitlyis to use -count=1. 总结在 Go 1.11 之前，通过 GOCACHE=off 的方式来禁用测试缓存：GOCACHE=off go test ./... 在 Go 1.11 之后，通过 -count=1 的方式来禁用测试缓存：go test -count=1 ./... 相关参考 cmd/go: how to disable (run test) Cached · Issue #24573 · golang/go testing - Force retesting or disable test caching - Stack Overflow]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控磁盘空间使用率并发送钉钉提醒]]></title>
    <url>%2F2019%2F06%2F18%2Fdisk-monitor-send-dingtalk%2F</url>
    <content type="text"><![CDATA[今天在使用测试服务器时，发现服务器被好多测试的日志文件占用掉了十几个G的磁盘空间，通过 du -ah --max-depth=1 命令检查删除后，突发奇想的觉得不如顺手写个shell脚本来定时提醒自己磁盘空间的占用率。和 Prometheus 这种大型的监控系统比起来，一个shell脚本可谓是非常的 轻量级 了。 说干就干，项目源码已放到 Github 上，猛戳 leafney/disk-monitor-dingtalk: disk monitor 监控磁盘空间使用率并发送钉钉提醒 查看。 说明脚本比较简单，一看就明白了。通过 df 命令来查看磁盘各个分区的占用率并设置阈值，当到达指定阈值时就发送钉钉消息进行提醒。 设置了四个可选参数： -t – 钉钉的token，必填项 -p – 磁盘占用率百分比阈值，默认为80% -h – 默认情况下获取服务器主机的 hostname ，可以自定义一个服务器名称 -n – 当磁盘的占用率在正常阈值内是否也发送提醒，默认是不发送 使用首先，为shell脚本赋予可执行权限： 1$ chmod +x ./disk-monitor.sh 然后，通过 crontab 来定时执行。我设置的是每天的9点检查一次： 12$ crontab -l0 9 * * * /home/tiger/disk-monitor.sh -t fbbdf72e581f3bcc9469d49708857d2fa93a684 &gt; /dev/null 2&gt;&amp;1 &amp; 效果相应的效果如下： 资料 crontab 定时任务 — Linux Tools Quick Tutorial]]></content>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Docker镜像加速器2019]]></title>
    <url>%2F2019%2F05%2F29%2Fsetting-docker-mirror-2019%2F</url>
    <content type="text"><![CDATA[朋友提醒博客中的一篇设置Docker镜像加速器的文章 配置Docker镜像加速器 | IT范儿 中介绍的方法太过时了，看过之后才发现那篇文章是2016年的时候写的。所以赶紧更新一下。 废话不多说，直接上干货。 安装／升级Docker客户端推荐安装 1.10.0 以上版本的Docker客户端，参考Docker官方文档 About Docker CE | Docker Documentation 或我的文章 Ubuntu16.04下安装Docker-CE社区版 | IT范儿 阿里云镜像加速器打开 阿里云控制台 – 左侧导航菜单 产品与服务 – 弹性计算 – 容器镜像服务 – 左侧导航菜单 镜像中心 – 镜像加速器 。可以看到 “您的加速器地址” 即 https://xxxxxxx.mirror.aliyuncs.com 。 或者直接打开 镜像加速器页面 。 注意，需要登录阿里云账号 配置镜像加速器这里还是以 Linux 系统为例，其他系统可直接参考上面加速器页面中的配置方法。 针对Docker客户端版本大于 1.10.0 的用户 您可以通过修改daemon配置文件 /etc/docker/daemon.json 来使用加速器12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxxxx.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 注意将其中的 xxxxxxx 修改为自己阿里云账户的给定地址。 DaoCload镜像加速器访问DaoCloud官方镜像页面 DaoCloud – 企业级云计算领域的创新领导者 。 DaoCloud的镜像加速地址，不需要注册就可以使用 配置镜像加速器Linux1curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io 然后重启docker服务： 1sudo systemctl restart docker macOSDocker For Mac 右键点击桌面顶栏的 docker 图标，选择 Preferences ，在 Daemon 标签（Docker 17.03 之前版本为 Advanced 标签）下的 Registry mirrors 列表中加入下面的镜像地址:1http://f1361db2.m.daocloud.io 点击 Apply &amp; Restart 按钮使设置生效。 WindowsDocker For Windows 在桌面右下角状态栏中右键 docker 图标，修改在 Docker Daemon 标签页中的 json ，把下面的地址:1http://f1361db2.m.daocloud.io 加到” registry-mirrors”的数组里。点击 Apply 。 以上两种方法，看自己的需求任选其一配置。]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes入门 -- 二优化与进阶]]></title>
    <url>%2F2019%2F05%2F17%2Fkubernetes-introduction-for-optimization-and-advancement%2F</url>
    <content type="text"><![CDATA[上一篇文章介绍了通过kubeadm来配置Kubernetes集群运行环境。那在开始运行我们的项目之前，还是来了解一些能够提高我们执行效率的技巧吧！ kubectl命令自动补全kubectl completion在 Master 节点上，执行 kubectl 命令时，默认是无法使用自动提示的功能。也就导致了我们需要把命令敲完整才可以。kubectl 工具本身就支持自动补全，只不过需要设置一下。 如果你使用的是 bash, 则执行如下命令：12$ echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc$ source ~/.bashrc 如果你使用的是 zsh,则执行如下命令：12$ echo &quot;source &lt;(kubectl completion zsh)&quot; &gt;&gt; ~/.zshrc$ source ~/.zshrc 或者直接编辑 ~/.zshrc 加上 source &lt;(kubectl completion zsh) 一行。 Kube-prompt：交互式 Kubernetes 客户端Kube-prompt 可以让你在命令行下接受与 Kubectl 相同的命令，并且不需要提供 Kubectl 前缀。Kube-prompt 还提了交互式会话下的命令提示、自动补全等功能。 项目地址：c-bata/kube-prompt: An interactive kubernetes client featuring auto-complete. 安装： 直接访问地址 Releases · c-bata/kube-prompt 下载相应文件并解压到本地。然后给 kube-prompt 加上执行权限并移懂到系统目录： 12$ chmod +x kube-prompt$ sudo mv ./kube-prompt /usr/local/bin/kube-prompt 手把手教你打造高效的 Kubernetes 命令行终端 - 运维之美 打造高效的Kubernetes命令行终端 - 宋净超的博客|Cloud Native|云原生布道师 重置 kubernetes init如果需要在 kubeadm init 中加入一些其他的参数配置，那么如何重置刚才的操作呢？ 执行 kubeadm reset 命令即可，该命令会将主机恢复原状： 123[root@master ~]# kubeadm reset[reset] WARNING: changes made to this host by &apos;kubeadm init&apos; or &apos;kubeadm join&apos; will be reverted.[reset] are you sure you want to proceed? [y/N]: 如何从集群中移除Node节点如果需要从集群中移除 node1 这个Node执行下面的命令： 在master节点上执行：12# kubectl drain &lt;node1&gt; --delete-local-data --force --ignore-daemonsets# kubectl delete node &lt;node1&gt; 在 node1 上执行以下几条命令:123456# kubeadm reset# ifconfig cni0 down# ip link delete cni0# ifconfig flannel.1 down# ip link delete flannel.1# rm -rf /var/lib/cni/ 新增Node节点但token过期了默认情况下，Kubernetes生成的token过期时间是24小时。可以通过 kubeadm token list 命令来查看：123➜ ~ kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPSrunell.pdp1y28g1dsayy1o 20h 2019-05-18T08:03:41+08:00 authentication,signing The default bootstrap token generated by &apos;kubeadm init&apos;. system:bootstrappers:kubeadm:default-node-token 在 token 过期之后，如果想要增加新的节点，可以通过如下命令生成新的 token 值：1kubeadm token create 查看密钥的 hash 值：1openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos; 在要新增的节点上执行：1kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; Creating a single master cluster with kubeadm - Kubernetes 在其他电脑上使用kubectl远程管理在管理Kubernetes集群时，我们每次执行kubectl命令都要登录到 Master 节点上操作，有一些麻烦。我们可以直接在自己的开发电脑上通过安装单独的 kubectl 文件来进行远程管理。 安装kubectl以MacOS为例。 二进制方式安装执行如下命令安装最新版本的kubectl:1curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl 要下载特定版本，可通过以下命令查询可用版本：1curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt 然后通过下面的命令下载，以 v1.14.0 版本为例：1curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.14.0/bin/darwin/amd64/kubectl 然后，为其赋予可执行权限并放到系统目录下：123chmod +x ./kubectlsudo mv ./kubectl /usr/local/bin/kubectl 验证是否可用：1kubectl version 不过由于“网络原因”，地址 https://storage.googleapis.com 可能访问不到。也就导致上面的下载命令会一直卡着不动。 我们只能通过去指定的二进制文件下载地址了。 找到 Kubernetes在 GitHub上的仓库地址其中的 CHANGELOG.md 文件：kubernetes/CHANGELOG.md at master · kubernetes/kubernetes 选择指定版本下的 Client Binaries ： 选择指定的文件下载： 下载到本地：1➜ wget https://dl.k8s.io/v1.14.1/kubernetes-client-darwin-amd64.tar.gz 注：https://dl.k8s.io 这个网址可能也访问不到，建议还是使用 FQ 工具后操作。 安装好后进行验证：123➜ kubectl versionClient Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;14&quot;, GitVersion:&quot;v1.14.1&quot;, GitCommit:&quot;b7394102d6ef778017f2ca4046abbaa23b88c290&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-04-08T17:11:31Z&quot;, GoVersion:&quot;go1.12.1&quot;, Compiler:&quot;gc&quot;, Platform:&quot;darwin/amd64&quot;&#125;The connection to the server localhost:8080 was refused - did you specify the right host or port? 正常显示版本信息。 通过homebrew安装如果觉得上面的方式太繁琐，还可以选择使用 Homebrew 来安装：123brew install kubernetes-clikubectl version 其他系统其他系统可用的 kubectl 除了上面的二进制方式，还可以在这个地址中下载（无需FQ）： Index of /kubernetes/ 获取授权文件要连接到Kubernetes集群，还需要指定授权文件。只需将 Master 节点上的授权文件拷贝到本地的默认路径 $HOME/.kube 中。 创建 $HOME/.kube 目录:1➜ mkdir -p $HOME/.kube 执行 scp 命令：1➜ scp root@192.168.5.28:/etc/kubernetes/admin.conf ~/.kube/config 验证能否正常连接到集群：1234➜ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 5h52m v1.14.1node1 Ready &lt;none&gt; 4h48m v1.14.1 因为 kubectl默认的配置文件路径是 $HOME/.kube/config ，所以我们直接设置成这个。如果是其他路径，则需要通过 --kubeconfig 参数指定配置文件：1kubectl --kubeconfig ./admin.conf get nodes 启用自动补全这里，依然需要设置一下 kubectl 命令的自动补全（zsh）：12$ echo &quot;source &lt;(kubectl completion zsh)&quot; &gt;&gt; ~/.zshrc$ source ~/.zshrc Creating a single master cluster with kubeadm - Kubernetes 常用命令查看集群信息命令：kubectl cluster-info12345➜ ~ kubectl cluster-infoKubernetes master is running at https://192.168.5.28:6443KubeDNS is running at https://192.168.5.28:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;. 查看版本信息命令：kubectl version123➜ ~ kubectl versionClient Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;14&quot;, GitVersion:&quot;v1.14.1&quot;, GitCommit:&quot;b7394102d6ef778017f2ca4046abbaa23b88c290&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-04-08T17:11:31Z&quot;, GoVersion:&quot;go1.12.1&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;14&quot;, GitVersion:&quot;v1.14.1&quot;, GitCommit:&quot;b7394102d6ef778017f2ca4046abbaa23b88c290&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-04-08T17:02:58Z&quot;, GoVersion:&quot;go1.12.1&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125; 查看集群所有Pod信息: kubectl get pod --all-namespaces12345678910111213➜ ~ kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-fb8b8dccf-cm28l 1/1 Running 1 3h48mkube-system coredns-fb8b8dccf-lqh8n 1/1 Running 1 3h48mkube-system etcd-master 1/1 Running 1 3h47mkube-system kube-apiserver-master 1/1 Running 1 3h47mkube-system kube-controller-manager-master 1/1 Running 1 3h47mkube-system kube-flannel-ds-amd64-2rzqc 1/1 Running 1 3h16mkube-system kube-flannel-ds-amd64-thg6z 1/1 Running 1 165mkube-system kube-proxy-8x8f6 1/1 Running 1 108mkube-system kube-proxy-k54d5 1/1 Running 1 108mkube-system kube-scheduler-master 1/1 Running 1 3h48m➜ ~ 未完待续。。。]]></content>
      <categories>
        <category>云原生系列</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes入门 -- 一使用kubeadm部署Kubernetes集群v1.14.1]]></title>
    <url>%2F2019%2F05%2F17%2Fkubernetes-introduction-for-install-by-kubeadm%2F</url>
    <content type="text"><![CDATA[上一次通过kubeadm来配置Kubernetes的环境使用的还是 v1.13 的版本，最近看到Kubernetes的稳定版本已经更新到了 v1.14.1 ，所以决定重新安装一次，并把配置过程和遇到的问题同时整理一下。 kubeadm是Kubernetes官方提供的用于快速安装Kubernetes集群的工具，伴随Kubernetes每个版本的发布都会同步更新，kubeadm会对集群配置方面的一些实践做调整，通过实验kubeadm可以学习到Kubernetes官方在集群配置上一些新的最佳实践。 系统信息 master ip : 192.168.5.28 node1 ip : 192.168.5.29 配置均为：2核2G 系统环境配置注意：在 Master 和 Node 节点均操作 切换到 root 权限1$ su - root 更改hostnamemaster123# hostname# hostnamectl set-hostname master# hostname node1123# hostname# hostnamectl set-hostname node1# hostname 修改 hostsmaster编辑 /etc/hosts 文件，在底部新增下面两行，然后重启系统：123456# vim /etc/hosts192.168.5.28 master192.168.5.29 node1reboot 禁用防火墙12# systemctl disable firewalld &amp;&amp; systemctl stop firewalld# systemctl status firewalld 禁用SELinux12345# setenforce 0# vim /etc/selinux/config#SELINUX=enforcingSELINUX=disabled 禁用swap查看当前swap状态：1234# free -m total used free shared buff/cache availableMem: 1466 142 1063 8 260 1151Swap: 3071 0 3071 禁用swap:1# swapoff -a 编辑 /etc/fstab 文件，注释掉带有 swap 的那一行：123# vim /etc/fstab#/dev/mapper/centos-swap swap swap defaults 0 0 查看：1234# free -m total used free shared buff/cache availableMem: 1466 142 1063 8 260 1152Swap: 0 0 0 修改iptables配置创建 /etc/sysctl.d/k8s.conf 文件，加入如下内容：123net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 执行命令使修改生效:12# modprobe br_netfilter# sysctl -p /etc/sysctl.d/k8s.conf kube-proxy开启ipvs的前置条件由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块：12345ip_vsip_vs_rrip_vs_wrrip_vs_shnf_conntrack_ipv4 执行以下脚本来配置： 1234567891011cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 保证 ipset 已安装，同时要管理ipvs，需要安装ipvsadm:1# yum install ipset ipvsadm 安装docker省略。 修改docker cgroup driver为systemd根据文档CRI installation中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为docker的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里修改各个节点上docker的cgroup driver为systemd。 查看docer的cgroup:12# docker info |grep -i cgroupCgroup Driver: cgroupfs 创建或修改 /etc/docker/daemon.json123&#123; &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125; 重启docker:1# systemctl restart docker 再次查看cgroup:12# docker info |grep -i cgroupCgroup Driver: systemd 使用kubeadm部署Kubernetes安装kubeadm和kubelet需要在各个节点分别配置地址源123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 更新缓存：1# yum makecache fast Master节点安装在 Master 节点上安装 kubelet kubeadm kubectl:123456# yum install -y kubelet kubeadm kubectlInstalling: kubeadm 1.14.1-0 kubectl 1.14.1-0 kubelet 1.14.1-0 Node节点安装在 Node1 节点上安装 kubelet kubeadm:1# yum install -y kubelet kubeadm kubectl 在 node 节点上是非必需的。 设置 kubelet 开机启动1# systemctl enable kubelet &amp;&amp; systemctl start kubelet 此时如果查看 kubelet 的状态，会发现 处于 loaded 状态，错误码是 255:123456789# systemctl status kubelet● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since Thu 2019-05-16 23:51:36 CST; 808ms ago Docs: https://kubernetes.io/docs/ Process: 4317 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=255) Main PID: 4317 (code=exited, status=255) 提前获取镜像可以通过命令 kubeadm config images list 查看当前可用的最新镜像版本信息。 Kubernetes启动时默认会从 k8s.gcr.io 去拉取所需的镜像，但该地址在国内无法访问，需要更换为国内可用的地址。 Azure 中国 提供了 gcr.io 及 k8s.gcr.io 容器仓库的镜像代理服务。 镜像地址：docker pull gcr.azk8s.cn/google_containers/&lt;imagename&gt;:&lt;version&gt; 默认情况下无法访问获取最新的版本，会根据使用的 kubeadm 的版本给出相应版本：12345678910# kubeadm config images listI0517 00:03:01.427109 4857 version.go:96] could not fetch a Kubernetes version from the internet: unable to get URL &quot;https://dl.k8s.io/release/stable-1.txt&quot;: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)I0517 00:03:01.427382 4857 version.go:97] falling back to the local client version: v1.14.1k8s.gcr.io/kube-apiserver:v1.14.1k8s.gcr.io/kube-controller-manager:v1.14.1k8s.gcr.io/kube-scheduler:v1.14.1k8s.gcr.io/kube-proxy:v1.14.1k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.3.10k8s.gcr.io/coredns:1.3.1 也可以直接指定版本：1kubeadm config images list --kubernetes-version=v1.14.1 下载镜像在 Master 和 Node 节点均执行 创建一个名为 kubeadm_pull.sh 脚本文件: 12345678# kubeadm_pull.shfor i in `kubeadm config images list`; do imageName=$&#123;i#k8s.gcr.io/&#125; docker pull gcr.azk8s.cn/google_containers/$imageName docker tag gcr.azk8s.cn/google_containers/$imageName k8s.gcr.io/$imageName docker rmi gcr.azk8s.cn/google_containers/$imageNamedone; 在网上也找到一个阿里云的地址源 registry.aliyuncs.com/google_containers，替换脚本中的 gcr.azk8s.cn/google_containers 部分即可。 另外，如果想下载指定版本，可以将第一行改为 kubeadm config images list --kubernetes-version=v1.14.1 即加上版本的限制: 1--kubernetes-version=v1.14.1 然后执行，等待下载： 1234# vim ./kubeadm_pull.sh# chmod +x ./kubeadm_pull.sh# ./kubeadm_pull.sh 使用kubeadm init初始化集群kubeadm init在 Master 节点执行 1# kubeadm init --kubernetes-version=v1.14.1 --apiserver-advertise-address=192.168.5.28 --pod-network-cidr=10.244.0.0/16 其中，–apiserver-advertise-address这是 API server 用来告知集群中其它成员的地址，这也是在 init 流程的时候用来构建 kubeadm join 命令行的地址。 更多的配置参数说明可见：kubeadm 设置工具参考指南 | Kubernetes 当看到输出信息中的 Your Kubernetes control-plane has initialized successfully! 说明Kubernetes初始化成功了。 后面的几段输出比较重要。 要管理集群，我们需要执行如下命令：12345To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 安装支持的Pod网站组件：123You should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ 要将其他Node节点加入到当前Master节点的集群中，需要执行如下命令：1234Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.5.28:6443 --token runell.pdp1y28g1dsayy1o \ --discovery-token-ca-cert-hash sha256:349ee7b8a8f8a255065ebdbd1de2a98127f45fd190716af6a7a780e025f8cdfd 上面的三步，也就是我们初始化集群要做的。 授权管理集群如果需要使用Kubernetes集群，则首先要执行上面的授权操作，否则你看到的就是下面这样：12# kubectl get nodesThe connection to the server localhost:8080 was refused - did you specify the right host or port? 在 Master 节点上操作 因为我常用的是非root用户，所以这里我退出root用户权限来操作。当然，你也可以在其他的系统上来管理集群，只需要将 /etc/kubernetes/admin.conf 拷贝到 $HOME/.kube/config 目录中即可。 123456789[root@master ~]# exitlogout➜ ~ pwd/home/tiger➜ ~ mkdir -p $HOME/.kube➜ ~ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config[sudo] tiger 的密码：➜ ~ sudo chown $(id -u):$(id -g) $HOME/.kube/config 我们可以通过 kubectl get nodes 查看节点的状态:123➜ ~ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster NotReady master 14m v1.14.1 master 节点 处于 NotReady 状态，还需要配置网络。 安装网络组件Kubernetes系统上Pod网络的实现依赖于第三方插件进行，简单易用的实现是为CoreOS提供的flannel项目。 安装文档 Creating a single master cluster with kubeadm - Kubernetes 中的介绍，直接执行如下命令：1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml 由于上面我是在 tiger 用户下设置了授权，所以这里安装 flannel 就需要在 tiger 用户下来操作（不需要sudo），执行结果：12345678910➜ ~ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.ymlclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds-amd64 createddaemonset.extensions/kube-flannel-ds-arm64 createddaemonset.extensions/kube-flannel-ds-arm createddaemonset.extensions/kube-flannel-ds-ppc64le createddaemonset.extensions/kube-flannel-ds-s390x created 之后，再次查看节点状态：123➜ ~ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 35m v1.14.1 现在是 Ready 状态了。 如果是用root权限操作，由于上面没有为root账户授权，会报如下错误：12unable to recognize &quot;https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml&quot;: Get http://localhost:8080/api?timeout=32s: dial tcp [::1]:8080: connect: connection refusedunable to recognize &quot;https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml&quot;: Get http://localhost:8080/api?timeout=32s: dial tcp [::1]:8080: connect: connection refused 检查 Flannel 的pod状态：123➜ ~ kubectl get pods -n kube-system -l app=flannelNAME READY STATUS RESTARTS AGEkube-flannel-ds-amd64-2rzqc 1/1 Running 0 6m51s 验证Master节点上相关Pod是否正常通过命令 kubectl get pods --all-namespaces 验证master节点上kubernetes集群的相关Pod是否都正常创建并运行： 12345678910➜ ~ kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-fb8b8dccf-cm28l 1/1 Running 0 40mkube-system coredns-fb8b8dccf-lqh8n 1/1 Running 0 40mkube-system etcd-master 1/1 Running 0 39mkube-system kube-apiserver-master 1/1 Running 0 39mkube-system kube-controller-manager-master 1/1 Running 0 39mkube-system kube-flannel-ds-amd64-2rzqc 1/1 Running 0 8m10skube-system kube-proxy-mb87m 1/1 Running 0 40mkube-system kube-scheduler-master 1/1 Running 0 40m 如果发现有状态错误的Pod，可以通过命令 kubectl --namespace=kube-system describe pod &lt;pod_name&gt; 来查看具体错误原因。 查看集群中各个组件的状态：12345➜ ~ kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy okcontroller-manager Healthy oketcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 设置Master节点调度PodKubeadm 在 master节点上也安装了 kubelet，出于安全考虑Pod不会被调度到Master Node上，也就是说Master Node不参与工作负载。这是因为master节点被打上了 node-role.kubernetes.io/master:NoSchedule 的标记： 查看Master节点的 Taint kubectl describe node &lt;host_name&gt; | grep Taint:12➜ ~ kubectl describe node master | grep TaintTaints: node-role.kubernetes.io/master:NoSchedule 如果希望在 Master 节点上也可以运行 Pod，可以执行如下命令（删除 Node 的 Label “node-role.kubernetes.io/master”，让Master节点成为Node节点）：1234# 当前只有一个master节点，可以使用 --all 来执行kubectl taint nodes --all node-role.kubernetes.io/master-# 或者指定节点名称kubectl taint nodes &lt;host_name&gt; node-role.kubernetes.io/master- 结果：12➜ ~ kubectl taint nodes --all node-role.kubernetes.io/master-node/master untainted 另外，如果要恢复禁止master部署Pod，可以执行： 1kubectl taint nodes &lt;host_name&gt; node-role.kubernetes.io/master:NoSchedule 向Kubernetes集群中添加Node节点注意：在 Node 节点上操作 按照上面的第三步操作，直接在 Node 节点上执行，这里需要注意的是必须以root权限来执行： 12kubeadm join 192.168.5.28:6443 --token runell.pdp1y28g1dsayy1o \ --discovery-token-ca-cert-hash sha256:349ee7b8a8f8a255065ebdbd1de2a98127f45fd190716af6a7a780e025f8cdfd 输出结果：12345678910111213141516[root@node1 ~]# kubeadm join 192.168.5.28:6443 --token runell.pdp1y28g1dsayy1o \&gt; --discovery-token-ca-cert-hash sha256:349ee7b8a8f8a255065ebdbd1de2a98127f45fd190716af6a7a780e025f8cdfd[preflight] Running pre-flight checks[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.14&quot; ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet-start] Activating the kubelet service[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &apos;kubectl get nodes&apos; on the control-plane to see this node join the cluster. 查看集群节点状态回到主节点master上，查看集群节点状态：1234➜ ~ kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 65m v1.14.1node1 Ready &lt;none&gt; 77s v1.14.1 至此，node1 节点顺利添加到了集群中。 kube-proxy开启ipvs注意：在 Master 节点下操作 通过命令 ipvsadm -L -n 查看当前ipvs状态：1234➜ ~ sudo ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn 发现并没有使用ipvs。 修改 ConfigMap的kube-system/kube-proxy 中的 config.conf，执行命令：1➜ ~ kubectl edit cm kube-proxy -n kube-system 找到其中的如下部分：12345... kind: KubeProxyConfiguration metricsBindAddress: 127.0.0.1:10249 mode: &quot;&quot;... 将 mode: &quot;&quot; 改为 mode: &quot;ipvs&quot;。 之后重启各个节点上的kube-proxy Pod:1kubectl get pod -n kube-system | grep kube-proxy | awk &apos;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&apos; 上面的命令是将原有 kube-proxy 的 Pod 删除，然后重新创建的。执行结果：12345678910➜ ~ kubectl get pod -n kube-system | grep kube-proxykube-proxy-d78m2 1/1 Running 0 55mkube-proxy-mb87m 1/1 Running 0 119m➜ ~ kubectl get pod -n kube-system | grep kube-proxy | awk &apos;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&apos;pod &quot;kube-proxy-d78m2&quot; deletedpod &quot;kube-proxy-mb87m&quot; deleted➜ ~ kubectl get pod -n kube-system | grep kube-proxykube-proxy-8x8f6 1/1 Running 0 10skube-proxy-k54d5 1/1 Running 0 3s➜ ~ 查看其中一个 kube-proxy Pod 的日志输出：123456789101112➜ ~ kubectl logs kube-proxy-k54d5 -n kube-systemI0517 02:04:00.609209 1 server_others.go:177] Using ipvs Proxier.W0517 02:04:00.609514 1 proxier.go:381] IPVS scheduler not specified, use rr by defaultI0517 02:04:00.609660 1 server.go:555] Version: v1.14.1I0517 02:04:00.619582 1 conntrack.go:52] Setting nf_conntrack_max to 131072I0517 02:04:00.620296 1 config.go:202] Starting service config controllerI0517 02:04:00.620318 1 controller_utils.go:1027] Waiting for caches to sync for service config controllerI0517 02:04:00.620338 1 config.go:102] Starting endpoints config controllerI0517 02:04:00.621083 1 controller_utils.go:1027] Waiting for caches to sync for endpoints config controllerI0517 02:04:00.720469 1 controller_utils.go:1034] Caches are synced for service config controllerI0517 02:04:00.721541 1 controller_utils.go:1034] Caches are synced for endpoints config controller➜ ~ 日志中打印出了 Using ipvs Proxier ，说明ipvs模式已经开启。 再次通过 ipvsadm -L -n 命令查看：1234567891011121314151617➜ ~ sudo ipvsadm -L -n[sudo] password for tiger:IP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.96.0.1:443 rr -&gt; 192.168.5.28:6443 Masq 1 0 0TCP 10.96.0.10:53 rr -&gt; 10.244.0.2:53 Masq 1 0 0 -&gt; 10.244.0.3:53 Masq 1 0 0TCP 10.96.0.10:9153 rr -&gt; 10.244.0.2:9153 Masq 1 0 0 -&gt; 10.244.0.3:9153 Masq 1 0 0UDP 10.96.0.10:53 rr -&gt; 10.244.0.2:53 Masq 1 0 0 -&gt; 10.244.0.3:53 Masq 1 0 0➜ ~ 也显示出了相应的配置信息。 至此，kubeadm配置Kubernetes集群的操作就完成了。 相关参考 使用kubeadm安装Kubernetes 1.14 - 青蛙小白 centos7.4 kubeadm安装Kubernetes 1.14.1 集群-随记千秋-51CTO博客 Creating a single master cluster with kubeadm - Kubernetes]]></content>
      <categories>
        <category>云原生系列</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zsh无法更换主题]]></title>
    <url>%2F2019%2F05%2F15%2Fzsh-cannot-change-themes%2F</url>
    <content type="text"><![CDATA[今天在知乎上发现一款zsh的主题，感觉比较好看，推荐给大家。 可能很多人都用过 ys 这款主题，显示的信息很全也很清爽。但是对于我来说，不太喜欢它的一点就是前面的 # user @ hostname in 部分，感觉这部分完全没有显示的必要，同时如果进入的目录比较深的话，还会导致显示的提示信息很长。所以我就一直没有选择这款主题。 偶然看到一个名为 astro 的zsh主题 iplaces/astro-zsh-theme: Astro Theme for Oh My ZSH，是基于 ys 修改而来的。没想到也遇到了和我有同样想法的同学（ps: 只不过人家已经把想法变成了现实，而我却…） 因为加上用户名和 machine 信息之后很容易在文件路径较长时候产生换行，而且用户名和 machine 信息在我们使用 iTerm 的时候基本上用处很小所以我直接把他们省略掉了，看着清爽。 主要的部分就是文件路径、git 状态、git hash 和时间 Astro 主题的安装方法也很简单，直接按照给出的命令操作即可。 我之前一直使用的是 spaceship 这款主题。 要想修改zsh的主题设置，只需要将 ~/.zshrc 文件中的 ZSH_THEME=&quot;spaceship&quot; 部分，改成相应主题的名字即可。 但当我将其改成 ZSH_THEME=&quot;astro&quot; 之后，却发现 source ~/.zshrc 无法切换到新的主题，显示的还是之前的 spaceship 的主题样式： spaceship theme:123Leafney.github.io on  hexo [⇡] is 📦 v0.0.03.7.1 via ⬢ v10.15.3➜ 然后我去 zsh 的 github 中查询是否有相关的 issues。发现其中一种方法是将：1234plugins=( git zsh-autosuggestions) 改成在一行的方式：1plugins=(git zsh-autosuggestions) 不过这个方法在测试后无效。 然后我又将其尝试更改成其他的主题样式，如默认的 robbyrussell，结果发现还是 spaceship 的主题样式。那么到这里，基本上可以确定是 spaceship 这个主题的问题了，可能是当初我在配置 spaceship 主题时有什么全局设置，导致它每次 source 时都会覆盖更改的主题。 随后，我去 spaceship 主题的官方网站 Home · Spaceship ZSH 查找是否有相关的全局设置。发现了下面的一段：123# Set Spaceship ZSH as a promptautoload -U promptinit; promptinitprompt spaceship 当我把 ~/.zshrc 中这部分注释掉之后再次 source，发现新的主题可以正常使用了： astro theme:12# ~/Project/Leafney.github.io [hexo ● (0673186)] [11:53:36]➜ hexo s -g 更换成其他的主题，也一样可以正常切换：robbyrussell theme:1➜ Leafney.github.io git:(hexo) hexo s -g 至于上面这段关于 prompt 的配置，“咱也不知道为啥，咱也不敢问”。 oh my zsh 哪些主题比较好看、有特点？ - 木童的回答 - 知乎 iplaces/astro-zsh-theme: Astro Theme for Oh My ZSH oh my zsh - oh-my-zsh not applying themes - Stack Overflow Home · Spaceship ZSH]]></content>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何添加URL到shadowsocks的列表让其使用代理访问]]></title>
    <url>%2F2019%2F05%2F13%2Fss-add-urls-use-proxy%2F</url>
    <content type="text"><![CDATA[添加自定义网址开启 Shadowsockets 的 自动代理模式 一般情况下并不能正常访问到 medium.com 的站点。 选择 编辑自动模式的PAC... 选项，会打开一个名为 gfwlist.js 的配置文件： 按照该文件中已有URL的格式，将我们的 medium.com 添加到文件中： 1234567var rules = [ &quot;||medium.com&quot;, &quot;||altrec.com&quot;, &quot;||darpa.mil&quot;, ... ...&#125; 保存修改。 之后直接刷新页面即可，无需重启 ss ，立即生效了。 MAC 下点击“从 GFWList 更新 PAC”，提示“404”错误 由于太久没更新，且 gfwlist.txt 是 hard code 在代码里面的，所以升级 GFWList 会报 404 错误。主要是因为原来的 GFWList 托管在 Google Code 上，现在托管在 GitHub 上。 所以，就不要去管这一项了。 不能更新 PAC 文件 · Issue #212 · shadowsocks/shadowsocks-iOS shadowSocks 从 gwflist更新 PAC 时404 不支持Google Play服务，无法运行使用ss-android的扫码方式添加ss配置时，提示设备不支持Google Play服务，无法运行 不要使用扫码功能，手动设置添加完美解决这个问题 设备不支持Google Play服务，无法运行 · Issue #2171 · shadowsocks/shadowsocks-android]]></content>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客添加Gitalk评论系统]]></title>
    <url>%2F2019%2F04%2F30%2Fhexo-add-gitalk-comment%2F</url>
    <content type="text"><![CDATA[经朋友的提醒，我发现我的博客中的评论插件Gitment已经不能正常使用了。简单的分析了一下：发布评论内容后 Gitment 区域就会一直显示 Logging in... 的加载错误信息，查看网络请求，发现是Gitment插件中使用的一个域名 https://gh-oauth.imsun.net 的Https证书已经过期了。 查看了一下该域名的证书，发现早在 2018年9月14日 就到期了，哎，我说为什么我的博客一直没有人评论呢，原来是这个原因。 问题是找到了，但博客评论的功能可不能去掉，毕竟这是一个很好的交流问题的地方。 在网上搜索了一下，发现了一款名为 Gitalk 的评论插件，和 Gitment 功能实现差不多。看了看github中的issues信息，发现 Gitalk 的活跃度还是很高的。 因为我用的是 Hexo 的 Next 主题，去 Next 的官网中找了一下文档，发现并没有直接集成 Gitalk 评论插件。那看来只能自己改造了。 想想当时我加入 Gitment 评论插件时，Next主题已经集成好了，所以只要打开并添加好自己的 GitHub token 信息之后，就能正常使用了。而 Gitment 和 Gitalk 都是评论插件，所以只要按照 Gitment的方式来修改即可，也是很简单的。 废话不多说，Gitalk 用起来。 提示：建议和我之前的文章 Hexo博客添加Gitment评论系统 | IT范儿 一起食用，体验更好哟！！！ 禁用Gitment将 themes/next/_config.yml 文件中的 gitment: enable:true 改为 false。关闭 Gitment 的评论插件。 使用Gitalk先简单过一下 Gitalk 的文档：gitalk/gitalk: Gitalk is a modern comment component based on Github Issue and Preact. Gitalk 的使用非常简单： 导入链接 添加占位标签 初始化插件 自定义设置 添加初始化代码在 Next 主题中，第三方的插件都放在了 _third-party 目录下。 在 themes/next/layout/third-party/comments 中新建 gitalk.swig: 1234567891011121314151617181920212223&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.owner &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id:&apos;&#123;&#123; theme.gitalk.IdPrefix || gitalk &#125;&#125;_&#123;&#123; date(page.date, &quot;YYYYMMDDHHmmss&quot;) &#125;&#125;&apos;, labels: &apos;&#123;&#123; theme.gitalk.labels &#125;&#125;&apos;, perPage: &#123;&#123; theme.gitalk.perPage &#125;&#125;, pagerDirection: &apos;&#123;&#123; theme.gitalk.pagerDirection &#125;&#125;&apos;, createIssueManually: &#123;&#123; theme.gitalk.createIssueManually &#125;&#125;, distractionFreeMode: &#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 载入插件在 themes/next/layout/third-party/comments 中找到 index.swig 文件，新增 gitalk.swig: 1&#123;% include &apos;gitalk.swig&apos; %&#125; 添加占位标签在 themes/next/layout/_partials 中，找到 comments.swig 文件，这里面是所有支持的评论插件的占位符所放的位置。就拿之前使用的 gitment 来说，可以看到如下的代码： 123456789&#123;% elseif theme.gitment.enable %&#125; &lt;div class=&quot;comments&quot; id=&quot;comments&quot;&gt; &#123;% if theme.gitment.lazy %&#125; &lt;div onclick=&quot;showGitment()&quot; id=&quot;gitment-display-button&quot;&gt;&#123;&#123; __(&apos;gitmentbutton&apos;) &#125;&#125;&lt;/div&gt; &lt;div id=&quot;gitment-container&quot; style=&quot;display:none&quot;&gt;&lt;/div&gt; &#123;% else %&#125; &lt;div id=&quot;gitment-container&quot;&gt;&lt;/div&gt; &#123;% endif %&#125; &lt;/div&gt; 其中的每一个1&#123;% elseif theme.xxxxx.enable %&#125; 部分，表示的就是一个评论插件功能。 将上面代码段精简一下： 1234&#123;% elseif theme.gitment.enable %&#125; &lt;div class=&quot;comments&quot; id=&quot;comments&quot;&gt; &lt;div id=&quot;gitment-container&quot;&gt;&lt;/div&gt; &lt;/div&gt; 可以发现：&lt;div id=&quot;gitment-container&quot;&gt;&lt;/div&gt; 就是评论框的占位标签了。 那么依葫芦画瓢，我们将上面的代码稍微修改成 gitealk 的占位标签： 1234&#123;% elseif theme.gitalk.enable %&#125; &lt;div class=&quot;comments&quot; id=&quot;comments&quot;&gt; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;/div&gt; 然后将其加入到任意两个1&#123;% elseif theme.xxxxx.enable %&#125; 代码段之间即可。 自定义配置打开 Next 主题的配置文件 themes/next/_config.yml ，加上如下内容： 12345678910111213gitalk: enable: true ClientID: xxxxxx ClientSecret: xxxxxxxxxxxx repo: gitalk owner: xxxxx adminUser: xxxxx IdPrefix: gitalk labels: gitalk perPage: 10 pagerDirection: last createIssueManually: true distractionFreeMode: false 其中：repo 表示将 issues 提交到哪个仓库。 IdPrefix 是我自定义添加的参数，表示ID 值的前缀。其他项可直接参考官方的文档来进行修改：gitalk/readme-cn.md at master · gitalk/gitalk 问题解决i.concat(…).join is not a function执行 hexo s -g 预览博客，发现评论部分报错： 1Error: i.concat(...).join is not a function 这个问题是 labels 部分的问题，通过如下方式处理，将 labels 修改为： 123&#123; labels: &apos;&#123;&#123; theme.gitalk.labels &#125;&#125;&apos;.split(&apos;,&apos;).filter(l =&gt; l),&#125; Error: u.concat(…).join is not a function! · Issue #114 · gitalk/gitalk 未找到相关的 Issues 进行评论更改为 Gitalk 之后，发现之前使用 Gitment 已经创建了 issues 的文章却提示 未找到相关的 Issues 进行评论 : 原因是： Gitalk 评论插件是通过 issues 的 labels 来标识一篇文章的。如果 labels 中存在相应文章的 label 标签，那就说明该文章已经初始化过了。 比如 我一篇文章设置的 ID 为 itfanr_blog_20190426225702 ，默认的 labels 为 gitalk，那么相应的issues如下： 这两个label一起来标识一篇文章。 因为上面我将ID值的格式进行了修改： 原来: 1id: &apos;itfanr_blog_&#123;&#123; date(page.date, &quot;YYYYMMDDhhmmss&quot;) &#125;&#125;&apos;, 现在： 1id:&apos;&#123;&#123; theme.gitalk.IdPrefix || gitalk &#125;&#125;_&#123;&#123; date(page.date, &quot;YYYYMMDDHHmmss&quot;) &#125;&#125;&apos;, 其中的时间戳格式进行了更改，也就导致了 labels 不匹配而找不到了。 由于暂时没有找到如何批量更新 labels 的方法，而一个一个的手动更改又太麻烦了。所以我就删除原来的 issues，重新进行创建。此时，我发现 Gitalk 一个好用的地方是，当将配置项 createIssueManually 设置为 false 时，如果发现是管理员浏览文章，会自动为该文章初始化评论功能，非常方便。 另外一个主要的原因是：这几个月我的博客一直没有评论，所以好多都是空的 issues，删除重建也就没有什么犹豫了。 关于文章ID这里需要说明的是 ID 这一项。 依照gitalk文档中的解释，该值表示当前页面的唯一id，且长度不能超过50： 1The unique id of the page. Length must less than 50. 所以，我这里设置为了 前缀+文章create时间戳的方式来实现唯一性。 通过在配置文件中指定 IdPrefix 来表示前缀，默认值为 gitalk。 如果你不想用时间戳的方式，也可以使用文章链接的MD5值来实现唯一ID，方法如下： 在上面 themes/next/layout/third-party/comments/gitalk.swig 中添加对 md5.js的引用： 1&lt;script src=&quot;https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js&quot;&gt;&lt;/script&gt; 修改ID部分为： 1id: md5(location.pathname), 即可。 但是，不建议直接使用默认的 id: location.pathname, 即 文章链接。有时候文章标题可能会很长，当超过50个字符之后就会提交失败，这个是由 GitHub中的 Issues labels 限制的。 相关参考 gitalk/gitalk: Gitalk is a modern comment component based on Github Issue and Preact. Hexo中Gitalk配置使用教程-可能是目前最详细的教程 | ioChen’s Blog]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS中安装pip]]></title>
    <url>%2F2019%2F04%2F26%2Fcentos-install-pip%2F</url>
    <content type="text"><![CDATA[直接执行 yum install python-pip 会报错:找不到 python-pip 安装包 需要先安装 epel-release : 1$ sudo yum -y install epel-release 再安装: 1$ sudo yum -y install python-pip 将pip更新到最新: 1$ sudo pip install --upgrade pip]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell命令自动补全插件zsh-autosuggestions]]></title>
    <url>%2F2019%2F04%2F26%2Fshell-command-auto-completion-plug-in-zsh-autosuggestions%2F</url>
    <content type="text"><![CDATA[Talk is cheep , show you the code. InstallClone this repository into $ZSH_CUSTOM/plugins (by default ~/.oh-my-zsh/custom/plugins): 1git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions Add the plugin to the list of plugins for Oh My Zsh to load (inside ~/.zshrc): 1plugins=(zsh-autosuggestions) Start a new terminal session or run source ~/.zshrc. More: zsh-autosuggestions/INSTALL.md at master · zsh-users/zsh-autosuggestions Change default colorThis color can be changed by setting the ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE variable. For Example: You can edit your ~/.zshrc and change/add the variable ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=&#39;fg=value&#39; like ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=&#39;fg=66&#39;. The number of colors is in any case limited to 256(i.e. the range 0 to 255). You can view the detailed colors from here: When the auto prompt appears, press → key or Ctrl(Control) + f to enter the auto prompt command into the current terminal. linux - How to change zsh-autosuggestions color - Stack Overflow Z Shell colors! (Example)]]></content>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppeteer配置小记]]></title>
    <url>%2F2019%2F04%2F10%2Fconfiguration-development-of-puppeteer%2F</url>
    <content type="text"><![CDATA[最近项目中需要实现动态数据的抓取，之前在抓取动态页面的时候都是通过 Phantomjs 、Selenium 、Chrome 或 Firefox的 Headless 模式等方法来实现，自从 Google Chrome 团队推出官方的 Headless Chrome 工具 Puppeteer 之后，似乎之前使用的那些工具一下都黯淡了。 Puppeteer 是一个 Node 代码库，基于 DevTools 协议，提供高级 API 自动化控制谷歌 Chrome 或 Chromium 浏览器。Puppeteer 默认以 无界面方式 运行。 安装 Puppeteer 过程中会下载完整版的谷歌Chromium浏览器到 node_modules 目录。 从 1.7.0 版后，谷歌发布了新的 puppeteer-core 安装包，默认不再自动下载谷歌Chromium浏览器。 puppeteer-core 是 Puppeteer 的轻量级版本，复用本地已安装的浏览器，或者连接到远程浏览器。 安装yarn这里我使用 yarn 来管理依赖包。 Mac12$ brew install yarn# 由于地址源的问题，该命令执行失败 12$ sudo npm install -g yarn# 使用这条命令安装成功 WinChocolatey 是一个windows下的包管理器。 1choco install yarn Chocolatey - The package manager for Windows 使用yarn查看版本信息12$ yarn -v1.15.2 初始化项目1$ yarn init 添加一个依赖123$ yarn add [package]$ yarn add [package]@[version]$ yarn add [package]@[tag] 全局安装依赖1$ yarn global add [package] 更新一个依赖123$ yarn upgrade [package]$ yarn upgrade [package]@[version]$ yarn upgrade [package]@[tag] 移除一个依赖1$ yarn remove [package] 安装package.json中所有的依赖项123$ yarn# or:$ yarn install 查看yarn配置1$ yarn config list 更改 registry12#安装淘宝镜像$ yarn config set registry &quot;https://registry.npm.taobao.org&quot; 安装Puppeteer修改地址源这里我采用的是 puppeteer-core。由于国内网络原因，需要修改仓库源地址： 12345$ npm config set registry &quot;https://registry.npm.taobao.org&quot;$ yarn config set registry &quot;https://registry.npm.taobao.org&quot;$ yarn add puppeteer-core 配置Chrome路径使用 puppeteer-core，需要手动指定已安装的Chrome浏览器的安装路径。 Mac电脑上Chrome浏览器的的安装路径，可以通过在浏览器中输入 chrome:\\version 来查看。 我的电脑上的路径为： 1/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome Puppeteer配置无界面模式Puppeteer 默认使用 headless 模式运行，通过设置 headless:false 来显示GUI界面： 123const browser = await puppeteer.launch(&#123; headless: false&#125;); 其他配置参数其他 puppeteer.launch() 配置项： 123456789101112&#123; // 若是手动下载的chromium需要指定chromium地址, 默认引用地址为 `/项目目录/node_modules/puppeteer/.local-chromium/` executablePath: &apos;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome&apos;, //设置超时时间 timeout: 15000, //如果是访问https页面 此属性会忽略https错误 ignoreHTTPSErrors: true, // 打开开发者工具, 当此值为true时, headless总为false devtools: false, // 关闭headless模式, 不会打开浏览器 headless: false,&#125; 沙箱、共享内存123const browser = await puppeteer.launch(&#123; args: [&apos;--no-sandbox&apos;, &apos;--disable-dev-shm-usage&apos;]&#125;); --no-sandbox: 去沙箱运行 --disable-dev-shm-usage: 默认情况下，Docker运行一个 /dev/shm 共享内存空间为64MB 的容器。这通常对Chrome来说太小，并且会导致Chrome在渲染大页面时崩溃。要修复，必须运行容器 docker run --shm-size=1gb 以增加 /dev/shm 的容量。从Chrome 65开始，使用 --disable-dev-shm-usage 标志启动浏览器即可，这将会写入共享内存文件 /tmp 而不是 /dev/shm . Linux沙箱：在计算机安全领域，沙箱(Sandbox)是一种程序的隔离运行机制，其目的是限制不可信进程的权限。沙箱技术经常被用于执行未经测试的或不可信的客户程序。为了避免不可信程序可能破坏其它程序的运行。 参考 截图的诱惑：Docker部署Puppeteer项目 - 掘金 跳转到指定页1await page.goto(&apos;https://github.com/login&apos;); 等待12345# 等待指定时间 ，secondawait page.waitFor(2*1000);# 等待某元素显示await page.waitForSelector(&apos;body.blog&apos;); 设置视图大小1await page.setViewport(&#123;width: 1280, height: 600&#125;) 要注意：这里的视图大小指的是网页页面显示的大小，和浏览器界面的大小是两个概念。 截屏fullPage 可以控制是否截取整个页面: 1234await page.screenshot(&#123; path: &apos;jd.png&apos;, fullPage: true&#125;); 设置UserAgent1await page.setUserAgent(&apos;Mozilla/5.0 (iPhone; CPU iPhone OS 9_0_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13A404 Safari/601.1&apos;) 获取页面内容返回页面的完整 html 代码，包括 doctype ： 1page.content(); 拦截请求页面中的图片12345678910// 拦截请求页面中的图片await page.setRequestInterception(true);page.on(&apos;request&apos;, interceptedRequest =&gt; &#123; let url = interceptedRequest.url(); if (url.indexOf(&apos;.png&apos;) &gt; -1 || url.indexOf(&apos;.jpg&apos;) &gt; -1) &#123; interceptedRequest.abort(); &#125; else &#123; interceptedRequest.continue(); &#125;&#125;); 参考 Puppeteer：模拟浏览器操作行为的利器 · Issue #38 · chenxiaochun/blog 跳转等待页面加载完毕有时候使用 timeout:3000 这样的方式，并不能完全确定页面能在相应的时间范围内加载完而导致异常，可以通过如下的参数来实现，而尽量少用 timeout 这种限定性的方式： 1await page.goto(&apos;https://discordbots.org&apos;, &#123;waitUntil: &apos;domcontentloaded&apos;&#125;); 参考 UnhandledPromiseRejectionWarning on Navigation Timeout Exceeded · Issue #2482 · GoogleChrome/puppeteer getBoundingClientRect()getBoundingClientRect()用于获得页面中某个元素的左，上，右和下分别相对浏览器视窗的位置。 一个例子这里，实现了一个简单的页面截屏的功能： get_png.js: 123456789101112131415161718192021222324252627282930313233const puppeteer = require(&apos;puppeteer-core&apos;);const execPath = &apos;/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome&apos;;(async () =&gt; &#123; const browser = await puppeteer.launch(&#123; // 关闭headless模式, 会打开浏览器 headless: false, executablePath: execPath, args: [&apos;--no-sandbox&apos;, &apos;--disable-dev-shm-usage&apos;], // 超时时间 timeout: 30000, &#125;); const page = await browser.newPage(); await page.setViewport(&#123; width: 1280, height: 800, // deviceScaleFactor: 1, // isMobile: true &#125;); await page.goto(&apos;https://www.cnblogs.com/&apos;, &#123; waitUntil: &apos;domcontentloaded&apos; &#125;); // wait for some seconds await page.waitFor(3000); let title = await page.title(); console.log(title); // 截屏 await page.screenshot(&#123; path: &apos;test.png&apos;, fullPage: true &#125;); await browser.close();&#125;)(); 执行 node get_png.js 看效果。 遇到的问题ERR_NAME_RESOLUTION_FAILED使用 puppeteer 测试时报错： 12345678910112019-04-07 19:41:50: received 122600732019-04-07 19:41:50: https://item.jd.com/12260073.html2019-04-07 19:41:56: the task data for 12260073 get result error: Error: net::ERR_NAME_RESOLUTION_FAILED at https://item.jd.com/12260073.html2019-04-07 19:41:56: at navigate (/app/node_modules/puppeteer-core/lib/FrameManager.js:101:37)2019-04-07 19:41:56: at processTicksAndRejections (internal/process/task_queues.js:86:5)2019-04-07 19:41:56: -- ASYNC --2019-04-07 19:41:56: at Frame.&lt;anonymous&gt; (/app/node_modules/puppeteer-core/lib/helper.js:110:27)2019-04-07 19:41:56: at Page.goto (/app/node_modules/puppeteer-core/lib/Page.js:656:49)2019-04-07 19:41:56: at Page.&lt;anonymous&gt; (/app/node_modules/puppeteer-core/lib/helper.js:111:23)2019-04-07 19:41:56: at Object.runPuppet (/app/src/puppet.js:51:16)2019-04-07 19:41:56: at processTicksAndRejections (internal/process/task_queues.js:86:5) 找到一种说法：设置 UserAgent ，如下： 12345678910111213(async function main() &#123; try &#123; const browser = await puppeteer.launch(&#123;headless: true&#125;); const page = await browser.newPage(); await page.setUserAgent(&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3419.0 Safari/537.36&apos;); await page.goto(&apos;http://example.com&apos;); //your code await browser.close(); &#125; catch(e)&#123; console.log(e); &#125;&#125;)(); 参考 page.goto() method generates Error: net::ERR_CONNECTION_RESET error · Issue #1477 · GoogleChrome/puppeteer 经测试观察，添加了 UserAgent 设置后确实不会报错了。 Promise中的console.log在函数内有 console.log(&#39;按f12,我出现在浏览器的console中，并不在node命令行&#39;) 你会发现node命令行看不到这句话，而在Chromium的console中看见。 123456789const result = await page.$eval(selector, el =&gt; &#123; //如果需要赋值要返回Promise return new Promise(resolve =&gt; &#123; //...一波骚操作 //可以用Dom api啦 reslove(obj) &#125;)&#125;);await iframe.$$eval(selector, el =&gt; &#123;...&#125;); 在page.evaluate中用console是不能在node命令行打印出来的，不过有了监听事件就可以改变这个规则了。也可以在监听事件里面做容错处理。 如下的方式实现监听事件： 123page.on(&apos;console&apos;, msg =&gt; &#123; console.log(msg);&#125;); 参考 我常用的puppeteer爬虫api - 掘金 Docker镜像为了部署的方便，我实现了 puppeteer 环境的Docker镜像，具体可查看： leafney/alpine-puppeteer: Alpine Docker Puppeteer Environment 相关参考 Puppeteer v1.14.0 截图的诱惑：Docker部署Puppeteer项目 - 掘金 值的参考 爬虫利器 Puppeteer 实战 - 掘金 puppeteer初体验 - 掘金 「译」如何用 Node.Js 和 Puppeteer 爬取网页 - 掘金 手动下载 Chrome，解决 puppeteer 无法使用问题 - 简书]]></content>
      <tags>
        <tag>数据抓取</tag>
        <tag>Puppeteer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过Docker部署Nodejs项目产生的一些思考]]></title>
    <url>%2F2019%2F04%2F08%2Fdeploying-nodejs-applications-with-docker%2F</url>
    <content type="text"><![CDATA[最近遇到动态页面数据抓取的需求，所以有在研究 Puppeteer 的使用方法。不过之前没有接触过 Nodejs，所以也是通过网上的几篇教程在不断的摸索和测试中一点点了解。 也可以说是自己习惯了但凡遇到一个项目都想要把它Docker容器化来便于后续的操作，也就顺便研究了一下Nodejs项目的Docker化部署。 期间一些小的思考，随手记录一下。 第一版Dockerfile从网上搜索了一些通过docker部署nodejs项目的文章，其中大部分的 Dockerfile 文件写法都如下面的方式： 1234567891011121314151617181920212223242526272829FROM node:11-alpineLABEL maintainer=&quot;leafney &lt;babycoolzx@126.com&gt;&quot;# 设置国内阿里云镜像站、安装chromium 68、文泉驿免费中文字体等依赖库RUN echo &quot;https://mirrors.aliyun.com/alpine/v3.9/main/&quot; &gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/v3.9/community/&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/edge/testing/&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ apk -U --no-cache update &amp;&amp; \ apk -U --no-cache --allow-untrusted add tzdata chromium ttf-freefont wqy-zenhei ca-certificates &amp;&amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone &amp;&amp; \ mkdir -p /logs &amp;&amp; \ rm -rf /var/cache/apk/*WORKDIR /app# 复制宿主机当前路径下所有文件到docker的工作目录COPY . /appRUN npm config set registry &apos;https://registry.npm.taobao.org&apos; &amp;&amp; \ yarn config set registry &apos;https://registry.npm.taobao.org&apos; &amp;&amp; \ yarn global add pm2 &amp;&amp; \ yarn install &amp;&amp; \ yarn cache cleanVOLUME [&quot;/logs&quot;]# Start pm2.json process fileCMD [&quot;pm2-runtime&quot;, &quot;start&quot;, &quot;ecosystem.config.js&quot;] 一般的项目目录结构如下： 123456|-- node_app -- src -- index.js -- package.json -- ecosystem.config.js -- Dockerfile 按照上面的 Dockerfile 文件操作步骤，其中关键的一步： 12# 复制宿主机当前路径下所有文件到docker的工作目录COPY . /app 表示将 node_app 项目目录下的所有文件拷贝到了Docker镜像中，然后执行 yarn install 来安装所有依赖包，最后通过 pm2 启动项目。之后基于该镜像来构建容器直接运行即可。 那么问题来了，当我的项目代码有更新后需要重新上线新版本时，要如何操作呢？ 按照上面的 Dockerfile ，操作步骤应该是： 停止容器，删除容器 从git拉取最新项目代码 重新 docker build 镜像，同时把代码打包到镜像中 通过新镜像创建容器，并启动容器运行 过程似乎很简单，但细想一下，每次一有代码更新，都需要重新来构建镜像。那如果每次的更新都是一些比较小的改动呢？相比之下重新构建镜像所耗费的时间就比较长了。 更严重的是，每一次重新构建镜像，之前可用的镜像就直接作废了，如果不及时删除，会占用很大的硬盘空间。 基于以上诸多的问题，我们来考虑如何优化？ 第二版Dockerfile那么，在我看来，理想状态的操作应该是这样的： 停止容器 从git拉取最新项目代码 重启容器 That’t all! 就是这么简单。 操作非常的简单明了，那看一下如何修改上面第一版的 Dockerfile 文件吧： 12345678910111213141516171819202122232425FROM node:11-alpineLABEL maintainer=&quot;leafney &lt;babycoolzx@126.com&gt;&quot;# 在国内由于网络原因，软件下载比较慢，所以加入了国内的软件源以加速构建# 设置国内阿里云镜像站，安装chromium、文泉驿免费中文字体等依赖库，配置npm和yarn的taobao仓库RUN echo &quot;https://mirrors.aliyun.com/alpine/v3.9/main/&quot; &gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/v3.9/community/&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ echo &quot;https://mirrors.aliyun.com/alpine/edge/testing/&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ apk add -U --no-cache --allow-untrusted tzdata chromium ttf-freefont wqy-zenhei ca-certificates &amp;&amp; \ mkdir -p /app /logs &amp;&amp; \ npm config set registry &apos;https://registry.npm.taobao.org&apos; &amp;&amp; \ yarn config set registry &apos;https://registry.npm.taobao.org&apos; &amp;&amp; \ yarn global add pm2 &amp;&amp; \ yarn cache clean &amp;&amp; \ rm -rf /var/cache/apk/*COPY ./startup.sh /usr/local/bin/RUN chmod +x usr/local/bin/startup.shWORKDIR /appVOLUME [&quot;/app&quot;]EXPOSE 8000CMD [ &quot;startup.sh&quot; ] startup.sh : 12345678910111213141516171819#!/bin/shset -eWDir=/appif [ &quot;$(ls -A $&#123;WDir&#125;)&quot; ]; then echo &quot;[i] ***** dir /app have files,so start init. *****&quot; echo &quot;[i] ***** yarn install *****&quot; yarn install echo &quot;[i] ***** pm2 start *****&quot; pm2-runtime start ecosystem.config.jselse echo &quot;[e] ***** dir /app is empty,so can not run. *****&quot; echo &quot;[i] ***** Please copy project files to VOLUME for /app and then restart docker container *****&quot; nodefi 总体来说，改动的思路就是：将不需要变化的那些操作打包进docker镜像中，而需要经常改动的操作如 更新项目代码，执行 yarn install 安装新的依赖包等，都放到 startup.sh 中。而对于更复杂的操作，后续可以基于该镜像直接做扩展。 另外，这里使用 yarn install 而没有用 npm install 的一个优势是 如果你的 package.json 文件在更新时没有变化，yarn install 也只会执行一次，后续的操作都是读取cache缓存了，所以后续的代码更新操作也就非常快速了。 具体关于 yarn 和 npm 的区别，这里不再详细展开说明。 进一步优化上面的操作虽说已经很简便了，但每次更新代码的时候还是需要重启一下容器才能应用上最新的改动。那还有没有优化的空间呢？ 答案是 当然。 一般的Nodejs项目我们可以通过 pm2 来管理和监控进程，保证node进程持续运行或崩溃时自动重启。而 pm2 的 watch 参数可以监听应用目录的变化，一旦发生变化，就会自动重启。我们可以利用这个功能来实现改动代码的自动更新效果。 在 pm2 的配置文件中增加如下代码： 1234&#123; &quot;watch&quot;: [&quot;server&quot;, &quot;client&quot;], &quot;ignore_watch&quot; : [&quot;node_modules&quot;, &quot;client/img&quot;],&#125; watch 参数默认情况下为 false ,可以设置需要监听改动的文件或目录。在 ignore_watch 参数中设置排除监听改动的文件或目录。 这样，只要监听到代码有改动，pm2 就会自动重启。对于项目更新的操作我们需要做的也就只有一项 从git拉取最新项目代码 而已了。 总结其实无论是第一种的每次生成镜像还是第三种更加灵活的自动重启，具体如何应用还是需要看所对应的需求而言的，并不能一味的评判孰优孰劣。 我实现的Docker镜像地址：leafney/alpine-nodejs - Docker Hub 简单的实现了一个Nodejs项目的Docker镜像，如有考虑不到的地方，欢迎大家提出建议和讨论。 相关参考 PM2 - Watch &amp; Restart]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Python依赖包文件requirements]]></title>
    <url>%2F2019%2F03%2F22%2Frequirements-for-python%2F</url>
    <content type="text"><![CDATA[Python项目中的依赖包一般通过 requirements.txt 来记录。 问题一般情况下我们都是通过命令 pip freeze &gt; requirements.txt 来生成项目依赖文件： 123456789101112131415161718192021amqp==2.4.2aniso8601==6.0.0billiard==3.5.0.5celery==4.2.2certifi==2019.3.9chardet==3.0.4Click==7.0Flask==1.0.2Flask-RESTful==0.3.7Flask-Script==2.0.6idna==2.8itsdangerous==1.1.0Jinja2==2.10kombu==4.3.0MarkupSafe==1.1.1pytz==2018.9requests==2.21.0six==1.12.0urllib3==1.24.1vine==1.3.0Werkzeug==0.15.0 但看到这么多的依赖包不禁要产生一些疑问了：难道这些都是我这个项目需要的依赖包吗？？？ 查看当前环境下安装的所有依赖包： 1234567891011121314151617181920212223242526➜ pip listPackage Version ------------- --------amqp 2.4.2 aniso8601 6.0.0 billiard 3.5.0.5 celery 4.2.2 certifi 2019.3.9chardet 3.0.4 Click 7.0 Flask 1.0.2 Flask-RESTful 0.3.7 Flask-Script 2.0.6 idna 2.8 itsdangerous 1.1.0 Jinja2 2.10 kombu 4.3.0 MarkupSafe 1.1.1 pip 19.0.3 pytz 2018.9 requests 2.21.0 setuptools 18.1 six 1.12.0 urllib3 1.24.1 vine 1.3.0 Werkzeug 0.15.0 可以看到是一样的。也就是说通过 pip freeze 生成的是当前环境下的所有依赖包，而不是当前项目所需的依赖包。 解决要想生成当前项目所需的依赖包文件列表，可以通过 pipreqs 来实现。 1$ pip install pipreqs 命令介绍123456789101112131415161718192021➜ pipreqs --helppipreqs - Generate pip requirements.txt file based on importsUsage: pipreqs [options] &lt;path&gt;Options: --use-local Use ONLY local package info instead of querying PyPI --pypi-server &lt;url&gt; Use custom PyPi server --proxy &lt;url&gt; Use Proxy, parameter will be passed to requests library. You can also just set the environments parameter in your terminal: $ export HTTP_PROXY=&quot;http://10.10.1.10:3128&quot; $ export HTTPS_PROXY=&quot;https://10.10.1.10:1080&quot; --debug Print debug information --ignore &lt;dirs&gt;... Ignore extra directories, each separated by a comma --encoding &lt;charset&gt; Use encoding parameter for file open --savepath &lt;file&gt; Save the list of requirements in the given file --print Output the list of requirements in the standard output --force Overwrite existing requirements.txt --diff &lt;file&gt; Compare modules in requirements.txt to project imports. --clean &lt;file&gt; Clean up requirements.txt by removing modules that are not imported in project. 常用命令12345678# 查看当前项目所有的依赖包$ pipreqs --print ./# 获取当前项目所需的依赖包并保存到默认的 requirements.txt $ pipreqs ./# 获取当前项目所需的依赖包并保存到默认的 requirements.txt ，如果已存在则覆盖$ pipreqs --force ./ 结果由于我的项目下已经通过 freeze 命令生成了 requirements.txt 文件，所以需要执行如下命令： 1$ pipreqs --force ./ 之后，再查看： 1234Flask_Script==2.0.6Flask_RESTful==0.3.7Flask==1.0.2celery==4.2.2 这才是当前项目真正需要的依赖包。 使用1$ pip install -r requirements.txt 这算是一个小的注意事项吧！]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磨刀不误砍柴工 -- Flutter开发技巧]]></title>
    <url>%2F2019%2F03%2F11%2Fflutter-development-skills%2F</url>
    <content type="text"><![CDATA[上一篇文章中我们配置好了Flutter的开发环境，可以选择 VS Code(以下简称VS) 或 Android Studio(以下简称AS) 其中任意一款工具来开发。 下面，我整理了这两款工具中常用的快捷键及一些技巧，以帮助大家在开发过程中提高效率。 StatelessWidget和StatefulWidget快速创建基于StatelessWidget和StatefulWidget的组件只需要输入 stless 就可以创建一个StatelessWidget。 只需要输入 stful 就可以创建一个StatefulWidget。 功能 VS Code Android Studio StatelessWidget stless + Tab stless + Tab / stless + Enter StatefulWidget stful + Tab stful + Tab / stful + Enter 将 StatelessWidget 改成 StatefulWidget在 AS 中，将光标放在 StatelessWidget 上，按住 Alt+Enter (in Mac is Option+Enter) ，然后单击 Convert to StatefulWidget 将自动进行转换。 在 VS Code 中，将光标放在 StatelessWidget 上，按住 Ctrl + . (in Mac is Cmd + .) ，然后单击 Convert to StatefulWidget 将自动进行转换。 Alt+Enter 扩展选项AS Win: 单击任意组件名称 + Alt + Enter Mac: 单击任意组件名称 + Option + Enter VS Code Win: 单击任意组件名称 + Ctrl + . Mac: 单击任意组件名称 + Command + . 将代码块提取到方法中 Extract Method提取一段代码块，生成一个新的方法。当你发现某个方法里面过于复杂，需要将某一段代码提取成单独的方法时，该技巧是很有用的。 AS在 AS 中，选中代码段 – Menu – Refactor – Extract – Method... ： 对应的快捷键是： * Win: `选中代码段` + `Ctrl + Alt + M` * Mac: `选中代码段` + `Command + Option + M` 最强 Android Studio 使用小技巧和快捷键-设计师-51CTO博客 VS Code在 VS Code 中，选中代码段 – 右键菜单 – 重构... – Extract Method : 对应的快捷键： * Win: `选中代码段` + `Ctrl + .` + 选择 `Extract Method` * Mac: `选中代码段` + `Command + .` + 选择 `Extract Method` 参考： v2.12 - Dart Code - Dart &amp; Flutter support for Visual Studio Code Refactoring source code in Visual Studio Code 匹配括号高亮当代码量多了之后，想要找到某一部分代码时，通过匹配的括号来找是比较方便的。 AS在 AS 中，默认支持匹配括号高亮： VS Code在 VS Code 中，默认的括号匹配比较简单： 当代码量多了之后，找起来让人看着有些眼晕。 这里，推荐一个比较好用的插件：Bracket Pair Colorizer 2 : 安装之后，相邻的括号颜色不同，区分起来很明显。 不过，这里我不太喜欢自带的这个匹配线，所以我就把它去掉了。在该插件的官方介绍中，可以看到是通过 &quot;bracket-pair-colorizer-2.showHorizontalScopeLine&quot; 类似的选项定义的，在 用户设置 中可以关闭这些。 快捷键AS 中快捷键格式化代码： * Win: `Ctrl +Alt + L` * Mac: `Command + Option + L` 快速选中整个小部件： * Win: `双击选中部件名称 + Ctrl + W` * Mac: `双击选中部件名称 + Option + Up` 部件操作（Alt + Enter）： * Win: `单击任意组件名称 + Alt + Enter` * Mac: `单击任意组件名称 + Option + Enter` 重命名： * `点击选中任意组件名称 + Shift + F6` 查看组件源码: * Win: * `Ctrl + Click` * `Ctrl + B` * `F4` * `Ctrl + Enter` * Mac: * `Command + Click` * `Command + B` * `F4` * `Command + Down` 注意：我只找到了跳转过去的快捷键，但没找到跳转回来的快捷键。 查看 Widget 包含的属性： * Win: `单击任意组件名称 + Ctrl + Shift + I` * Mac: `单击任意组件名称 + Command + Y` 移除没用的 imports: * Win: `Ctrl + Alt + O` * Mac: `Command + Option + O` 上下移动行： * Win: `单击任意行 + Alt + Shift + Up/Down` * Mac: `单击任意行 + Option + Shift + Up/Down` 上下移动方法： * Win: `单击任意方法名称 + Ctrl + Shift + Up/Down` * Mac: `单击任意方法名称 + Command + Shift + Up/Down` Flutter开发中常用的快捷键 - 掘金 提升 Flutter 开发效率的快捷键 | Wml’Blog 最强 Android Studio 使用小技巧和快捷键-设计师-51CTO博客 ⭐️⭐️⭐️ VS Code 中快捷键我们知道 VS Code 的插件非常丰富。其中一款名为 Awesome Flutter Snippets 为我们整理了常用的方法和组件的快捷键操作。 VS Code 调试 Flutter调试点击 F5 进入调试模式。点击 Shift + F5 退出调试模式。 “Hot Reload” and “Hot Restart”调试模式下Hot Reload: 保存后自动重载 * Win: `Ctrl + S` * Mac: `Command + S` 点击调试菜单中的 重载按钮 或使用快捷键： * Win: `Ctrl + Shift + F5` * Mac: `Command + Shift + F5` Hot Restart: * Win: `Ctrl + F5` * Mac: `Control + F5` How to do full reload? · Issue #754 · Dart-Code/Dart-Code Key Bindings - Dart Code - Dart &amp; Flutter support for Visual Studio Code 命令模式下Hot Reload: * 在命令窗口输入 `r` Hot Restart: * 在命令窗口输入 `R` 代码自动格式化AS 或 IntelliJ IDE手动执行在代码窗口中，右键单击代码窗口并选择 Reformat code with dartfmt 菜单，实现自动格式化代码。 相应的快捷键： * Win: `Ctrl + Alt + L` * Mac: `Command + Option + L` 自动执行选择菜单 Android Studio – Preferences – 搜索 flutter – 在 Languages &amp; Frameworks 中的 Flutter 右侧界面中，找到 General 选项。 勾选 Format code on save 一项。也可以将子项 Organize imports on save 同时选中。 这里我使用的 Android Studio 版本为 Android Studio 3.3.1 。其他版本可能位置有变化。 VS Code手动执行在 VS Code 代码界面中，右键单击代码窗口并选择 Format Document（格式化文档） 菜单，实现自动格式化代码。 相应的快捷键： * Win: `Alt + Shift + F` * Mac: `Option + Shift + F` 自动执行相比起手动执行的方式，更多人都会选择通过在保存文档时来实现代码的自动格式化。 在 VS Code 界面中，通过快捷键 Ctrl + , ( Command + , in Mac) 打开 设置 窗口，或者通过 文件 – 首选项 – 设置（ Code – 首选项 – 设置 in Mac） 打开 设置 窗口。在搜索栏中输入 edit:formatonsave 打开设置界面。 默认情况下，在保存文件时不会自动格式化文件。 当勾选这一项后，表示在格式化程序可用的前提下，保存文件时会自动格式化。 也可以选择下面的 在 settings.json 中编辑 一项，来自定义该项。 当勾选上面的选项后，默认是在 settings.json 中添加了一行: 123&#123; &quot;editor.formatOnSave&quot;: true,&#125; 默认为 false。 个性化设置比如，我想只在 Dart 代码中实现保存时自动格式化的操作，那么可以这样来设置：编辑 settings.json 文件，增加如下代码： 1234567&#123; &quot;editor.formatOnSave&quot;: false, &quot;[dart]&quot;:&#123; &quot;editor.formatOnSave&quot;: true, &#125;&#125; 再比如，我想在所有语言下都支持保存时自动格式化的操作，但只在 javascript 代码中不支持保存时自动格式化的功能，那么可以通过如下的方式来设置： 123456&#123; &quot;editor.formatOnSave&quot;: true, &quot;[javascript]&quot;: &#123; &quot;editor.formatOnSave&quot;: false, &#125;&#125; 可见，VS Code 的设置是非常灵活的。 相关参考 格式化Flutter代码 - Flutter中文网 至此，关于工具的一些使用技巧也就介绍完了。]]></content>
      <categories>
        <category>Flutter之旅</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[兵马未动，粮草先行 -- Flutter开发环境配置]]></title>
    <url>%2F2019%2F03%2F08%2Fflutter-development-environment-configuration%2F</url>
    <content type="text"><![CDATA[对于Flutter开发环境的配置，官方网站 Install - Flutter 中已经介绍的非常详细了，只要按照步骤来操作即可。 我也是按照官方的教程来操作的，这里只是做一个记录。另外，我的操作并不是完全按照官方的流程来的，这里也仅仅是给各位做一个参考。 关于系统我的电脑是 Mac，系统版本为 macOS Mojave 10.14.3。 配置Flutter SDK我安装的时候Flutter的版本还是 v1.0.0 ，今天看已经更新到 v1.2.1 了。不得不说Flutter的更新是真给力。 下载从网站地址 MacOS install - Flutter 下载 Flutter SDK 安装包。 我将 flutter sdk 安装在 ~/sdk (或者写成 $HOME/sdk) 目录下： 12$ cd ~/sdk$ unzip ~/Downloads/flutter_macos_v1.0.0-stable.zip 配置添加 flutter 相关工具到环境变量 path 中: 编辑 $HOME/.bash_profile 文件，在底部添加如下命令： 1export PATH=&quot;$PATH:[PATH_TO_FLUTTER_GIT_DIRECTORY]/flutter/bin&quot; 其中的 [PATH_TO_FLUTTER_GIT_DIRECTORY] 表示你解压 flutter sdk 的目录，我这里就是 ~/sdk。即： 1export PATH=&quot;$PATH:~/sdk/flutter/bin&quot; 另外，在国内由于 众所周知 的原因，还需要设置一下pub源，用以下载相关的依赖文件。其中 PUB_HOSTED_URL 和 FLUTTER_STORAGE_BASE_URL 是google为国内开发者搭建的临时镜像。 12export PUB_HOSTED_URL=https://pub.flutter-io.cnexport FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cn 所以，需要添加的就是上面的三条命令： 123export PUB_HOSTED_URL=https://pub.flutter-io.cnexport FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cnexport PATH=[PATH_TO_FLUTTER_GIT_DIRECTORY]/flutter/bin:$PATH 其中 PATH_TO_FLUTTER_GIT_DIRECTORY 为你 flutter sdk 的路径。如我这里就是改成(推荐用这种方式)： 1export PATH=$HOME/sdk/flutter/bin:$PATH 刷新bash: 1$ source $HOME/.bash_profile 如果使用的是 zsh ，则执行： 1$ source $HOME/.zshrc 查看： 1echo $PATH 验证是否配置成功： 1flutter -h 2019-10-20 更新：最近在安装最新的 flutter_1.9.1 版本时发现，配置好上面的环境变量后，第一次运行 flutter -h 不会立即显示出下面的结果，就是我们通常所说的 卡住了 。观察发现在第一次执行 flutter -h 命令的时候会去执行一些后台的操作(比如git)，所以第一次执行的时候会需要等待一段时间。 这个时候应该能展示flutter的命令帮助： 检查flutter环境在安装环境的过程中，Flutter官方提供了一个依赖检查的命令 flutter doctor ，可以查看到哪些依赖项或程序没有安装成功。 1$ flutter doctor 另外，该命令的 -v 选项在开发过程中也非常有帮助，执行 flutter doctor -v 查看。 第一次运行时间会有点长(所以。。。如果看到没反应的话千万别慌，等等就好了；另外，如果你是安装最新的flutter版本，在执行 flutter -h 时卡住了，那么在执行 flutter doctor 时则不会了)，它会去下载相关的依赖项并自行编译。执行结果： 12345678910111213141516171819202122232425262728293031➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[!] Android toolchain - develop for Android devices ✗ No valid Android SDK platforms found in /usr/local/Caskroom/android-platform-tools/latest/platforms. Directory was empty.[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ Xcode requires additional components to be installed in order to run. Launch Xcode and install additional required components when prompted. ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[!] Android Studio (not installed)[!] VS Code (version 1.31.1)[!] Connected device ! No devices available! Doctor found issues in 5 categories. 通过上面的提示信息，可以看到 Android toolchain 或 iOS toolchain 是必须安装其一的。这里我是都要安装，毕竟两个平台都想要体验一下的。 开发工具呢除了之前 官方 的 Android Studio 和 XCode 之前，Flutter非常推荐通过轻量级的 VS Code 来进行开发。 配置VS Code安装VS Code ,安装1.20.1或更高版本. 安装Flutter插件 启动 VS Code 调用 View &gt; Command Palette… 输入 install, 然后选择 Extensions: Install Extension action 在搜索框输入 flutter , 在搜索结果列表中选择 Flutter, 然后点击 Install(会自动附带安装好 Dart 插件) 选择 OK 重新启动 VS Code 通过Flutter Doctor验证您的设置 调用 View &gt; Command Palette… 输入 doctor, 然后选择 Flutter: Run Flutter Doctor 选项 查看 “OUTPUT” 窗口中的输出是否有问题 运行 flutter doctor 查看结果： 12345678910111213141516171819202122232425262728➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[!] Android toolchain - develop for Android devices ✗ No valid Android SDK platforms found in /usr/local/Caskroom/android-platform-tools/latest/platforms. Directory was empty.[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[!] Android Studio (not installed)[✓] VS Code (version 1.31.1)[✓] Connected device (1 available)! Doctor found issues in 3 categories. 可以看到 [✓] VS Code (version 1.31.1) 一项已经打钩了。 起步: 配置编辑器 - Flutter中文网 创建Flutter项目通过 VS Code 创建Flutter项目非常简单。直接调出VS Code的命令模式 Cmd(Control) + Shift + P 或者选择菜单 View &gt; Command Palette… 输入 flutter new 选择 Flutter: New Project 选项，回车，输入项目目录名称，会让你选择项目保存目录，然后等待自动初始化项目。 Android环境配置Android toolchain 中要求必须安装好 Android SDK ，而 Android SDK 的安装方法常见的有两种： 通过安装 Android Studio 会自动给安装好 Android SDK ,这种方法操作起来比较简单，基本上 Android Studio 都帮你配置好了； 直接下载 Android SDK 安装包，但需要自己去手动配置，而该配置过程稍显复杂； 虽然开发工具上面已经配置了 VS Code也就没必要再安装 Android Studio 了，不过为了方便快捷，这里我选择采用第一种方式来安装。 这里需要注意的是：最好自备 梯子 ，有些Android依赖包下载的过程中可能会由于网络原因需要多次重试。 安装 Android Studio 及配置打开官网 ，会直接根据当前系统显示推荐下载版本： 直接点开安装即可。结果弹出了一个错误页面： 出现这个错误的原因是：在第一次安装AS，启动后，检测到电脑没有安装 Android SDK。 相应的解决方法是直接点击 Cancel 选项，在后续的界面中再安装SDK。 点击 Next 后，我这里选择的是 Custom （自定义）选项。 可以看到 Android SDK 是默认勾选的。另外两项我这里全部勾选上了。还可以在这里选择自定义安装目录。 下一页是Android模拟器的内存设置： SDK Path 默认为 /Users/xyz/Library/Android/sdk 。 然后就是等待下载安装的过程： 由于某些资源包是访问的 google.com 网址，如果没有 梯子 ，是需要等待很久。。。很久。。。的。 等待安装完成后，再次查看： 123456789101112131415161718192021222324252627282930➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[!] Android toolchain - develop for Android devices (Android SDK 28.0.3) ✗ Android licenses not accepted. To resolve this, run: flutter doctor --android-licenses[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[✓] Android Studio (version 3.3) ✗ Flutter plugin not installed; this adds Flutter specific functionality. ✗ Dart plugin not installed; this adds Dart specific functionality.[✓] VS Code (version 1.31.1)[!] Connected device ! No devices available! Doctor found issues in 3 categories. 解决 Android licenses 问题看上面的提示，这里不得不夸赞一下Flutter工具的🐂🍺了。有什么问题直接在下面显示并给出解决方法，不会让一些小白再需要去网上搜索了。 看上面的错误提示： 12[!] Android toolchain - develop for Android devices (Android SDK 28.0.3) ✗ Android licenses not accepted. To resolve this, run: flutter doctor --android-licenses 直接执行命令： 123456➜ flutter doctor --android-licensesWarning: File /Users/xyz/.android/repositories.cfg could not be loaded..6 of 6 SDK package licenses not accepted. 100% Computing updates...Review licenses that have not been accepted (y/N)?...... 按照提示，一直输入 y 即可。直到看到： 1All SDK package licenses accepted 就说明配置成功了。再次查看： 1234567891011121314151617181920212223242526272829➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[✓] Android toolchain - develop for Android devices (Android SDK 28.0.3)[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[✓] Android Studio (version 3.3) ✗ Flutter plugin not installed; this adds Flutter specific functionality. ✗ Dart plugin not installed; this adds Dart specific functionality.[✓] VS Code (version 1.31.1)[!] Connected device ! No devices available! Doctor found issues in 2 categories. 发现 [✓] Android toolchain 配置成功了。 安装Flutter插件看上面的错误提示： 123[✓] Android Studio (version 3.3) ✗ Flutter plugin not installed; this adds Flutter specific functionality. ✗ Dart plugin not installed; this adds Dart specific functionality. 看提示，需要在 Android Studio 中安装两个必要的插件：Flutter plugin 和 Dart plugin 打开 Android Studio，可以不用新建项目，直接选择菜单栏中的 Android Studio – Preferences – 选择或者搜索 Plugins 菜单 – 然后搜索 Flutter 插件，可以看到会自动提示安装依赖的 Dart 插件： 之后，需要重启。 再次查看： 123456789101112131415161718192021222324252627➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[✓] Android toolchain - develop for Android devices (Android SDK 28.0.3)[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[✓] Android Studio (version 3.3)[✓] VS Code (version 1.31.1)[!] Connected device ! No devices available! Doctor found issues in 2 categories. unable to access android sdk add-on list - 薛瑄的博客 - CSDN博客 创建Flutter项目使用 Android Studio 创建 Flutter 项目也非常便捷。直接选择启动页中的 Start a new Flutter project 菜单，然后选择 Flutter Application – Next – 输入 Project name 及保存目录后，即可初始化一个 Flutter 项目。 连接Android真机运行上面 Android 的环境已经配置好了，我就有些迫不及待的想要在手机上运行了。 跑起来连接上安卓手机，开始运行 flutter run 命令： 1234567➜ flutter run No connected devices.Run &apos;flutter emulators&apos; to list and start any available device emulators.If you expected your device to be detected, please run &quot;flutter doctor&quot; to diagnosepotential issues, or visit https://flutter.io/setup/ for troubleshooting tips. 结果却提示 No connected devices 。根据提示，执行： 123456789101112➜ flutter emulators2 available emulators:Nexus_5X_API_28_x86 • Nexus 5X • Google • Nexus 5X API 28 x86apple_ios_simulator • iOS Simulator • AppleTo run an emulator, run &apos;flutter emulators --launch &lt;emulator id&gt;&apos;.To create a new emulator, run &apos;flutter emulators --create [--name xyz]&apos;.You can find more information on managing emulators at the links below: https://developer.android.com/studio/run/managing-avds https://developer.android.com/studio/command-line/avdmanager 按照提示，执行 flutter emulators --launch &lt;emulator id&gt; 命令: 123456➜ flutter run -d Nexus_5XNo devices found with name or id matching &apos;Nexus_5X&apos;➜ flutter run -d Nexus_5X_API_28_x86No devices found with name or id matching &apos;Nexus_5X_API_28_x86&apos; 结果仍然是 找不到设备。 dart - Flutter - Command line - Emulator- Device not found - Stack Overflow 到这里的结果就是： 安卓手机发现不了设备。 Android模拟器一直连接失败，即使连接上了，在安装app的时候也会提示 no devices 的信息。好不容易安装成功后，发现网上提到的 hot reload 的功能却用不了。Android Studio 上的热加载 ⚡️ 按钮也是灰色的。 ios模拟器安装启动正常，而且热更新的功能也能正常使用。 后来再次查看了官方的安装文档，恍然大悟之间，才发现我忘记操作了一步：我只安装了 Android Studio ，但并没有配置 ANDROID_HOME 环境变量，而是直接就开始安装App了。 见官方文档：Set up your Android device - Flutter 配置 ANDROID_HOME 环境变量查看当前环境变量： 打开 AS ，找到 Preferences – Appearance &amp; Behavior – System Settings – Android SDK – 在右侧找到 Android SDK Location – 复制 在命令行中输入 echo $ANDROID_HOME，发现当前值确实为空。 然后在 $HOME/.bash_profile 中加入下列代码: 123export ANDROID_HOME=$HOME/Library/Android/sdkexport PATH=$&#123;PATH&#125;:$&#123;ANDROID_HOME&#125;/toolsexport PATH=$&#123;PATH&#125;:$&#123;ANDROID_HOME&#125;/platform-tools 重启命令行窗口或者执行 source $HOME/.bash_profile or source $HOME/.zshrc 刷新配置。 配置Android模拟器打开 AS, Android Studio &gt; Tools &gt; Android &gt; AVD Manager and select Create Virtual Device . （更多的去参考一下文档去吧）&gt; Set up the Android emulator - Flutter 后来发现，如果没有配置，是会启动一个默认的模拟器。 在上面的操作中，由于我太着急，直接就运行程序了，所以默认给我创建了一个 Nexus 5X 的模拟器。 ADB server didn’t ACK将手机通过usb连接，通过 adb devices 命令来查看设备连接状态: 12345➜ adb devicesList of devices attachedadb server version (40) doesn&apos;t match this client (39); killing...ADB server didn&apos;t ACK... 结果却报了 ADB server didn&#39;t ACK 的错误。 相应的解决方法如下： 查看端口被占用情况：在终端输入 lsof -i tcp:5037 查看占用 5037 端口的pid号 1234➜ lsof -i tcp:5037COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEadb 38752 xyz 3u IPv4 0xec93d79cdb5a9d91 0t0 TCP localhost:49653-&gt;localhost:5037 (CLOSED)adb 38752 xyz 11u IPv4 0xec93x80a5492d411 0t0 TCP localhost:5037 (LISTEN) 2.去任务管理器（应用程序-其他-活动监视器）找到对应pid号(这里是38752)的进程，并关闭 再次查看： 12345➜ adb devicesList of devices attachedadb server version (40) doesn&apos;t match this client (39); killing...* daemon started successfullyFA6AB0311758 device 现在，设备已经正常连接了。 【MAC版】Android ADB server didn’t ACK failed to start daemon 解决办法 - AZZ的博客 - CSDN博客 Android license status unknown12345678➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[!] Android toolchain - develop for Android devices (Android SDK 28.0.3) ✗ Android license status unknown.[✓] Android Studio (version 3.3)。。。。。。 解决方法是：再执行一次 flutter doctor --android-licenses 命令，在提示后输入 y 确认，然后再通过 flutter doctor 查看。 ✗ Android license status unknown. · Issue #16025 · flutter/flutter Android license status unknown - Code is Poetry - 开源中国 某些安卓手机需要解锁对于某些安卓设备默认情况下都没有启用开发者调试的功能，这次我换用一台小米手机来进行真机调试。 当有多个设备连接时，可以通过 -d &lt;deviceId&gt; 连接指定设备，或者使用 -d all 连接所有设备来调试。其中 &lt;deviceId&gt; 支持模糊匹配设备名称： 123456789101112131415161718192021➜ flutter runMore than one device connected; please specify a device with the &apos;-d &lt;deviceId&gt;&apos; flag, or use &apos;-d all&apos; to acton all devices.Redmi Note 4X • a1529b418604 • android-arm64 • Android 7.0 (API 24)Android SDK built for x86 • emulator-5554 • android-x86 • Android 9 (API 28) (emulator)➜ flutter run -d RedmiLaunching lib/main.dart on Redmi Note 4X in debug mode...Initializing gradle... 1.0sResolving dependencies... 7.7sGradle task &apos;assembleDebug&apos;... Gradle task &apos;assembleDebug&apos;... Done 10.4sBuilt build/app/outputs/apk/debug/app-debug.apk.Installing build/app/outputs/apk/app.apk... 8.1sError: ADB exited with exit code 1adb: failed to install /Users/xyz/Learn/flutter/hello_world/build/app/outputs/apk/app.apk: Failure[INSTALL_FAILED_USER_RESTRICTED: Install canceled by user]Error launching application on Redmi Note 4X. 可以看到，我这里设备选择成功了，但当运行到 Install 阶段报错了。 这里，需要更改一下手机设置，以小米手机为例： 打开手机的开发者模式: 设置 – 我的设备 – 全部参数 – MIUI版本 – 连续点击7下即可 再次点击 设置 – 更多设置 – 开发者选项 – 将 开启开发者选项 启用 、 USB调试 启用 、 USB安装 启用 再次执行 flutter run 命令进行安装，此时手机上会弹出 USB安装提示 的命令，选择 允许 即可 12345678910111213➜ flutter runLaunching lib/main.dart on Redmi Note 4X in debug mode...Initializing gradle... 0.8sResolving dependencies... 1.5sGradle task &apos;assembleDebug&apos;... Gradle task &apos;assembleDebug&apos;... Done 1.5sBuilt build/app/outputs/apk/debug/app-debug.apk.Installing build/app/outputs/apk/app.apk... 14.6sSyncing files to device Redmi Note 4X... 1.6s🔥 To hot reload changes while running, press &quot;r&quot;. To hot restart (and rebuild state), press &quot;R&quot;.An Observatory debugger and profiler on Redmi Note 4X is available at: http://127.0.0.1:61766/For a more detailed help message, press &quot;h&quot;. To detach, press &quot;d&quot;; to quit, press &quot;q&quot;. INSTALL_FAILED_USER_RESTRICTED : android studio using redmi 4 device 最终运行再次检查状态： 1234567891011121314151617181920212223242526➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[✓] Android toolchain - develop for Android devices (Android SDK 28.0.3)[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[✓] Android Studio (version 3.3)[✓] VS Code (version 1.31.1)[✓] Connected device (1 available)! Doctor found issues in 1 category. 打开 VS Code, 在终端中运行 flutter run 命令： 12345678910111213➜ flutter runLaunching lib/main.dart on Pixel in debug mode...Initializing gradle... 1.1sResolving dependencies... 8.2sGradle task &apos;assembleDebug&apos;... Gradle task &apos;assembleDebug&apos;... Done 12.4sBuilt build/app/outputs/apk/debug/app-debug.apk.Installing build/app/outputs/apk/app.apk... 3.4sSyncing files to device Pixel... 1.5s🔥 To hot reload changes while running, press &quot;r&quot;. To hot restart (and rebuild state), press &quot;R&quot;.An Observatory debugger and profiler on Pixel is available at: http://127.0.0.1:49724/For a more detailed help message, press &quot;h&quot;. To detach, press &quot;d&quot;; to quit, press &quot;q&quot;. 可以看到，现在才是正常运行的状态。已经成功的连接上了我的 Pixel 手机，同时在手机端，已经打开了示例app的界面。输入 r 来实现热更新。 IOS环境配置查看当前的状态： 1234567891011121314151617181920212223242526➜ flutter doctorDoctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[✓] Android toolchain - develop for Android devices (Android SDK 28.0.3)[!] iOS toolchain - develop for iOS devices (Xcode 10.1) ✗ libimobiledevice and ideviceinstaller are not installed. To install with Brew, run: brew update brew install --HEAD usbmuxd brew link usbmuxd brew install --HEAD libimobiledevice brew install ideviceinstaller ✗ ios-deploy not installed. To install with Brew: brew install ios-deploy ✗ CocoaPods not installed. CocoaPods is used to retrieve the iOS platform side&apos;s plugin code that responds to your plugin usage on the Dart side. Without resolving iOS dependencies with CocoaPods, plugins will not work on iOS. For more info, see https://flutter.io/platform-plugins To install: brew install cocoapods pod setup[✓] Android Studio (version 3.3)[✓] VS Code (version 1.31.1)[✓] Connected device (1 available)! Doctor found issues in 1 category. 依照上面的提示信息，依次执行，安装 iOS toolchain 所有相关依赖。 连接IPhone真机运行No valid code signing certificates were found没想到第一次运行却报错了： 12345678910111213141516171819202122232425262728➜ flutter runLaunching lib/main.dart on xyz的iPhone in debug mode...════════════════════════════════════════════════════════════════════════════════No valid code signing certificates were foundYou can connect to your Apple Developer account by signing in with your Apple IDin Xcode and create an iOS Development Certificate as well as a Provisioning Profile for your project by: 1- Open the Flutter project&apos;s Xcode target with open ios/Runner.xcworkspace 2- Select the &apos;Runner&apos; project in the navigator then the &apos;Runner&apos; target in the project settings 3- In the &apos;General&apos; tab, make sure a &apos;Development Team&apos; is selected. You may need to: - Log in with your Apple ID in Xcode first - Ensure you have a valid unique Bundle ID - Register your device with your Apple Developer Account - Let Xcode automatically provision a profile for your app 4- Build or run your project again 5- Trust your newly created Development Certificate on your iOS device via Settings &gt; General &gt; Device Management &gt; [your new certificate] &gt; TrustFor more information, please visit: https://developer.apple.com/library/content/documentation/IDEs/Conceptual/ AppDistributionGuide/MaintainingCertificates/MaintainingCertificates.htmlOr run on an iOS simulator without code signing════════════════════════════════════════════════════════════════════════════════No development certificates available to code sign app for device deployment 按照上面的提示，用 Xcode 打开示例项目中的 ios/Runner.xcworkspace 这个文件， 选择项目菜单 Runner – General 选项 ，可以看到 Signing 中的 Status 提示错误信息： 12Signing for &quot;Runner&quot; requires a development team.Select a development team in the projct editor. 点击 Team 选项的 Add Account... 按钮，登录 Apple ID ，没有则需要创建一个。回到 General 界面，选择 Team 名称。等待验证。 No profiles for xxx were found现在又提示下面的错误： 在 VSCode中执行 flutter run 命令： 123456789101112131415161718192021222324252627282930➜ flutter runLaunching lib/main.dart on xyz的iPhone in debug mode...Automatically signing iOS for device deployment using specified development team in Xcode project:9Y41Q9PF28Starting Xcode build... Xcode build done. 1.3sFailed to build iOS appError output from Xcode build:↳ ** BUILD FAILED **Xcode&apos;s output:↳ === BUILD TARGET Runner OF PROJECT Runner WITH CONFIGURATION Debug === Code Signing Error: No profiles for &apos;com.example.helloWorld&apos; were found: Xcode couldn&apos;t find any iOS App Development provisioning profiles matching &apos;com.example.helloWorld&apos;. Automatic signing is disabled and unable to generate a profile. To enable automatic signing, pass -allowProvisioningUpdates to xcodebuild. Code Signing Error: Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos; Code Signing Error: Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos; Code Signing Error: Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos;Could not build the precompiled application for the device.It appears that your application still contains the default signing identifier.Try replacing &apos;com.example&apos; with your signing id in Xcode: open ios/Runner.xcworkspaceError launching application on xyz的iPhone. 在 XCode中编译，提示如下错误： 1234567Failed to create provisioning profile. The app ID &quot;com.example.helloWorld&quot; cannot be registered to your development team. Change your bundle identifier to a unique string to try again.No profiles for &apos;com.example.helloWorld&apos; were found: Xcode couldn&apos;t find any iOS App Development provisioning profiles matching &apos;com.example.helloWorld&apos;.Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos;Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos;Code signing is required for product type &apos;Application&apos; in SDK &apos;iOS 12.1&apos; 通过一番查找，在 Stack Overflow 上找到了一个解决方法： 将 Bundle Identifier 的值改变一下，比如在结尾随机加上几个数字。 Failed to create provisioning profile 再次在 VS Code 中运行： 期间需要输入密码。 123456789101112131415161718➜ flutter run Launching lib/main.dart on xyz的iPhone in debug mode...Automatically signing iOS for device deployment using specified development team in Xcode project:9Y41Q9PF28Starting Xcode build... ├─Assembling Flutter resources... 1.3s └─Compiling, linking and signing... 3.4s Xcode build done. 6.2sInstalling and launching... 4.6s⢿2019-02-24 17:17:33.270 ios-deploy[15328:80609] [ !! ] Unable to locate DeviceSupport directory with suffix &apos;Symbols&apos;. This probably means you don&apos;t have Xcode installed, you will need to launch the app manually and logging output will not be shown! 6.8sCould not install build/ios/iphoneos/Runner.app on f1b5b10369882093413772c363995b5cda163c34.Try launching Xcode and selecting &quot;Product &gt; Run&quot; to fix the problem: open ios/Runner.xcworkspaceError launching application on xyz的iPhone. Device is locked使用 XCode编译，提示如下错误： 这个问题是需要在手机端开启允许调试。 依次点击 通用 – 设备管理 – 开发者应用 – 点击开发者账号 – 点击 信任应用 再次在 VS Code 中运行： 1234567891011121314151617➜ flutter run Launching lib/main.dart on xyz的iPhone in debug mode...Automatically signing iOS for device deployment using specified development team in Xcode project:9Y41Q9PF28Starting Xcode build... ├─Assembling Flutter resources... 1.4s └─Compiling, linking and signing... 4.6s Xcode build done. 7.7sInstalling and launching... 6.1s12.0sSyncing files to device xyz的iPhone... 1.7s🔥 To hot reload changes while running, press &quot;r&quot;. To hot restart (and rebuild state), press &quot;R&quot;.An Observatory debugger and profiler on xyz的iPhone is available at: http://127.0.0.1:1024/For a more detailed help message, press &quot;h&quot;. To detach, press &quot;d&quot;; to quit, press &quot;q&quot;. 这次能够正常运行了，也支持热加载调试。 Flutter版本更新对于Flutter的版本更新，看最近的形势迭代频率越来越快，而更新操作也很简单： 123456789101112131415161718➜ flutter doctor ╔════════════════════════════════════════════════════════════════════════════╗ ║ A new version of Flutter is available! ║ ║ ║ ║ To update to the latest version, run &quot;flutter upgrade&quot;. ║ ╚════════════════════════════════════════════════════════════════════════════╝Doctor summary (to see all details, run flutter doctor -v):[✓] Flutter (Channel stable, v1.0.0, on Mac OS X 10.14.3 18D109, locale zh-Hans-CN)[✓] Android toolchain - develop for Android devices (Android SDK 28.0.3)[✓] iOS toolchain - develop for iOS devices (Xcode 10.1)[✓] Android Studio (version 3.3)[✓] VS Code (version 1.31.1)[!] Connected device ! No devices available! Doctor found issues in 1 category. 直接按照官方给出的提示执行 flutter upgrade 即可。 至此，Android和iOS的开发环境配置基本ok了。]]></content>
      <categories>
        <category>Flutter之旅</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打开新世界的大门 -- Flutter介绍]]></title>
    <url>%2F2019%2F03%2F08%2Fflutter-get-start%2F</url>
    <content type="text"><![CDATA[Flutter是一个由谷歌开发的开源移动应用软件开发工具包，用于为Android和iOS开发应用，同时也将是Google Fuchsia下开发应用的主要工具。 系列文章列表 打开新世界的大门 – Flutter介绍 | IT范儿 兵马未动，粮草先行 – Flutter开发环境配置 | IT范儿 磨刀不误砍柴工 – Flutter开发技巧 | IT范儿]]></content>
      <categories>
        <category>Flutter之旅</category>
      </categories>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Golang下json.Marshal默认对html标签转义问题]]></title>
    <url>%2F2018%2F12%2F27%2Fgolang-json-marshal-for-html%2F</url>
    <content type="text"><![CDATA[最近在用Golang下的json对含有html标签的Object序列化的时候，发现Golang会默认对html标签做转义处理。比如我的一段html代码： 123456789101112131415161718&lt;div id=&quot;choose-results&quot; class=&quot;li&quot; style=&quot;display:none&quot;&gt;&lt;div class=&quot;dt&quot;&gt;已选择&lt;/div&gt;&lt;div class=&quot;dd&quot;&gt;&lt;/div&lt;/div&gt; &lt;div id=&quot;choose-luodipei&quot; class=&quot;choose-luodipei li&quot; style=&quot;display&lt;div class=&quot;dt&quot;&gt;送装服务&lt;/div&gt; &lt;div class=&quot;dd&quot;&gt;&lt;/div&gt; &lt;/div&gt;&lt;div id=&quot;choose-suits&quot; class=&quot;li choose-suits&quot; style=&quot;display:none&quot;&gt; &lt;div class=&quot;dt&quot;&gt;套&amp;#x3000;&amp;#x3000;装&lt;/div&gt; &lt;div class=&quot;dd clearfix&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id=&quot;choose-gift&quot; class=&quot;choose-gift li&quot; style=&quot;display: none;&quot;&gt; &lt;div class=&quot;dt&quot;&gt;搭配赠品&lt;/div&gt; &lt;div class=&quot;dd clearfix&quot;&gt; &lt;div class=&quot;gift J-gift&quot; clstag=&quot;shangpin|keycount|product|dapeizengpin&quot;&gt; &lt;i class=&quot;sprite-gift J-popup&quot;&gt;&lt;/i&gt;&lt;span class=&quot;gift-tips&quot;&gt;选择搭配赠品(共&lt;em&gt;0&lt;/em&gt;个)&lt;/span&gt; &lt;/div&gt; &lt;!--choosed--&gt; &lt;div class=&quot;J-gift-selected hide&quot;&gt; &lt;div class=&quot;gift choosed J-gift-choosed&quot;&gt;&lt;/div&gt; &lt;a href=&quot;#none&quot; class=&quot;gift-modify J-popup&quot; clstag=&quot;shangpin|keycount|product|zengpin-genggai&quot;&gt;更改&lt;/a&gt; 在经过 json.Marshal() 处理之后就变成了： 1\u003cdiv id=\&quot;choose-results\&quot; class=\&quot;li\&quot; style=\&quot;display:none\&quot;\u003e\u003cdiv class=\&quot;dt\&quot;\u003e已选择\u003c/div\u003e\u003cdiv class=\&quot;dd\&quot;\u003e\u003c/div\u003e\u003c/div\u003e\n \u003c/div\u003e\n\n \n \u003cdiv id=\&quot;choose-luodipei\&quot; class=\&quot;choose-luodipei li\&quot; style=\&quot;display:none\&quot;\u003e\n \u003cdiv class=\&quot;dt\&quot;\u003e送装服务\u003c/div\u003e\n \u003cdiv class=\&quot;dd\&quot;\u003e\u003c/div\u003e\n \u003c/div\u003e\n \u003cdiv id=\&quot;choose-suits\&quot; class=\&quot;li choose-suits\&quot; style=\&quot;display:none\&quot;\u003e\n \u003cdiv class=\&quot;dt\&quot;\u003e套\u0026#x3000;\u0026#x3000;装\u003c/div\u003e\n \u003cdiv class=\&quot;dd clearfix\&quot;\u003e\u003c/div\u003e\n \u003c/div\u003e\n \u003cdiv id=\&quot;choose-gift\&quot; class=\&quot;choose-gift li\&quot; style=\&quot;display: none;\&quot;\u003e\n \u003cdiv class=\&quot;dt\&quot;\u003e搭配赠品\u003c/div\u003e\n \u003cdiv class=\&quot;dd clearfix\&quot;\u003e\n \u003cdiv class=\&quot;gift J-gift\&quot; clstag=\&quot;shangpin|keycount|product|dapeizengpin\&quot;\u003e\n \u003ci class=\&quot;sprite-gift J-popup\&quot;\u003e\u003c/i\u003e\u003cspan class=\&quot;gift-tips\&quot;\u003e选择搭配赠品(共\u003cem\u003e0\u003c/em\u003e个)\u003c/span\u003e\n \u003c/div\u003e\n \u003c!--choosed--\u003e\n \u003cdiv class=\&quot;J-gift-selected hide\&quot;\u003e\n \u003cdiv class=\&quot;gift choosed J-gift-choosed\&quot;\u003e\u003c/div\u003e\n \u003ca href=\&quot;#none\&quot; class=\&quot;gift-modify J-popup\&quot; clstag=\&quot;shangpin|keycount|product|zengpin-genggai\&quot;\u003e更改\u003c/a\u003e\n 通过上网搜索，发现Golang为我们提供了一个 SetEscapeHTML() 方法，默认情况下该值为 true ，我们只要将其设置为 false 即可实现不对html标签转义。 我的封装方法如下： 123456789101112131415161718package utilsimport ( &quot;bytes&quot; &quot;encoding/json&quot;)// json.Marshal方法优化，不对html做转义处理func MarshalHTML(v interface&#123;&#125;) ([]byte, error) &#123; var buf bytes.Buffer enc := json.NewEncoder(&amp;buf) enc.SetEscapeHTML(false) err := enc.Encode(v) if err != nil &#123; return nil, err &#125; return buf.Bytes(), nil&#125; go - How to stop json.Marshal from escaping &lt; and &gt;? - Stack Overflow]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么我要放弃Python而转投Golang]]></title>
    <url>%2F2018%2F12%2F21%2Fwhy-me-give-up-python-to-golang%2F</url>
    <content type="text"><![CDATA[扎心了，老铁！！！]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fiddler抓包时HTTPS证书报错问题]]></title>
    <url>%2F2018%2F12%2F13%2Ffiddler-cannot-create-the-key-of-the-subject-joesoft-failed%2F</url>
    <content type="text"><![CDATA[今天项目中通过Fiddler抓包的时候，发现遇到 https 的请求无法抓取到，在Host一栏显示的是 Tunnel to 。我的第一感觉推测是Fiddler的证书出问题了。 当在Fiddler中选择 Tools – Fiddler Options – HTTPS 中的选项移除证书的时候，却发现报错了。 错误信息为： Can&#39;t create the key of the subject (&#39;JoeSoft&#39;) Failed 如下面的形式： 123456789101112--------------------------- Unable to Generate Certificate --------------------------- Creation of the interception certificate failed. makecert.exe returned -1. Results from C:\Program Files\Fiddler2\MakeCert.exe -ss my -n &quot;CN=DO_NOT_TRUST_FiddlerRoot, O=DO_NOT_TRUST, OU=Created by http://www.fiddler2.com&quot; -eku 1.3.6.1.5.5.7.3.1 -r -cy authority -a sha1 Error: Can&apos;t create the key of the subject (&apos;JoeSoft&apos;) Failed ------------------------------------------- 有时候，也可能是下面的错误： 解决方法在网上搜索，找到一种简单粗暴的方式，经测试后确实有效。 在Fiddler的选项中操作移除现有证书–见下面的 移除证书 方法。 退出Fiddler。 打开windows资源管理器，输入 %userprofile%\AppData\Roaming\Microsoft\Crypto\RSA ，回车打开； 将该目录下的文件夹删除即可（删除之前以防出问题可以备份一下）。 然后，就可以为Fiddler重新添加证书了–见下面的 安装证书 方法。 移除证书打开Fiddler，选择 Tools – Fiddler Options – HTTPS 选项， 去掉勾选 Capture HTTPS CONNECTs 的对勾： 此时，窗口中右下角的 Remove Interception Certificates 按钮就可以点击了： 点击移除即可。 另外需要说明一点的是，即使你的证书移除失败了，也要把 Capture HTTPS CONNECTs 一项前面的对勾取消掉，这很关键。 安装证书打开Fiddler，选择 Tools – Fiddler Options – HTTPS 选项， 勾选 Capture HTTPS CONNECTs Decrypt HTTPS traffic 选项，会弹出安装证书文件的提示，点击确定即可安装。 点到 第2步 的时候就会弹出安装证书的弹窗，选择 Yes： 完成后点击最下面的 OK 选项。 然后将Fiddler关闭，再重新打开。 之后，就可以对HTTPS的请求进行抓包了。 相关参考 Creation of the interception certificate failed. - Fiddler on PCs - Fiddler Forum]]></content>
      <tags>
        <tag>数据抓取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang通过Channel实现N个任务并发执行并统一返回结果]]></title>
    <url>%2F2018%2F12%2F12%2Fgolang-task-concurrent-execution-through-channel%2F</url>
    <content type="text"><![CDATA[最近在项目中想要实现一个需求： 在一个过程中，可以实现多个任务并发执行，并同时返回结果 多个任务的入参相同或入参类型相同，返回结果类型相同 设置默认的超时时间，当某一任务执行超时，则返回默认值 举一个例子如：根据一个用户的 userId，任务1 查询用户信息；任务2 查询用户所有订单信息；任务3 查询用户关注的商品信息；三个任务并发执行，并将三个任务的执行结果统一返回。 一个🌰参考自：Golang 中的并发限制与超时控制 - 简书 中的 “超时控制” 示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344func main()&#123; Test()&#125;func Run(task_id, sleeptime, timeout int, ch chan string) &#123; ch_run := make(chan string) go run(task_id, sleeptime, ch_run) select &#123; case re := &lt;-ch_run: ch &lt;- re case &lt;-time.After(time.Duration(timeout) * time.Second): re := fmt.Sprintf(&quot;task id %d, timeout &quot;, task_id) ch &lt;- re &#125;&#125;func run(task_id, sleeptime int, ch chan string) &#123; time.Sleep(time.Duration(sleeptime) * time.Second) ch &lt;- fmt.Sprintf(&quot;task id %d,sleep %d second&quot;, task_id, sleeptime) return&#125;func Test() &#123; input := []int&#123;3, 5, 8&#125; timeout := 8 // 创建N个任务管道，用来接收各个并发任务的完成结果 chs := make([]chan string, len(input)) sTime := time.Now() fmt.Println(&quot;start&quot;) for i, sleeptime := range input &#123; chs[i] = make(chan string) go Run(i, sleeptime, timeout, chs[i]) &#125; // 获取结果 for _, ch := range chs &#123; fmt.Println(&lt;-ch) &#125; eTime := time.Now() fmt.Printf(&quot;finished,Process time %s. Number of task is %d \n&quot;, eTime.Sub(sTime), len(input))&#125; 我的改造我将上面的示例改造成了：将要执行的方法作为参数传入，这样就可以随意传入不同的任务了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687func main()&#123; Test()&#125;func Run(f func(s string, ch chan string), s string, timeout int, cOut chan string) &#123; ch_run := make(chan string) // go run(s, ch_run) go f(s, ch_run) select &#123; case re := &lt;-ch_run: cOut &lt;- re case &lt;-time.After(time.Duration(timeout) * time.Second): re := fmt.Sprintf(&quot;task timeout &quot;) cOut &lt;- re &#125;&#125;// func run(s string, ch chan string) &#123;// time.Sleep(time.Duration(3) * time.Second)// ch &lt;- fmt.Sprintf(&quot;task input %s,sleep %d second&quot;, s, 3)// return// &#125;func aa1(s string, ch chan string) &#123; time.Sleep(time.Duration(3) * time.Second) ch &lt;- fmt.Sprintf(&quot;task1 input %s,sleep %d second&quot;, s, 3)&#125;func aa2(s string, ch chan string) &#123; time.Sleep(time.Duration(5) * time.Second) ch &lt;- fmt.Sprintf(&quot;task2 input %s,sleep %d second&quot;, s, 5)&#125;func aa3(s string, ch chan string) &#123; time.Sleep(time.Duration(10) * time.Second) ch &lt;- fmt.Sprintf(&quot;task3 input %s,sleep %d second&quot;, s, 10)&#125;func Test() &#123; a := synchron(20, &quot;aaa&quot;, aa1, aa2, aa3) fmt.Printf(&quot;result: %v \n&quot;, a)&#125;// timeout: 超时时间// input: 统一入参// args: 方法func synchron(timeout int, input string, args ...func(s string, ch chan string)) []string &#123; // input := []string&#123;&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;&#125; // timeout := 8 // 创建N个任务管道，用来接收各个并发任务的完成结果 chs := make([]chan string, len(args)) defer func() &#123; for _, c := range chs &#123; if c != nil &#123; close(c) &#125; &#125; &#125;() sTime := time.Now() fmt.Println(&quot;start&quot;) for i, f := range args &#123; chs[i] = make(chan string) go Run(f, input, timeout, chs[i]) &#125; resList := []string&#123;&#125; // 获取结果 for _, ch := range chs &#123; v := &lt;-ch fmt.Println(v) resList = append(resList, v) &#125; eTime := time.Now() fmt.Printf(&quot;finished,Process time %s. Number of task is %d \n&quot;, eTime.Sub(sTime), len(args)) // 将多个异步任务同时返回 return resList&#125; 执行结果： 123456789101112131415161718# timeout 20 input &quot;aaa&quot;➜ go run main.gostarttask1 input aaa,sleep 3 secondtask2 input aaa,sleep 5 secondtask3 input aaa,sleep 10 secondfinished,Process time 10.0028964s. Number of task is 3result: [task1 input aaa,sleep 3 second task2 input aaa,sleep 5 second task3 input aaa,sleep 10 second]# timeout 7 input &quot;aaa&quot;➜ go run main.gostarttask1 input aaa,sleep 3 secondtask2 input aaa,sleep 5 secondtask timeoutfinished,Process time 7.001273493s. Number of task is 3result: [task1 input aaa,sleep 3 second task2 input aaa,sleep 5 second task timeout ] 你的扩展当然，我上面只是实现了一种情况，还可以修改成为不同的方法传入相应类型的参数等等。 目前我对Golang的Channel了解的不深，只是想要实现类似的效果就在网上找了一下，后期会再深入去学习。 相关参考 这个讲的挺全的: Golang 中的并发限制与超时控制 - 简书 你可以从一个简单的例子入手: golang 多个routine之间的同步 - 翔云 - CSDN博客 尝试封装一个并发执行器: golang 并发之后同步 - @奮 鬥@的专栏 - CSDN博客 Channel详解: Go Channel 详解 | 鸟窝]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git主分支有更改后如何合并提交]]></title>
    <url>%2F2018%2F11%2F30%2Fhow-to-merge-when-main-branch-changed%2F</url>
    <content type="text"><![CDATA[公司里的项目部署在私有的GitLab站点上，项目的 master 分支不能直接进行 git push 操作，只能通过将其他分支合并到 master 分支来上线新功能。 比如我基于 master 分支创建了一个名为 dev-1130 的分支做功能开发。当功能开发完成后需要合并到 master 分支，却发现 master 分支上已经有同事提交了自己的分支，提示有代码合并冲突，不能自动合并。 那么这种情况下该如何合并当前的分支呢？ 其实解决方法有很多，下面说一种。其他的方法后续补充。 第一种方法查看当前分支状态123➜ git statusOn branch dev-1130nothing to commit, working tree clean 拉取当前分支最新代码12➜ git pull origin dev-1130:dev-1130Already up to date. 切换到master分支123➜ git checkout masterSwitched to branch &apos;master&apos;Your branch is up to date with &apos;origin/master&apos;. 拉取master分支最新代码12➜ git pull origin master:masterAlready up to date. 手动合并dev-1130到master分支1234➜ git merge dev-1130Auto-merging hello_world/hello.pyCONFLICT (content): Merge conflict in hello_world/hello.pyAutomatic merge failed; fix conflicts and then commit the result. 提示代码冲突，手动解决提交更改1234➜ git add .➜ git commit -m &quot;解决冲突&quot;[master 9c7471f] 解决冲突 查看当前分支状态1234➜ git statusOn branch masterYour branch is ahead of &apos;origin/master&apos; by 3 commits. (use &quot;git push&quot; to publish your local commits) 将当前master分支提交到远端的dev-1130分支注意这里，是将本地我们解决冲突合并之后的 master 分支代码提交到远端的 dev-1130 分支上。 12345678➜ git push origin master:dev-1130Counting objects: 4, done.Delta compression using up to 8 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (4/4), 548 bytes | 548.00 KiB/s, done.Total 4 (delta 2), reused 0 (delta 0)To mycompany_gitlab:Leafney/hello_world.git 49c7684..9c7471f master -&gt; dev-1130 拉取远端的dev-1130分支到本地的dev-1130分支1234➜ git pull origin dev-1130:dev-1130From mycompany_gitlab:Leafney/hello_world 49c7684..9c7471f dev-1130 -&gt; dev-1130Already up to date. 至此，操作完毕。]]></content>
      <categories>
        <category>Git操作系列</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fork别人的项目源作者更新后如何同步更新]]></title>
    <url>%2F2018%2F11%2F29%2Fsynchronize-project-updated-after-fork%2F</url>
    <content type="text"><![CDATA[fork项目同步更新 我之前 fork 了 https://github.com/imroc/req 这个项目，今天看到这个项目进行了一些更新操作。 该项目的最新更新： 我的更新： 更新操作如下： 回到我fork过来的项目主页面，点击 New pull request 按钮： 在进入的界面中，将左侧的 base fork 选为自己的仓库，源fork项目作为右边的 head fork ： 当选择完左侧 base fork 后，界面会变成如下： 此时，点击右上角的 compare across forks ，下面就会出现可选择的选框： 这时，再将左侧选择为自己的仓库，右侧选择为源fork项目： 可以看到，下面已经显示出了源作者的变更操作。 点击 Create pull request 按钮，填写提交的信息： 之后，点击 Create pull request 即可。 至此，就将源项目的变更在自己的项目下作了一个 Pull requests 的合并请求。点击下面的 Merge pull request ,完成合并。 修改了项目提交更新未完待续。。。 相关参考 Github上怎么修改别人的项目并且提交给原作者！图文并茂！ - 刘桂林的博客 - CSDN博客 github fork 别人的项目源作者更新后如何同步更新 - zhongzunfa的专栏 - CSDN博客]]></content>
      <categories>
        <category>Git操作系列</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang http malformed HTTP response 探究]]></title>
    <url>%2F2018%2F11%2F28%2Fgolang-http-error-malformed-http-response%2F</url>
    <content type="text"><![CDATA[问题处理请求返回内容的时候， 遇到 error malformed HTTP response &quot;&lt;html&gt;&quot; 异常信息 探究根据目前的测试情况，得出的结论是： 在请求返回结果为 html 页面时，proxy 需要带上 http:// 前缀。 在请求返回结果为 api 接口时，proxy 需要去掉 http:// 前缀。 待后续多次验证。 经验证： 以上结论 错误。 请求网址 返回结果类型 proxy格式 proxy是否带http 请求结果 http://ip38.com/ html http://27.203.219.181:8060 是 ok，已验证 http://ip38.com/ html 27.203.219.181:8060 否 请求正常，代理未生效,已验证 https://www.cnblogs.com/ html http://27.203.219.181:8060 是 error,malformed HTTP response &quot;&lt;html&gt;&quot;,已验证 https://www.cnblogs.com/ html 27.203.219.181:8060 否 ok，已验证 https://p.3.cn/prices/mgets json http://27.203.219.181:8060 是 error,malformed HTTP response &quot;&lt;html&gt;&quot;,已验证 https://p.3.cn/prices/mgets json 27.203.219.181:8060 否 ok,已验证 即： 请求 http://ip38.com/ 时，需要使用 proxy格式为 http://27.203.219.181:8060 才能访问成功。 请求 https://www.cnblogs.com/ 时，需要使用proxy格式为 27.203.219.181:8060 才能访问成功。 请求 https://p.3.cn/prices/mgets 时，需要使用proxy格式为 27.203.219.181:8060 才能访问成功。 我的一种解法项目中在测试使用代理的代码段： 代码中的 req.XReq() 是对 imroc/req: a golang http request library for humans 的封装。 123456789101112131415161718192021222324252627282930313233343536373839404142 // 使用了代理ip //为防止使用代理ip请求超时太长，设置默认超时时间为30s if _, ok := rh[&quot;time-out&quot;]; !ok &#123; // 请求头中 time-out 参数不存在 rh[&quot;time-out&quot;] = 30 &#125; is_malformedHttp := falseHandleProxy: for _, ag := range rAgents &#123; // 表示在使用proxy ip时，是否遇到返回错误信息为 malformed HTTP response &quot;&lt;html&gt;&quot; 的情况 if is_malformedHttp &#123; // 将代理ip的 http:// 去掉 ag = GetHostAndPort(ag) fmt.Printf(&quot;[info] remove http for proxy ip: %s .\n&quot;, ag) &#125; rh[&quot;proxy&quot;] = ag fmt.Printf(&quot;[info] use proxy to request: %s .\n&quot;, ag) resData, errMsg = req.XReq(rUrl, rh, rp) if errMsg != nil &#123; fmt.Printf(&quot;[info] the proxy result error: %s .\n&quot;, errMsg.Error()) if !is_malformedHttp &#123; // 当 is_malf 为 false时，才对 mailformed http response 处理 if strings.Contains(errMsg.Error(), &quot;malformed HTTP response&quot;) &#123; fmt.Printf(&quot;[error] the proxy ip format error: %s .\n&quot;, errMsg.Error()) is_malformedHttp = true time.Sleep(1 * time.Second) goto HandleProxy &#125; &#125; continue &#125; else &#123; fmt.Printf(&quot;[info] the proxy ok %s .\n&quot;, ag) break &#125; &#125; 实现逻辑是： 当传入的代理ip格式为 http://27.203.219.181:8060 ，先发起请求，如果请求报错，判断错误信息是否包含 malformed HTTP response ，如果包含，则认为是代理ip的格式错误，需要对代理ip处理。 通过 goto 语句，直接跳回到 for 循环之外，对代理ip做格式化处理，截取到 host:port 的格式再次去请求。 为了防止第二次请求时再遇到 malformed HTTP response 错误的话，又会 goto 到 for 循环之外，所以这里加一个标记 is_malformedHttp ，标明代理ip出现格式问题时是否被处理过。 后经测试验证，这种方法无效。 验证结果： 当代理格式为 [&quot;http://192.168.1.100:8080&quot;,&quot;192.168.1.120:8080&quot;] 时，proxy1第一次请求异常，经“处理”后请求仍异常，proxy2第一次请求异常。请求结束。 当代理格式为 [&quot;192.168.1.100:8080&quot;,&quot;192.168.1.120:8080&quot;] 时，proxy1第一次请求正常。请求结束。 猜测为什么在代理Ip经处理后的请求，仍然会出错呢？ 个人怀疑是 defer 导致的。 defer语句调用一个函数，这个函数执行会推迟，直到外围的函数返回，或者外围函数运行到最后，或者相应的goroutine panic. 在请求之后，需要 defer 去 close 请求。而 defer 又有延后性，也就导致了在 for 循环中的多次请求之间都是有关联的，第一次的请求对象并没有被关闭就继续进行了后续的请求，直到函数结束，请求才被关闭掉。 也就导致了，即使第二次请求时的代理ip去掉了 http:// ，请求仍然会失败。 之后如何处理 先用 http://27.203.219.181:8060 的代理格式去请求，当遇到 malformed HTTP response 错误时，直接抛出异常，等待下次请求。 在第二次请求时，将代理ip的格式更改为 27.203.219.181:8060 传入，再去执行请求操作。 相关 https://github.com/golang/go/blob/master/src/net/http/response.go#L168 HTTP Method | holys’ 推荐推荐两个请求类： req: imroc/req: a golang http request library for humans gorequest: parnurzeal/gorequest: GoRequest – Simplified HTTP client ( inspired by nodejs SuperAgent ) 以上，仅做记录。由于暂未查询到问题原因，后续持续更新。]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客Next主题解决不蒜子统计不显示问题]]></title>
    <url>%2F2018%2F11%2F12%2Fbusuanzi-counter-error%2F</url>
    <content type="text"><![CDATA[今天在查看博客中文章的时候，发现页面中的统计都不显示了： 看了一下Chrome的控制台，发现是 不蒜子 统计的js文件找不到而报错了： 打开 不蒜子 的官方网站 不蒜子 | 不如 居然看到了如下的提示： 竟然是原来的域名不可用了。 额。。。看完我只想说：七牛确实坑啊。。。 解决方法： 官方也给出了相应的方法，即只需要更改 next 主题下的 不蒜子 插件的js引用链接即可。 进入 hexo 博客项目的 themes 目录下，在 next 主题目录中的 layout/_third-party/analytics/ 下找到 busuanzi-counter.swig 文件， 将: 1&lt;script async src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 换成： 12&lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 即可。 当然，改起来并不麻烦。关键是你得知道改哪里。]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Pixel解锁BL、刷入Twrp及Root折腾小记]]></title>
    <url>%2F2018%2F10%2F16%2Fgoogle-pixel-unlock-bl-and-root%2F</url>
    <content type="text"><![CDATA[因为个人项目上的需要，我从某宝入手了一款二手的Google Pixel 欧版手机。当初选择时主要是考虑到它的大内存–4G内存，可以流畅运行常用的程序。（不过入手之后的感觉就是，要想用好Google的手机，「科学上网」是必备的技能，否则的话，还是用国内的手机吧！） 因为需要在手机上安装按键精灵的手机版app，而调试按键精灵的脚本又需要获取手机的Root权限，所以就开始了我的Pixel刷机之旅。 准备工具 Google Pixel手机 欧版（国际版） Android 8.1.0 Windows或Mac twrp Magisk ss 欧版判断点击Settings(设置) -&gt; System(系统) -&gt; About phone(关于手机) -&gt; Regulatory labels(监管标签) 查看。 MODEL: G-2PW4200 ，其中 4200 表示欧版，4100 表示美版。 解锁Bootloader（注意：解锁 Bootloader 重置设备数据，请注意备份。一定不要忘记退出你的Google账号和取消指纹识别及锁屏设置。） 由于我的手机是新买的，所以这些操作就免了。 开启USB调试和OEM解锁安装「科学上网」工具，并成功接入互联网。 选择 「设置-系统-关于手机-版本号」，猛击「版本号」7次开启 「开发者选项」。 返回「上一页」，在「开发者选项」中开启「USB调试」和「OEM解锁」两个选项。如果「OEM解锁」选项显示为灰色，请检查网络连接是否正常。 通过数据线将手机连接至电脑，此时，手机端会弹出 USB 调试申请，点击「允许」。 可以通过命令 adb devices 来验证是否允许adb调试： 123➜ adb devicesList of devices attachedFA6XXXXXXX53 device 进入 Bootloader模式进入bootloader默认有两种方式，第一种是通过在关机状态下「按住电源键+音量减少键」；第二种是通过「ADB命令」进入。 这里我采用「adb命令」来操作。 回到命令提示符窗口，键入 adb reboot bootloader 并回车，手机会立即重启至 Bootloader 模式。 12~/test/pixel➜ adb reboot bootloader 之后，通过 fastboot devices 命令验证 fastboot 是否成功： 12➜ fastboot devicesFA6AB0311758 fastboot 解锁 Bootloader上一步进入Bootloader页面后，手机界面应该是如下图： 在命令提示符窗口键入 fastboot flashing unlock 并回车，手机进入 Bootloader 解锁界面。 1234➜ fastboot flashing unlock...OKAY [ 0.049s]finished. total time: 0.049s 对于 Pixel 2 XL 机型，要用如下的命令： 1fastboot flashing unlock_critical 详情查看：Factory Images for Nexus and Pixel Devices | Google APIs for Android | Google Developers 在 Bootloader 解锁界面中，使用音量键 +/- 来控制光标，选择「Yes」并按下电源键来进行 Bootloader 解锁。 确认完毕后,稍作等待。通过 fastboot reboot 命令重启手机： 1234➜ fastboot rebootrebooting...finished. total time: 0.050s 稍等片刻之后，你的设备会自动重启。 判断解锁成功当手机重启时出现黑底白字的英文警告页以及屏幕下方出现一把打开的小锁，那 Bootloader 就解锁成功啦。 重启手机，出现如下两个界面就算解锁成功： 当然，还有一种更简单的方法，就是再次进入 fastboot 模式，查看： 解锁Bootloader后的两个问题恢复初始在解锁 Bootloader 之后，可以看到手机系统已经是完全初始化的状态了。 在进入 「关于手机」 界面后，可以发现之前开启的「开发者选项」也是默认关闭了，需要再次点击7次「版本号」开启。 那么，在执行后面的操作时是否仍需要再次将「OEM解锁」打开呢？答案是：不需要。 然而，因为后面需要用到 adb 命令去操作手机，所以「USB调试」选项还是需要打开的。 关于「OEM锁与bootloader锁的关系」，可以看下面的 疑难解答 。 错误提示成功解锁Bootloader后，每次手机启动或重启时，都会出现黑底白字的英文警告页，提示 “Your device software can’t be checked for corruption. Please lock the bootloader”。 这没有什么可担心的，这是正常的！ 这仅仅是提示你 Bootloader 被解锁了，直接忽视即可。 刷入第三方Recovery:TWRP及Root由于Pixel及Pixel XL都采用A/B升级系统，因而可以理解为手机里有2个系统，如果你按照传统刷入Twrp的方法刷入的话，那么你并不会获得一个永久的Twrp。所以需要先刷入一个临时的Twrp，在通过临时的Twrp来刷入永久的Twrp从而来获取Root权限。 下载必要软件需要下载临时的Twrp、永久Twrp及Magisk三个文件。 首先，前往 TWRP 官网 Devices 下载最新版 TWRP 压缩包（.zip）和临时 TWRP 镜像文件（.img）。 我的Pixel对应选择从这个页面 Download TWRP for sailfish 下载的 3.2.3-1 版本： 12twrp-pixel-installer-sailfish-3.2.3-1.zip （永久twrp）twrp-3.2.3-1-sailfish.img (临时twrp) 从github Releases · topjohnwu/Magisk 下载最新的 Magisk 包。 这里我下载的是 17.2 版本： 1Magisk-v17.2.zip 拷贝文件到手机假设我电脑上的操作目录为: ~/test/pixel 。 将 twrp-3.2.3-1-sailfish.img 拷贝到该目录下。 将 twrp-pixel-installer-sailfish-3.2.3-1.zip 和 Magisk-v17.2.zip 拷贝到手机中。 在将文件拷贝到手机中时，我发现通过数据线连接到电脑时，选择 传输文件 电脑中并没有出现手机存储的盘符，也就无法直接将文件拖拽到手机中。 在经过一番摆弄之后，我觉得最靠谱的还是通过 adb 的方式来上传文件。 连接手机，在手机端弹出「USB调试」点击确定，打开item2，切换到目录 ~/test/pixel ： 123~/test/pixel➜ lsMagisk-v17.2.zip twrp-3.2.3-1-sailfish.img twrp-pixel-installer-sailfish-3.2.3-1.zip 查看adb连接状态： 1234~/test/pixel➜ adb devicesList of devices attachedFA6XXXXXXX53 device 先通过 adb shell 命令进入手机的bash命令下，在 /sdcard 目录下创建临时文件夹 tmp : 123456789101112131415161718~/test/pixel➜ adb shellsailfish:/ $ cd sdcard/sailfish:/sdcard $ mkdir tmpsailfish:/sdcard $ lsAlarms Android DCIM Download Movies Music Notifications Pictures Podcasts Ringtones tmpsailfish:/sdcard $ ls -altotal 100drwxrwx--x 13 root sdcard_rw 4096 2018-10-16 17:27 .drwx--x--x 4 root sdcard_rw 4096 2009-01-01 16:02 ..drwxrwx--x 2 root sdcard_rw 4096 2009-01-01 16:02 Alarmsdrwxrwx--x 3 root sdcard_rw 4096 2009-01-01 16:02 Androiddrwxrwx--x 2 root sdcard_rw 4096 2009-01-01 16:02 DCIMdrwxrwx--x 2 root sdcard_rw 4096 2009-01-01 16:02 Download......drwxrwx--x 2 root sdcard_rw 4096 2018-10-16 17:27 tmpsailfish:/sdcard $ 通过 adb push &lt;local&gt; &lt;remote&gt; 命令将文件上传到手机的 /sdcard/tmp/ 目录中： 12345678~/test/pixel➜ adb push twrp-pixel-installer-sailfish-3.2.3-1.zip /sdcard/tmp/twrp-pixel-installer-sailfish-3.2.3-1.zip: 1 file pushed. 14.6 MB/s (11492088 bytes in 0.753s)~/test/pixel➜ adb push Magisk-v17.2.zip /sdcard/tmp/Magisk-v17.2.zip: 1 file pushed. 16.3 MB/s (4174026 bytes in 0.245s) 查看手机中文件列表： 1234567~/test/pixel➜ adb shell ls -al /sdcard/tmp/total 15328drwxrwx--x 2 root sdcard_rw 4096 2018-10-16 17:32 .drwxrwx--x 13 root sdcard_rw 4096 2018-10-16 17:27 ..-rw-rw---- 1 root sdcard_rw 4174026 2018-10-16 16:07 Magisk-v17.2.zip-rw-rw---- 1 root sdcard_rw 11492088 2018-10-16 15:56 twrp-pixel-installer-sailfish-3.2.3-1.zip 注：对于为什么将文件拷贝到手机的 /sdcard 目录，可以看下面的 疑难解答 刷临时Twrp引导进入 Bootloader执行命令 adb reboot bootloader: 12~/test/pixel➜ adb reboot bootloader 刷入临时Twrp执行命令 fastboot boot *.img 来启动临时Twrp： 1234567~/test/pixel took 5s➜ fastboot boot twrp-3.2.3-1-sailfish.imgdownloading &apos;boot.img&apos;...OKAY [ 0.712s]booting...OKAY [ 0.903s]finished. total time: 1.615s 之后，手机会进入到临时的Twrp中： 滑动下面的 Swipe to Allow Modifications 滑条，进入Twrp操作页面： 刷入永久Twrp选择 Install – 找到目录 /sdcard/tmp/ – 选择 twrp*.zip 文件 – 弹出安装界面 – 直接滑动底部的滑条 Swipe to confirm Flash 安装： 这里也间接验证了为什么要选择 /sdcard 目录：点击 Install 按钮后，直接进入的就是 /sdcard 目录，即只能操作这个目录。 等待进度条执行完毕，最后会显示 ...done 的提示。说明这一步执行完成。 刷入Magisk上一步安装完成后，我们发现界面中只有两个按钮：Wipe cache/dalvik 和 Reboot System 。后一项肯定不能选，如果选择重启，那还有一个 Magisk 文件没有刷入，否则的话还需要走一遍上面的 刷入临时Twrp 的操作；而第一项 清除临时缓存文件，只是我不清楚该文件具体是干什么用的，所以也怕点了之后会出问题。 这种情况下，我只好上网去查询看看是否有相关的操作介绍，可想而知，这个问题可能太简单了，很难找到相关的介绍。 正当我一脸迷蒙时，我的手误按了顶部的 “蓝色条” 部分，发现… 界面返回了 Install 页面： 我只想说，这操作简直是 666 啊！！！ 经过验证，只要点击顶部的「install Zip」 蓝色条部分左侧的「图标」处，就会返回 Team Win Recovery Project 界面。 依照上面的安装步骤，继续安装 Magisk-v17.2.zip 文件。直到界面中提示 ...done 时，说明安装完成。 安装完成后，点击下面的 Reboot System 按钮，重启系统。 不过，这时候发现界面会提示询问是否安装 TWRP App ？ 这里，千万不要安装。直接点击中间的 Do Not Install 即可。 待手机重启进入系统后，可以发现手机APP中多了一个 Magisk 的脸谱Logo图标。 至此，整个刷机过程就结束了。 验证是否成功Root至于如何验证是否成功Root，最简单的方法就是安装几个需要获取Root权限的软件就可以了。 可以在「脸谱Logo」的菜单中选择「超级用户」，为相应的软件开启Root权限。 优化去掉wifi叉号标记在国内的网络环境下，通过wifi联网之后，Pixel的wifi图标上会默认显示一个「叉号」。虽然能够正常联网，但对于强迫症来说，还是觉得很碍眼。 对于这个问题，原理性的解释是： 谷歌原生安卓系统当连接到移动数据网络或者WIFI网络的时候，其NetworkMonitor模块会向特定的服务器发起一个http的请求并利用收到的响应进行网络状态判断。由于谷歌的服务器被GFW屏蔽，所以导致没有返回值，这个时候谷歌安卓系统就会在信号或者wifi上打一个感叹号或叉号。 可以通过换成v2ex的验证方式来解决。在命令提示符中执行： 1adb shell settings put global captive_portal_https_url https://www.google.cn/generate_204 然后开启飞行模式，再关闭飞行模式即解决！ 操作前： 执行命令： 12345~/test/pixel➜ adb shell settings put global captive_portal_https_url https://www.google.cn/generate_204~/test/pixel➜ 操作后： 如果你想恢复的话，使用下面的命令：（未亲测） 12adb shell settings delete global captive_portal_server adb shell settings put global captive_portal_detection_enabled 1 疑难解答fastboot oem unlock or fastboot flashing unlock在网上搜索到的一些教程中，有的说是使用 fastboot oem unlock 来解BL，有的说是通过 fastboot flashing unlock 来解BL。 最终在google的官网中，我找到了如下的介绍： If necessary, unlock the device’s bootloader using one of the following methods: If you are updating a Nexus or Pixel device that is manufactured in 2015 or later (for example, a Nexus 5X, Nexus 6P, Pixel, Pixel XL, Pixel 2 or Pixel 2 XL device), run this command: fastboot flashing unlock If you are updating an older device, run this command: fastboot oem unlock 更多介绍，请看： Factory Images for Nexus and Pixel Devices | Google APIs for Android | Google Developers OEM锁与bootloader锁的关系OEM锁是限制了bootloader锁，OEM锁系统默认是关闭的，必须在开发者中手动打开。之后 bootloader锁才能进行解锁。 通俗一点的说，OEM锁只跟bootloader锁有关系，和之后的Root操作没有关系。所以当解锁Bootloader后系统配置被重置了，即使 「开发者选项」中的 「OEM解锁」显示为灰色不能操作，也无关紧要了。 参考：关于解锁bootloader的重要性.机友们务必细读,生死问题,请勿忽视! - Pixel | Pixel XL 论坛 - 智友论坛 解锁bootloader的好处 最重要是为自己的手机买了份保险,留了条生路.卡死 系统抽风或变砖后,可在bootloader界面下线刷原厂镜像恢复系统。(不解锁的无法刷机救回) 作为亲儿子机型，XDA上很多资源，有大量第三方ROM、优化补丁、Recoovery、ROOT 解锁bootloader后，不ROOT和修改系统文件，不影响在线OTA升级。 解锁后 开机Google logo下有个小锁和两秒钟的警示语说你的手机已经解了bootloader锁,机友们可以无视之，不影响使用。 adbpush文件时权限不够在使用命令 adb push 将文件 twrp-pixel-installer-sailfish-3.2.3-1.zip 上传到手机时，可能由于权限问题而报错： 1234~/test/pixel➜ adb push twrp-pixel-installer-sailfish-3.2.3-1.zip /adb: error: failed to copy &apos;twrp-pixel-installer-sailfish-3.2.3-1.zip&apos; to &apos;/twrp-pixel-installer-sailfish-3.2.3-1.zip&apos;: remote couldn&apos;t create file: Read-only file systemtwrp-pixel-installer-sailfish-3.2.3-1.zip: 0 files pushed. 22.7 MB/s (1048448 bytes in 0.044s) 我们可以通过 adb shell 命令来进入到手机的bash命令下，也可以直接在后面跟上bash命令来执行。进行验证： adb shell : 1234567891011~/test/pixel➜ adb shellsailfish:/ $ sailfish:/ $ lsls: ./verity_key: Permission deniedls: ./init.rc: Permission deniedls: ./postinstall: Permission deniedls: ./init.usb.configfs.rc: Permission deniedls: ./init.zygote64_32.rc: Permission denied...... 或者 adb shell mkdir tmp : 123~/test/pixel➜ adb shell mkdir tmpmkdir: &apos;tmp&apos;: Read-only file system 发现，果然是当前用户的权限不够。 经过验证，发现当前用户对 /sdcard 目录是有权限进行文件或目录的操作的。 12345678910111213~/test/pixel➜ adb shellsailfish:/ $ cd sdcard/sailfish:/sdcard $ lsAlarms Android DCIM Download Movies Music Notifications Pictures Podcasts Ringtonessailfish:/sdcard $ mkdir tmpsailfish:/sdcard $ lsAlarms Android DCIM Download Movies Music Notifications Pictures Podcasts Ringtones tmpsailfish:/sdcard $ rm -rf tmpsailfish:/sdcard $ lsAlarms Android DCIM Download Movies Music Notifications Pictures Podcasts Ringtonessailfish:/sdcard $ exit 码字不易，以上操作均为本人实际操作并验证。如果该文章对您有所帮助，可以赠送一杯咖啡！！！ 相关链接工具 Releases · shadowsocks/shadowsocks-android Download TWRP for sailfish Releases · topjohnwu/Magisk 教程 Pixel XL解锁BL、刷入Twrp及Root教程 | XZYMOE’S BLOG ☆ 从 Bootloader 解锁到必备应用推荐：我的 Google Pixel 折腾手记 - 少数派 Android ADB命令大全(通过ADB命令查看wifi密码、MAC地址、设备信息、操作文件、查看文件、日志信息、卸载、启动和安装APK等) - mingy的专栏 - CSDN博客 2019年08月27日 Update Magisk更新将 Magisk 从 v17.2 版本升级到 v19.3 版本。 可以从 Magisk 下载最新版本的Magisk的zip压缩包。 第一步 adb连接要确保手机设备通过adb正确连接。如果提示为 offline 则需要重新设置手机的连接。 123➜ adb devicesList of devices attachedFA6XXXXXXX53 offline 直到出现 device 时，说明手机正确连接了。123➜ adb devicesList of devices attachedFA6XXXXXXX53 device 一般出现 offline 的情况可能是usb数据线的问题，或者连接设置的问题。 这里我的解决方法是： 断开usb设备连接 执行命令 adb kill-server 来停止adb服务 执行命令 adb start-server 来重新运行adb服务 重新通过usb连接手机设备 打开 开发者选项 ，重新勾选 usb调试，在弹出的窗口选择 确定 再次执行命令 adb devices，发现显示 device 了 第二步 拷贝Magisk文件通过 adb push 命令将新版的Magisk文件拷贝到手机设备中： 12➜ adb push Magisk-v19.3.zip /sdcard/tmp/Magisk-v19.3.zip: 1 file pushed. 21.0 MB/s (5348187 bytes in 0.243s) 这里我之前使用的是 Magisk-v17.2.zip 版本，现在要更新到 Magisk-v19.3.zip 版本。 第三步 进入Bootloader执行 adb reboot bootloader 进入 Bootloader 界面。 第四步 进入临时Twrp通过 twrp*.img 文件，启动进入临时Twrp： 1234567➜ fastboot boot twrp-3.2.3-1-sailfish.imgERROR: Couldn&apos;t create a device interface iterator: (e00002bd)downloading &apos;boot.img&apos;...OKAY [ 0.712s]booting...OKAY [ 0.893s]finished. total time: 1.605s 第五步 安装Magisk进入 Twrp 页面后，滑动下面的 Swipe to Allow Modifications 滑条，进入Twrp操作页面。 选择 Install – 找到目录 /sdcard/tmp/ – 选择 Magisk-v19.3.zip 文件，滑动 Swipe to confirm Flash 来安装。 安装完成后，点击下面的 Reboot System 按钮，进入下一步。 之后，直接点击中间的 Do Not Install 等待手机重启进入系统即可。]]></content>
      <tags>
        <tag>Skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniGraffle常用快捷键]]></title>
    <url>%2F2018%2F10%2F10%2Fomnigraffle-shortcut-keys%2F</url>
    <content type="text"><![CDATA[OmniGraffle 是 Mac 上的绘图利器。Graffle 在很多方面对标 Windows 系统上的 Microsoft Visio，是制作各种文档的绝妙工具。 变换移动放大：Cmd+Shift+. 或 z+点击 缩小：Cmd+Shift+, 或 z+Option+点击 缩放：按住Cmd+双指推移 中心缩放：按住Cmd + 按住Option + 双指推移 旋转对象：点击对象 + 选择定位块 + 旋转 常用工具选取工具：按住 v 不放并拖拽对象 或 按 1 切换：按一次选中 ；按二次保持选中 形状工具：按住 s 不放并在空白处拖拽 或 按 2 切换：按一次选中 ；按二次保持选中 线条工具：按住 c 不放先后点击目标形状连接 或 按 3 切换：按一次选中 ；按二次保持选中 文字工具：按住 t 并单击后输入文字 或 按 4 切换：按一次选中 ；按二次保持选中 磁化工具：按住 m 不放并点击形状内任意位置 或 按 9 切换：按一次选中 ；按二次保持选中 其他： 复制复制对象：选中对象 + Cmd+d 磁化点添加磁化点：按住 m 不放并点击形状内任意位置 或 按 9 切换：按一次选中 ；按二次保持选中 删除磁化点：在磁化按钮保持选中状态下 + Option + 点击磁化点 检查器面板切换检查器面板：Cmd+1/2/3/4/5 对象检查器：Cmd+1 类型检查器：Cmd+2 …以此类推。 层级前移对象：Cmd+Option+F 后移对象：Cmd+Option+B 置于最前：Cmd+Shift+F 置于最后：Cmd+Shift+B 锁定：选中对象 + Cmd+L 解锁：选中对象 + Cmd+Option+L 创建群组：Cmd+Shift+G (Group) 解散群组：Cmd+Shift+U (Ungroup) 导出在将完成后的流程图导出成jpg等其他格式时，有一个「导出区域」的选项。默认情况下是「所有对象」，但选择这种后导出的图片中可能出现元素显示的不完整的情况。 要想将所有元素都显示，那么需要选择「当前版面」选项。 相关参考 Omnigraffle快捷键 - Shiyu_Huang - 博客园 OmniGraffle 基础入门（一）：从工具栏开始 - 少数派]]></content>
      <tags>
        <tag>Skill</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker图形化管理工具Portainer]]></title>
    <url>%2F2018%2F09%2F30%2Fdocker-management-tool-portainer%2F</url>
    <content type="text"><![CDATA[Portainer 是一个轻量级的Docker容器管理界面，可让您轻松管理 Docker 主机 或 Swarm 集群。 在服务器上部署了很多Docker容器后，总觉得还差点什么。感觉确实需要一个图形化的容器管理工具，便于直观的查看目前服务器中容器的状态等。 通过对各种管理工具的比较，最后确定使用 Portainer 这款轻量级的。毕竟是个人服务器，也用不到特别大的量级。 部署这里我直接使用官网提供的 docker-compose.yml 来启动portainer容器。下载该文件: Download the Compose file ，更多的安装信息可见官方文档：Deployment — Portainer 1.20.1 documentation 。 1234567891011121314version: &apos;2&apos;services: portainer: image: portainer/portainer ports: - &quot;9000:9000&quot; command: -H unix:///var/run/docker.sock volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/datavolumes: portainer_data: 第一次登录，需要输入管理员的密码。 管理界面： 更多内容可以查看官方文档。 相关参考 Deployment — Portainer 1.20.1 documentation]]></content>
      <categories>
        <category>Docker容器技术</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS泛域名证书申请之三-七牛云图片链接升级https]]></title>
    <url>%2F2018%2F09%2F24%2Fhttps-certificate-three-of-qiniu-https%2F</url>
    <content type="text"><![CDATA[上篇文章 HTTPS泛域名证书申请之二-Nginx配置 说道，要让我的博客 https://www.itfanr.cc 用上全站的HTTPS安全模式，必须解决七牛云图片链接http的问题。 而七牛云官方推荐的https方案，费用比价高。那有没有什么免费的方法呢？答案就是通过 自定义域名 来设置。 也就是域名我们自定义，证书使用之前设置的泛域名证书，那么问题就搞定了。 在七牛云中添加自定义域名在个人的 “存储空间” 设置菜单中选择 “绑定域名” ，域名类型中选择 “普通域名” 即可。 在 “加速域名” 处设置一个自定义的域名，比如我设置的是 qiniu.itfanr.cc 。 “通信协议” 选择 HTTPS 方式。 由于要为自定义域名添加证书文件，而之前也没有添加过，所以这里选择 “SSL 证书管理” 来设置。 在 “SSL证书服务 &gt; 证书管理” 界面中，选择 “上传自有证书” 来添加之前申请到的证书文件。 设置完成后，等待七牛云处理。 处理完成后，会给出如下提示： 在阿里云设置域名CNAME七牛云自定义域名添加成功后，还要添加域名的解析。也就是需要在域名服务商处添加一条 CNAME 记录。 以下是我在阿里云中添加的配置： 稍等片刻，等待生效。 设置七牛云图片外链默认域名域名解析成功后，还要在七牛云中添加图片的默认域名。 打开七牛云 “存储空间” 设置，在 “内容管理” 中的 “外链默认域名” 处选择刚刚添加的 自定义域名，之后 “保存默认域名” 即可。 选择一张图片，通过自定义域名访问： 可以看到，已经能正常支持https了。 图片优化一般直接截图或者上传本地的图片到七牛云后，通过链接直接访问，图片体积都会很大，加载时间也会很长。 而七牛云中也有相关的图片优化设置。打开 “存储空间设置” – “图片样式” 选项，在这里可以添加自定义的图片优化方案。 在 “样式分隔符设置” 中，可以设置分隔符。 那么，添加上图片优化的链接就如下：我的图片样式定义为blog，分隔符为 - 1https://qiniu.itfanr.cc/blog/170809/26B1D9j4eI.jpg-blog 替换Hexo博客中已有的图片链接因为之前的文章中也有添加很多的七牛云图片链接，但都是http 的，想要一篇文章一篇文章的替换也很麻烦，所以我就写了一个Py脚本来做替换的事。 Py脚本主要内容如下：完整代码查看：Leafney/md-qiniu-imges-replace: markdown文件中七牛云图片链接替换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def md_img_replace(md_file): &quot;&quot;&quot; 替换md文件中的图片链接 &quot;&quot;&quot; result=False post=md_read(md_file) matches = re.compile( &apos;!\\[.*?\\]\\((.*?)\\)|&lt;img.*?src=[\&apos;\&quot;](.*?)[\&apos;\&quot;].*?&gt;&apos;).findall(post) if matches and len(matches)&gt;0: # 该md文件中有图片 # 输出文件名称 print(&apos;文件：[&#123;0&#125;] 中含有图片&apos;.format(md_file)) new_post=post for sub_match in matches: # 正则里包含或，所以这里sub_matth是元组 # print(sub_match) for match in sub_match: if match and len(match)&gt;0: # 得到单张图片链接 print(&apos;找到图片链接：[&#123;0&#125;]&apos;.format(match)) # 在这里遍历一遍后，发现我的文章中图片链接的特点主要有三种格式： &quot;&quot;&quot; https://qiniu.itfanr.cc/blog/20180924112100.png?imageslim -- 已经符合要求的 http://ouej55gp9.bkt.clouddn.com/blog/20180920204113.png -- 只有旧版链接的 http://ouej55gp9.bkt.clouddn.com/blog/180116/B2c2Deah5B.png?imageslim -- 旧版链接带优化参数的 所以，下面的操作主要针对于上面的三种情况来处理 ***** 所以，这里要改成针对于你自己的文章图片链接来处理 ***** &quot;&quot;&quot; # print(&apos;----------------&apos;) # 判断图片域名是否为 http://ouej55gp9.bkt.clouddn.com/ 是的话，则替换为 https://qiniu.itfanr.cc if match.startswith(&apos;http://ouej55gp9.bkt.clouddn.com&apos;): # 记录下替换前的链接 old_url=match new_url = match.replace( &apos;http://ouej55gp9.bkt.clouddn.com&apos;, &apos;https://qiniu.itfanr.cc&apos;) # print(&apos;step_1_new_url:[&#123;0&#125;]&apos;.format(new_url)) # 判断是否以 ?imageslim 结尾 if not match.endswith(&apos;imageslim&apos;): # 不是，在结尾添加 new_url += &apos;?imageslim&apos; print(&apos;step_2_new_url:[&#123;0&#125;]&apos;.format(new_url)) # 替换 post 中的 old_url为 new_url，并将新内容写回文件 new_post = new_post.replace(old_url, new_url) result = True print(&apos;----------------&apos;) if result: # 将内容重新写回文件 # print(new_post) md_write(md_file,new_post) print(&apos;ok-修改成功&apos;) print(&apos;****************&apos;) return result 执行过程记录： 123456789101112131415161718192021222324252627282930313233343536373839404142文件：[./_posts/https-certificate-two-of-nginx-settings.md] 中含有图片找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919001532.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919001532.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919180924.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919180924.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919171901.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919171901.png?imageslim]----------------找到图片链接：[https://qiniu.itfanr.cc/blog/20180924000202.png?imageslim]----------------找到图片链接：[https://qiniu.itfanr.cc/blog/20180924000229.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919165205.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919165205.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919170111.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919170111.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919173643.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919173643.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919180924.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919180924.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180919180907.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180919180907.png?imageslim]----------------ok-修改成功****************文件：[./_posts/https-certificate-one-of-application.md] 中含有图片找到图片链接：[https://qiniu.itfanr.cc/blog/20180921175821.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180918225700.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180918225700.png?imageslim]----------------找到图片链接：[http://ouej55gp9.bkt.clouddn.com/blog/20180918232923.png]step_2_new_url:[https://qiniu.itfanr.cc/blog/20180918232923.png?imageslim]----------------ok-修改成功****************]]></content>
      <categories>
        <category>HTTPS</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS泛域名证书申请之二-Nginx配置]]></title>
    <url>%2F2018%2F09%2F24%2Fhttps-certificate-two-of-nginx-settings%2F</url>
    <content type="text"><![CDATA[在申请成功https的泛域名证书账号，接下来就是为主域名以及二级域名配置添加证书文件，以让“小绿锁” 显示出来。 显示小绿锁却提示404NotFound上篇文章末尾，我为二级域名 gogit.itfanr.cc 的Nginx配置中指定了证书目录，网站也正常应用上了https： 1234567891011121314151617181920212223server &#123; listen 443 ssl; server_name gogit.itfanr.cc; ssl_certificate /etc/acme.sh/itfanr.cc/fullchain.cer; ssl_certificate_key /etc/acme.sh/itfanr.cc/itfanr.cc.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; location / &#123; proxy_pass http://127.0.0.1:3000/; &#125;&#125;server &#123; listen 80; server_name gogit.itfanr.cc; return 301 https://$server_name$request_uri;&#125; 但当我按照上面的配置为主域名 www.itfanr.cc 也指定https证书后： 1234567891011121314151617181920212223server &#123; listen 443 ssl; server_name www.itfanr.cc; ssl_certificate /etc/acme.sh/itfanr.cc/fullchain.cer; ssl_certificate_key /etc/acme.sh/itfanr.cc/itfanr.cc.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; location / &#123; proxy_pass http://localhost:8080/; &#125;&#125;server &#123; listen 80; server_name www.itfanr.cc; return 301 https://$server_name$request_uri;&#125; 结果，页面却显示了 404 Not Found 的错误。 解决多域名下设置证书通过相关问题的搜索，结果却没有找到什么有效的解决方法。另外由于我对Nginx的配置也不是特别精通，所以一下子陷入了迷茫中。 后来，在一篇相关文章 Let’s Encrypt 泛域名证书申请及配置 中找到了一种方法。 第一步在Nginx的 snippets 目录下，创建一个配置文件，我这里命名为 ssl-itfanr.conf，内容用来设置SSL相关的配置： 1234567891011121314151617181920212223242526272829# /etc/nginx/snippets/ssl-itfanr.confserver_tokens off;ssl_session_cache shared:SSL:10m;ssl_session_timeout 60m;ssl_session_tickets on;ssl_stapling on;ssl_stapling_verify on;resolver 8.8.4.4 8.8.8.8 valid=300s;resolver_timeout 10s;ssl_prefer_server_ciphers on;# 证书路径 绝对地址ssl_certificate /etc/acme.sh/itfanr.cc/fullchain.cer;ssl_certificate_key /etc/acme.sh/itfanr.cc/itfanr.cc.key;ssl_protocols TLSv1 TLSv1.1 TLSv1.2;ssl_ciphers &quot;EECDH+AESGCM:EDH+AESGCM:ECDHE-RSA-AES128-GCM-SHA256:AES256+EECDH:DHE-RSA-AES128-GCM-SHA256:AES256+EDH:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4&quot;;add_header Strict-Transport-Security &quot;max-age=31536000;includeSubDomains;preload&quot;;add_header X-Frame-Options deny;add_header X-Content-Type-Options nosniff;add_header x-xss-protection &quot;1; mode=block&quot;;add_header Content-Security-Policy &quot;default-src &apos;self&apos;; script-src &apos;self&apos; &apos;unsafe-inline&apos; &apos;unsafe-eval&apos; blob: https:; connect-src &apos;self&apos; https:; img-src &apos;self&apos; data: https: blob:; style-src &apos;unsafe-inline&apos; https:; font-src https:&quot;; 第二步然后在 Nginx 主配置文件中开启 SSL 支持： 1234567891011121314# /etc/nginx/nginx.confhttp &#123; ... ... ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ... ...&#125; 我的配置文件中 SSL配置 这里默认是启用状态，所以保持默认即可。 第三步修改域名的配置文件。 比如，修改我的网站主域名 itfanr.cc 配置文件如下: 123456789101112131415161718192021# /etc/nginx/conf.d/itfanr.confserver &#123; listen 80; listen [::]:80; server_name itfanr.cc www.itfanr.cc; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443 default_server; listen [::]:443 default_server; server_name itfanr.cc www.itfanr.cc; include snippets/ssl-itfanr.conf; location / &#123; proxy_pass http://localhost:8080/; &#125;&#125; 同时，修改二级域名 gogit.itfanr.cc 的配置文件： 12345678910111213141516171819# /etc/nginx/conf.d/gogit.confserver &#123; listen 80; server_name gogit.itfanr.cc; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443 ssl; listen [::]:443 ssl; server_name gogit.itfanr.cc; include snippets/ssl-itfanr.conf; location / &#123; proxy_pass http://127.0.0.1:3000/; &#125;&#125; 其中，关键的一点就是在配置文件中包含SSL的配置文件： 1include snippets/ssl-itfanr.conf; 第四步如果还有其他的二级域名，同样依照上面的方法进行配置，然后重新载入Nginx配置文件。 在重载之前，可以先验证一下刚刚修改的配置文件是否有误： 123$ sudo nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 无误后，再执行重载操作： 1$ sudo nginx -s reload 此时，再次访问两个域名地址，可以发现都能够正常访问且都是https安全连接了。 itfanr.cc: gogit.itfanr.cc: 设置默认站点因为我的域名设置了支持泛域名，所以支持的二级域名都会跳转到我的服务器的IP地址。 那么，对于一些我们没有添加到二级域名在没有进行定义时，会返回什么呢？这就需要设置 默认站点 了。 也就是通过参数 default_server 来指定。 我们可以查看一下 /etc/nginx/sites-available/default 文件： 1234567server &#123; listen 80 default_server; listen [::]:80 default_server; ... ... root /var/www/html; &#125; 上面的设置说明，当访问域名是没有匹配到我们添加的域名，那么就会返回默认的地址。也就是这里的 Nginx默认的页面。 比如，我访问 http://abc.itfanr.cc 时： 而该文件中并没有配置当使用 https 方式访问时，要返回什么默认页面。所以我在上面的 itfanr.conf配置中添加了一项： 12345...listen 443 default_server;listen [::]:443 default_server;server_name itfanr.cc www.itfanr.cc;... 默认返回我的博客地址。比如访问 https://abc.itfanr.cc 时： 另外，要注意的是：只能设置一个网址为默认地址，当设置了多个时会提示错误： 123$ sudo nginx -tnginx: [emerg] a duplicate default server for 0.0.0.0:80 in /etc/nginx/sites-enabled/default:17nginx: configuration file /etc/nginx/nginx.conf test failed 解决网站中的 data 类型字体图片无法载入问题配置好Nginx的 https 配置后，再次请求网址 https://gogit.itfanr.cc，发现浏览器地址栏中已经显示了安全的 “小绿锁” 标志。但是一打开Chrome浏览器的F12调试工具，发现有一些请求是报错的。 可以发现，报错的基本都是前缀为 data:application 类型的字体图片文件。 通过查询，在 Content-Security-Policy 段中应该包含以下内容： 1font-src &apos;self&apos; data:; 所以只需要在 font-src 和 https 之间添加 ：&#39;self&#39; data: 即可。注意前后之间要用空格分隔。 原： 123# /etc/nginx/snippets/ssl-itfanr.confadd_header Content-Security-Policy &quot;default-src &apos;self&apos;; script-src &apos;self&apos; &apos;unsafe-inline&apos; &apos;unsafe-eval&apos; blob: https:; connect-src &apos;self&apos; https:; img-src &apos;self&apos; data: https: blob:; style-src &apos;unsafe-inline&apos; https:; font-src https:&quot;; 修改后： 123# /etc/nginx/snippets/ssl-itfanr.confadd_header Content-Security-Policy &quot;default-src &apos;self&apos;; script-src &apos;self&apos; &apos;unsafe-inline&apos; &apos;unsafe-eval&apos; blob: https:; connect-src &apos;self&apos; https:; img-src &apos;self&apos; data: https: blob:; style-src &apos;unsafe-inline&apos; https:; font-src &apos;self&apos; data: https:&quot;; 修改完成后，重新载入Nginx配置，再次刷新网站，发现已经没有 data:application 红色的错误请求链接了： javascript - Refused to load the font ‘data:font/woff…..’it violates the following Content Security Policy directive: “default-src ‘self’”. Note that ‘font-src’ - Stack Overflow 解决七牛云图片外链http无法载入的问题访问我的博客网址 https://www.itfanr.cc ，发现有些文章中的七牛云外链图片都不显示了。查看F12调试工具： 发现所有的七牛云 http 外链图片均不加载。 然后我又去七牛云的网站中查看了一下配置，发现如果按照官方的方法切换成 https 的链接，是需要收费的，此时心里是一万头草泥马狂奔的景象… 无奈只能找寻其他的解决方法了。 查看F12的Console中的错误信息： 1Refused to load the image &apos;http://ouej55gp9.bkt.clouddn.com/blog/20180917193602.png&apos; because it violates the following Content Security Policy directive: &quot;img-src &apos;self&apos; data: https: blob:&quot;. 搜索到 Content-Security-Policy 介绍页面：Content Security Policy CSP Reference &amp; Examples 参照里面的介绍，尝试把七牛云图片的域名加到 img-src 中，更改如下： 12345img-src &apos;self&apos; data: https: blob:;# 更改为：img-src &apos;self&apos; ouej55gp9.bkt.clouddn.com data: https: blob:; 再次刷新页面后，发现如果页面中没有引用到七牛云的图片链接，地址栏中是显示“小绿锁”的，比如首页；而到了文章详情页中，引用了七牛云的图片链接后，地址栏中就会显示“叹号”的不安全标志。 访问首页，提示“安全连接”： 访问带有http外链图片的文章详情，提示“连接并非完全安全”： 根据上面的验证发现，必须得整站的链接都是 https 的情况下，才会是一直处于“小绿锁”的安全模式下。那么接下来就是解决整站https的问题了。目前来看，也就是解决七牛云图片链接如何从 http 到 https 的问题。 遗留的问题虽然通过独立出SSL配置，然后在需要启用 https 的域名配置文件 server{} 中 include 的方式能够正常运行，但我心里一直还是有个疑问的：为什么分别指定证书文件地址时配置却不生效？ 由于目前还未找到原因，这个问题暂留，以待后续解答。]]></content>
      <categories>
        <category>HTTPS</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS泛域名证书申请之一-申请流程]]></title>
    <url>%2F2018%2F09%2F24%2Fhttps-certificate-one-of-application%2F</url>
    <content type="text"><![CDATA[自从 Let&#39;s Encrypt 支持泛域名之后，为网站设置https就变得非常简单了。之前需要维护多个子域名的证书更新，操作起来也是很麻烦的。 因为最近我的 gogit.itfanr.cc 的https证书到期，所以就研究了一下泛域名的申请过程，想要将我所有 itfanr.cc 下的二级域名都设置成https的请求方式。 目前比较常用的为 Let&#39;s Encrypt 生成证书的工具比较多，比如 certbot 和 acme.sh 是我之前接触过的两款。这里我要使用 acme.sh 这个工具来安装 Let&#39;s Encrypt 证书。 acme.shacme.sh 是由国人利用 shell 脚本开发的，兼容各种 Linux 系统。仅仅依赖 curl。 acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。 acme.sh 支持 --webroot, --standalone, --apache, --nginx and --dns 5种证书申请模式。 安装可以直接通过下面的脚本来安装 acme.sh： 1curl https://get.acme.sh | sh 安装过程不会污染已有的系统任何功能和文件，acme.sh 会被自动安装到 ~/.acme.sh/ 中。 并且，还默认创建一个 bash 的 alias, 方便你的使用: alias acme.sh=~/.acme.sh/acme.sh 。 此外，acme.sh 还自动创建了 cronjob任务, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书. 单域名申请当你只想要为一个域名设置 https 时，可以使用 --standalone 模式来申请。 比如我之前在为 gogit.itfanr.cc 设置时，我的网站程序是跑在Docker容器下的，外面用 Nginx 来做跳转。 首先，我需要先将占用 80 端口的 Nginx 服务停掉，然后再设置： 1$ sudo service nginx stop 然后，生成https证书： 1$ acme.sh --issue -d gogit.itfanr.cc --standalone 其中，gogit.itfanr.cc 请换成自己的站点域名。 Standalone 模式默认使用的是 80 端口，如果你的 80 端口无法使用的话，也可以指定相应的端口： 1$ acme.sh --issue -d gogit.itfanr.cc --standalone --httpport 88 获取AccessKeys因为我要将 itfanr.cc 域名下所有的二级域名都设置成 https ，那么上面一个域名一个域名的设置方法就不行了。 泛域名就是类似于 *.example.com 这样的域名。 acme.sh 目前支持数十种域名解析商的API，可以自动添加 TXT 记录来验证。 这里我以阿里云DNS为例，其他支持的域名验证方式，可以查看这里了解 以及相应的设置方法 acme.sh 访问阿里云 DNS 是通过阿里云 DNS 公开的 API 以及用户的 AccessKeys 来进行交互的。 为了保证安全，阿里云 AccessKeys 是使用 阿里云子账户 来添加的。 登录 [阿里云管理控制台](https://home.console.aliyun.com/) – 点击头像中的 accesskeys – 选择 开始使用子用户AccessKeys {或者直接点击该网址} – 设置 用户名 – 选择权限中输入“DNS”，选择 AliyunDNSFullAccess(管理员解析（DNS）的权限) 这项 – 之后子账户和AK都创建成功了。 AliyunDNSFullAccess 表示 “管理员解析（DNS）的权限”，既该账户就有了添加DNS记录和删除DNS记录的权限，但没有其他权限。 一定要在这一步记录下这个 AccessKey 信息，之后就无法看到了。 添加配置在 bash 中执行如下命令，将参数添加到环境变量中： 12export Ali_Key=&quot;AccessKeyId&quot;export Ali_Secret=&quot;AccessKeySecret&quot; 注意，这里的 Ali_Key 和 Ali_Secret 是和你所使用的域名提供商一一对应的。具体的可在这里查找：相应的设置方法 另外，这个临时环境变量只需配置这一次，当成功申请证书后，API信息会被自动保存在 ~/.acme.sh/account.conf ，下次你使用 acme.sh 的时候会被自动使用。 生成泛域名证书接下来正式开始申请泛域名证书，将 example.com 换成你自己的域名： 1$ acme.sh --issue --dns dns_ali -d example.com -d &apos;*.example.com&apos; 申请完成后可以在 ~/.acme.sh/example.com 下看到证书文件： 证书文件是 fullchain.cer密钥文件是 example.com.key 证书续期Let’s Encrypt 证书的有效期为三个月，acme.sh会每隔60天自动帮你续期。在以上命令执行后，会在 crontab 里添加计划，通过命令查看： 1$ crontab -l 将证书配置到Nginx放在 ~/.acme.sh/example.com 目录下的证书文件不能直接拿来使用，需要拷贝到一个自定义的目录下，再配置到Nginx中才能正常的使用。 Docker使用acme.sh上面的方法安装起来虽说已经很简单了，但是对于像我这种但凡能用Docker来解决的问题绝对不用其他方式。 获取镜像1$ docker pull neilpang/acme.sh 创建acme.sh证书保存目录1$ mkdir /etc/acme.sh 运行 acme.sh 容器这里依然需要从域名服务商处获得的ID和Secret： 12345$ docker run --rm \-v /etc/acme.sh:/acme.sh \-e Ali_Key=&quot;sdfsdfsdfljlbjkljlkjsdfoiwje&quot; \-e Ali_Secret=&quot;jlsdflanljkljlfdsaklkjflsa&quot; \neilpang/acme.sh --issue --dns dns_ali -d example.com -d &apos;*.example.com&apos; 注意这里第一个域名为顶级域名，后面一个为泛域名。 这种方式将自动为你的域名添加一条 txt 解析，验证成功后，这条解析记录会被删除，所以对你来说是无感的，就是要等待 120 秒。 证书生成成功后，默认保存在 .acme.sh/example.com 中。 容器化自动续期可以以后台进程的方式运行一个容器： 1234$ docker run --name acme.sh \-d --restart unless-stopped \-v /etc/acme.sh:/acme.sh \neilpang/acme.sh daemon 这样，acme.sh 证书到60天就会自动更新。 注意事项当我按照如上方法生成域名证书时，执行命令： 12345$ docker run --rm \-v /etc/acme.sh:/acme.sh \-e Ali_Key=&quot;sdfsdfsdfljlbjkljlkjsdfoiwje&quot; \-e Ali_Secret=&quot;jlsdflanljkljlfdsaklkjflsa&quot; \neilpang/acme.sh --issue --dns dns_ali -d itfanr.cc -d *.itfanr.cc 发现会提示如下错误： 1234567➜ acme.sh docker run --rm \-v /etc/acme.sh:/acme.sh \-e Ali_Key=&quot;sdfsdfsdfljlbjkljlkjsdfoiwje&quot; \-e Ali_Secret=&quot;jlsdflanljkljlfdsaklkjflsa&quot; \neilpang/acme.sh --issue --dns dns_ali -d itfanr.cc -d *.itfanr.cczsh: no matches found: *.itfanr.cc➜ acme.sh 经查证，其中的泛域名 *.example.com 中由于带有 * 号，会报错。相应的解决方法是添加引号：-d &#39;*.example.com&#39; Issue Wildcard certificate with zsh failed · Issue #1334 · Neilpang/acme.sh 我的操作记录创建本地证书保存目录： 1$ mkdir /etc/acme.sh 执行： 1234567891011121314151617➜ acme.sh docker run --rm \-v /etc/acme.sh:/acme.sh \-e Ali_Key=&quot;sdfsdfsdfljlbjkljlkjsdfoiwje&quot; \-e Ali_Secret=&quot;jlsdflanljkljlfdsaklkjflsa&quot; \neilpang/acme.sh --issue --dns dns_ali -d itfanr.cc -d &apos;*.itfanr.cc&apos;[Tue Sep 18 15:11:27 UTC 2018] Registering account[Tue Sep 18 15:11:28 UTC 2018] Registered[Tue Sep 18 15:11:28 UTC 2018] ACCOUNT_THUMBPRINT=&apos;AR2Gc73349sl32z_kw-kY9nP7qqesQqFlK8&apos;[Tue Sep 18 15:11:28 UTC 2018] Creating domain key[Tue Sep 18 15:11:29 UTC 2018] The domain key is here: /acme.sh/itfanr.cc/itfanr.cc.key[Tue Sep 18 15:11:29 UTC 2018] Multi domain=&apos;DNS:itfanr.cc,DNS:*.itfanr.cc&apos;[Tue Sep 18 15:11:29 UTC 2018] Getting domain auth token for each domain[Tue Sep 18 15:11:30 UTC 2018] Getting webroot for domain=&apos;itfanr.cc&apos;[Tue Sep 18 15:11:30 UTC 2018] Getting webroot for domain=&apos;*.itfanr.cc&apos;[Tue Sep 18 15:11:30 UTC 2018] Found domain api file: /root/.acme.sh/dnsapi/dns_ali.sh[Tue Sep 18 15:11:31 UTC 2018] Found domain api file: /root/.acme.sh/dnsapi/dns_ali.sh[Tue Sep 18 15:11:32 UTC 2018] Sleep 120 seconds for the txt records to take effect 发现，当最后一行提示信息为 Sleep 120 seconds for the txt records to take effect 时，说明正在自动执行DNS绑定的操作。 当日志继续输出时，可以看到最后提示执行成功了 Cert success.： 12345678910111213141516171819202122[Tue Sep 18 15:11:32 UTC 2018] Sleep 120 seconds for the txt records to take effect[Tue Sep 18 15:13:32 UTC 2018] Verifying:itfanr.cc[Tue Sep 18 15:13:35 UTC 2018] Success[Tue Sep 18 15:13:35 UTC 2018] Verifying:*.itfanr.cc[Tue Sep 18 15:13:38 UTC 2018] Success[Tue Sep 18 15:13:38 UTC 2018] Removing DNS records.[Tue Sep 18 15:13:42 UTC 2018] Verify finished, start to sign.[Tue Sep 18 15:13:44 UTC 2018] Cert success.-----BEGIN CERTIFICATE-----MIIGCjCCBPKgAwIBAgISA95TIaF4XRlosoA/zwdEbLRaMA0GCSqGSIb3DQEBCwUAMEoxCzAJBgNVBAYTAlVTMR34dcvKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQDExpMZXQncyBFbmNyeXB0IEF1dGhvcml0eSBYMzAeFw0xODA5MTgxNDEzNDJaFw0x......A6l0KWm2/jjYcf5YPGIoK3jMzNm17B88yoPYoDwecxWC59t5+DQjpQo7iM7tyTV+q4UZMY9jlrbaCJVSdrM=-----END CERTIFICATE-----[Tue Sep 18 15:13:44 UTC 2018] Your cert is in /acme.sh/itfanr.cc/itfanr.cc.cer[Tue Sep 18 15:13:44 UTC 2018] Your cert key is in /acme.sh/itfanr.cc/itfanr.cc.key[Tue Sep 18 15:13:44 UTC 2018] The intermediate CA cert is in /acme.sh/itfanr.cc/ca.cer[Tue Sep 18 15:13:44 UTC 2018] And the full chain certs is there: /acme.sh/itfanr.cc/fullchain.cer➜ acme.sh 查看 /etc/acme.sh 目录下： 12345➜ acme.sh lsaccount.conf ca http.header itfanr.cc➜ acme.sh ls itfanr.ccca.cer fullchain.cer itfanr.cc.cer itfanr.cc.conf itfanr.cc.csr itfanr.cc.csr.conf itfanr.cc.key➜ acme.sh 其中， 证书文件是 fullchain.cer ，密钥文件是 itfanr.cc.key 。 配置Nginx在域名的nginx配置文件中新增证书配置，例如我的 gogit.itfanr.cc 域名的配置文件 gogit.conf 如下： 1234567891011121314151617181920212223server &#123; listen 443 ssl; server_name gogit.itfanr.cc; ssl_certificate /etc/acme.sh/itfanr.cc/fullchain.cer; ssl_certificate_key /etc/acme.sh/itfanr.cc/itfanr.cc.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; location / &#123; proxy_pass http://127.0.0.1:3000/; &#125;&#125;server &#123; listen 80; server_name gogit.itfanr.cc; return 301 https://$server_name$request_uri;&#125; 然后更新nginx，重新载入配置： 1$ sudo nginx -s reload 在浏览器中访问域名，可以看到地址栏中的小绿锁已经出现了。 相关参考 说明 · Neilpang/acme.sh Wiki How to issue a cert · Neilpang/acme.sh Wiki acme.sh/README.md at master · Neilpang/acme.sh 利用acme.sh申请 Letsencrypt 免费 SSL 证书 | Nero Blog]]></content>
      <categories>
        <category>HTTPS</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客添加Gitment评论系统]]></title>
    <url>%2F2018%2F09%2F17%2Fhexo-add-gitment-review-system%2F</url>
    <content type="text"><![CDATA[之前我的Hexo博客中使用的是 多说 的评论插件，后来多说停止运营了之后就直接把评论功能去掉了，而后一直使用的是邮件的方式。但邮件也是很不方便的，是一种不得已的选择。 最近，看到好多博客中都添加了一个名为 Gitment 的评论插件，直接使用GitHub的 Issues 作为评论内容的存储位置，也是非常方便的。 Update:2019-04-30 Gitment 评论插件已经长时间不更新了，另外由于插件内引用的域名Https证书已经过期，导致无法提交评论。建议更换为更好用的 Gitalk 评论插件。 配置方法见：Hexo博客添加Gitalk评论系统 | IT范儿 Next主题版本我的hexo主题使用的是 Next 主题,当前版本为 v5.1.3 。这一版是直接内置支持 gitment 功能的。关于如何升级 Next 主题，可以看我之前的文章：Hexo博客添加搜索功能 另外我发现，当前 Next 主题的最新版本为 v6.4.1，而 v6.x.x 版本和 v5.x.x 版本又有所不同，不能平滑的升级，所以这里我就没有升级 Next 到最新，直接使用的 v5.1.3 版本。 添加Gitment评论创建GitHub OAuth Apps打开链接 OAuth Apps – New OAuth App 。按要求填写相应内容即可。 其中，Homepage URL 表示站点的网址。Authorization callback URL 为站点的回调地址，一般也默认为站点的网址。 最后，得到 Client ID 和 Client Secret 备用。 修改配置在 themes/next 目录下，找到 _config.yml 配置文件，找到 gitment 配置段： 123456789101112131415# Gitment# Introduction: https://imsun.net/posts/gitment-introduction/gitment: enable: false mint: true # RECOMMEND, A mint on Gitment, to support count, language and proxy_gateway count: true # Show comments count in post meta area lazy: false # Comments lazy loading with a button cleanly: false # Hide &apos;Powered by ...&apos; on footer, and more language: # Force language, or auto switch by theme github_user: # MUST HAVE, Your Github Username github_repo: # MUST HAVE, The name of the repo you use to store Gitment comments client_id: # MUST HAVE, Github client id for the Gitment client_secret: # EITHER this or proxy_gateway, Github access secret token for the Gitment proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: # Protocol of redirect_uri with force_redirect_protocol when mint enabled 设置 enable 为 true ，表示启用 gitment 评论插件。 Update:2019-04-30 Gitment 评论插件已经长时间不更新了，另外由于插件内引用的域名Https证书已经过期，导致无法提交评论。建议更换为更好用的 Gitalk 评论插件。 配置方法见：Hexo博客添加Gitalk评论系统 | IT范儿 其他的必需项是 github_user ，表示你的github账号名称。 github_repo 表示保存评论数据的仓库名称，这里可以使用当前博客所在的仓库名称，也可以单独设置一个专门的仓库。client_id 和 client_secret 为上面创建的值。 修改完成后，将hexo博客文件上传到github。因为gitment功能必需在线上才能进行操作。 注意事项点击登录github发现一直显示loading在创建 OAuth Apps 中填写 Authorization callback URL 时，网站的地址末尾不能带有 / 。 某些文章不能生成Issues当点击文章页面底部的 初始化本文的评论页 按钮时，页面会弹出错误信息：Error:Validation Failed 信息。 通过查看操作请求，gitment会在生成Issues时创建两个 label 标签。 一个是文章标题的路径: window.location.pathname 值，如 /2018/09/05/pip-install-locale-error-unsupported-locale-setting/ ；另一个是定值 gitment 。 而由于 github 中 Issues 的 label 长度限制为最大 50 个字符，当 文章标题长度过长时，该label就会生成失败，而导致初始化错误，弹出 Validation Failed 的提示。 通过网上的搜索，发现可以使用文章创建时的时间来代替文章标题，作为这个唯一的label标签。 找到giment的配置：/themes/next/layout/_third-party/comments/gitment.swig 文件： 找到如下部分： 12345var gitment = new &#123;&#123;CommentsClass&#125;&#125;(&#123; id: window.location.pathname, owner: &apos;&#123;&#123; theme.gitment.github_user &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitment.github_repo &#125;&#125;&apos;, ... 修改为： 12345var gitment = new &#123;&#123;CommentsClass&#125;&#125;(&#123; id: &apos;itfanr_blog_&#123;&#123; date(page.date, &quot;YYYYMMDDhhmmss&quot;) &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitment.github_user &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitment.github_repo &#125;&#125;&apos;, ... 这样，在初始化时就不会出错了。 有新的Issues时发送钉钉提醒上面我们添加了评论功能，但是在使用中会出现不能及时响应的问题。当有人对文章做了评论或提出什么疑问后，我们并不能及时的知道或者回复，这样给人的感觉是不好的。虽然添加了评论功能，但反而不如使用邮件的方式高效了。 经过一番思考后，我发现平时工作中用到的钉钉中是可以添加GitHub的钉钉机器人的。而手机端的钉钉也能做到有新提醒后立即响应。所以，可以设置当GitHub的Issues有变动时，通过钉钉机器人提醒我们查看新的评论或作出回复。 生成Github机器人WebHook地址钉钉机器人只有在群中才能添加，个人是无法添加的。但是一个人又无法创建群。那么该如何添加一个钉钉群机器人呢？ Update:2019-05-05 我采用的方法是 “偷梁换柱” 的方式。首先呢，在手机或PC端选择 “发起群聊”，至少选择二个人进来，此时注意不要在群里发任何信息。然后在 群设置 中的 群成员 选项中移除其他人就可以了，整个过程其他人不会接收到任何消息（有点类似于微信清理联系人的操作）。就这么简单。这样，这个群里就只有你一个人了，添加群机器人后也不会打扰到别人。 之前钉钉中组建群组至少必须是二个人，最近测试发现组建群组至少必须是三个人了。也就是必须选择另外两个好友才能组成一个群组。如果只选择一个好友，那进入的就是 “发消息” 的界面了。 然后在 群 设置中选择 群机器人 选项，选择 GitHub机器人 ，按照设置流程生成GitHub机器人，即可获取到相应群的WebHook地址，其格式如下： 1https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx 在GitHub中设置项目的webhook进入 GitHub 的 Hexo 博客仓库，依次点击 Settings – Webhooks &amp; Services – Add Webhook ，新增一项。 在 payload URL 中填写刚才获得的钉钉WebHook地址； 在 Content type 选项下选择 application/json 项； 在 Secret 中不填写内容，保持空值即可； 在 Event 选项下，我这里选择了 issues 相关的所有 event 事件，也可以按照自己的需求自定义。 然后，点击 Add webhook 按钮即可。 至此，当 Issues 中有新的评论时，在钉钉手机客户端就能立即接收到提醒了。 参考 解决Gitment初始化评论时validation failed | Pace’s Blog Hexo博客Next主题添加Gitment评论系统坑点 · swlfigo/Study Wiki 钉钉中设置代码提交提醒–Github机器人 - CSDN博客]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决pip install时unsupported locale setting错误]]></title>
    <url>%2F2018%2F09%2F05%2Fpip-install-locale-error-unsupported-locale-setting%2F</url>
    <content type="text"><![CDATA[今天在安装 docker-compose 时，使用 pip install 命令出现了下面这个错误： 123456789➜ sudo pip install -U docker-composeTraceback (most recent call last): File &quot;/usr/bin/pip&quot;, line 11, in &lt;module&gt; sys.exit(main()) File &quot;/usr/lib/python2.7/dist-packages/pip/__init__.py&quot;, line 215, in main locale.setlocale(locale.LC_ALL, &apos;&apos;) File &quot;/usr/lib/python2.7/locale.py&quot;, line 581, in setlocale return _setlocale(category, locale)locale.Error: unsupported locale setting 后来查询到是语言配置错误导致的： 12345678➜ locale -alocale: Cannot set LC_CTYPE to default locale: No such file or directoryCC.UTF-8en_USen_US.iso88591en_US.utf8POSIX 解决方法： 执行如下命令即可。 1➜ export LC_ALL=C 再次尝试安装： 123456789101112131415➜ sudo pip install -U docker-composeThe directory &apos;/home/ubuntu/.cache/pip/http&apos; or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo&apos;s -H flag.The directory &apos;/home/ubuntu/.cache/pip&apos; or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo&apos;s -H flag.Collecting docker-compose Downloading https://files.pythonhosted.org/packages/67/03/b833b571595e05c933d3af3685be3b27b1166c415d005b3eadaa5be80d25/docker_compose-1.22.0-py2.py3-none-any.whl (126kB) 100% |################################| 133kB 143kB/sCollecting websocket-client&lt;1.0,&gt;=0.32.0 (from docker-compose) Downloading https://files.pythonhosted.org/packages/09/12/d21872b618befc489cabde794c7af281d12fa2e194e279132ef1f04a3b07/websocket_client-0.52.0-py2.py3-none-any.whl (198kB) 100% |################################| 204kB 34kB/s......Successfully installed PyYAML-3.11 backports.ssl-match-hostname-3.5.0.1 cached-property-1.4.3 certifi-2018.8.24 chardet-2.3.0 docker-3.5.0 docker-compose-1.22.0 docker-pycreds-0.3.0 dockerpty-0.4.1 docopt-0.6.2 enum34-1.1.2 functools32-3.2.3.post2 idna-2.0 ipaddress-1.0.16 jsonschema-2.6.0 requests-2.9.1 six-1.10.0 texttable-0.9.1 urllib3-1.13.1 websocket-client-0.52.0You are using pip version 8.1.1, however version 18.0 is available.You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. 关于LC_ALL=C LC_ALL=C 是为了去除所有本地化的设置，让命令能正确执行。 在Linux中通过 locale 来设置程序运行的不同语言环境，locale 由ANSI C提供支持。locale 的命名规则为 &lt;语言&gt;_&lt;地区&gt;.&lt;字符集编码&gt; ，如zh_CN.UTF-8，zh代表中文，CN代表大陆地区，UTF-8表示字符集。 在shell控制台中输入 locale 就可以查看本地默认设置: 123456789➜ localeLANG=&quot;zh_CN.UTF-8&quot;LC_COLLATE=&quot;zh_CN.UTF-8&quot;LC_CTYPE=&quot;zh_CN.UTF-8&quot;LC_MESSAGES=&quot;zh_CN.UTF-8&quot;LC_MONETARY=&quot;zh_CN.UTF-8&quot;LC_NUMERIC=&quot;zh_CN.UTF-8&quot;LC_TIME=&quot;zh_CN.UTF-8&quot;LC_ALL= “C”是系统默认的locale ，”POSIX”是”C”的别名。所以当我们新安装完一个系统时，默认的 locale 就是 C 或 POSIX 。 LANG LC_* 的默认值，是最低级别的设置。可以理解成 LANG是一个缺省值，所有没有显式设置值的 LC_* 变量都会取LANG的值。类似于 LC_ALL 。 LC_ALL 它是一个宏，如果该值设置了，则该值会覆盖所有 LC_* 的设置值。注意，LANG的值不受该宏影响。 注意: LC_ALL 并不是一个环境变量，而是一个glibc中定义的一个宏。LC_ALL=C 这样的语法实际上是调用了 setlocale 把所有的 LC_* 的变量设置了一遍，所以在终端中直接 echo $LANG 等可以输出对应变量的值，但是 echo $LC_ALL 什么都没有，因为它压根就不是一个变量。 所以设置 LC_ALL=C ，就是解决各种与区域设置有关的warning。从程序运行角度看，就是保持程序输出的统一格式，这样有些程序才能正确执行下去。 相关参考： 解决pip install时unsupported locale setting错误 | 阿阿燃 LC_ALL=C表示什么？ | 云上小悟]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保定市如何更换驾驶证]]></title>
    <url>%2F2018%2F06%2F17%2Fhow-to-change-the-driver-license-in-baoding%2F</url>
    <content type="text"><![CDATA[6月15日周五我去保定车管所（保定市长城北大街2601号）更换了新驾照，以下是我的换证记录，希望能帮到想要更换驾照的朋友们。 上班时间周一到周五 冬季： 9:00 – 12:00 14:00 – 17:00 夏季： 9:30 – 12:30 14:30 – 17:30 首先，对于周六日能不能办理，这个我没有专门去向车管所的办公人员考证，所以在这里也就不能确认。我也是为了防止周六日白跑一趟，才在周五这天请了一天假过来的。 15号当天我是大概12点10分左右到的车管所，结果进去却被告知要下班了等下午再来，一问下午上班时间是14:30 。 另外，车管所分两个服务大厅（在外面有相应的标识），A区应该主要是办理车辆相关的业务，B区主要是办理证件相关的业务。 所以，要更换新驾照，直接去B区就好了。 在中午这段时间呢，车管所的两个服务大厅都会锁门，也就是说，在这里是没有可以休息的地方的。 15号这天的温度大概在29°左右，已经是相当的闷热了。中午这段时间来这里办理业务的人也是络绎不绝，一看关着门也就只好在外面等着了。 在两个大厅之间有可以遮阳的顶棚，两边各有一排座椅可以休息。但对于夏季29°的闷热气温来说，也着实热的不行。 所以我建议大家如果来的话，尽量赶在上午或者下午2点之后再过来。当天中午我在外面坐着等了两个多小时实在是难受啊。 需要带什么要更换新驾照， 身份证 和 驾驶证 当然是必需的。 首先要说明的一点是，服务大厅的入口是需要刷身份证并且需要人脸比对才能进去的，应该是为了防止黄牛的一种措施。 其次，还需要带上一些零钱。这里要着重解释一下，这里指的是“纸币”，主要是相对于的微信和支付宝而言的，因为是不支持用微信和支付宝来缴费的。 其中一部分是需要进行体检，体检费是15元。另一部分是换证的工本费是10元。 再者，可以自行携带照片。注意，照片的要求是 一寸白底免冠彩照，需要两张。如果没有照片的话，在服务大厅内是有两台可以照相的机器的，立等可取。费用好像是10元一份吧。因为我是自己带的照片，所以拍照片就不太清楚了。 总结一下： 身份证 驾驶证 人民币 （大概共计 15+10+10 元，一共带50或100左右就够了 注意：最好是带零钱，要带个整的50元或100元过去，光找零钱就很浪费时间了；再者，大家都带整钱不一定能找开… 办理流程因为我是第一次去，对于办理的流程刚开始也不是很清楚，也是一点一点的看着别人是怎么弄得，然后自己也跟着去做，慢慢的就了解了。 身份证复印件首先呢，要有身份证复印件。这个在大厅的进门左手边是有一台身份证复印机的。 体检其次，需要进行体检。在大厅的进门左手边有一条通道，进去第一个门口就是了，写着体检呢。 进去后是先在门口处缴费，然后去旁边第二个办公人员那里等着叫名字，按照她的要求去做就好了。然后是到旁边第三个人那里测视力。 最后通过后会给你一张单子，签名然后去大厅排队拿号。 排队拿号在大厅里，进门右手边是排队拿号的地方。也是有摄像头通过人脸识别给号。 这里要说一下，在这里排队拿号和当时进门时刷身份证人脸比对属于先后的步骤。如果你在进门时没有刷上或人脸比对不成功就进来了，在这里拿号的时候就没有你的信息。我在排队时看到好几人去又重新去门口刷了一遍才能拿号。 拿完号后进入业务大厅等着叫号就行了。 需要多久总的来说，从我进入办证大厅，到我办好证件走出大厅，大概是花了50分钟左右。当然，这是对于一个像我这样的第一次换证的小白而言的，毕竟我在里面浪费了很多“学习”的时间。 你说我想快点办，有没有什么秘籍呢？ 当然，秘籍当然有了。那么下面，我就把我总结的 “快速换证” 秘籍告诉你。 如何快速换证 带好 身份证 驾驶证 人民币 刷身份证进入大厅后，先去大厅入口左手边的 “身份证复印机” 去复印身份证，按照机器上的要求做就好了。 如果自己有携带照片，直接进行下一步。如果没有携带照片，在 “身份证复印机” 旁边有两台 “相片快照机” ，直接进去照相。 去旁边的通道里的第一个房间，进行体检。 拿着 身份证复印件 和 照片 及 体检单 到大厅入口右手边去排队拿号。 进入大厅后等着叫号办理即可。 对于第一次来办理的人来说，时间应该就是浪费在了来回的咨询中，像无头苍蝇那样。 我刚进去的时候，看到好多人直接就奔着大厅入口右手边的排队叫号处就去了，应该是看到了上面写着“业务办理”的字样，结果被告知先要进行体检才能拿号。等找到体检的地方，又被告知必须有照片才行，因为体检单上需要贴照片。 体会通过这次换证，也有一些个人的体会，当然并不算是吐槽。 挺大的一个车管所，没有一个让来办理业务的群众可以休息或坐着的 “凉快儿” 的地方，毕竟大热的天，感觉非常不人性化。办公人员可以在办公室里吹着空调休息，让来办理业务的群众们在外面晒着大太阳等着。。。 在业务大厅中没有可以咨询的工作人员。我看到的只有一个机器人。就是你说一句它回一句的那种。 感觉如果没有安排相应的咨询人员的话，可以贴一张业务办理流程图，标明第一二三步，不会让来办业务的群众在里面团团转。 在来办理之前也在网上查到过这里有提供自助服务办理的机器。我也看到了是摆放在“身份证复印机”旁边的，有两台。我去旁边看了看，没有找到更换驾驶证的按钮或标识，倒是有几个来办理违章的人在那里排队。因为旁边也没有找到可以咨询的工作人员，所以我也就没太关注这个。本来来之前是想着如果这种自助服务机上可以直接办理的话我就直接在机器上办理了，毕竟相比人工的要快很多。不过办完后想想，这个流程下来要进行体检，贴照片，当场制作新证件等等操作，还是人工的要靠谱一些。 感觉办公人员的服务态度不是很好。 总的来说，办理业务还算非常快速的，业务大厅内也是井然有序。 如果真的帮到了你，别忘了回来给个小小的鼓励呀！！！]]></content>
      <tags>
        <tag>人在帝都</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker共享volume的权限问题]]></title>
    <url>%2F2018%2F06%2F12%2Fdocker-volume-permission%2F</url>
    <content type="text"><![CDATA[有时候在创建Docke容器时，我一般都会先在host主机下创建一个用来映射到容器内的目录作为 volume 映射目录。但在某些情况下，我们可能会忘记提前创建该目录，而直接执行了 docker run .... -v /data/sites:/app ....ubuntu:latest 命令。该命令会自行在 host 主机下创建目录 /data/sites 。 但当向该文件中拷贝文件时，就会提示 permission denied 的错误，这是因为当前用户对该目录没有可操作权限导致的。 volume 的权限在于主机是怎么给的，如果你想要给phpfpm文件夹 www-data:www-data 权限，在你的主机挂载目录执行 chown -R www-data:www-data /data/sites 即可。 在宿主机为 volume 目录重新设置host主机下当前用户的权限即可： 如在 host 主机下，当前用户为 tiger： 1$ chown -R tiger:tiger /data/sites]]></content>
      <categories>
        <category>Docker容器技术</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac系统下快速搜索神器Spotlight]]></title>
    <url>%2F2018%2F05%2F14%2Fspotlight-skills%2F</url>
    <content type="text"><![CDATA[在Mac系统下如何更快速的找到想要的文件？ 技巧 直接按下 Command + Space 显示 输入文件名或相关字符，回车直接打开。 列表文件通过上/下箭头选择 查看全部搜索结果，点击 “在Finder中显示全部” 后回车 查找并打开文件所在文件夹：选中要查找的文件后按下Command+回车 显示文件完整路径：选中要查找的文件后按下Command键，在下方出现完整路径名； 进行数学计算、单位转换：直接输入数学公式进行计算；直接输入货币单位进行转换； 定制查找范围：“系统偏好设置–Spotlight”。 利用文件类型查找：“kind:(file type)” 如 find:image 。“find type”可选：“image”、“movie”、“music”、“email”、“application”、“text”、“archive”等 通过文件格式查找：“kind:(file format)” 如 find:pdf。 “find format”可选：“jpeg”、“gif”、“pdf”、“mp3”、“mp4”、“zip”等。 联合文件类型和文件名查找：“kind:(file type/file fromat) &quot;file name&quot;” 如 kind:pdf &quot;python&quot; 即搜索文件名带有“python”的pdf文件。 参考 Spotlight–Mac上的查询利器]]></content>
      <tags>
        <tag>Skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同一设备下多重SSH Keys管理]]></title>
    <url>%2F2018%2F05%2F14%2Fmultiple-ssh-keys-management-under-the-same-device%2F</url>
    <content type="text"><![CDATA[一般我们在自己的个人电脑上使用git时都会通过SSH的方式来连接代码管理站点如Github等。但有时候我们也会遇到多重SSH的问题。 需求最常见的情况就是一般的公司都会有自己的私有git仓库，比如用gitlab来搭建的git仓库站点。而公司里也会为每位员工设置一个个人专属的公司域名邮箱，这样的情况下就遇到问题了：我们在自己的电脑上已经配置了自己的邮箱账号作为主力的git账户，而在开发公司的项目时，用来提交git操作的时候就要切换为公司分配的邮箱账号了。虽然我们可以在项目目录内使用 git config user.name 和 git config user.email 来为该项目指定单独的git提交账户，但在 git pull 和 git push 时，每次都需要使用 http 的方式输入密码才行，非常的麻烦。 准备那么现在问题就来了，个人使用的git账户和公司分配的git账户应该如何在一台电脑上同时存在并保证都能分别使用SSH的方式来提交代码呢？ 首先，我们指定下面示例使用的git账户： 我的个人git账户: leafney leafney@gmail.com git仓库：github.com我的公司git账户: wuyazi wuyazi@company.com git仓库：111.206.223.205:8080 （公司配置的gitlab对应ip地址）我使用的Bash : iTerm2+zsh 我的需求是，因为我使用的是个人电脑，所以我希望的是在默认情况下，仍然使用我自己的git账户 leafney@gmail.com 作为全局账户来提交项目。对于公司的项目，则使用公司的git账户 wuyazi@company.com 作为局部账户来仅提交公司的项目。 之前在我的mac下已经设置了默认的git账号 leafney@gmail.com 对应的ssh密钥 。如果你还没有设置过SSH，可以参考我之前的文章：Linux下使用SSH密钥连接Github 新增SSH key现在要新增一个工作的账号，以 wuyazi wuyazi@company.com 为示例账户来添加。 查看已添加SSH密钥查看mac下已经添加的我的个人git账号信息: 123~/.ssh➜ lsid_rsa id_rsa.pub known_hosts 查看 id_rsa.pub 内容: 12➜ vim id_rsa.pubssh-ras xxxxxxxxxxxx leafney@gmail.com 新增SSH密钥创建新的 ssh key： 1234// 切换到 .ssh 目录下➜ cd ~/.ssh// 输入工作邮箱来创建新的ssh key,git唯一认证标准是邮箱➜ ssh-keygen -t rsa -C &quot;wuyazi@company.com&quot; 需要注意的一点是，当提示 Enter file in which to save the key (/Users/leafney/.ssh/id_rsa): 时，我们不使用默认的名称 id_rsa ，因为该名称我们之前在设置个人git账户时已经使用过了，所以这里新设置一个针对于公司git账户的名称 id_rsa_work。 操作记录： 123456789101112131415161718192021222324~/.ssh➜ ssh-keygen -t rsa -C &quot;wuyazi@company.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/leafney/.ssh/id_rsa): id_rsa_workEnter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in id_rsa_work.Your public key has been saved in id_rsa_work.pub.The key fingerprint is:SHA256:gZO6tyeOrp0FLGT5q2kBn3+9Et+P1shzjuyv3rUXWY0 wuyazi@company.comThe key&apos;s randomart image is:+---[RSA 2048]----+| || o ||. + . . || o o . . E .|| B . S o . || o = ... o || . B oo.o o .. || = Ao.oo*++. . || +=B.o+.+BB=.. |+----[SHA256]-----+~/.ssh took 22s 将密钥添加到ssh agent管理通过ssh agent对密钥的管理我们可以实现免密码提交。使用 ssh-add 命令来将新增的密钥添加到 ssh-agent 的高速缓存中： 12345~/.ssh//添加之前所新生成的用于work的密钥➜ ssh-add ~/.ssh/id_rsa_workIdentity added: /Users/leafney/.ssh/id_rsa_work (/Users/leafney/.ssh/id_rsa_work) 可以通过命令 ssh-add -l 来查看存在于 ssh-agent 密钥管理器中所有的密钥列表： 1234~/.ssh➜ ssh-add -l2048 SHA256:gZO6tyeOrp0FLGT5q2kBn3+9Et+P1shzjuyv3rUXWY0 /Users/leafney/.ssh/id_rsa_work (RSA)2048 SHA256:My6EL2r7d20oq01x1PeuRiYJSK2aID3sQlR+xCagPnE /Users/leafney/.ssh/id_rsa (RSA) 这里如果发现之前的 id_rsa 的密钥不存在，可以重新添加一下。 如果要删除所有已添加的密钥，可以使用命令：ssh-add -D 。 配置ssh config编辑configSSH 程序可以从以下途径获取配置参数： 用户配置文件：~/.ssh/config系统配置文件：/etc/ssh/ssh_config 配置文件可分为多个配置区段，每个配置区段使用 Host 来区分。我们可以在命令行中输入不同的Host来加载不同的配置段。 在 ~/.ssh 目录下打开配置文件 config(没有则新增该文件)，如下是我的配置示例： 新增： 12➜ cd ~/.ssh/➜ touch config config 内容: 123456789Host work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_workHost github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa 配置项说明常用的SSH配置项： Host 别名 : Host myhost 表示自定义的host简称，以后连接远程服务器就可以使用命令 ssh myhost (注意下面有缩进) HostName 主机名 : 主机名可以是ip也可以是域名(如:github.com或者bitbucket.org);如果主机名中包含 %h ，则实际使用时会被命令行中的主机名替换。 Port 端口 : 表示服务器open-ssh端口，默认22，默认时一般不写此行 User 用户名 : User git 表示登录ssh的用户名，如 git IdentityFile ： 表示证书文件路径（如 ~/.ssh/id_rsa_*) 其他SSH配置项： IdentitiesOnly 只接受 SSH Key 登录 可选 yes or no PreferredAuthentications 强制使用Public Key验证 测试如上，我用别名 work 指代了公司gitlab的ip地址 111.206.223.205:8080 ，使用 ssh -T 命令来验证一下： 123456➜ ssh -T git@workThe authenticity of host &apos;111.206.223.205:8080 (111.206.223.205:8080)&apos; can&apos;t be established.RSA key fingerprint is SHA256:/UwiMSDZVkgF+3yLAxHwMJfYGxK2XGk5DU3txRr+LNg.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;111.206.223.205:8080&apos; (RSA) to the list of known hosts.Welcome to GitLab, 无崖子! 第一版示例项目clone如上的步骤配置完成后，我们就可以通过ssh别名的方式来区分使用不同的SSH Key了。 在 clone 项目到本地之前，我们需要进行一个小小的改动。 之前的clone命令： 1➜ git clone git@111.206.223.205:8080:how_to_use_multiple_git_ssh/you_can_by_this_way.git 更改后的clone命令： 1➜ git clone git@work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 即我们将原来ssh地址中的域名用我们在配置文件中的别名来代替了，而相应的别名又对应着ssh密钥文件。 当然，我们还可以更精简一下，因为我们在config 文件中已经指定了用户为 git ，所以可将路径中的用户名也省略掉： 1➜ git clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 这样，看起来是不是非常的舒服呢？ 而如果我要clone自己的个人项目，则仍然按照之前的操作即可： 1➜ git clone git@github.com:Leafney/docker-alpine-mysql.git 设置项目提交账户在将项目 clone 到本地之后，还要为该项目单独设置commit提交时使用的git账户。 因为我们在之前已经按照 Linux下使用SSH密钥连接Github 操作中的方法将我的个人账户 leafney leafney@gmail.com 设置为了全局的git账户，在提交项目时如果没有设置项目单独的git账户，就会使用全局的，那这样就不对了。 不加 --global 参数，为刚刚clone下来的公司项目设置公司分配的git账户： 12➜ git config user.name &quot;wuyazi&quot; # 双引号是为了防止name中含有空格而导致错误➜ git config user.email &quot;wuyazi@company.com&quot; 这样就配置完成了。 还能再快一点吗总结上面的操作步骤，无非是设置了如下两项： 指定git项目使用的SSH Key 指定git项目提交时使用的git账户 那么第一步我们已经在ssh的 config 中做了指定，貌似已经是最快的操作了。那就看看第二项如何优化呢？ 我们是在git项目clone到本地之后，再去为该项目添加了使用的git账户，那是否能将这两步合并为一步呢？ 答案当然是可以的。 设置Base/Zsh方便clone操作为了以后方便使用不同git账户 git clone 项目，我们在 bash 的 ~/.bashrc 或者 zsh 的 ~/.zshrc 内加入： 1alias work-git-clone=&apos;git clone --config user.name=&quot;wuyazi&quot; --config user.email=&quot;wuyazi@company.com&quot; $@&apos; 以后就只要输入 work-git-clone REPO-SSH-URL ，效果就相当于执行了如下的命令: 1234git clone REPO-SSH-URLcd REPOgit config user.name &quot;wuyazi&quot;git config user.email &quot;wuyazi@company.com&quot; 然后，更新 Bash/Zsh 的设置： 12345# 更新Bash设置➜ source ~/.bashrc# 更新zsh设置➜ source ~/.zshrc 参考自；多重 SSH Keys 與 Github 帳號 第二版示例经过上面的操作，我们在 git clone 公司的git项目时，只需要执行如下简单的两步即可： 第一步：更改SSH地址 1234# 将项目SSH地址：git@111.206.223.205:8080:how_to_use_multiple_git_ssh/you_can_by_this_way.git# 更改为:work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 第二步：执行 work-git-clone 1➜ work-git-clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 而操作个人的git项目，命令只需要一步： 1➜ git clone git@github.com:Leafney/docker-alpine-mysql.git 新的复杂需求上面的需求可能是相对来说比较常见而且普通的一种情况了，那么下面的需求算是一种稍微复杂的情况了。 因为在Github上发布私有的项目，是需要付费的，所以一般针对于个人的私有项目，我们一般会选择自己购买服务器来搭建属于自己的私有个人仓库，比如我自己的 gogit.itfanr.cc 就是我用开源项目 Gogs 来搭建的。有兴趣可查看我的开源项目：Docker Ubuntu-Gogs 用更简单的方式部署、升级或迁移Gogs服务。 。 那么，现在就出现了下面的四种情况： 对于我个人想要开源的代码项目，我会选择使用个人账户发布到 github.com 站点下； 对于我个人的私有代码项目，我会选择使用个人账户发布到我自己搭建的 gogit.itfanr.cc 仓库站点下； 对于公司的私有项目，我要选择使用公司分配的git账户发布到公司搭建的私有仓库 111.206.223.205:8080 站点下； 对于我在工作中的一些积累或私人的项目，我想使用公司分配的git账户发布到我个人的 gogit.itfanr.cc 仓库站点下； 修改ssh config经过上面的步骤，我们很容易的就知道想要实现上面的需求，只需要通过修改SSH的配置文件 config 中的配置即可实现。 对于公司的项目，针对于上面第3个情况，我们仍然如之前的配置即可： config : 12345# company repo accountHost work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_work 那么在clone项目时的操作如下： 更改项目SSH地址中的域名部分； 执行命令： 1➜ work-git-clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 对于工作中的私人项目，我们要使用公司的git账户来发布到我的个人仓库站点 gogit.itfanr.cc。配置时我们还需要指定使用密钥 id_rsa_work ： config : 12345# wuyazi private repo accountHost wuyazigogit HostName gogit.itfanr.cc User git IdentityFile ~/.ssh/id_rsa_work 那么在clone项目时的操作如下： 更改项目SSH地址中的域名部分； 1234# 如将: ssh://git@gogit.itfanr.cc:9527/wuyazi/repo_for_myself.git# 更改为:ssh://git@wuyazigogit:9527/wuyazi/repo_for_myself.git 执行命令： 1work-git-clone ssh://git@wuyazigogit:9527/wuyazi/repo_for_myself.git 2019-02-11-更新 在上面的 配置项说明 中也有指出，如果你的ssh链接中不是默认的端口 22 如 ssh://git@gogit.itfanr.cc:9527/wuyazi/repo_for_myself.git ，那么可以通过参数 Port 来指定： 123456# wuyazi private repo accountHost wuyazigogit HostName gogit.itfanr.cc Port 9527 User git IdentityFile ~/.ssh/id_rsa_work 则，后面执行的命令就是： 1work-git-clone ssh://git@wuyazigogit/wuyazi/repo_for_myself.git 这样，看起来更简洁一些了。 因为我的个人账户是作为全局账户来使用的，就是说在 config 文件中如果上面的 Host 部分没有匹配上，那么要保证最后一个 Host 匹配到我的个人git账户。再次回顾 config 配置项中的常用参数，我们发现 HostName 除了可以设置域名或ip地址之外，还可以设置为 %h ，表示实际使用时会被命令行中的主机名替换。 所以，为了实现上面的第1种和第2种情况，以及实现对未特殊说明的项目的默认匹配，我用如下的方式来配置： 12345# leafney default account for github.com or gogit.itfanr.ccHost github.com gogit.itfanr.cc HostName %h User git IdentityFile ~/.ssh/id_rsa 如上，针对于不同主机地址使用同一私钥进行登录的情况，可以在 Host 中指定多个别名来匹配，而 HostName 中的 %h 会自动匹配用户输入的ssh地址中的域名部分，来匹配到对应的密钥。 那么在clone项目时的操作如下： 1git clone git@github.com:Leafney/ubuntu-gogs.git 综上，我的 config 配置内容如下： 1234567891011121314151617# company repo accountHost work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_work# wuyazi private repo accountHost wuyazigogit HostName gogit.itfanr.cc User git IdentityFile ~/.ssh/id_rsa_work# leafney default account for github.com or gogit.itfanr.ccHost github.com gogit.itfanr.cc HostName %h User git IdentityFile ~/.ssh/id_rsa 新增项目配置上面的操作中说到的方法一般适用的场景比如你去到一家新公司，然后会给你分配公司的邮箱及git账号，以及公司项目的私有git站点，直接从站点上面 clone 项目到你的开发电脑上，这些项目一般都是公司已有的项目了。 某些情况下，可能需要你新增一个公司的项目，那对于新增公司的项目时，我们要如何使用指定的SSH账户来操作呢？ 一般的步骤如下： 初始化项目在你的开发电脑上，新增一个git管理的项目。在项目目录下使用 git init 来初始化。 设置项目git账户注意，这里就是最关键的一步了。我们要为该新增的项目创建针对于该项目的git账户。在上面的流程中也提到过，要使用不加 --global 的命令来设置： 12git config user.name &quot;wuyazi&quot;git config user.email &quot;wuyazi@company.com&quot; 创建远端项目然后就是在公司的私有git站点上创建一个空项目。一般在创建完成后都会有类似于下面的一个提示页面： 1234567891011从命令行创建一个新的仓库touch README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git remote add origin ssh://git@111.206.223.205:8080:how_to_use_multiple_git_ssh/new.gitgit push -u origin master从命令行推送已经创建的仓库git remote add origin ssh://git@111.206.223.205:8080:how_to_use_multiple_git_ssh/new.gitgit push -u origin master 提交到远端仓库对于只有一个SSH密钥的情况下，我们要将本地项目提交到远端，只要执行页面中后面这两句就可以了。而现在我们要将本地新增的公司项目使用我的公司git账户提交到公司的私有git站点上，首先呢还是需要更改一下提交的项目地址： 1234# 将项目SSH地址：ssh://git@111.206.223.205:8080:how_to_use_multiple_git_ssh/new.git# 更改为:ssh://work:how_to_use_multiple_git_ssh/new.git 然后我们就可以执行上面两条命令了： 12git remote add origin ssh://work:how_to_use_multiple_git_ssh/new.gitgit push -u origin master 有没有简洁命令可能有的朋友会想了，在之前 clone 已有项目时，我们使用了一条简洁的命令： work-git-clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 来直接省略了单独设置git操作账户的步骤，那在新增时，是不是也可以有类似的操作呢？ 答案是否定的。 因为 git clone 命令是可以接收 --config 参数的，以便在clone的同时指定配置；而 git push 命令却是没有该项的。具体的可以通过命令 git clone help 和 git push help 来详细了解。 至此，后面的操作就是常用的 pull 和 push 等操作了。 相关参考 同一设备多个git账号的ssh管理 Git多帐号配置 利用SSH的用户配置文件Config管理SSH会话 多重 SSH Keys 與 Github 帳號]]></content>
      <categories>
        <category>Git操作系列</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客功能优化二]]></title>
    <url>%2F2018%2F03%2F11%2Fhexo-blog-optimization-two%2F</url>
    <content type="text"><![CDATA[介绍Hexo博客功能优化项。 将“打赏”两字更改为“鼓励”一直觉得 “打赏” 两个字不太适合博客这种语境，搞得像是杂耍完了向围观群众要赏钱的感觉：“有钱的捧个钱场，没钱的捧个人场…” 。写作，本来就是在学习技术的路上一次次总结，亦或和志同道合的技术人的一次次讨论，无关金钱或其他。而“鼓励”则更适合这种语境。如果我的文章帮到了你，虽然不能改变世界，但也许为你节省了一些时间，亦或在你进入一个技术死角一直出不来的情况下，带来的一点点希望或是灵感。你觉得我的文章对你带来了帮助，送我一杯咖啡，我内心是非常高兴地。如果你还想多聊两句，我也会感到非常荣幸。 相应的修改方法是： 找到项目目录下 /themes/next/languages/zh-Hans.yml 文件，因为我的博客采用的是中文。这里可以按照自己的博客设置选择相应的语言文件。 12345reward: donate: 鼓励 #打赏 wechatpay: 微信支付 alipay: 支付宝 bitcoin: 比特币 找到 reward 部分，将 donate 的值修改为自己想要的内容即可。这里我测试了一下，最长是4个汉字，否则就要修改按钮的样式了。 关于评论自此评论插件 “多说” 关闭之后，我就把博客中的评论功能去掉了，因为确实没有找到一款心仪的评论插件。 目前的话，也只是在博客的 “关于” 页面加了一个 email 地址能够立即联系到我。 因为我的邮箱手机客户端是24小时在线的，让我感到高兴的是确实还有一些朋友通过邮件向我咨询技术问题，我都一一为他们做了解答。之前还觉得这个邮箱地址放在“关于” 页面会比较隐蔽，今天稍微改版了一下，在每篇文章的末尾都加上了 email 地址，以方便交流。 这段提示文字我是直接加在了 next 主题配置文件 _config.yml 中的 Reward 打赏功能 部分。 原来的打赏功能提示文字 reward_comment 参数，如果添加的字符太多的话，就会导致自动换行。所以这里我修改了一下页面文件。 找到目录下 /themes/next/layout/_macro/reward.swig 文件，找到第二行的 1&lt;div&gt;&#123;&#123; theme.reward_comment &#125;&#125;&lt;/div&gt; 部分再复制一行，如下： 123456789&lt;div style=&quot;padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;&quot;&gt; &lt;div&gt;&#123;&#123; theme.reward_comment &#125;&#125;&lt;/div&gt; &lt;div&gt;&#123;&#123; theme.reward_comment2 &#125;&#125;&lt;/div&gt; &lt;button id=&quot;rewardButton&quot; disable=&quot;enable&quot; onclick=&quot;var qr = document.getElementById(&apos;QR&apos;); if (qr.style.display === &apos;none&apos;) &#123;qr.style.display=&apos;block&apos;;&#125; else &#123;qr.style.display=&apos;none&apos;&#125;&quot;&gt; &lt;span&gt;&#123;&#123; __(&apos;reward.donate&apos;) &#125;&#125;&lt;/span&gt; &lt;/button&gt; &lt;div id=&quot;QR&quot; style=&quot;display: none;&quot;&gt;...... 我这里就直接改成了 theme.reward_comment2 。然后在主题的配置文件中也添加一个 reward_comment2 部分即可。 12345# Reward 打赏功能reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！reward_comment2: 如有疑问或需要技术讨论，请发邮件到 service@itfanr.ccwechatpay: /images/wechat-reward-image.jpg... 页面载入进度这个效果也是刚刚查看配置文件的时候偶然看到的。 之前就曾看别人的博客做的特别炫。页面头部可以显示一个加载进度条，非常的羡慕。 在 next 主题的配置文件 _config.yml 中 找到 pace: false 将其改为 pace: true 即可。 在下面可以选择不同的加载主题样式，通过 pace_theme 参数设置。 123456pace: true# Themes list:#pace-theme-big-counter#pace-theme-bounce# ...pace_theme: pace-theme-flash 感谢支持截止目前为止，共收到了3位朋友的扫码红包鼓励，在这里对他们表示感谢。也很高兴我的文章帮助到了他们。 不过由于微信扫码支付无法查看到支付者的微信账号信息，所以在这里就没有列出他们的昵称等信息。具体列表可查看 关于 页面。]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百万英雄，看程序员带你如何任性吃瓜(1)]]></title>
    <url>%2F2018%2F01%2F16%2Fchi-gua-qun-zhong-bu-chi-gua-one%2F</url>
    <content type="text"><![CDATA[今天中午的时候没事，随手打开掘金app打算看看最近有什么好文章。看到热门推荐下有一篇文章名为 qanswer：冲顶大会等游戏答题神器（Golang） 号称《冲顶大会》,《百万英雄》等答题游戏的答题神器，让人顺利吃鸡！ 因为我最近也一直在关注西瓜视频里的“百万英雄”这个“全民直播答题吃瓜”的活动，但无奈自己的知识储备量太少，最高的一次答到第9题就被kill了。看到这篇文章顿时来了兴趣，准备好好研究一番。 该项目的github地址为 silenceper/qanswer 。在 README.md 中也记录了如何来部署运行，下面把我的部署流程简单的记录如下。 qanswer部署我使用的设备是 MacBook Pro，手机是 红米Note4x 高通版，分辨率为1920x1080。 对于其他平台如 Win或Linux，我也会顺带提一下。 安装go环境配置golang运行环境，可以直接参考我之前写的博客文章来安装：Golang运行环境配置 安卓设备连接安卓设备时需要安装一个驱动类工具adb。adb全称为 Android Debug Bridge ,即Android调试桥。Android 调试桥 (adb) 是一个通用命令行工具，其允许您与模拟器实例或连接的 Android 设备进行通信。它可为各种设备操作提供便利，如安装和调试应用，并提供对 Unix shell（可用来在模拟器或连接的设备上运行各种命令）的访问。 Mac系统安装adb通过 homebrew 来安装，执行如下命令： 1$ brew cask install android-platform-tools 当看到提示 android-platform-tools was successfully installed! 信息，说明安装成功。 命令 adb devices 可以用来查看当前连接的安卓设备： 1234$ adb devicesList of devices attached* daemon not running; starting now at tcp:5037* daemon started successfully 可见当前并没有连接的设备。 Ubuntu安装adb使用如下的命令来安装： 123sudo add-apt-repository ppa:nilarimogard/webupd8sudo apt-get updatesudo apt-get install android-tools-adb Win安装adb直接下载解压后就可使用 Download the ADB ZIP file for Windows ios设备对于ios设备，需要安装WDA。 具体的安装方法可参考项目中给出的文章 iOS 真机如何安装 WebDriverAgent 开启小米手机 MIUI9 USB调试模式为了能够调试手机，需要打开小米手机或其他安卓手机的USB调试模式。 小米手机 MIUI9系统的开启方法： 打开 “设置” – “我的设备” – “全部参数” 页面 然后连续三次以上点击“MIUI版本”一栏，会出现 开发者模式已打开的提示信息 返回设置主界面，进入“更多设置”，在无障碍选项下面出现了“开发者选项”，点击进入 在开发者选项中就可以找到“USB调试”，启用即可 通过数据线连接手机，再次执行上面命令： 1234$ adb devicesList of devices attacheda1529b810604 device 可以看到发现了我的安卓手机，并连接上了。 文字识别对于文字图像识别，项目中实现了两种方式：百度ocr 和 tesseract。这里我采用百度ocr来实现。 从百度的文字识别接口网站 百度文字识别 中，登录百度云管理平台后，在左侧选择“产品服务”–“人工智能”–“文字识别” 一项，选择 “创建应用” 就可以获得需要的api key 和secret key。 百度的文字识别接口有 500次/天 的免费使用权限，一般也够用了。 运行将项目克隆到 gopath 目录下 git clone https://github.com/silenceper/qanswer.git，如我这里是 /Go/xgo_workspace/src 目录下，然后添加项目引用： 1$ go get github.com/silenceper/qanswer 执行编译： 123$ cd qanswer/cmd$ go build -o ../qanswer 然后会在 qanswer 目录下生成一个名为 qanswer 的执行文件。 执行该程序： 1$ ./qanswer 结果输出： 1234配置文件：./config.yml设备：ios; 图片识别方式：baidu请按空格键开始搜索答案... 设置配置文件程序运行用到的配置文件是在当前目录下的 config.yml 文件。 配置参数说明如下： 123456789101112131415161718192021# 是否开始调试模式debug: false# 对应的设备类型：ios or androiddevice: ios# 使用的ocr工具：baidu or tesseractocr_type: baidu# ios 设备连接wda的地址wda_address: &apos;127.0.0.1:8100&apos;# 截取题目的位置 ：question_x: 30question_y: 310question_w: 650question_h: 135# 截取答案的位置answer_x: 30answer_y: 500answer_w: 680answer_h: 370#当选用baidu ocr时，需要执行api_key和secret_keybaidu_api_key: &quot;xxx....&quot;baidu_secret_key: &quot;xxx....&quot; 成功的关键在上面的配置文件中，关键的一点就是配置文件中设置的对于不同手机类型及不同分辨率的坐标设定了。 你需要根据自己手机对直播问答页面进行截图后获取的坐标点及像素长度来设定。 12345678910# 截取题目的位置question_x: 30question_y: 310question_w: 650question_h: 135# 截取答案的位置answer_x: 30answer_y: 500answer_w: 680answer_h: 370 对直播答题界面截屏，然后通过Mac系统自带的图片预览可以得到该界面中题目左上角顶点的x坐标位置和y坐标位置以及题目区域的宽度和高度。同理能够获得答案部分的值。 这里要提一下的是，这里的坐标是向右为x轴正方向，向下为y轴正方向。所以值均为正数。 经过测量，我的手机的配置信息如下： 123456789101112131415# 百万英雄 红米Note4x 高通版 1920x1080debug: truedevice: androidocr_type: baiduwda_address: &apos;127.0.0.1:8100&apos;question_x: 80question_y: 270question_w: 920question_h: 400answer_x: 80answer_y: 680answer_w: 920answer_h: 580baidu_api_key: xxx...baidu_secret_key: xxx... 另外，baidu_api_key 和 baidu_secret_key 设置成在百度文本识别中创建应用的对应值。如果使用的是 tesseract 这两项则不用管。 执行效果1234567891011121314151617181920212223242526272829配置文件：./config.yml设备：android; 图片识别方式：baidu请按空格键开始搜索答案...正在开始搜索....2018/01/16 13:33:27 image.go:41: [debug] 保存question截图成功2018/01/16 13:33:27 image.go:51: [debug] 保存answer截图成功2018/01/16 13:33:27 image.go:22: [debug] 保存完整截图成功，./images/screenshot.png2018/01/16 13:33:28 qanswer.go:144: [debug] 斗杓东指,天下皆冬北斗一星为天权玉衡星是七星中最亮的星2018/01/16 13:33:28 qanswer.go:133: [debug] 2.关于北七斗七星,下列说法正确的是?识别题目：关于北七斗七星,下列说法正确的是?识别答案：[斗杓东指,天下皆冬 北斗一星为天权 玉衡星是七星中最亮的星]================百度搜索==============关于北七斗七星,下列说法正确的是?答案：斗杓东指,天下皆冬 : 结果总数 7400 ， 答案出现频率： 0北斗一星为天权 : 结果总数 189000 ， 答案出现频率： 0玉衡星是七星中最亮的星 : 结果总数 383000 ， 答案出现频率： 0======================================耗时：7.24113s请按空格键开始搜索答案... 另外附上一些执行过程截图： 出现的问题在实际的测试中，我也发现了该项目的一些问题。 判断逻辑的可行性目前该项目中使用的搜索引擎是百度。 而程序当前对问题答案获取的后台逻辑是：通过将问题和三个不同的答案拼接输出到搜索引擎中进行搜索查询，如使用百度，在搜索结果页面中会输出：“百度为您找到相关结果约487,000个” 类似这样的一段话。而答案的判断逻辑就是看三种答案对应的搜索结果的数据总条数来预测该答案可能为正确的答案。 但这样的方法并不一定能保证完全的正确，如下面的一个问题： 如果按照推荐的答案，要选 “探戈” 。而这道题的正确答案应该是 “森巴” 。 后来，我又对其他常用的搜索引擎做了对比。如我对比了 Baidu 、Bing国内版 、 Bing国际版 和 Google（需FQ） ，结果发现这四种搜索结果的正确率为： Google &gt; Bing国际版 &gt; Bing国内版 &gt; Baidu 但是后来我增加了问题的测试数量，发现Google对于答案的判断正确率也比较低。 例如其中的一个问题： 哪一种反应属于化学反应? 食物腐烂冰化水玻璃碎成块 通过百度测试，对于三个答案的搜索结果数量为： 可见，按照搜索数量结果来看的话，要选 “玻璃碎成块” ，但正确的答案应该是 “食物腐烂”。 后来我又使用 google 进行了测试: 食物腐烂 98400冰化水 483000玻璃碎成块 116000 可见在Google下这种方式得到的答案也不正确。 所以，我觉得这种判断逻辑只能给出70%的正确率，在答题过程中也仅仅作为参考答案，而不能一味的相信。 否定句如果遇到标题是否定句式的情况，通过上面这种搜索的形式就无法找到正确的答案了，一般搜索出来的也是“肯定句式”下的答案。 比如下面这个问题： 正确的答案应该是 爱如潮水。 文字识别出错还有一种情况就是图像文字没有识别出来的情况，最后也就不能给出相应的答案了。 其他方法实现个人认为类似这种问答类的题目，可行的方式比如对问题进行分词处理，然后对关键词去搜索匹配，通过词频来判断；或者弹出浏览器由用户自己去判断最终的答案，一般像搜索引擎的搜索结果页面，都会有标题和简短的内容，内容中的关键字会被标红显示，由用户自己去判断，准确性会更高一些，但这样耗费的时间也会特别长。应该还有其他的方法吧。 目前我也在用python来实现一种可能的方法，我会在后续的文章中详细说明，敬请期待吧！ 最后再说一句。如果看到这篇文章后你也对这种“答题吃瓜”的直播问题活动产生了兴趣，可以使用我的邀请码来获得一张复活卡的机会，输入下面的邀请码即可。 相关参考 qanswer How to Install ADB on Windows, macOS, and Linux Android 调试桥 在 MAC OS X 安装 ADB (Android调试桥)]]></content>
      <tags>
        <tag>直播问答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(三)-任务]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-third%2F</url>
    <content type="text"><![CDATA[在上一篇 Celery分布式任务队列入门(二)-环境配置 中介绍了一种简单任务的创建方法。 对于任务，在Celery中主要分为 异步任务 和 定时任务，下面详细的来说说。 配置Celery中的配置可以直接在应用上设置，也可以使用一个独立的配置模块。 直接配置例如你可以通过修改 CELERY_TASK_SERIALIZER 选项来配置序列化任务载荷的默认的序列化方式： 1app.conf.CELERY_TASK_SERIALIZER = &apos;json&apos; 一次性设置多个选项，你可以使用 update() 方法： 1234567app.conf.update( CELERY_TASK_SERIALIZER=&apos;json&apos;, CELERY_ACCEPT_CONTENT=[&apos;json&apos;], # Ignore other content CELERY_RESULT_SERIALIZER=&apos;json&apos;, CELERY_TIMEZONE=&apos;Europe/Oslo&apos;, CELERY_ENABLE_UTC=True,) 示例： 1234567891011121314151617181920212223242526from celery import CeleryCELERY_CONFIG = &#123; &apos;CELERY_TIMEZONE&apos;: &apos;Asia/Shanghai&apos;, &apos;CELERY_ENABLE_UTC&apos;: True, # content &apos;CELERY_TASK_SERIALIZER&apos;: &apos;json&apos;, &apos;CELERY_RESULT_SERIALIZER&apos;: &apos;json&apos;, &apos;CELERY_ACCEPT_CONTENT&apos;: [&apos;json&apos;], &apos;CELERYD_MAX_TASKS_PER_CHILD&apos;: 1&#125;SETTINGS = &#123; &apos;user&apos;: &apos;www-data&apos;, &apos;password&apos;: &apos;www-data&apos;, &apos;host&apos;: &apos;127.0.0.1&apos;, &apos;port&apos;: &apos;5672&apos;, &apos;vhost&apos;: &apos;t_celery&apos;&#125;app = Celery( &apos;test_celery&apos;, broker=&apos;amqp://&#123;user&#125;:&#123;password&#125;@&#123;host&#125;:&#123;port&#125;/&#123;vhost&#125;&apos;.format( **SETTINGS))app.conf.update(**CELERY_CONFIG) 独立配置模块对于大型项目，采用独立配置模块更为有效。 可以调用 config_from_object() 来让 Celery 实例加载配置模块： 1app.config_from_object(&apos;celeryconfig&apos;) 配置模块通常称为 celeryconfig ，你也可以使用任意的模块名。名为 celeryconfig.py 的模块必须可以从当前目录或 Python 路径加载。 celeryconfig.py 格式一般为： 12345678BROKER_URL = &apos;amqp://&apos;CELERY_RESULT_BACKEND = &apos;amqp://&apos;CELERY_TASK_SERIALIZER = &apos;json&apos;CELERY_RESULT_SERIALIZER = &apos;json&apos;CELERY_ACCEPT_CONTENT=[&apos;json&apos;]CELERY_TIMEZONE = &apos;Europe/Oslo&apos;CELERY_ENABLE_UTC = True 检查配置文件的语法错误，可以： 1$ python -m celeryconfig 更多配置参数参考：Configuration and defaults 有关配置的使用可以看我另一篇文章中的详细介绍。 异步任务在初级篇中我们创建的简单任务 tasks.py 就是一个异步任务。tasks.py ： 1234567891011121314#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.taskdef add(x, y): return x + y 创建了一个 Celery 实例 app ，指定名称为 tasks 指定消息中间件 broker 使用 RabbitMQ ，指定结果存储 backend 使用 RabbitMQ 创建了一个 Celery 任务 add，当函数被 @app.task 装饰后，就成为可被 Celery 调度的任务 运行 worker在 tasks.py 文件所在目录执行： 1$ celery -A tasks worker --loglevel=info 这个命令会开启一个在前台运行的 worker。 参数说明： worker : 运行 worker 模块 -A: –app=APP 指定使用的 Celery 实例所在的文件模块 -l: -–loglevel=INFO 指定日志级别，默认为 WARNING，可选：DEBUG, INFO, WARNING, ERROR, CRITICAL, FATAL 如果是创建任务模块，可以使用模块名称来启动： 1$ celery -A proj worker -l info 或者使用完整命令： 1$ celery worker --app=proj -l info 查看完整的帮助信息： 1$ celery worker --help 示例： 12345678910111213root@b792ae940e3e:/app# celery worker --helpusage: celery worker [options] Start worker instance.Examples: $ celery worker --app=proj -l info $ celery worker -A proj -l info -Q hipri,lopri $ celery worker -A proj --concurrency=4 $ celery worker -A proj --concurrency=1000 -P eventlet $ celery worker --autoscale=10,0 Workers Guide celery.bin.worker 扩展 对于参数 -A: –app=APP 表示指定使用的 Celery 实例。即指py文件的文件名（不包括扩展名.py）或项目的模块名 比如项目结构如下： 12345testcelery/ |- src/ |- __init__.py |- app.py |- task.py 那么启动worker任务 task.py 的命令即为： 1$ celery worker -A src.task -l info 调用 Taskdelay调用在异步调用方式中，可以通过 delay 或者 apply_async 来实现。 123from tasks import addadd.delay(3, 4) 示例，创建文件 client.py : 1234567#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import addif __name__ == &apos;__main__&apos;: add.delay(1, 5) 执行 $ python3 client.py 就能调用执行了。 apply_async12345678#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import addif __name__ == &apos;__main__&apos;: # add.delay(1, 5) add.apply_async(args=(5, 6)) delay 和 apply_async 这两种调用方式等价，delay 是 apply_async 的简写。用于一个任务消息（task message）。之前的示例中我们发现 add 任务并没有返回 “计算结果”，而是返回了一个对象 AsyncResult，它的作用是被用来检查任务状态，等待任务执行完毕或获取任务结果，如果任务失败，它会返回异常信息或者调用栈。 apply_async 参数 apply_async 相比 delay的优点就是，apply_async支持更多的参数。 1apply_async(args=(), kwargs=&#123;&#125;, route_name=None, **options) apply_async 常用的参数如下： countdown ：任务延迟执行的秒数，默认立即执行； 1task1.apply_async(args=(2, 3), countdown=5) # 5 秒后执行任务 eta ：任务被执行的绝对时间，参数类型是 datetime 1234from datetime import datetime, timedelta# 当前 UTC 时间再加 10 秒后执行任务task1.multiply.apply_async(args=[3, 7], eta=datetime.utcnow() + timedelta(seconds=10)) expires : 任务过期时间，参数类型可以是 int，也可以是 datetime 1task1.multiply.apply_async(args=[3, 7], expires=10) # 10 秒后过期 更多的参数列表可以在 官方文档 中查看。 send_task调用除了使用 delay 的方式，还已通过 send_task() 的方式来调用。同时 send_task() 也支持设置更多的参数。 示例，client.py : 123456789#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import appif __name__ == &apos;__main__&apos;: # add.delay(1, 5) # add.apply_async(args=(5, 6)) app.send_task(&apos;tasks.add&apos;, args=(12, 23),) 注意，这里引入的是 app 实例。args 参数是一个元组类型。相应的执行结果为： 12[2017-12-10 07:11:38,057: INFO/MainProcess] Received task: tasks.add[83fd530f-d800-43c7-bcfe-920a176812e2] [2017-12-10 07:11:43,217: INFO/ForkPoolWorker-1] Task tasks.add[83fd530f-d800-43c7-bcfe-920a176812e2] succeeded in 5.1578904589996455s: 35 AsyncResult方法上一篇文章中我们提到过返回对象 AsyncResult 的 ready() 方法，继续来看一下其他的方法： ready 为 True 表示已经返回结果了 12&gt;&gt;&gt; result.ready()True status 表示任务执行状态，失败还是成功 12&gt;&gt;&gt; result.status&apos;SUCCESS&apos; result 和 get() 表示返回的结果 12345&gt;&gt;&gt; result.result7&gt;&gt;&gt; result.get() 7 id 用来查看任务的id属性： 12&gt;&gt;&gt; result.id&apos;c178619e-3af3-41ed-8d2c-6371de80a601&apos; 定时任务Celery Beat 进程通过读取配置文件的内容，周期性地将定时任务发往任务队列。 在Celery的定时任务中，重要的两个方法是 定时器 和 执行器： 定时器，也叫作 beater，也就是帮助我们计算什么时候执行什么操作 执行器，也叫作 worker，真正执行任务的地方，我们的任务都是通过这个运行的 创建Celery定时任务有多中方法。 通过配置文件方式可以在配置文件中通过 CELERYBEAT_SCHEDULE 设置定时。 简单定时任务创建一个Celery的任务 tasks.py： 1234567891011121314151617181920212223242526#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.update( # 配置定时任务 CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125; &#125;)@app.taskdef add(x, y): return x + y 然后，启动这个 worker 进程： 1# celery -A tasks worker -l info 接着，启动 Celery Beat 进程，定时将任务发送到 Broker ，在另一个命令行窗口下执行： 1# celery beat -A tasks -l info 可以看到提示信息： 123456789101112root@b792ae940e3e:/app# celery beat -A tasks -l infocelery beat v4.1.0 (latentcall) is starting.__ - ... __ - _LocalTime -&gt; 2017-12-10 08:48:29Configuration -&gt; . broker -&gt; amqp://myuser:**@localhost:5672/hellohost . loader -&gt; celery.loaders.app.AppLoader . scheduler -&gt; celery.beat.PersistentScheduler . db -&gt; celerybeat-schedule . logfile -&gt; [stderr]@%INFO . maxinterval -&gt; 5.00 minutes (300s)[2017-12-10 08:48:29,141: INFO/MainProcess] beat: Starting... 一段时间后，可以看到执行结果： beat 执行结果： 1234567[2017-12-10 08:49:29,277: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:50:29,289: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:51:29,322: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:52:29,334: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:53:29,375: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:54:29,411: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:55:29,426: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add) workder 执行结果： 1234567891011[2017-12-10 08:41:37,839: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 08:49:29,290: INFO/MainProcess] Received task: tasks.add[1667ee3b-58c8-4a1a-be9f-0c20c3086bde] [2017-12-10 08:49:29,321: INFO/ForkPoolWorker-1] Task tasks.add[1667ee3b-58c8-4a1a-be9f-0c20c3086bde] succeeded in 0.029423292000501533s: 56[2017-12-10 08:50:29,295: INFO/MainProcess] Received task: tasks.add[db2d9ead-c22f-4efe-8d1c-6995f0ce9148] [2017-12-10 08:50:29,345: INFO/ForkPoolWorker-1] Task tasks.add[db2d9ead-c22f-4efe-8d1c-6995f0ce9148] succeeded in 0.046812374001092394s: 56[2017-12-10 08:51:29,324: INFO/MainProcess] Received task: tasks.add[7b23af5f-a467-4263-9cd0-87486f2df25d] [2017-12-10 08:51:29,338: INFO/ForkPoolWorker-1] Task tasks.add[7b23af5f-a467-4263-9cd0-87486f2df25d] succeeded in 0.011024585000996012s: 56[2017-12-10 08:52:29,336: INFO/MainProcess] Received task: tasks.add[2f3489e4-625e-460a-bc57-3fdf13456d97] [2017-12-10 08:52:29,349: INFO/ForkPoolWorker-1] Task tasks.add[2f3489e4-625e-460a-bc57-3fdf13456d97] succeeded in 0.01185457899919129s: 56[2017-12-10 08:53:29,381: INFO/MainProcess] Received task: tasks.add[ec7377fb-1859-4980-861b-2592422aad8c] [2017-12-10 08:53:29,408: INFO/ForkPoolWorker-1] Task tasks.add[ec7377fb-1859-4980-861b-2592422aad8c] succeeded in 0.021194035000007716s: 56 上面定时任务的配置信息表示： 12345678# 配置定时任务CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;&#125; 其中： my_task 表示当前任务的名称，可以自定义指定 task 表示 tasks.py 模块下的 add 方法 schedule 表示 任务执行的间隔，如果使用 int 类型，则单位是秒；还可以使用 timedelta 类型 args 表示任务函数参数，注意参数类型为元组 如果不通过 update 来修改，还可以通过设置 beat_schedule 配置项来设置。 1234567891011121314151617181920212223#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.beat_schedule = &#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (1, 2), &#125;&#125;app.conf.timezone = &apos;UTC&apos;@app.taskdef add(x, y): return x + y 多项定时任务我们还可以在配置文件中同时定义多个定时任务，只需要在 CELERYBEAT_SCHEDULE 项中添加即可: 12345678910111213# 配置定时任务CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;, &apos;your_task&apos;:&#123; &apos;task&apos;:&apos;tasks,add&apos;, &apos;schedule&apos;:30, &apos;args&apos;:(1,4), &#125;&#125; 相应的执行结果： beat 执行结果： 12345678910root@b792ae940e3e:/app# celery beat -A tasks -l info[2017-12-10 09:34:50,113: INFO/MainProcess] beat: Starting...[2017-12-10 09:35:20,151: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:35:50,145: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:35:50,149: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 09:36:20,166: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:36:50,187: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:36:50,188: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 09:37:20,208: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add) worker 执行结果： 1234567891011121314151617root@b792ae940e3e:/app# celery worker -A tasks -l info[2017-12-10 09:34:45,833: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 09:35:20,165: INFO/MainProcess] Received task: tasks.add[2b236ccf-c4af-430c-8d4e-a5cbaf331123] [2017-12-10 09:35:20,213: INFO/ForkPoolWorker-1] Task tasks.add[2b236ccf-c4af-430c-8d4e-a5cbaf331123] succeeded in 0.04618659699917771s: 5[2017-12-10 09:35:50,151: INFO/MainProcess] Received task: tasks.add[01f843bc-8506-4d61-97ce-5f989c576509] [2017-12-10 09:35:50,159: INFO/MainProcess] Received task: tasks.add[f3230694-ce5a-4bc3-9c92-eea71b9c4949] [2017-12-10 09:35:50,187: INFO/ForkPoolWorker-1] Task tasks.add[01f843bc-8506-4d61-97ce-5f989c576509] succeeded in 0.03170933700130263s: 5[2017-12-10 09:35:50,214: INFO/ForkPoolWorker-2] Task tasks.add[f3230694-ce5a-4bc3-9c92-eea71b9c4949] succeeded in 0.04673135899975023s: 56[2017-12-10 09:36:20,168: INFO/MainProcess] Received task: tasks.add[410e86bf-2e06-4a7d-965d-92d2e6a72c12] [2017-12-10 09:36:20,186: INFO/ForkPoolWorker-1] Task tasks.add[410e86bf-2e06-4a7d-965d-92d2e6a72c12] succeeded in 0.01682951399925514s: 5[2017-12-10 09:36:50,191: INFO/MainProcess] Received task: tasks.add[d2b32ff2-8e8e-4903-ad8f-7d12da132739] [2017-12-10 09:36:50,193: INFO/MainProcess] Received task: tasks.add[dc7fc344-374e-438b-8a0f-85f9e9f08aac] [2017-12-10 09:36:50,207: INFO/ForkPoolWorker-1] Task tasks.add[d2b32ff2-8e8e-4903-ad8f-7d12da132739] succeeded in 0.013693080998564255s: 5[2017-12-10 09:36:50,211: INFO/ForkPoolWorker-2] Task tasks.add[dc7fc344-374e-438b-8a0f-85f9e9f08aac] succeeded in 0.017022554000504897s: 56[2017-12-10 09:37:20,213: INFO/MainProcess] Received task: tasks.add[49113d2d-a36d-44b0-92dc-9ad0382c26a2] [2017-12-10 09:37:20,246: INFO/ForkPoolWorker-1] Task tasks.add[49113d2d-a36d-44b0-92dc-9ad0382c26a2] succeeded in 0.027591496000241023s: 5 在上面，我们用两个命令启动了 Worker 进程和 Beat 进程，我们也可以将它们放在一个命令中： 1$ celery -B -A tasks worker --loglevel=info 相应的执行结果为： 123456789101112131415root@b792ae940e3e:/app# celery -B -A tasks worker -l info[2017-12-10 10:07:36,153: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 10:07:36,158: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:07:36,169: INFO/MainProcess] Received task: tasks.add[d92a952e-e3f6-4224-9e8b-dda771740fe2] [2017-12-10 10:07:36,221: INFO/ForkPoolWorker-2] Task tasks.add[d92a952e-e3f6-4224-9e8b-dda771740fe2] succeeded in 0.049944616001084796s: 5[2017-12-10 10:08:06,148: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:08:06,151: INFO/MainProcess] Received task: tasks.add[678c33ae-9d2d-40c1-b5ce-25ffbdf763d8] [2017-12-10 10:08:06,175: INFO/ForkPoolWorker-2] Task tasks.add[678c33ae-9d2d-40c1-b5ce-25ffbdf763d8] succeeded in 0.02311466900027881s: 5[2017-12-10 10:08:36,148: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:08:36,149: INFO/Beat] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 10:08:36,150: INFO/MainProcess] Received task: tasks.add[b05841b8-a382-4a1a-a583-3695e6d369d2] [2017-12-10 10:08:36,152: INFO/MainProcess] Received task: tasks.add[baebd820-4a22-496c-8c39-6b9f52d2f22b] [2017-12-10 10:08:36,195: INFO/ForkPoolWorker-2] Task tasks.add[b05841b8-a382-4a1a-a583-3695e6d369d2] succeeded in 0.04302837300019746s: 5[2017-12-10 10:08:36,198: INFO/ForkPoolWorker-3] Task tasks.add[baebd820-4a22-496c-8c39-6b9f52d2f22b] succeeded in 0.0449830910001765s: 56 时区Celery定时任务默认使用UTC时区。我们可以在配置文件中来设置。最终的 tasks.py 文件： 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.update( # 配置所在时区 CELERY_TIMEZONE=&apos;Asia/Shanghai&apos;, CELERY_ENABLE_UTC=True, # 官网推荐消息序列化方式为json CELERY_ACCEPT_CONTENT=[&apos;json&apos;], CELERY_TASK_SERIALIZER=&apos;json&apos;, CELERY_RESULT_SERIALIZER=&apos;json&apos;, # 配置定时任务 CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;, &apos;your_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 30, &apos;args&apos;: (1, 4), &#125; &#125;)@app.taskdef add(x, y): return x + y 通过on_after_configure定义使用 on_after_configure 处理程序来装饰定时任务。如 tasks.py 文件： 123456789101112131415161718192021#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.on_after_configure.connectdef setup_periodic_tasks(sender, **kwargs): # Calls test(&apos;hello&apos;) every 10 seconds. sender.add_periodic_task(10.0, add.s(&apos;hello&apos;), name=&apos;add every 10&apos;)@app.taskdef add(arg): print(arg) return arg 执行示例： 123456789101112root@b792ae940e3e:/app# celery -B -A tasks worker -l info[2017-12-10 10:53:30,420: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 10:53:30,596: INFO/Beat] beat: Starting...[2017-12-10 10:53:30,620: INFO/Beat] Scheduler: Sending due task add every 10 (tasks.add)[2017-12-10 10:53:30,628: INFO/MainProcess] Received task: tasks.add[315383b8-5bd7-48ab-8dd2-c5d39e71f058] [2017-12-10 10:53:30,630: WARNING/ForkPoolWorker-3] hello[2017-12-10 10:53:30,667: INFO/ForkPoolWorker-3] Task tasks.add[315383b8-5bd7-48ab-8dd2-c5d39e71f058] succeeded in 0.03778552899893839s: &apos;hello&apos;[2017-12-10 10:53:40,602: INFO/Beat] Scheduler: Sending due task add every 10 (tasks.add)[2017-12-10 10:53:40,607: INFO/MainProcess] Received task: tasks.add[5f8ef21e-fbfd-4c82-8dbd-6fa2aeaf4fa4] [2017-12-10 10:53:40,610: WARNING/ForkPoolWorker-3] hello[2017-12-10 10:53:40,631: INFO/ForkPoolWorker-3] Task tasks.add[5f8ef21e-fbfd-4c82-8dbd-6fa2aeaf4fa4] succeeded in 0.022007824998581782s: &apos;hello&apos; 同时，add_periodic_task() 方法也能设置其他参数： 12# Calls test(&apos;world&apos;) every 30 secondssender.add_periodic_task(30.0, add.s(&apos;world&apos;), expires=10) 或者也能通过 crontab() 来应用 cron 表达式，实现多种时间的设定。 12345# Executes every Monday morning at 7:30 a.m.sender.add_periodic_task( crontab(hour=7, minute=30, day_of_week=1), add.s(&apos;Happy Mondays!&apos;),) 相关参考 Periodic Tasks 异步任务神器 Celery]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(二)-环境配置]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-second%2F</url>
    <content type="text"><![CDATA[实践在Docker容器中配置Celery运行环境。 创建Docker容器在容器 Ubuntu:16.04 系统中来搭建，创建容器： 1$ docker run -it --name celery1 -p 5672:5672 -p 15673:15672 -v /home/tiger/dckerfile/celery1:/app ubuntu /bin/bash 需要注意的是在Docker容器中不需要 sudo 命令，默认即是 root 权限。下面的命令请根据自己所在系统类型自行添加 sudo 操作。 更新软件源12345# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list# apt-get update 安装Erlang依赖Erlang可以通过包管理器来安装，或者直接从官方网站下载安装包来安装。 执行如下命令安装： 123456cd /tmpwget http://packages.erlang-solutions.com/ubuntu/erlang_solutions.asc# apt-key add erlang_solutions.asc# apt-get update# apt-get install erlang# apt-get install erlang-nox 或者直接从网站 Erlang Downloads 下载 .deb 安装包来安装。 安装RabbitMQ执行如下命令通过包管理器来安装： 123456# echo &quot;deb https://dl.bintray.com/rabbitmq/debian xenial main&quot; | tee /etc/apt/sources.list.d/bintray.rabbitmq.list# wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | apt-key add -# apt-get update# apt-get install rabbitmq-server 发现通过上面方法安装的 Erlang Version 为 Erlang/OTP 18 [erts-7.3] [source] [64-bit] [smp:2:2] ，RabbitMQ Version 为 &quot;RabbitMQ&quot;,&quot;3.5.7&quot; 都不是官网上的最新版本，但在软件源中来说已是可安装的最新版本。所以如果想要安装官方的最新版本，可以采用直接从官网获取安装包的方式来安装。 安装官方最新版在Ubuntu系统下直接下载 rabbitmq 的 *.deb 安装包： 从地址 Installing on Debian / Ubuntu 看到最新版本是 3.7.0 rabbitmq-server_3.7.0-1_all.deb 也可以从网址 Released Artifacts 选择其他指定版本。 下面以 rabbitmq-server_3.7.0-1_all.deb 为例安装： 12# wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.0/rabbitmq-server_3.7.0-1_all.deb# dpkg -i rabbitmq-server_3.7.0-1_all.deb 如果提示依赖其他的包，执行如下命令安装依赖包: 1# apt-get -f install 然后再次执行安装： 1# dpkg -i rabbitmq-server_3.7.0-1_all.deb 我在执行 apt-get -f install 时遇到问题，输出提示是要移除 rabbitmq-server ，并没有自动安装其他依赖： 123456789101112131415161718192021222324252627282930root@b792ae940e3e:/app# dpkg -i rabbitmq-server_3.7.0-1_all.deb Selecting previously unselected package rabbitmq-server.(Reading database ... 7744 files and directories currently installed.)Preparing to unpack rabbitmq-server_3.7.0-1_all.deb ...Unpacking rabbitmq-server (3.7.0-1) ...dpkg: dependency problems prevent configuration of rabbitmq-server: rabbitmq-server depends on erlang-nox (&gt;= 1:19.3) | esl-erlang (&gt;= 1:19.3); however: Package erlang-nox is not installed. Package esl-erlang is not installed. rabbitmq-server depends on logrotate; however: Package logrotate is not installed. rabbitmq-server depends on socat; however: Package socat is not installed.dpkg: error processing package rabbitmq-server (--install): dependency problems - leaving unconfiguredProcessing triggers for systemd (229-4ubuntu21) ...Errors were encountered while processing: rabbitmq-serverroot@b792ae940e3e:/app# apt-get -f installReading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following packages will be REMOVED: rabbitmq-server0 upgraded, 0 newly installed, 1 to remove and 2 not upgraded.1 not fully installed or removed.After this operation, 13.3 MB disk space will be freed.Do you want to continue? [Y/n] 所以，我选择手动安装 Erland 的 .deb 包。 从 网站 RabbitMQ Erlang Version Requirements 中可以看到RabbitMQ和Erlang版本之间的对应关系。这里上面的我按照的是RabbitMQ的 3.7.0 版本，所以我可以选择Erlang的最新版即 20.1.7 版本安装。下载地址见：Erlang Downloads 。 123# wget http://packages.erlang-solutions.com/site/esl/esl-erlang/FLAVOUR_1_general/esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 这次安装时也提示缺少依赖，所以我执行： 1# apt-get -f install 结果是找到了相关的依赖包，输入 y 进行安装。 12345678910111213141516171819202122232425262728293031root@b792ae940e3e:/app# lsesl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb rabbitmq-server_3.7.0-1_all.debroot@b792ae940e3e:/app# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb Selecting previously unselected package esl-erlang.(Reading database ... 7744 files and directories currently installed.)Preparing to unpack esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb ...Unpacking esl-erlang (1:20.1.7) ...dpkg: dependency problems prevent configuration of esl-erlang: esl-erlang depends on libwxbase2.8-0 | libwxbase3.0-0 | libwxbase3.0-0v5; however: Package libwxbase2.8-0 is not installed. Package libwxbase3.0-0 is not installed. Package libwxbase3.0-0v5 is not installed. esl-erlang depends on libwxgtk2.8-0 | libwxgtk3.0-0 | libwxgtk3.0-0v5; however: Package libwxgtk2.8-0 is not installed. Package libwxgtk3.0-0 is not installed. Package libwxgtk3.0-0v5 is not installed. esl-erlang depends on libsctp1; however: Package libsctp1 is not installed.dpkg: error processing package esl-erlang (--install): dependency problems - leaving unconfiguredErrors were encountered while processing: esl-erlangroot@b792ae940e3e:/app# apt-get -f installReading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following additional packages will be installed:............ 然后再次安装 esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 包： 1# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 最后，安装RabbitMQ的包： 1# dpkg -i rabbitmq-server_3.6.14-1_all.deb 如果中途再出现缺少依赖包的问题，通过 apt-get -f install 来解决。 1234567891011121314151617181920212223242526272829303132root@b792ae940e3e:/app# dpkg -i rabbitmq-server_3.7.0-1_all.deb Selecting previously unselected package rabbitmq-server.(Reading database ... 29232 files and directories currently installed.)Preparing to unpack rabbitmq-server_3.7.0-1_all.deb ...Unpacking rabbitmq-server (3.7.0-1) ...dpkg: dependency problems prevent configuration of rabbitmq-server: rabbitmq-server depends on logrotate; however: Package logrotate is not installed. rabbitmq-server depends on socat; however: Package socat is not installed.dpkg: error processing package rabbitmq-server (--install): dependency problems - leaving unconfiguredProcessing triggers for systemd (229-4ubuntu21) ...Errors were encountered while processing: rabbitmq-serverroot@b792ae940e3e:/app# apt-get -f install Reading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following additional packages will be installed: cron libpopt0 libwrap0 logrotate socat tcpdSuggested packages: anacron checksecurity exim4 | postfix | mail-transport-agent mailxThe following NEW packages will be installed: cron libpopt0 libwrap0 logrotate socat tcpd0 upgraded, 6 newly installed, 0 to remove and 2 not upgraded.1 not fully installed or removed.Need to get 522 kB of archives.After this operation, 1674 kB of additional disk space will be used.Do you want to continue? [Y/n] Downloading and Installing RabbitMQ RabbitMQ安装方式及常用命令 ☆ Erlang Downloads Run RabbitMQ Server启动 RabbitMQ 服务:1# service rabbitmq-server start 安装 RabbitMQWeb 管理插件：12# rabbitmq-plugins enable rabbitmq_management # service rabbitmq-server restart 打开浏览器登录：http://127.0.0.1:15672，登录账号密码默认都是 guest 12345678910111213root@730778dc65bd:/app# rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@730778dc65bd... started 6 plugins.root@730778dc65bd:/app# service rabbitmq-server restart * Restarting RabbitMQ Messaging Server rabbitmq-server [ OK ] root@730778dc65bd:/app# 测试代码： 12345678910111213141516171819202122232425262728293031323334353637383940## 查看rabbitmq状态root@730778dc65bd:/app# rabbitmqctl statusStatus of node rabbit@730778dc65bd ...Error: unable to connect to node rabbit@730778dc65bd: nodedownDIAGNOSTICS===========attempted to contact: [rabbit@730778dc65bd]rabbit@730778dc65bd: * connected to epmd (port 4369) on 730778dc65bd * epmd reports: node &apos;rabbit&apos; not running at all no other nodes on 730778dc65bd * suggestion: start the nodecurrent node details:- node name: &apos;rabbitmq-cli-9223@730778dc65bd&apos;- home dir: /var/lib/rabbitmq- cookie hash: MwPrvM8WUeAkWCiIWYw2fg==root@730778dc65bd:/app# root@730778dc65bd:/app# service rabbitmq-server start * Starting RabbitMQ Messaging Server rabbitmq-server [ OK ] root@730778dc65bd:/app# rabbitmqctl statusStatus of node rabbit@730778dc65bd ...[&#123;pid,9527&#125;, &#123;running_applications,[&#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.5.7&quot;&#125;, &#123;mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.13.3&quot;&#125;, &#123;xmerl,&quot;XML parser&quot;,&quot;1.3.10&quot;&#125;, &#123;os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.4&quot;&#125;, &#123;sasl,&quot;SASL CXC 138 11&quot;,&quot;2.7&quot;&#125;, &#123;stdlib,&quot;ERTS CXC 138 10&quot;,&quot;2.8&quot;&#125;, &#123;kernel,&quot;ERTS CXC 138 10&quot;,&quot;4.2&quot;&#125;]&#125;, &#123;os,&#123;unix,linux&#125;&#125;, &#123;erlang_version,&quot;Erlang/OTP 18 [erts-7.3] [source] [64-bit] [smp:2:2] [async-threads:64] [kernel-poll:true]\n&quot;&#125;, &#123;memory,[&#123;total,83922208&#125;, &#123;connection_readers,0&#125;, &#123;connection_writers,0&#125;, RabbitMQ中的vitrual hostVirtual host，是起到隔离作用的。每一个 vhost 都有自己的 exchanges 和 queues，它们互不影响。不同的应用可以跑在相同的 rabbitmq 上，使用 vhost 把它们隔离开就行。默认情况下，rabbitmq 安装后，默认的 vhost 是 /。 创建用户并设置虚拟主机可以发现上面我们通过 guest 用户在其他电脑上或外网段访问时，会提示 User can only log in via localhost ，这是因为 guest 是仅允许在 localhost 下才能登陆的。如果我们想在外部访问，可以创建一个新的账户。 创建用户的同时为该用户指定允许访问的虚拟主机 myvhost 123# rabbitmqctl add_user myuser mypassword# rabbitmqctl add_vhost myvhost# rabbitmqctl set_permissions -p myvhost myuser &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 此时，新创建的账户 myuser 也并没有权限在外网访问，可以用 set_user_tags 为用户设置角色： 1# rabbitmqctl set_user_tags myuser administrator 然后我们就能在外网通过地址 http://192.168.5.107:15673/ 来访问管理端了。 示例： 1234567891011# User: myuser # UserPwd: hello# VHost: hellohostroot@b792ae940e3e:/app# rabbitmqctl add_user myuser helloAdding user &quot;myuser&quot; ...root@b792ae940e3e:/app# rabbitmqctl add_vhost hellohostAdding vhost &quot;hellohost&quot; ...root@b792ae940e3e:/app# rabbitmqctl set_permissions -p hellohost myuser &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;Setting permissions for user &quot;myuser&quot; in vhost &quot;hellohost&quot; ...root@b792ae940e3e:/app# 然后重启服务： 1# service rabbitmq-server restart CeleryCelery官方推荐使用 RabbitMQ 或 Redis 来作为中间件。设置也很简单，通过 broker 和 backend 参数即可绑定。 broker 和 backend可以用RabbitMQ和Redis来作为broker或backend： 1app = Celery(&apos;tasks&apos;, backend=&apos;amqp&apos;, broker=&apos;amqp://&apos;) 1app = Celery(&apos;tasks&apos;, backend=&apos;redis://localhost&apos;, broker=&apos;amqp://&apos;) 注意，虽然推荐使用RabbitMQ来作为 broker，但不推荐其作为 backend 。具体原因我会在后面的文章中说明。 中间人RabbitMQRabbitMQ 功能完备、稳定，是一个非常可靠的选择。 123BROKER_URL =transport://userid:password@hostname:port/virtual_hostBROKER_URL = &apos;amqp://guest:guest@localhost:5672//&apos; 完整的格式为： 1CELERY_BROKER_URL = &apos;amqp://[YOUR_NAME]:[PASSWORD]@localhost:[PORT]/[VHOST_NAME]&apos; 中间人Redis与 RabbitMQ 相比，使用 Redis 作为 broker 缺点是可能因为掉电或异常退出导致数据丢失，优点是使用简单。 以下命令可以同时安装 celery 和 redis 相关的依赖，但是 redis server 还是必须单独安装的。 1$ pip install -U celery[redis] # -U 的意思是把所有指定的包都升级到最新的版本 1BROKER_URL = &apos;redis://localhost:6379//&apos; 安装celery先安装 python3 pip3 等依赖: 1# apt-get install -y python3 python3-pip 123# pip3 install celery# 或者：# pip3 install -U Celery 创建一个 tasks.py 文件: 1234567from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://guest@localhost//&apos;)@app.taskdef add(x, y): return x + y 注意，其中的： 1app = Celery(&apos;tasks&apos;, broker=&apos;amqp://guest@localhost//&apos;) 中 broker 要改为上面设置的RabbitMQ的信息，所以结果为： 1app = Celery(&apos;tasks&apos;,broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;) Celery 的第一个参数是当前模块的名称，这个参数是必须的，这样的话名称可以自动生成。第二个参数是中间人关键字参数，指定你所使用的消息中间人的 URL。 保存结果执行完成后的结果，Celery 需要在某个地方存储或发送任务处理后的状态，可以通过 backend 参数来指定。格式和 broker 一致。 完整的 tasks.py: 1234567891011121314#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.taskdef add(x, y): return x + y 运行Celery用 worker 参数执行程序: 1$ celery -A tasks worker --loglevel=info 输出： 123456789101112131415161718192021222324252627282930313233343536root@b792ae940e3e:/app# celery -A tasks worker --loglevel=info/usr/local/lib/python3.5/dist-packages/celery/platforms.py:795: RuntimeWarning: You&apos;re running the worker with superuser privileges: this isabsolutely not recommended!Please specify a different user using the -u option.User information: uid=0 euid=0 gid=0 egid=0 uid=uid, euid=euid, gid=gid, egid=egid,/usr/local/lib/python3.5/dist-packages/celery/backends/amqp.py:68: CPendingDeprecationWarning: The AMQP result backend is scheduled for deprecation in version 4.0 and removal in version v5.0. Please use RPC backend or a persistent backend. alternative=&apos;Please use RPC backend or a persistent backend.&apos;) -------------- celery@b792ae940e3e v4.1.0 (latentcall)---- **** ----- --- * *** * -- Linux-4.4.0-42-generic-x86_64-with-Ubuntu-16.04-xenial 2017-12-09 13:50:06-- * - **** --- - ** ---------- [config]- ** ---------- .&gt; app: tasks:0x7f97a8360dd8- ** ---------- .&gt; transport: amqp://myuser:**@localhost:5672/hellohost- ** ---------- .&gt; results: amqp://- *** --- * --- .&gt; concurrency: 2 (prefork)-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)--- ***** ----- -------------- [queues] .&gt; celery exchange=celery(direct) key=celery [tasks] . tasks.add[2017-12-09 13:50:06,121: INFO/MainProcess] Connected to amqp://myuser:**@127.0.0.1:5672/hellohost[2017-12-09 13:50:06,137: INFO/MainProcess] mingle: searching for neighbors[2017-12-09 13:50:07,178: INFO/MainProcess] mingle: all alone[2017-12-09 13:50:07,228: INFO/MainProcess] celery@b792ae940e3e ready. 可以看到 celery 的 worker 已经准备就绪了。 查看 worker 完整的命令行参数列表: 123$ celery worker --help## 或者：$ celery help 调用任务使用 delay() 方法来调用任务。 新打开一个控制台界面， 1$ docker exec -it celery1 /bin/bash 执行： 1234# python3&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; add.delay(4, 4) 示例： 12345678root@b792ae940e3e:/app# python3Python 3.5.2 (default, Nov 23 2017, 16:37:01) [GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; add.delay(3,4)&lt;AsyncResult: e1ae8ea3-8a8f-47c5-befb-e6ba975f0580&gt;&gt;&gt;&gt; 执行结果： 同时，也可以在 RabbitMQ web 管理页面看到新增了一个任务并存储了处理结果： 为了得到调用任务后返回的 AsyncResult 实例，通过一个参数来接收： 1&gt;&gt;&gt; result=add.delay(3,4) ready() 方法查看任务是否完成处理: 12&gt;&gt;&gt; result.ready()True #结果返回 `True` 表示任务处理完成 这里是异步调用，如果我们需要返回的结果，那么要等 ready 状态为 True 才行。 执行结果： 12345[2017-12-09 13:50:07,228: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-09 14:00:33,132: INFO/MainProcess] Received task: tasks.add[e1ae8ea3-8a8f-47c5-befb-e6ba975f0580] [2017-12-09 14:00:33,163: INFO/ForkPoolWorker-1] Task tasks.add[e1ae8ea3-8a8f-47c5-befb-e6ba975f0580] succeeded in 0.02956800399988424s: 7[2017-12-09 14:17:21,033: INFO/MainProcess] Received task: tasks.add[c178619e-3af3-41ed-8d2c-6371de80a601] [2017-12-09 14:17:21,058: INFO/ForkPoolWorker-1] Task tasks.add[c178619e-3af3-41ed-8d2c-6371de80a601] succeeded in 0.024445844999718247s: 7 相关参考 Celery 初步]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
        <tag>Docker</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(一)-理论]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-first%2F</url>
    <content type="text"><![CDATA[之前曾在公司的一个分布式爬虫项目中使用 Celery 和 RabbitMQ 实现过分布式爬虫的功能。最近在整理之前的开发笔记时，看到之前写的关于 Celery 的文章，决定趁着有时间再把关于Celery相关的内容好好的整理一番，没想到越写越想把相关的点都理清楚，也就有了这个Celery系列文章。 Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。它是一个专注于实时处理的任务队列，同时也支持任务调度。 主要模块 任务模块 Task包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列。 消息中间件 Broker一个消息传输的中间件，可以理解为一个邮箱，作为消费者和生产者之间的桥梁。接收任务生产者发来的消息（即任务），将任务存入队列。Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。 任务执行单元 WorkerWorker 是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。 任务结果存储 BackendBackend 用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。 系列文章目录 Celery分布式任务队列入门(一)-理论 Celery分布式任务队列入门(二)-环境配置 Celery分布式任务队列入门(三)-任务 未完待续。。。]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客功能优化]]></title>
    <url>%2F2017%2F12%2F06%2Fhexo-blog-optimization%2F</url>
    <content type="text"><![CDATA[介绍Hexo博客功能优化项，如 文章置顶、显示版权、访问统计、字数统计、显示更新时间等 文章置顶在Hexo博客中，有时候我们想要将一些特别的文章一直置顶在首页。Hexo博客中，默认的情况是按照时间倒序来排列的，即新发布的文章排在前面。虽然有一种很简单的方法，就是更改文章的发布时间到一个“未来”的时间点，这样虽然能让文章一直置顶，但是给人的体验和感觉是非常不好的。 今天介绍一种非常简单而且体验上也非常好的方法。 安装node插件12$ npm uninstall hexo-generator-index --save$ npm install hexo-generator-index-pin-top --save 添加标记在需要置顶的文章的 Front-matter 中加上 top: true 即可。 比如： 12345678910---title: 从0到1学Golang之基础--Go 数组date: 2017-05-24 22:07:58tags: - Golangcategories: - 从0到1学Golangdescription: Golang下的数组操作top: true--- ok，现在发布文章，就能看到我们设置的文章已经置顶显示了，即使是之前发布的文章，同时日期也不会被更改。 相关参考 解决Hexo置顶问题 hexo-generator-index-pin-top 使用Hexo基于GitHub Pages搭建个人博客（三） 如何置顶post？ 显示版权信息一般在网络上发表文章时，都要时刻提防着网络爬虫的抓取。特别是有些网站在抓取到你的文章后进行一些词语、段落的修改，公然改为自己发表的文章。完全无视原作者的辛苦。 为了更好的标明文章的版权，一般我们都会在文章中添加上文章的链接、版权声明等信息，虽然不能完全彻底的抵制文章抄袭的情况，也算是“防君子不防小人”吧。 启用版权我使用的是 Hexo 的 Next 主题。找到主题目录下的 _config.yml 文件，更改以下部分： 12345# Declare license on postspost_copyright: enable: false license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 将其中的 enable: false 改为 enable: true 即可。 但是改完后，使用 hexo s -g 预览，发现 “本文链接” 部分有问题。 这就需要我们修改主站点的配置文件了。打开主站点的 _config.yml 文件，修改： 将 url 部分改成自己站点的域名地址即可。 相关参考 Hexo持续优化-在文章尾部添加版权声明信息 访问统计功能在博客中我们一般都比较在意自己博客的访问量，或者哪篇文章比较受欢迎之类的。 在Hexo的 Next 主题下带有多种统计和分析的功能。这里我选择 不蒜子统计来显示文章的访客数、浏览量等信息。 启用统计找到 Next 主题下的配置文件 _config.yml ，找到 busuanzi_count 部分： 1234567891011121314151617# Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: 访客数 &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; site_uv_footer: 人次 # custom pv span for the whole site site_pv: true site_pv_header: 访问量 &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: 阅读量 &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; page_pv_footer: 次 当 enable: true 时，代表开启全局开关。 当 site_uv: true 时，代表在页面底部显示站点的UV值。当 site_pv: true 时，代表在页面底部显示站点的PV值。当 page_pv: true 时，代表在文章页面的标题下显示该页面的PV值（阅读数）。 相关参考 不蒜子统计 显示文章更新时间在文章列表中我们一般都能看的文章的发布时间。对于一些文章来说，比如涉及到文章中的内容过期，或者软件的升级等等，我们都会进行一些修改。这种情况下，我们就像把文章的更新日期也显示处理，也能让读者看的我们写的之前的文章也是有更新的，不会过时的。 显示更新日期在 Next 主题下添加显示更新时间非常简单，找到主题下的配置文件 _config.yml 的 post_meta 部分： 123456# Post meta display settingspost_meta: item_text: true created_at: true updated_at: false categories: true 将 updated_at: false 修改为 updated_at: true 即可。 通过 hexo s -g 预览，可以看到已经自动添加上了更新日期。 自定义显示更新日期对于某些特殊的文章，我们也想能够自定义这个更新的日期。当然，更改起来也非常的简单，Hexo默认就支持更新日期的配置。 在每一篇文章的 Front-matter 部分，只要添加 updated 参数即可。 12345678910---title: 从0到1学Golang之基础--Go 数组date: 2017-05-24 22:07:58updated: 2017-12-01 10:35:18tags: - Golangcategories: - 从0到1学Golangdescription: Golang下的数组操作--- 这样我们就自定义了这篇文章的更新时间。 相关参考 Front-matter 添加文章字数统计一般为了让读者大概估计阅读文章的时间，有的文章在头部会显示总的字数统计。 启用字数统计首先安装一个依赖插件： 1npm i --save hexo-wordcount 然后修改主题配置文件 _config.yml 中的 post_wordcount 部分： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true //底部是否显示“总字数”字样 wordcount: false //文章字数统计 min2read: false //文章预计阅读时长（分钟） totalcount: false //网站总字数，位于底部 separated_meta: true //是否将文章的字数统计信息换行显示 将 wordcount: false 改为 wordcount: true 即可显示单篇文章的总字数了。另外，totalcount 是用来统计整站总的字数的。 相关参考 hexo-wordcount 畅玩Hexo——2：骚起来吧，NexT]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度人工智能开放平台DuerOS初体验]]></title>
    <url>%2F2017%2F12%2F05%2Fthe-initial-experience-of-dueros-open-platform%2F</url>
    <content type="text"><![CDATA[今年11月初的时候在百度DuerOS开放平台上申请了DuerOS的“开发套件个人版”的开发板，前几天正式收到了该开发板，经过几天的摸索，发现DuerOS开放平台还是有很多可挖掘的功能的。在此将这几天的研究成果记录一下。 双十一的时候在天猫上买了一个阿里的天猫精灵，通过对比小米的小爱同学，阿里的天猫精灵，和百度的DuerOS开发板比起来，个人感觉DuerOS开发板要更贴近于开发者，可以让开发者自己动手去实现想要的智能化的功能。 DuerOS唤醒百度的DuerOS开发套件个人版需要用户自备一个树莓派3B来结合使用。开发板上带有2颗高灵敏度MEMS麦克风，搭载百度DuerOS SDK，可为用户提供百度海量的信息服务能力。 按照官方给的硬件安装文档和提供的镜像系统将设备组合成功，插入刷好系统的内存卡，通电等待系统开机。在初次连接时，可以使用百度提供的 “小度之家app” 将系统接入网络。 小度联网成功后，直接说 “小度小度+内容” 即可实现语音式的对话交互操作。 总体来说，唤醒小度的这一步非常的简单，附上一张设备的合影。 接入Python SDKDuerOS开发平台中也提供了相应的Python SDK，以便于个人开发者通过该SDK来实现想要的技能。 通过SSH登陆官方提供的DuerOS镜像系统是基于Raspbian系统的，所以我们可以按照在树莓派上安装Raspbian系统的方式来配置SSH服务。 为了找到树莓派的IP地址，我们可以使用 Fing 这个app来查看当前局域网上连接的所有设备。 然后通过SSH使用默认的用户名 pi 密码 raspberry 登陆DuerOS系统。我这里使用的是 Xshell，也可以选择 Putty 等其他软件。 在当前的用户目录下创建一个目录，用于后面的操作。比如我这里创建的目录名为 Leafney： 12$ mkdir Leafney$ cd Leafney 停止现有小度功能，因为会占用MIC资源12$ sudo systemctl disable duer$ sudo systemctl stop duer 安装需要的依赖更换地址源在操作之前，建议先更换地址源。因为DuerOS系统是基于 Raspbian jessie 版本的，操作如下： 1$ sudo vim /etc/apt/sources.list 把原来的第一行用#注释掉，在末尾添加下面一行： 1deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main contrib non-free rpi 还需要更改deb的源地址，这里可选择清华的源: 1deb https://mirrors.tuna.tsinghua.edu.cn/raspberrypi/ jessie main ui 或中科大的源： 1deb http://mirrors.ustc.edu.cn/archive.raspberrypi.org/debian/ jessie main ui 编辑以下文件添加:1$ sudo vim /etc/apt/sources.list.d/raspi.list update更新修改完成后，更新： 1$ sudo apt-get update 其他依赖包安装其他的依赖包： hyper库用来支持http2.0 client, pyaudio用来支持录音，tornado用来完成oauth认证。 12$ sudo apt-get install python-dateutil gir1.2-gstreamer-1.0 python-pyaudio libatlas-base-dev python-dev$ sudo pip install tornado hyper 下载编译好的openssl和Python安装包由于DuerOS运行所需要的依赖环境跟平台是相关的。比如DuerOS是基于Http2 ALPN的，但树莓派官方镜像的OpenSSL并不支持，而对应的Python库依赖于OpenSSL。为了在树莓派平台上支持Python的DuerOS SDK，专门交叉编译了OpenSSL和Python。 从如下地址下载openssl安装包(链接: https://pan.baidu.com/s/1skAP6WH 密码: wknz)从如下地址下载python2.7.14安装包(链接: https://pan.baidu.com/s/1o8MHkzK 密码: ngx4) 将下载的两个文件用 FileZilla 传输到树莓派的 /home/pi/Leafney 目录下： 然后分别解压： 1$ sudo tar -zxvf openssl1.1.tar.gz -C /usr 1$ sudo tar -zxvf python2.7.14.tar.gz -C /usr/local/ 替换已有的python： 12$ sudo rm -rf /usr/bin/python$ sudo ln -s /usr/local/python2.7.14/bin/python /usr/bin/python 下载Python SDK和示例代码123$ git clone https://github.com/MyDuerOS/DuerOS-Python-Client.git$ cd DuerOS-Python-Client$ git checkout raspberry-dev 初次授权如果直接按照官方给出的教程配置 Step by Step带你玩转DuerOS - Python DuerOS SDK[树莓派平台] (3)，下一步就是授权操作了。 1$ ./auth.sh 执行后在 Xshell 中有提示 A web page should is opened. If not, go to http://127.0.0.1:3000 to start 。 因为这里是要求访问 127.0.0.1 ，所以必须在树莓派系统中通过浏览器来访问。我在Windows系统下通过 树莓派IP+端口3000 的方式访问，会提示 “授权回调页地址错误” 的错误页面。 我并没有多余的HDMI数据线来直接连接树莓派和显示器，所以这里我用远程桌面的方式来配置。 安装远程桌面树莓派下的远程桌面我们选择 xrdp 或者 VNC 来实现。 xrdpxrdp 可以使用 windows下的远程桌面直接连接，不过这种方式只适合于Windows系统下连接。 在树莓派下执行安装： 1$ sudo apt-get install xrdp 打开windows系统的 “远程桌面连接” 程序，输入树莓派的IP地址进行连接。 在弹出的 Login to xrdp 窗口中，输入树莓派的用户名和密码，点击 OK 连接。 VNC如果你是MAC系统或者不喜欢Windows自带的远程桌面，可以使用适合于全平台的 VNC 。 VNC初始化在树莓派下执行安装： 1$ sudo apt-get install tightvncserver 增加一个桌面，执行： 1$ tightvncserver 会要求设置一个连接的密码并重复输入。 会询问是否设置一个只读方式的密码，一般选择否 n 。 连接从网站 vncViewer 下载vncViewer。打开程序后连接： 1234your Pi IP:1# 比如我的设置：192.168.5.130:1 关闭桌面关闭VNC桌面只需要在树莓派中将VNC的服务kill掉即可。在 Xshell 中操作： 1$ vncserver -kill :1 再次授权再次进入树莓派的 /home/pi/Leafney/DuerOS-Python-Client 目录，启动授权： 123$ cd /home/pi/Leafney/DuerOS-Python-Client$ ./auth.sh 通过远程桌面访问，在树莓派的桌面系统下打开浏览器，访问 127.0.0.1:3000 地址，会出现 “百度账号的登陆授权页面” 。 不过这个是官方的测试账号 GitHub项目测试账号。如果我们想要配置自己的设备，还是需要去申请自己的client_id和client_secret来调用。 这里我不在继续往下操作，先去申请自己的ClientID信息。 在 Xshell 中按 Ctrl+C 停止启动的web服务。 创建设备打开 DuerOS开放平台官网 DuerOS开放平台 ，选择右上角 “控制台” – “设备控制台” – 在打开的新页面选择 “配置新设备” 。 然后在 请选择终端场景 中选择 “音箱” 点击 “下一步” 。 在 请选择操作系统 界面选择第一项 “Linux” 或者也可以选择最下面的 “点击这里” ，没有太大区别。 输入 “产品名称”，比如这里我取名叫 贾维斯 （电影钢铁侠里的人工智能系统），点击 “申请ClientID” ，下面会显示出相应的 client_id 和 client_secret等信息。这里，我们先将这两项记下来以待后面使用。 接下来是配置 “端能力”的页面，可以自定义选择，或者直接保持默认下一步即可。 然后会弹出 BOT配置 页面。 可以看到上面是一些 音乐 有声点播 有声直播 等等选项；下面有 聊天定制 语音唤醒服务 自定义控制指令 这些，如果看不懂呢可以不用管，直接下一步。后面会询问是否下载SDK，也不用管，直接点击下面的 “完成” 会提示 “创建产品成功” 。 这样我们就创建好了自己的client_id和client_secret。 设置个人的ClientID信息使用 FileZilla 软件，在树莓派的目录 /home/pi/Leafney/DuerOS-Python-Client 下找到 app/auth.py 这个文件，因为在控制台界面下不太方便编辑文件，所以这里我选择将该文件下载到Windows本地来编辑。 将 auth.py 下载到本地后，推荐使用 SublimeText 或 NotePad++ 来进行编辑。 找到 开发者注册信息 部分，替换成刚刚申请的信息： 123# 开发者注册信息CLIENT_ID = &apos;XXXXX&apos;CLIENT_SECRET = &apos;XXXXXX&apos; 然后将下面的 使用开发者注册信息 一行下面代码段前面的井号 # 去掉，解注释这一行。 12# 使用开发者注册信息auth.auth_request(CLIENT_ID, CLIENT_SECRET) 再将下面的 使用默认的CLIENT_ID和CLIENT_SECRET 一行下面代码行前面加一个井号 # 注释掉这一行。 12# 使用默认的CLIENT_ID和CLIENT_SECRET# auth.auth_request() 然后使用 FileZilla 将我们刚刚改好的 auth.py 上传到树莓派中。 设置授权回调地址在浏览器中访问 控制台 – 设备控制台 页面 设备控制台 , 选择我们刚刚创建的产品点击 “编辑” 选项。 在 基础信息 页面，可以查看刚刚创建设备的 client_id 等信息。这里我们点击 OAUTH CONFIG URL 这个链接： 在新页面的左侧点击 安全设置 选项，在 授权回调页 的输入框中输入如下内容，然后点击 确定 保存修改。 1http://127.0.0.1:3000/authresponse 使用个人设备授权完成上面的配置后，回到 Xshell 中，在树莓派的 /home/pi/Leafney/DuerOS-Python-Client 目录下，再次执行授权命令： 12$ ./auth.shA web page should is opened. If not, go to http://127.0.0.1:3000 to start 然后在树莓派系统浏览器输入 127.0.0.1:3000 访问。 可以看到页面右侧的授权应用变成了我自己创建的设备名称。 如果你的授权页面中这里显示的是空的，那是因为你用的是中文名称。在“基础信息” 的 “名称”那里需要再次添加一下名称。如果是英文的话，这个名称会直接显示。我觉得这里可能是一个bug。 在授权页面输入我的百度账号和密码进行授权。 看到提示 Succeed to login DuerOS Voice Service 的信息就说明授权成功了。 同时在 Xshell 下我们会看到输出相应的授权信息。 语言唤醒执行如下命令： 1$ ./wakeup_trigger_start.sh 使用唤醒词 小度小度 就能唤醒了。 因为我在 Xshell 下操作时发现命令行下的中文会有乱码的情况，所以我改用远程桌面下树莓派上自带的 Terminal 程序来执行。 也可以使用enter按键唤醒，执行命令： 1$ ./enter_trigger_start.sh 使用enter键回车唤醒。 这里我尝试了上面的两种唤醒方式，发现不知道是哪里的问题，音箱都没有声音输出。查看输出的日志信息是能看到有音频文件下载成功并播放的。 解决没有声音的问题我使用 alsamixer 然后按 F6 切换使用的声卡，发现无论如何切换，似乎都没有效果。 后来我考虑将音箱线换到树莓派本身的音频接口上，发现居然有声音输出了。不过树莓派自带的音频输出杂音还是很吵的。 这里要注意的是不能在树莓派通电的情况下切换音频口，我发现如果直接将音频线从DuerOS板子的音频口换到树莓派的音频口上时，刚一接触的时候噪音是非常大的，所以最后我是将树莓派关机然后切换的。 感受 使用Python SDK 最后唤醒的时候需要将音频接口插到树莓派的音频接口上，这一点在论坛的文档中没有说明，可能会给一些人操作时带来困惑。 个人认为应该是有方法使用DuerOS开发版的音频接口的，毕竟没有杂音嘛。需要进一步研究一下。 发现在使用 Python SDK 唤醒小度时，语言识别的效果不如镜像系统中语音的识别准确度高。]]></content>
      <categories>
        <category>DuerOS开放平台</category>
      </categories>
      <tags>
        <tag>DuerOS</tag>
        <tag>智能家居</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hexo博客搜索异常]]></title>
    <url>%2F2017%2F11%2F24%2Fresolve-hexo-blog-search-exception%2F</url>
    <content type="text"><![CDATA[最近在更新博客文章时发现之前新添加的搜索功能不太好用了。每次点击了搜索按钮之后，搜索弹框一直显示 “加载中” 的状态。 尝试因为我使用的是 hexo 的 Next 主题中的 Local Search 搜索功能，所以就去 Next 主题的github中查找了类似的 issues ，发现类似问题下作者是建议重新安装该搜索组件来解决的。 于是我就卸载了该组件，然后重新安装： 123$ npm uninstall hexo-generator-searchdb --save$ npm install hexo-generator-searchdb --save 结果问题依旧。 探究后来我发现 Local Search 的搜索功能是加载的项目目录下的 search.xml 文件：http://localhost:4000/search.xml。于是我在浏览器中打开，居然有报错提示。 按照错误信息的说明，我找到了出错的第 47 行第 35 列，发现和其他内容不同的是这里居然多了一个 “红点”，那么搜索弹窗出不来的问题应该就是这个 “红点” 搞的鬼了。 我通过 Sublime Text 打开了源博客文件，发现在段落的开头居然多了两个奇葩的字符：BS。 我觉得可能是什么时候复制文件时给加上的。删除后，再次生成。问题解决。 再次访问搜索的xml文件 http://localhost:4000/search.xml ，发现已经不会再报之前的错误了。 需要注意的一点：我在查看源博客文件时也使用了 VS Code 编辑器，但是 VS Code 却无法显示出来前面的特殊字符 BS，通过 Sublime Text 才查看到。 扩展在Hexo博客文件的项目目录下有一个 node_modules 目录。每次在windows系统下删除 (拷贝或者移动) 该目录时都会报 文件名或扩展名太长，目录层次超过限制 等错误而导致操作失败。 解决这个问题只需要使用 unix 或者 linux 下的 rm -rf（强制删除） 命令来删除即可，但要注意操作时一定要慎重，不要误删其他文件。 在 node_modules 文件夹所在目录下右键打开 Git Bash 窗口，执行： 1$ rm -rf ./node_modules/ 等待完成，即可。 相关参考 how to uninstall npm modules in node js? windows删除node_modules[文件名或扩展名太长，目录层次超过无法删除的问题]]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--下载神器aria2]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-docker-aria2%2F</url>
    <content type="text"><![CDATA[上一篇文章说了如何配置Docker加速器，现在下载Docker镜像文件已经非常的快了。但是对于其他的一些文件比如电影、程序文件等来说，如何在NAS中来快速的下载呢？ 虽然群晖中已经自带了下载套件，不过看到那个界面我就有种不想用的感觉。这里推荐一个开源的下载神器 – aria2，号称迅雷的替代者。 这里我还选择在Docker中来配置，选择的镜像为我之前创建的 leafney/debian-aria2-kode 镜像。该镜像自带了 aria2下载程序、ariaNg管理页面以及KodExplorer文件管理页面。 具体可以访问：Leafney/debian-aria2-kode 创建aria2容器打开群晖的docker套件，选择 “注册表” 项，搜索并下载镜像 leafney/debian-aria2-kode 。 下载完成后，选中该镜像，点击 “启动” 菜单，打开 “创建容器” 界面。 为该容器设置一个自定义的名称，我这里命名为 aria2-kode，然后打开 “高级设置” 窗口。 在 “高级设置” 选项卡，选中 “启用自动重新启动” 及 “创建桌面快捷方式” 。 自动重新启动是在容器不当关机的情况下回尝试自动重启的操作。 在 “卷” 菜单中，为创建的容器添加一个文件夹用来管理和查看我们通过aria2下载的文件。因为要存储新文件，所以这里不要勾选 “只读” 项。 在 “端口设置” 菜单中，已经列出了镜像中预设的端口信息，在 “本地端口” 项下，我们为其指定相应的端口，不选择默认的 “自动” 。 然后点击 “应用” 按钮。 回到 “创建容器” 界面，点击 “下一步” 。查看我们设置的容器信息，勾选左下角的 “向导完成后运行此容器” 项，然后点击 “应用” 等待容器启动。 查看容器信息选择左侧 “容器” 项，可以看到我们刚刚创建的容器已经启动了。 点击顶部的 “详情” 选项，可以查看容器 aria2-kode 的信息。 在 “日志” 项下，可以查看当前容器运行时输出的日志记录。 配置KodExplorer在浏览器中输入 群晖ip:6860 ，打开 KodExplorer 的登录界面。看到 “运行环境检测” 下输出 “Successful!” 说明我们的容器已经正常的跑起来了。 首先要设置 KodExplorer 资源管理器的管理员 admin 的密码。 然后使用管理员账号登录。登录后可以看到 KodExplorer 的文件管理页面和我们平时使用的资源管理器页面非常的相似，操作起来也没有什么难度。 配置aria2在浏览器中输入 群晖ip:6801 ,打开 AriaNg 的管理页面。进入后会弹出 “认证失败” 的错误弹窗，不用管它。 选择左侧 “系统设置” 下的 “AriaNg 设置” 项。在右侧选择 “RPC(192.168.x.xx…” 的菜单，然后配置之前创建容器时设置的 “Aria2 RPC 地址” 端口号和 “Aria2 RPC 密钥” 项。 RPC密钥默认是 123456 。设置完成后点击 “重新加载页面” 应用配置。 然后可以看到 Aria2 状态 已经显示为 “已连接” 的状态了。 至此，aria2就配置完成了。选择左侧的 “正在下载” 项新建下载任务即可。 管理下载文件这里我以下载 BaiduExporter 为例来示范如何管理下载的文件。 BaiduExporter 下载文件打开 BaiduExporter 的github页面，在master分支下，选择右侧的 Clone or download 项下的 Download Zip ，右击选择 “复制链接地址” 。 打开 “AriaNg” 页面，在 “正在下载” 页面 “新建” 下载任务。粘贴下载链接，点击 “立即下载” 开始。 下载完成后，会在 “已完成/已停止” 菜单中显示。 KodExplorer文件管理要查看我们刚刚下载的文件，在浏览器打开 KodExplorer 页面，选择上面的目录路径，点击根目录项，查看所有的文件及目录。 找到 app 目录，打开里面的 aria2down 目录即可查看到我们刚刚下载的文件了。 在群晖DSM中查看下载文件在创建容器时我们为容器指定了群晖本地的下载文件目录。打开群晖DSM界面 – “File Station” 文件管理器，找到我们设置的目录，可以看到容器为我们自动创建了三个目录，在 aria2down 下就能找到我们刚刚下载的文件了。 百度网盘文件下载知道了如何下载和如何管理文件，接下来我们看看具体的应用。因为之前网盘刚兴起的时候，我把大部分的文件都放在到了百度网盘里，但后来网盘逐渐衰落，百度网盘的客户端下载文件还会限速，除非你冲超级会员才行。 今天，我们就用aria2来解决这个问题。 安装插件想要下载百度网盘中的文件，首先需要安装一个插件，也就是上面我们已经下载的 BaiduExporter。 在 KodExplorer 管理界面或群晖的 DSM 界面，选中文件 BaiduExporter-master.zip 右击选择下载均可将该文件下载到当前电脑上，解压后看到一个名为 BaiduExporter.crx 的文件。 打开 Chrome 浏览器 – “更多工具” – “扩展程序” 界面。将 BaiduExporter.crx 拖放到该页面以安装。 打开百度网盘页面，在顶部菜单栏中可以看到多出了一项 “导出下载” 的按钮。 设置ARIA2 RPC仍在百度网盘页面，选择菜单 “导出下载” – “设置” 项，在 ARIA2 RPC 右侧输入RPC地址，格式为 ：http://192.168.5.120:6800/jsonrpc 。 因为我的aria2是添加了密钥的，所以最后的rpc地址格式应为：http://token:RPC密钥@192.168.5.120:6800/jsonrpc ，即 设置密码以后需要在导出下面的设置里在 JSONRPC 的地址的 http:// 后面 localhost 前面加上 token:你的密码@。 下载点击应用后，勾选百度网盘中要下载的文件或文件夹，选择 “导出下载” 菜单下的 “ARIA2 RPC”，会弹出 “下载成功，赶紧去看看吧！” 的提示信息。切换到 AriaNg 页面，我们可以看到在百度网盘上选择的文件已经在依次下载了。 另外在 KodExplorer 和群晖DSM的资源管理界面，都可以看到正在下载的文件。 注意这里发现一个问题：如果在 Mac10.13 系统上使用release下的 v0.8.5 的版本在百度网盘页面选中文件后，“导出下载” 的按钮就消失了。更新成当前的master版本 v0.9.10 后没有问题。所以上面直接推荐安装master版本。 具体可以看 github issues：mac os 10.13 无法使用了 相关参考 Aria2c那边设置rpc-secret后，chrome里的aria按钮点击后就不能无法下载了，报：是不是没有启动aria2]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--Docker加速]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-docker-accelerator%2F</url>
    <content type="text"><![CDATA[群晖的DSM系统上安装Docker套件非常的简单，只要点击一个按钮就行了。 但是由于某些 “你懂的” 原因，DockerHub的网站是在国外的，而在国内访问起来就会特别的慢。之前我也写过在其他Linux系统如Ubuntu下配置Docker加速器的方法，但经过一番研究发现群晖NAS下的Docker套件配置加速器的方法还是有一定区别的。 启用Docker套件进入群晖的 DSM 系统后，选择桌面的 “套件中心” 图标（或在 “主菜单” 界面中选择 “套件中心”），在左侧找到 “实用工具” 一项，右侧往下拉在 “第三方” 一栏下找到 “Docker” 的图标，点击 “安装套件” ，等待安装完成。 安装完成后，选择 “主菜单” 找到 “Docker” 图标并打开。 具体的操作可以查看 DSM 的帮助界面，这里主要说明重点的项： 总览 能看到当前群晖的 “CPU 使用率” 和 “内存使用率” 以及正在运行的 Docker 容器。 注册表 对应于 Docker 来说就是“Docker Hub”。我们可以在这里搜索以及下载镜像。 映像 对应于 Docker 来说就是“镜像”，用来管理镜像，创建容器等操作。 容器 是对创建的容器进行管理。 未启用加速器要在Docker套件中创建容器，我们可以在左侧菜单 “注册表” 项搜索相应的镜像名称，双击下载。但是我们发现下载中的镜像右侧的下载图标在一段时间之内一直显示 “0 B” 的情况，然后就自动消失了。 同时在 “映像” 中也会提示 “您未下载任何映像，请进入注册表选项卡以下载。”： 一连试过几次，都是下载中途镜像就自动消失了。 启用SSH要配置Docker的配置文件，还得需要在命令行下来操作。群晖NAS默认没有开启SSH功能，得需要我们先开启才行。 打开 “控制面板” 图标，选择 “应用程序” – “终端机和SNMP” – 勾选 “启用 SSH 功能” 。端口可以选择默认或自定义，然后点击应用。 启用用户主目录服务这时如果你以任何用户身份通过终端使用SSH方式访问NAS的ip地址，登陆后一般会看到一条警告提示： 1Could not chdir to home directory /var/services/homes/tiger: No such file or directory 发生此警告是因为主目录由DSM的“用户主目录服务”控制，默认情况下该主目录服务是禁用的。要防止错误，请通过选中 “控制面板” – “用户账户”菜单 – “高级设置”选项卡 – “家目录”组 – “启用家目录服务” 复选框来启用用户主目录服务。 这样再次尝试登陆，会看到警告信息没有了。 即使您不打算使用该家目录，但还是建议您选择启用用户主目录服务，以防影响其他某些程序的运行。 临时性Docker加速如果是临时性的想要 “加速” 下载镜像，可以选择通过命令的方式，执行 docker pull 时加入国内源地址，格式为： 1$ docker pull registry.docker-cn.com/myname/myrepo:mytag 例如: 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 虽然能实现加速效果，但是对于在群晖NAS中操作Docker来说，每次下载镜像都要先去登陆SSH，在命令行中下载好了镜像再回到 DSM 界面来操作，这样的流程未免有些太繁琐了。 配置Docker加速器我们可以通过配置 Docker 守护进程默认使用 Docker 官方镜像加速。 查看群晖下Docker版本这里我使用 admin 账号通过SSH登陆到群晖的命令模式下来操作。 使用命令 docker info 查看docker详细信息： 如果提示 Cannot connect to the Docker daemon. Is the docker daemon running on this host? 说明当前的账号没有 root 权限，可以使用 sudo 提权来操作，或者可以通过切换到 root 账户下来操作，这里我们选择后者。 通过 admin 账号登录后，执行 sudo su - 切换到 root 账户下(注意这一步输入的是admin账号的密码)： 示例命令如下： 12345678910111213141516171819202122232425262728293031323334admin@HomeNAS:/etc$ docker infoCannot connect to the Docker daemon. Is the docker daemon running on this host?admin@HomeNAS:~$ sudo su -Password: # 注意这一步输入的是admin账号的密码root@HomeNAS:~# docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.11.2Storage Driver: btrfsLogging Driver: dbCgroup Driver: cgroupfsPlugins: Volume: local Network: host bridge nullKernel Version: 4.4.15+Operating System: &lt;unknown&gt;OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.801 GiBName: HomeNASID: A3DQ:M62X:NLZP:RYMF:NINR:5QBY:7OIJ:L425:3WDR:4V2N:FEFL:OV42Docker Root Dir: /volume1/@dockerDebug mode (client): falseDebug mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 我们可以看到 Server Version 目前版本是 1.11.2 的。 要退出 root 账户模式，执行 exit 即可： 123root@HomeNAS:~# exitlogoutadmin@HomeNAS:~$ 配置加速器这里我选择使用阿里云的镜像加速器。打开阿里云的 开发者平台 , 选择 “管理中心” – “镜像加速器” ，可以看到 “您的专属加速器地址” 。 而且下面也给出了具体的操作方法。 通过上一步我们看到群晖下的 Docker 版本是大于 1.10.0 的，按照文档我们可以通过修改daemon配置文件 /etc/docker/daemon.json 来使用加速器。 但是，这里一定要说但是，文档中的方法是对应于在 Ubuntu 等Linux系统下通过 Docker 官方的安装方式安装的Docker而言的，对于群晖下的Docker来说，并不是这样的。 通过查找我发现群晖中Docker的配置文件地址在 /var/packages/Docker/etc/dockerd.json 下， 使用vim编辑： 1root@HomeNAS:~# vim /var/packages/Docker/etc/dockerd.json 可以看到内容如下： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: []&#125; 然后将从阿里云获得的加速器地址填入 registry-mirrors 部分即可： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: [&quot;https://xxxxxx.mirror.aliyuncs.com&quot;]&#125; 注意：网址要用英文的双引号引起来再添加到中括号中。 当然，也可以使用其他的加速器地址。比如使用Docker中国官方镜像的加速地址： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 然后需要重启群晖下的Docker服务。 重启群晖下的Docker服务上面也说到，群晖的DSM系统并不像其他的linux系统如 Ubuntu 那样，管理服务可以使用 systemctl(Ubuntu16.04后版本) 或 service 来操作: 12345root@HomeNAS:~# systemctl-ash: systemctl: command not foundroot@HomeNAS:~# service-ash: service: command not foundroot@HomeNAS:~# 可以看到这两个命令在群晖下都是找不到的。 那是因为在群晖下的操作命令都要加上 syno 前缀来操作，执行命令 synoservice 或 synoservice --help： 123456789101112131415161718192021222324252627root@HomeNAS:~# synoserviceCopyright (c) 2003-2017 Synology Inc. All rights reserved.SynoService Tool Help (Version 15217)Usage: synoservice --help Show this help --help-dev More specialty functions for deveplopment --is-enabled [ServiceName] Check if the service is enabled --status [ServiceName] Get the status of specified services --enable [ServiceName] Set runkey to yes and start the service (alias to --start) --disable [ServiceName] Set runkey to no and stop the service (alias to --stop) --hard-enable [ServiceName] Set runkey to yes and start the service and its dependency (alias to --hard-start) --hard-disable [ServiceName] Set runkey to no and stop the service and its dependency (alias to --hard-stop) --restart [ServiceName] Restart the given service --reload [ServiceName] Reload the given service --pause [ServiceName] Pause the given service --resume [ServiceName] Resume the given service --pause-by-reason [ServiceName] [Reason] Pause the service by given reason --resume-by-reason [ServiceName] [Reason] Resume the service by given reason --pause-all (-p) [Reason] (Event) Pause all service by given reason with optional event(use -p to include packages) --pause-all-no-action (-p) [Reason] (Event) Set all service runkey to no but leave the current service status(use -p to include packages) --resume-all (-p) [Reason] Resume all service by given reason(use -p to include packages) --reload-by-type [type] (buffer) Reload services with specified type --restart-by-type [type] (buffer) Restart services with specified type Type may be &#123;file_protocol|application&#125; Sleep $buffer seconds before exec the command (default is 0)root@HomeNAS:~# 好的，现在已经知道了如何在群晖下管理服务，那么按照步骤，下一步只需要重启Docker服务使其应用上加速器地址即可。 按照上面的规律可想而知，在群晖下Docker的守护进程服务名称肯定会和在 Ubuntu 下的名称不一样，那我们如何来找到呢？ 可以通过 synoservicecfg --list 命令来查看当前群晖系统下所有运行的服务： 1234567891011121314151617root@HomeNAS:~# synoservicecfg --listDSMapparmoratalkavahibluetoothdbonjour......pkgctl-Dockerpkgctl-FileStationpkgctl-LogCenterpkgctl-PDFViewerpkgctl-PHP7.0pkgctl-PhotoStation...... 可以看到通过群晖的 “套件中心” 添加的套件程序的服务名称均以 pkgctl- 为前缀来命名。 然后重启群晖的docker服务： 12root@HomeNAS:~# synoservice --restart pkgctl-Dockerroot@HomeNAS:~# 如果没有错误提示，说明docker服务重启正常。 现在我们再次回到 DSM 操作界面中，重新下载我们需要的Docker镜像即可。 可以看到现在后面的容量大小一直在增加，很快我们就看到 “消息通知” 里提示我们镜像下载完成了。 后面就是通过镜像来创建容器了，后文继续。 相关参考 Synology DSM 6 (terminal) service control restart WebServer bash command Documentation for /var/packages/Docker/etc config files? Docker 中国官方镜像加速]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--开篇]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-start%2F</url>
    <content type="text"><![CDATA[双十一的时候在天猫上入手了一台群晖的 DS218+ NAS主机，也算是很早就打算入手的一台设备。再加上去年双十一的时候在京东购置的两个4T的硬盘，就开始了我的玩转群晖NAS之旅。 对于开篇文章呢，也不想说太多吧，主要就是作为一个 “玩转群晖NAS” 系列的目录来展示，同时也算是时刻的提醒自己还是要多写写笔记的。 对于群晖的“+”系列NAS，最值得把玩的一个功能就是支持的Docker套件了。Docker简直就是一个 “神器”。至于有多么神，尽管看我后面的文章吧！ 目录 玩转群晖NAS–开篇 玩转群晖NAS–Docker加速 玩转群晖NAS–下载神器aria2]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过路由器找回忘记的宽带密码]]></title>
    <url>%2F2017%2F11%2F13%2Fretrieve-forgotten-broadband-passwords-through-routers%2F</url>
    <content type="text"><![CDATA[可能是因为赶上了双十一的缘故,最近我的宽带网络总是时好时坏的,给宽带客服打了电话,说会找师傅过来给我看看.突然间想起来好像我的宽带自从安装上以后,我就没再改动过,怎么也想不起来宽带的密码了.账号的话可以在路由器中直接看到,而密码却是显示成星号,还不能复制出来. 所以特意上网找了找方法,记录于此. 备份路由器配置我的路由器是 TP-Link WR847N 型号的，其他路由器的方法类似。 第一步：在浏览器输入路由器网关地址（一般是192.168.1.1）进入路由器登录界面 第二步：输入路由器账号和密码登录（如果未更改过一般都是admin）到路由器管理界面 第三步：在左菜单栏点击 “系统工具” – “备份和载入配置” 第四步：在右侧对话框中点击 “备份配置文件” 按钮 第五步：保存配置文件，名称为 config.bin 。 通过配置文件找回第六步：从网站 RouterPassView 下载软件RouterPassView。 RouterPassView 是 NirSoft 出品的一款路由密码恢复软件，可以查看绝大多数家用路由的配置文件中保存的密码。 第七步：用 RouterPassView打开备份的配置文件 config.bin, 就能看到当前路由器上已配置的所有账号和密码了。 附件百度网盘链接: Download 密码: hwpx]]></content>
      <tags>
        <tag>Skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红米Note4X高通版升级MIUI9]]></title>
    <url>%2F2017%2F11%2F12%2FRedmiNote4X-HP-version-upgrade-miui9%2F</url>
    <content type="text"><![CDATA[双十一当天在京东上买了一个红米Note4X高通版的手机,收到货后发现系统仍然是MIUI8的稳定版.之前看过MIUI9的介绍视频,官方给出的标语是”快如闪电”,所以就想体验一把.我的方法是采用 卡刷 的方式，不需要BL解锁。 当前系统版本在手机的”设置”–”我的设备” 下查看当前的MIUI版本: 1MIUI 8.5 稳定版 8.5.6.0(MCFCNED) 先从稳定版升级开发版不能直接刷最新版因为小米Note4x稳定版8.5的系统是基于Android6.0开发的，而最新的MIUI9是基于Android7.0开发的，Android版本不一致也就导致无法直接卡刷到最新版，会报错。 可行的方法是可以先卡刷MIUI8 7.4.6 的开发版（基于Android6.0），然后再刷MIUI9最新的开发版。 卡刷Android6.0开发版下载 7.4.6 开发版卡刷包,然后拷贝到手机的内置存储中。 在手机端选择 设置 – 我的设备 – MIUI版本 – 进入 “系统升级” 界面 点击 右上角三点 ，选择 手动选择安装包 选择刚刚下载的卡刷包，确定。等待其解密并自动升级。 升级完成后，在 设置 – 我的设备 – MIUI版本 – 进入 “系统升级” 界面 这时如果点击 “检查更新” 的话，收到的应该是MIUI8的最新开发版的更新包,所以这里不点击“立即更新”。(MIUI论坛中官方给出的说法是现在MIUI8开发版可以直接自动检查升级到MIUI9的最新开发版了,不知道我这里为什么不行?如果你的可以,那就直接升级即可,否则继续下面的操作) 卡刷MIUI9最新开发版从网址 http://www.miui.com/download-326.html 下载 红米Note4X(高通平台) 的最新开发版的完整卡刷包，然后拷贝到手机中，依照上一步的操作方法通过 手动更新 的方式来升级。 我这里下载到的是当前的最新版本 MIUI9开发版 7.11.9 的版本 : miui_HMNote4X_7.11.9_71db0b04ec_7.0.zip 。 等待其解密安装包并自动更新完成即可。 上面的整个升级过程要保证手机电量充足,按照步骤操作即可,非常适合小白升级. 附件百度网盘 Download 密码: d2v7 MIUI8(Android6.0)_7.4.6.zip MIUI9(Android7.0)_7.11.9.zip]]></content>
      <tags>
        <tag>XiaoMI</tag>
        <tag>Skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客添加搜索功能]]></title>
    <url>%2F2017%2F10%2F27%2Fadd-search-function-to-hexo-blog%2F</url>
    <content type="text"><![CDATA[渐渐的随着hexo博客中文章越来越多了之后,平时想要查找一篇文章时,一般都是记得部分标题内容或者某些关键词,而在”归档”下通过标题一页一页的找又非常的麻烦.所以考虑为博客增加搜索功能. 从Next主题网站上我们可以搜索多款搜索插件 第三方服务集成 – Next文档,个人感觉 “Local Search” 和 “Algolia” 这两款搜索插件比较和我的心意. 下面简要的介绍为hexo博客添加搜索插件的过程. 升级Next主题版本我的hexo主题安装的是 Next 主题,当前版本为 v5.0.1 .最新版本为 5.1.3. 因为我的hexo主题版本差距太大,而且我在 next 主题目录下的 .git 目录我已经删除了,所以我采用完全更新的方式. 先备份本地的 hexo 主题目录 your-hexo-site/themes/next ,其实只需要备份 _config.yml 一个文件即可,为了保险这里我将整个目录都备份一下. 另外还要注意如果你之前添加了自定义头像及打赏功能等所需图片,添加的图片是在 /themes/next/source/images/ 目录下的,也要记得做好备份. 如果你本地的主题 next 目录下的 .git 目录没有删除,你可以直接通过 git pull 命令来更新: 12$ cd themes/next$ git pull 完全更新先删除本地现在的 next 主题目录: 12$ cd &lt;your-hexo-site&gt;$ rm -rf ./themes/next 从github下载 hexo 主题文件最新版本: 12$ cd &lt;your-hexo-site&gt;$ git clone https://github.com/iissnan/hexo-theme-next themes/next 比照新的主题配置文件 _config.yml ,将旧的主题文件中的内容添加到新文件中. 我这里更改的地方有: menu scheme social sidebar highlight_theme tencent_analytics 打赏功能 reward_comment wechatpay alipay 站点建立时间 since 更改后,清除缓存,然后再查看: 12345$ hexo clean$ hexo s -gINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 打开浏览器,查看页面中是否有错误并修改. LocalSearch搜索安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 然后 重新生成 查看: 12345$ hexo clean$ hexo s -gINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这样,搜索功能就添加上了. Algolia搜索详情可参考官方教程,这里不再详述. Algolia – Next文档 相关链接 搜索服务 – Next文档 hexo-generator-search hexo-algoliasearch Hexo集成Algolia搜索插件]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac系统下配置Hexo博客运行环境遇到的问题]]></title>
    <url>%2F2017%2F10%2F27%2Fproblems-for-configuring-hexo-blog-in-mac%2F</url>
    <content type="text"><![CDATA[今天在Mac下更新hexo博客时,遇到了一些安装 Node.js 和安装 hexo 相关的小问题,特此记录下来. Mac下配置Node.js环境安装 node.js 有多种方法：使用 homebrew 安装或者直接下载 安装包。 官网下载安装包从node.js官网 Node.js 下载对应系统的安装包,打开会提示安装位置: 123This package will install: • Node.js v8.8.1 to /usr/local/bin/node • npm v5.4.2 to /usr/local/bin/npm 按照步骤安装即可. homebrew安装通过 homebrew 安装,直接执行如下命令: 1$ brew install node 检测安装是否成功终端输入 -v , 成功则显示版本号: 12345$ node -vv8.8.1$ npm -v5.4.2$ Mac系统下Finder显示隐藏文件涉及到一些以 . 开头的文件或目录(如.git目录)或者隐藏文件,默认在Finder下是看不到的. 我们可以通过命令 Command+Shift+. 来在Finder中快速的切换显示出隐藏的文件或文件夹,再按一次,恢复隐藏. 更换Node.js镜像源由于npm的官方镜像源在国外,而由于国内”众所周知的”的网络原因,访问默认的官方镜像源常常会出问题.我们可以更改为国内的镜像源来加速软件的安装. 淘宝npm镜像目前国内推荐的是淘宝的npm镜像: 搜索地址：http://npm.taobao.org/ registry地址：http://registry.npm.taobao.org/ 如何使用临时使用以下载 express 软件为例: 1npm --registry https://registry.npm.taobao.org install express 持久使用1npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来查看是否设置成功: 1npm config get registry 我的操作记录: 123456$ npm config get registryhttps://registry.npmjs.org/$ npm config set registry https://registry.npm.taobao.org$ npm config get registryhttps://registry.npm.taobao.org/$ 提醒 : 我在实际操作时发现淘宝的npm镜像源有时候也会请求失败,然后又切换回了官方源(npm config set registry https://registry.npmjs.org/)发现能够操作成功了.所以是否更换镜像源还要根据实际情况来定. 123456789101112131415161718192021222324252627282930313233343536373839$ npm config get registryhttps://registry.npm.taobao.org/$ npm installnpm ERR! code ENOTFOUNDnpm ERR! errno ENOTFOUNDnpm ERR! network request to https://registry.npm.taobao.org/hexo-generator-category failed, reason: getaddrinfo ENOTFOUND registry.npm.taobao.org registry.npm.taobao.org:443npm ERR! network This is a problem related to network connectivity.npm ERR! network In most cases you are behind a proxy or have bad network settings.npm ERR! networknpm ERR! network If you are behind a proxy, please make sure that thenpm ERR! network &apos;proxy&apos; config is set properly. See: &apos;npm help config&apos;npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-26T14_59_23_770Z-debug.log$ $ $ npm config set registry https://registry.npmjs.org/$ npm installnpm WARN deprecated swig@1.4.2: This package is no longer maintained&gt; dtrace-provider@0.8.5 install /Users/xxx/Project17/Leafney.github.io/node_modules/dtrace-provider&gt; node scripts/install.js&gt; fsevents@1.1.2 install /Users/xxx/Project17/Leafney.github.io/node_modules/fsevents&gt; node install[fsevents] Success: &quot;/Users/xxx/Project17/Leafney.github.io/node_modules/fsevents/lib/binding/Release/node-v57-darwin-x64/fse.node&quot; already installedPass --update-binary to reinstall or --build-from-source to recompile&gt; hexo-util@0.6.1 postinstall /Users/xxx/Project17/Leafney.github.io/node_modules/hexo-util&gt; npm run build:highlight&gt; hexo-util@0.6.1 build:highlight /Users/xxx/Project17/Leafney.github.io/node_modules/hexo-util&gt; node scripts/build_highlight_alias.js &gt; highlight_alias.jsonnpm notice created a lockfile as package-lock.json. You should commit this file.added 430 packages in 119.035s Mac install hexo use sudo but sitll permission denied安装报错参照hexo官网 Hexo 安装hexo时,使用命令 npm install hexo-cli -g 却报没有权限: 123456789101112131415161718$ npm install hexo-cli -gnpm WARN checkPermissions Missing write access to /usr/local/lib/node_modulesnpm ERR! path /usr/local/lib/node_modulesnpm ERR! code EACCESnpm ERR! errno -13npm ERR! syscall accessnpm ERR! Error: EACCES: permission denied, access &apos;/usr/local/lib/node_modules&apos;npm ERR! &#123; Error: EACCES: permission denied, access &apos;/usr/local/lib/node_modules&apos;npm ERR! stack: &apos;Error: EACCES: permission denied, access \&apos;/usr/local/lib/node_modules\&apos;&apos;,npm ERR! errno: -13,npm ERR! code: &apos;EACCES&apos;,npm ERR! syscall: &apos;access&apos;,npm ERR! path: &apos;/usr/local/lib/node_modules&apos; &#125;npm ERR!npm ERR! Please try running this command again as root/Administrator.npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-27T01_21_01_871Z-debug.log 然后我换用管理员权限,加上 sudo ,执行如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ sudo npm install hexo-cli -gPassword:/usr/local/bin/hexo -&gt; /usr/local/lib/node_modules/hexo-cli/bin/hexo&gt; dtrace-provider@0.8.5 install /usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider&gt; node scripts/install.jsfs.js:768 return binding.rename(pathModule._makeLong(oldPath), ^Error: EACCES: permission denied, rename &apos;/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/compile.py&apos; -&gt; &apos;/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/binding.gyp&apos; at Object.fs.renameSync (fs.js:768:18) at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/scripts/install.js:14:4) at Module._compile (module.js:612:30) at Object.Module._extensions..js (module.js:623:10) at Module.load (module.js:531:32) at tryModuleLoad (module.js:494:12) at Function.Module._load (module.js:486:3) at Function.Module.runMain (module.js:653:10) at startup (bootstrap_node.js:187:16) at bootstrap_node.js:608:3&gt; fsevents@1.1.2 install /usr/local/lib/node_modules/hexo-cli/node_modules/fsevents&gt; node install[fsevents] Success: &quot;/usr/local/lib/node_modules/hexo-cli/node_modules/fsevents/lib/binding/Release/node-v57-darwin-x64/fse.node&quot; already installedPass --update-binary to reinstall or --build-from-source to recompile&gt; hexo-util@0.6.1 postinstall /usr/local/lib/node_modules/hexo-cli/node_modules/hexo-util&gt; npm run build:highlight&gt; hexo-util@0.6.1 build:highlight /usr/local/lib/node_modules/hexo-cli/node_modules/hexo-util&gt; node scripts/build_highlight_alias.js &gt; highlight_alias.jsonsh: highlight_alias.json: Permission deniednpm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! hexo-util@0.6.1 build:highlight: `node scripts/build_highlight_alias.js &gt; highlight_alias.json`npm ERR! Exit status 1npm ERR!npm ERR! Failed at the hexo-util@0.6.1 build:highlight script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.┌────────────────────────────────────────────────────────┐│ npm update check failed ││ Try running with sudo or get access ││ to the local update config store via ││ sudo chown -R $USER:$(id -gn $USER) /Users/xxx/.config │└────────────────────────────────────────────────────────┘npm WARN optional SKIPPING OPTIONAL DEPENDENCY: dtrace-provider@0.8.5 (node_modules/hexo-cli/node_modules/dtrace-provider):npm WARN optional SKIPPING OPTIONAL DEPENDENCY: dtrace-provider@0.8.5 install: `node scripts/install.js`npm WARN optional SKIPPING OPTIONAL DEPENDENCY: Exit status 1npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! hexo-util@0.6.1 postinstall: `npm run build:highlight`npm ERR! Exit status 1npm ERR!npm ERR! Failed at the hexo-util@0.6.1 postinstall script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-27T02_56_29_887Z-debug.log 解决方法第一步,赋予目录权限: 1$ sudo chown -R `whoami` /usr/local/lib/node_modules 第二步,安装hexo: 1$ npm install hexo-cli -g 需要注意的点: 在安装hexo时,不要用 sudo 命令. 相关参考 国内优秀npm镜像推荐及使用 Mac install hexo use sudo but sitll permission denied npm update -g fails and causes /usr/local/lib/node_modules to be deleted]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs数据库及初始化配置]]></title>
    <url>%2F2017%2F09%2F07%2Fdocker-ubuntu-gogs-initialization%2F</url>
    <content type="text"><![CDATA[Ubuntu-Gogs 首次运行安装程序配置及多数据库配置方法整理。 app.ini中数据库配置说明 名称 描述 DB_TYPE 数据库类型，可以是 mysql、postgres、mssql 或 sqlite3 HOST 数据库主机地址与端口 NAME 数据库名称 USER 数据库用户名 PASSWD 数据库用户密码 SSL_MODE 仅限 PostgreSQL 使用 PATH 仅限 SQLite3 使用，数据库文件路径 初次启动时数据库设置Gogs 要求安装 MySQL、PostgreSQL、SQLite3、MSSQL 或 TiDB。 SQLite3数据库设置 数据库类型 ：SQLite3 数据库文件路径 ：可使用绝对路径：/app/gogs/data/gogs.db 或者 相对路径：data/gogs.db （推荐使用绝对路径） app.ini中配置结果12345678[database]DB_TYPE = sqlite3HOST = 127.0.0.1:3306NAME = gogsUSER = rootPASSWD = SSL_MODE = disablePATH = /app/gogs/data/gogs.db 示例容器1$ docker run --name gogs1 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs MySQL数据库设置 数据库类型 ：MySQL 数据库主机 ：127.0.0.1:3306 数据库用户 ：root 数据库用户密码 : ******* 数据库名称 ：gogs app.ini中配置结果12345678[database]DB_TYPE = mysqlHOST = 127.0.0.1:3306NAME = gogsUSER = rootPASSWD = `123456`SSL_MODE = disablePATH = data/gogs.db 示例容器第一种方法：创建mysql容器和gogs容器，让gogs容器通过 --link 直接链接mysql容器。 创建mysql容器，并设置root账户密码：123456；新用户：gogs123；密码：gogs123；新用户数据库：gogs ： 1$ docker run --name mysqlgogs -v /home/tiger/mysqldb/:/var/lib/mysql -v /home/tiger/mysqldbase/:/home/mysqldbase/ -d -e MYSQL_ROOT_PWD=&quot;123456&quot; -e MYSQL_USER=gogs123 -e MYSQL_USER_PWD=&quot;gogs123&quot; -e MYSQL_USER_DB=&quot;gogs&quot; leafney/docker-alpine-mysql 创建gogs容器并链接： 1$ docker run --name gogs2 -d -p 10080:3000 -p 10022:22 --link mysqlgogs:mydb -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 相对应的配置信息如下： 数据库类型 ：MySQL 数据库主机 ：mydb:3306 数据库用户 ：gogs123 数据库用户密码 : ******* 数据库名称 ：gogs 第二种方法：让gogs容器链接已有mysql地址。 在创建gogs容器之前，先创建mysql数据库： 在下载的 gogs 压缩包中，我们可以找到一个名为 mysql.sql 的文件，是用来初始化mysql数据库的，内容如下： 12DROP DATABASE IF EXISTS gogs;CREATE DATABASE IF NOT EXISTS gogs CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 使用 root 账户登录，然后执行 mysql -u root -p &lt; mysql.sql （需要输入密码）即可初始化好数据库。 还要注意：使用 MySQL 数据库时，必须要保证mysql的存储引擎为 INNODB 且 编码格式为 utf8_general_ci 。可以使用如下语句来设置： 12use gogs;set global storage_engine=INNODB; 或者使用如下命令创建数据库 gogs 及新用户 gogsUser, 并将数据库 gogs 的所有权限都赋予该用户,密码 123456: 123456mysql -u root -pmysql&gt; SET GLOBAL storage_engine = &apos;InnoDB&apos;;mysql&gt; CREATE DATABASE gogs CHARACTER SET utf8 COLLATE utf8_bin;mysql&gt; GRANT ALL PRIVILEGES ON gogs.* TO &apos;gogsUser&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;;mysql&gt; FLUSH PRIVILEGES;mysql&gt; QUIT； 使用 Gogs 搭建自己的 Git 服务器 - My Nook PostgreSQL数据库设置 数据库类型 ：PostgreSQL 数据库主机 ：127.0.0.1:5432 数据库用户 ：gogs 数据库用户密码 : ******* 数据库名称 ：gogs SSL 模式 : Disable (可选：Disable Require Verify Full) app.ini中配置结果12345678[database]DB_TYPE = postgresHOST = 127.0.0.1:5432NAME = gogsUSER = gogsPASSWD = gogsSSL_MODE = disablePATH = data/gogs.db 示例容器第一种方法：创建postgersql容器和gogs容器 创建postgresql容器，这里使用容器 docker pull ananthhh/postgress： 1docker run --name postgress -p 5432:5432 -e POSTGRES_PASSWORD=gogs -e POSTGRES_USER=gogs -d ananthhh/postgress 该postgresql容器创建的用户为：gogs；用户密码：gogs; 数据库：gogs 。 创建gogs容器并通过 --link 参数链接： 1$ docker run --name gogs3 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app --link postgress:psqldb leafney/ubuntu-gogs 相对应的配置信息如下： 数据库类型 ：PostgreSQL 数据库主机 ：psqldb:5432 数据库用户 ：gogs 数据库用户密码 : ******* 数据库名称 ：gogs SSL 模式 : Disable 第二种方法：让gogs容器链接已有PostgreSQL地址。 使用指定数据库账户登录PostgreSQL，先创建 gogs 数据库，链接成功后会自动创建所需表： 1&gt; CREATE DATABASE gogs MSSql数据库设置 数据库类型 ：MSSQL 数据库主机 ：127.0.0.1, 1433 数据库用户 ：sa 数据库用户密码 : ******* 数据库名称 ：gogs app.ini中配置结果12345678[database]DB_TYPE = mssqlHOST = 127.0.0.1, 1433NAME = gogsUSER = saPASSWD = 123456SSL_MODE = disablePATH = data/gogs.db 示例容器创建gogs容器链接已有MSSql地址： 1docker run --name gogs4 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 使用指定数据库账户登录MSSql，先创建gogs数据库，链接成功后会自动创建所需表： 1&gt; CREATE DATABASE gogs 应用基本设置以如下命令创建容器为例： 1$ docker run --name mygogs -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 仓库根目录： 更改为绝对路径 /app/gogs-repositories 运行系统用户： 使用默认用户 git 域名： 填写Docker宿主机的主机名或物理地址或要使用的域名(不带http/https) 如 192.168.137.140 SSH 端口号： 如果你映射Docker外部端口如 10022:22 那么这里就填写 10022 ；不要勾选“使用内置SSH服务器”（Don’t tick Use Builtin SSH Server） HTTP 端口号： 如果映射Docker外部端口如 10080:3000 这里要使用：3000 应用 URL： 使用域名和公开的HTTP端口值的组合(带http/https) 如 http://192.168.137.140:10080 日志路径： 可使用路径 /app/gogs/log(推荐) 或默认值 /home/git/gogs/log 可选设置app.ini中邮件(mailer)配置说明 名称 描述 ENABLED 启用该选项以激活邮件服务 DISABLE_HELO 禁用 HELO 操作 HELO_HOSTNAME HELO 操作的自定义主机名 HOST SMTP 主机地址与端口 FROM 邮箱的来自地址，遵循 RFC 5322规范，可以是一个单纯的邮箱地址或者 “名字” &#101;&#x6d;&#97;&#x69;&#x6c;&#64;&#101;&#120;&#97;&#x6d;&#x70;&#108;&#x65;&#x2e;&#99;&#x6f;&#x6d; 的形式 USER 邮箱用户名 PASSWD 邮箱密码 SKIP_VERIFY 不验证自签发证书的有效性 USE_PLAIN_TEXT 使用 text/plain 作为邮件内容格式 邮件服务设置 SMTP 主机： 以163为例 如 smtp.163.com:25 邮件来自： 格式为 &quot;Name&quot; &lt;email@example.com&gt; 如 GitAdmin &lt;xxxxx@163.com&gt; 发送邮箱： 邮箱地址 如 xxxxx@163.com 发送邮箱密码 : 邮箱密码 app.ini中配置结果 123456[mailer]ENABLED = trueHOST = smtp.163.com:25FROM = GitAdmin &lt;xxxxx@163.com&gt;USER = xxxxx@163.comPASSWD = 123456 服务器和其它服务设置 禁止用户自主注册 激活该选项来禁止用户注册功能，只能由管理员创建帐号 启用验证码服务 要求在用户注册时输入预验证码 启用登录访问限制 只有已登录的用户才能够访问页面，否则将只能看到登录或注册页面 管理员账号设置创建管理员帐号并不是必须的，因为 ID=1 的用户将自动获得管理员权限。 建议在此处直接创建管理员账户。 相关参考 How To Set Up Gogs on Ubuntu 14.04 | DigitalOcean 配置文件手册 - Gogs]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Gogs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下安装Docker-CE社区版]]></title>
    <url>%2F2017%2F08%2F25%2Fubuntu-install-docker-ce-and-configure-mirror-accelerator%2F</url>
    <content type="text"><![CDATA[在2017年3月份，Docker公司宣布Docker企业版（Enterprise Edition, EE），并将开源版本重命名为Docker社区版（Community Edition, CE）；同时公布了产品迭代计划，这会为企业客户提供透明的生命周期支持计划、并对Docker技术的稳定性和可维护性提升带来了帮助。 注：文章写于 2017年8月 ,文中所讲方法可能会过时，请查看Docker官方最新安装文档 Get Docker CE for Ubuntu | Docker Documentation，本文仅供参考。 Docker CE 还是 Docker EEDocker CEDocker CE表示社区版，是免费的Docker产品的新名称，Docker CE包含了完整的Docker平台，非常适合开发人员和运维团队构建容器APP。 Docker EEDocker EE表示企业版，由公司支持，可在经过认证的操作系统和云提供商中使用，并可运行来自Docker Store的、经过认证的容器和插件。 Docker EE提供三个服务层次： 服务层级 功能 Basic 1. 包含用于认证基础设施的Docker平台 2. Docker公司的支持 3. 经过认证的、来自Docker Store的容器与插件 Standard 1. 添加高级镜像与容器管理 2. LDAP/AD用户集成 3. 基于角色的访问控制(Docker Datacenter) Advanced 1. 添加Docker安全扫描 2. 连续漏洞监控 版本迭代Docker从17.03开始，转向基于时间的 YY.MM 形式的版本控制方案，类似于Canonical为Ubuntu所使用的版本控制方案。 Docker CE有两种版本： edge版本每月发布一次，主要面向那些喜欢尝试新功能的用户。 stable版本每季度发布一次，适用于希望更加容易维护的用户（稳定版）。 edge版本只能在当前月份获得安全和错误修复。而stable版本在初始发布后四个月内接收关键错误修复和安全问题的修补程序。这样，Docker CE用户就有一个月的窗口期来切换版本到更新的版本。 Docker EE和stable版本的版本号保持一致，每个Docker EE版本都享受为期一年的支持与维护期，在此期间接受安全与关键修正。 官方安装方法系统要求安装Docker CE,需要64位的Ubuntu系统： Zesty 17.04 Xenial 16.04 (LTS) Trusty 14.04 (LTS) 我的系统是 Ubuntu 16.04.2 LTS 版本，通过命令 lsb_release -a 我们可以查看到: 1234567$ sudo lsb_release -a[sudo] password for tiger: LSB Version: core-9.20160110ubuntu0.2-amd64Distributor ID: UbuntuDescription: Ubuntu 16.04.2 LTSRelease: 16.04Codename: xenial 通过 uname -r 来查看内核信息： 12$ uname -r4.4.0-85-generic 卸载旧版本Docker旧版本的docker被称为 docker 或者 docker-engine，而现在最新的Docker CE包被称为 docker-ce。在安装之前，需要先卸载旧版本(如果之前有安装)： 1$ sudo apt-get remove docker docker-engine docker.io 另外原来 /var/lib/docker/ 目录下的镜像，容器，数据卷，网络等都会保留，新安装的docker任然可以使用这些内容。 14.04 Trusty 需要安装额外包在 14.04 系统版本下，需要安装 linux-image-extra-* 包以允许Docker使用 aufs 存储驱动程序： 12345$ sudo apt-get update$ sudo apt-get install \ linux-image-extra-$(uname -r) \ linux-image-extra-virtual 安装 Docker CE更新源1$ sudo apt-get update 允许通过HTTPS使用存储库12345$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 导入官方 GPG 密钥1$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证密钥指纹是否正确 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 1$ sudo apt-key fingerprint 0EBFCD88 操作记录如下： 1234567$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -OK$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 选择稳定版本使用如下命令安装稳定版本的docker-ce,64位系统： amd64 or x86_64: 1234$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 更新源列表1$ sudo apt-get update 安装最新版本的Docker CE1$ sudo apt-get install docker-ce 安装特定版本的Docker CE使用命令 $ apt-cache madison docker-ce 查看可安装的版本列表： 123456$ apt-cache madison docker-ce docker-ce | 17.06.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.2~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages 中间一项为版本名称，执行命令选择安装指定版本 $ sudo apt-get install docker-ce=&lt;VERSION&gt; ,比如： 1234567$ sudo apt-get install docker-ce=17.06.1~ce-0~ubuntu[sudo] password for tiger: Reading package lists... DoneBuilding dependency tree Reading state information... Donedocker-ce is already the newest version (17.06.1~ce-0~ubuntu).0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded. 安装完成后docker守护进程会自动启动。 验证执行命令 docker 查看安装是否成功： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576$ docker Usage: docker COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default &quot;/home/tiger/.docker&quot;) -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (&quot;debug&quot;|&quot;info&quot;|&quot;warn&quot;|&quot;error&quot;|&quot;fatal&quot;) (default &quot;info&quot;) --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default &quot;/home/tiger/.docker/ca.pem&quot;) --tlscert string Path to TLS certificate file (default &quot;/home/tiger/.docker/cert.pem&quot;) --tlskey string Path to TLS key file (default &quot;/home/tiger/.docker/key.pem&quot;) --tlsverify Use TLS and verify the remote -v, --version Print version information and quitManagement Commands: config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker volume Manage volumesCommands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container&apos;s changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container&apos;s filesystem events Get real time events from the server exec Run a command in a running container export Export a container&apos;s filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codesRun &apos;docker COMMAND --help&apos; for more information on a command. 为当前用户添加管理员权限Docker进程启动后，执行docker命令都必须带上 sudo 才行，否则会报 permission denied 的错误： 12$ docker infoGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.30/info: dial unix /var/run/docker.sock: connect: permission denied 解决方法是将当前用户加入到 docker 用户分组下。 将当前用户添加到 docker 分组下1$ sudo usermod -aG docker &lt;your-user&gt; 或者直接用 $USER 表示当前用户： 1$ sudo usermod -aG docker $USER 然后重启系统： 1$ sudo reboot 再执行时就不会报错了： 12345678910111213141516171819$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.06.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 0 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactive 使用阿里云Docker CE镜像源安装Ubuntu 14.04 16.04 (使用apt-get进行安装)12345678910111213141516171819# step 1: 安装必要的一些系统工具sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# step 2: 安装GPG证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# Step 3: 写入软件源信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# Step 4: 更新并安装 Docker-CEsudo apt-get -y updatesudo apt-get -y install docker-ce# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# apt-cache madison docker-ce# docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial)# sudo apt-get -y install docker-ce=[VERSION] CentOS 7 (使用yum进行安装)12345678910111213141516171819202122# step 1: 安装必要的一些系统工具sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装 Docker-CEsudo yum makecache fastsudo yum -y install docker-ce# Step 4: 开启Docker服务sudo service docker start# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r# Loading mirror speeds from cached hostfile# Loaded plugins: branch, fastestmirror, langpacks# docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable# docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable# docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# Available Packages# Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)# sudo yum -y install docker-ce-[VERSION] 配置阿里云Docker镜像加速器打开阿里云 开发者平台 - 管理中心 - Docker Hub 镜像站点。可以看到 您的专属加速器地址 https://xxxxx.mirror.aliyuncs.com 配置Docker加速器通过修改daemon配置文件 /etc/docker/daemon.json (没有时新建该文件) 来使用加速器： 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 注意：上文代码段中给出的镜像加速器地址中的 xxxxx 为阿里云在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关参考 Get Docker CE for Ubuntu | Docker Documentation Docker 17.03系列教程（一）Docker EE/Docker CE简介与版本规划 | 周立|Spring Cloud Docker CE 镜像源站-博客-云栖社区-阿里云]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB备份与恢复]]></title>
    <url>%2F2017%2F08%2F22%2Fmongodb-mongodump-and-mongorestore%2F</url>
    <content type="text"><![CDATA[mongodb中有工具mongodump和mongorestore提供了非常方便的对数据库备份与恢复功能。可以在命令后面加 --help 选项查看两个工具的帮助文档。 12345678910111213141516171819/ # mongodump --helpUsage: mongodump &lt;options&gt;Export the content of a running server into .bson files.Specify a database with -d and a collection with -c to only dump that database or collection.See http://docs.mongodb.org/manual/reference/program/mongodump/ for more information.general options: --help print usage --version print the tool version and exitverbosity options: -v, --verbose=&lt;level&gt; more detailed log output (include multiple times for more verbosity, e.g. -vvvvv, or specify a numeric value, e.g. --verbose=N) --quiet hide all log output ... ... MongoDB备份mongodump备份命令语法: 1&gt; mongodump -h dbhost -d dbname -o dbdirectory -h : MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d : 需要备份的数据库实例，例如：test -o ：备份的数据存放位置，例如：c:\data\dump，当然该目录需要提前建立 备份指定数据库： 1&gt; mongodump -h 127.0.0.1:27017 -d local -o D:\Test\aatt 备份所有数据库： 1&gt; mongodump --host 127.0.0.1 --port 27017 如果mongodb设置了密码，则命令格式为： 1&gt; mongodump --host localhost --port 27017 -u dbUser -p dbPassword -d mydb --out /home/dbbackup 或者如下的格式： 1&gt; mongodump -h 127.0.0.1:27017 -u admin -p 123456 -d test -o /data/backup MongoDB恢复mongorestore 恢复备份命令语法： 1&gt; mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt; --host &lt;:port&gt;, -h &lt;:port&gt; : MongoDB所在服务器地址，默认为： localhost:27017 --db , -d ：需要恢复的数据库实例，该名称与备份时的名称可以不一致 --drop : 恢复的时候，先删除当前数据，然后恢复备份的数据。 &lt;path&gt; ：mongorestore 最后的一个参数，设置备份数据所在位置，例如：c:\data\dump\test。你不能同时指定 和 –dir 选项，–dir也可以设置备份目录。 --dir : 指定备份的目录 恢复备份数据到指定的服务器数据库中： 1&gt; mongorestore -h 127.0.0.1:27017 -d test2 D:\Test\aatt\local Alpine系统下的MongoDB备份与恢复Alpine系统下使用MongoDB，需要安装MongoDB包: apk add mongodb 。如果要使用备份与恢复功能，需要安装 mongodb-tools 包：apk add mongodb-tools。 1234567alpine:edge$ echo http://dl-4.alpinelinux.org/alpine/edge/testing &gt;&gt; /etc/apk/repositories$ apk add --no-cache mongodb mongodb-tools$ ls /usr/bin/]]></content>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang下通过Gin体验WebSocket框架Melody]]></title>
    <url>%2F2017%2F08%2F14%2Fwebsocket-framework-for-go-melody%2F</url>
    <content type="text"><![CDATA[Melody 是一个 Go 语言的微型 WebSocket 框架，基于 github.com/gorilla/websocket 开发. Gin-Gonic获取包： 1&gt; go get github.com/gin-gonic/gin 添加引用： 1inport &quot;github.com/gin-gonic/gin&quot; 创建Gin测试站点： 12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;Hello Gin&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125; 运行： 1&gt; go run main.go Melody获取包： 1&gt; go get gopkg.in/olahol/melody.v1 添加引用： 1import &quot;gopkg.in/olahol/melody.v1&quot; Simple Chat Demomain.go： 123456789101112131415161718192021222324252627package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;gopkg.in/olahol/melody.v1&quot; &quot;net/http&quot;)func main() &#123; r := gin.Default() m := melody.New() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; http.ServeFile(c.Writer, c.Request, &quot;templates/index.html&quot;) &#125;) //websocket r.GET(&quot;/ws&quot;, func(c *gin.Context) &#123; m.HandleRequest(c.Writer, c.Request) &#125;) m.HandleMessage(func(s *melody.Session, msg []byte) &#123; m.Broadcast(msg) &#125;) r.Run(&quot;:8080&quot;)&#125; index.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;WebSocket&lt;/title&gt; &lt;style&gt; #chat &#123; text-align: left; background: #f1f1f1; width: 500px; min-height: 300px; padding: 20px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;center&gt; &lt;h3&gt;Chat&lt;/h3&gt; &lt;pre id=&quot;chat&quot;&gt;&lt;/pre&gt; &lt;input placeholder=&quot;say something&quot; id=&quot;text&quot; type=&quot;text&quot;&gt; &lt;/center&gt; &lt;script&gt; var url = &quot;ws://&quot; + window.location.host + &quot;/ws&quot;; var ws = new WebSocket(url); var name = &quot;Guest&quot; + Math.floor(Math.random() * 1000); var chat = document.getElementById(&quot;chat&quot;); var text = document.getElementById(&quot;text&quot;); var now = function () &#123; var iso = new Date().toISOString(); return iso.split(&quot;T&quot;)[1].split(&quot;.&quot;)[0]; &#125;; ws.onmessage = function (msg) &#123; var line = now() + &quot; &quot; + msg.data + &quot;\n&quot;; chat.innerText += line; &#125;; text.onkeydown = function (e) &#123; if (e.keyCode === 13 &amp;&amp; text.value !== &quot;&quot;) &#123; ws.send(&quot;&lt;&quot; + name + &quot;&gt; &quot; + text.value); text.value = &quot;&quot;; &#125; &#125;; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 运行： 1&gt; go run main.go GitHub - olahol/melody: Minimalist websocket framework for Go]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Travis CI自动部署Hexo博客]]></title>
    <url>%2F2017%2F08%2F09%2Fusing-travis-ci-automatic-deploy-hexo-blogs%2F</url>
    <content type="text"><![CDATA[自从使用GitHub Pages和Hexo来发布博客之后，不得不说方便了许多，只需要几个简单的命令博客就发布了。但在不断的使用中发现每次的发布操作也挺耗时的。 我一般的操作是将平时整理好的md文件放到私有的git仓库中（感兴趣可了解 Ubuntu-Gogs 用更简单的方式部署、升级或迁移Gogs服务），每次发布的时候都要先将文件 clone 到本地，然后配置一下hexo的运行环境，接着再执行 hexo s -g 来预览和调整，最后执行 hexo d 命令将博客发布上去，在这之前如果你没有配置过GitHub的 SSH Key,还要花一些时间来弄权限的问题。久而久之就发现这样操作起来实在是太繁琐了。 后来看到一篇文章介绍可以使用Travis CI来自动部署hexo的博客，只需要将md文件 push 到仓库中博客就自动发布好了。趁着这几天工作任务不太着急，研究了一下，特纪录在此，希望能帮到有需要的朋友。 Travis CI 是目前新兴的开源持续集成构建项目，用来构建托管在GitHub上的代码。它提供了多种编程语言的支持，包括Ruby，JavaScript，Java，Scala，PHP，Haskell和Erlang在内的多种语言。 配置GitHub Pages如果你是新手或者还没有自己的 GitHub Pages 博客站点，可以先看我之前的文章 使用GitHub搭建Hexo静态博客 | IT范儿 了解如何配置，具体过程这里不再详述。 创建 hexo 分支因为我之前的博客源文件是存放在私有的git管理工具下，如果我们要使用Travis CI自动部署，必须将这些博客的源码文件放到GitHub上才能被Travis访问到。因为 GitHub Pages 默认要求必须使用 master 分支存放静态文件，我们可以在该仓库下使用其他分支来存放博客源码文件，或者新创建一个仓库来单独保存。这里我们把hexo博客的源码放在 hexo 分支下，博客的静态文件部署在 master 分支下。 对于如何在GitHub上创建分支，相关操作命令如下，仅供参考： 12345# 克隆项目到本地&gt; git clone https://github.com/Leafney/Leafney.github.io.git# 创建并切换到 hexo 分支&gt; git checkout -b hexo 当切换到 hexo 分支后，因为我们是需要用 hexo 分支来存放博客源码文件的，所以，将 hexo 分支下的文件除 .git 目录外全部删除，然后将博客源码文件拷贝到该目录下，并 commit 到 hexo 分支. 然后我们需要将本地的 hexo 分支提交到远程仓库中 12# 提交本地hexo分支到远程仓库的hexo分支&gt; git push origin hexo:hexo 这样我们在GitHub的仓库下就能看到 hexo 分支为博客源文件，master 分支为静态文件。 这里需要注意一点，当我们新增博客md文件时，获取远程分支时要指定分支的名称，否则会默认获取 master 分支： 1&gt; git pull origin hexo 设置 Travis CI使用 GitHub账户登录 Travis CI官网 ，进去后能看到已经自动关联了 GitHub 上的仓库。这里我们选择需要启用的项目，即 yourname/yourname.github.io 。 然后点击后面的齿轮图标进入设置界面。 如果你之前已经勾选过项目，可以进到项目主页中，在右上角找到 More options 选项下的 Settings 进入设置界面。 通用设置在 General 区域开启：Build only if .travis.yml is present 表示“只有当 .travis.yml 存在时才构建” ；开启：Build branch updates 表示 “当分支更新时构建” 两个选项，如下： Travis CI在自动构建完成后需要push静态文件到仓库的 master 分支下，而访问GitHub的仓库是需要权限的，下面来看看如何配置权限。 配置 Access Token如下图，Environment Variables 区域就是用来添加权限信息的。我们需要填写一个Token的名称和值，该名称可以在配置文件中以 ${变量名} 来引用，该Token我们需要从Github中获取。 从GitHub获取Access Token之前我们在使用命令 hexo d 部署hexo博客到GitHub上时，是因为本地有 SSH key，当交给 Travis 去自动部署时我们也需要设置可操作权限，这里我们使用GitHub提供的token变量来实现。 登陆 GitHub –Settings 选项，找到 Personal access tokens 页面。 点击右上角的 Generate new token 按钮会生成新的token，点击后提示输入密码后继续，然后来到如下界面，取个名字（我这里取 Travis_Token 下面的配置文件中会用到)，勾选相应权限，这里只需要 repo 下全部和 user 下的 user:email 即可。 生成完成后，将该token拷贝下来。这里需要注意的是该token只有这个时候才能看到，当再次进入这个页面时就只会显示之前设置的名称了。如果忘记了只能重新生成一个。 在Travis CI中配置将上面获取到的token添加到 Environment Variables 部分，值为该 token ,而名称即为上面设置的 Travis_Token (请更改为个人所设置名称)。不勾选后面的 Display value in build log . 否则会在日志文件中暴露你的 token 信息，而日志文件是公开可见的。 至此我们已经配置好了要构建的仓库和访问的token，接下来就是如何构建的问题了。 创建 .travis.yml 文件之前的步骤中我们勾选了一项 Build only if .travis.yml is present,所以我们要在博客源码文件的 hexo 分支下新增一个 .travis.yml 配置文件，其内容如下： 123456789101112131415161718192021222324252627language: node_js # 设置语言node_js: stable # 设置相应版本install: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - cd ./public - git init - git config user.name &quot;yourname&quot; # 修改name - git config user.email &quot;your email&quot; # 修改email - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master # GH_TOKEN是在Travis中配置token的名称branches: only: - hexo #只监测hexo分支，hexo是我的分支的名称，可根据自己情况设置env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改yourname 注意：需要将配置文件中的 GH_TOKEN 换成我们自己设定的名称，这里我的配置应该是 Travis_Token 即 - git push --force --quiet &quot;https://${Travis_Token}@${GH_REF}&quot; master:master # GH_TOKEN是在Travis中配置token的名称。 还要更改 GH_REF 中我们的博客仓库的地址。 配置文件中的操作也很简单，这也是网上找到的比较常见的一种配置格式了。然而，这份配置文件中却隐藏着一个大坑。至于如何跳过去，后面再详说。 实现自动部署当 .travis.yml 配置文件修改完成后，将其提交到远程仓库的 hexo 分支下，此时如果之前的配置一切ok，我们应该能在 Travis CI 的博客项目主页页面中看到自动构建已经在开始执行了。上面会显示出构建过程中的日志信息及状态等。 遇到的问题问题一：提示 .travis.yml 文件格式错误在 Travis CI 的日志文件中，如果遇到下面的错误提示，那可能就是 .travis.yml 文件的格式有问题。 1234ERROR: An error occured while trying to parse your .travis.yml file.Please make sure that the file is valid YAML.http://lint.travis-ci.org can check your .travis.yml.The log message was: Build config file had a parse error: found character that cannot start any token while scanning for the next token at line 6 column 1. 通过在github上查询，我发现这个问题是我在配置文件中的缩进使用了 tab 键导致的。因为在不同的编辑器下，tab 键表示的宽度可能不同。 这里建议是：不要用 tab 键，而是用适当的空格实现缩进 found character &#39;\t&#39; that cannot start any token while scanning for the next token at line · Issue #136 · ruby/psych · GitHub 问题二：Travis CI的自动构建成功，但是构建完成后的项目没有推送到github中123456......git commit -m &quot;Travis CI Auto Builder&quot;git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:masterremote: Anonymous access to Leafney/Leafney.github.io.git denied.fatal: Authentication failed for &apos;https://@github.com/Leafney/Leafney.github.io.git/&apos; 查看日志提示是权限问题。 这里的问题是我在 .travis.yml 配置文件中没有把 ${GH_TOKEN} 部分换成自己在 Travis CI 中填写的token名称而导致的。执行时找不到token，也就没法设置权限了。 问题三：master commit 树被清空 ☆如果你按照上面的 travis.yml 配置文件的设置去自动构建你的博客，你会发现 master 分支的提交记录只有当前提交的这一条，而且无论操作多少次，也仅仅只有一条。这还真的是一个大坑呀！ 比如下面这位网友的站点： GitHub - hhstore/hhstore.github.io: 个人技术博客 在 master 分支下就只有一条提交记录。 .travis.yml 部分配置内容： 12345678after_script: - cd ./public - git init - git config user.name &quot;yourname&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;update&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master 仔细查看上面的配置文件，我们发现每次都是将 public 目录下的文件重新生成了一个git项目，然后强制覆盖提交到了 master 分支下，这就是问题的所在。 为了解决这个问题，我将配置文件改为了如下的内容： 123456789101112after_script: - git clone https://$&#123;GH_REF&#125; .deploy_git - cd .deploy_git - git checkout master - cd ../ - mv .deploy_git/.git/ ./public/ - cd ./public - git config user.name &quot;yourname&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master 在 after_script 部分，我先将博客项目 clone 到本地的 .deploy_git 目录下（目录名可自定义）,然后切换到 master 分支，将 master 分支下的 .git 目录拷贝到了 public 目录下，接着继续后面的 commit 操作。 这里算是采用了一种 换位 的方式。之前我们通过git管理文件时并不会改动 .git 目录，而只是更改文件。但在这种情况下，我们需要提交的是 public 目录下的新文件。这样，就会保留之前的提交记录了。 附上我在使用的配置文件内容： 123456789101112131415161718192021222324252627282930313233343536373839language: node_js # 设置语言node_js: stable # 设置相应版本cache: apt: true directories: - node_modules # 缓存不经常更改的内容before_install: - npm install hexo-cli -ginstall: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - git clone https://$&#123;GH_REF&#125; .deploy_git - cd .deploy_git - git checkout master - cd ../ - mv .deploy_git/.git/ ./public/ - cd ./public - git config user.name &quot;your name&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:masterbranches: only: - hexo # 只监测hexo分支env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改成自己的仓库地址 注意上面配置文件中的某些参数改为自己的。 问题四：添加 commit 时间戳 2017-8-23 11:25:34 Update: 按照上面的方法配置 travis.yml 的内容，我在一段时间后发现在 master 分支下的提交记录是这样的： 1234567Travis CI Auto BuilderTravis CI Auto BuilderTravis CI Auto Builder.... 而之前在使用 hexo d 直接部署的时候的提交记录是这样的： 1234567Site updated: 2017-06-22 22:29:10Site updated: 2017-04-19 08:13:36Site updated: 2017-03-27 20:54:40... 看到每次的提交记录中没有提交的时间戳，感觉似乎缺少了些什么，所以考虑着要把 commit 的时间戳给加上。 通过查看 travis.yml 的文档，并没有找到如何直接获取当前时间或者和 date 有关的方法，但是 script 命令下是可以执行 shell 命令的，所以对 travis.yml 文件进行了修改。 在 shell 中获取当前的时间戳，可以这样： 1234#/bin/bash&gt; date +&quot;%Y-%m-%d %H:%M&quot;2017-08-23 11:07 需要注意的是：命令中要为 publish-to-gh-pages.sh 文件赋予可执行权限，否则会报无权限错误： 1234# travis-ci log$ ./publish-to-gh-pages.sh/home/travis/.travis/job_stages: line 57: ./publish-to-gh-pages.sh: Permission denied 另外，通过在测试中发现，Travis CI 中使用的linux系统在编译生成时使用的是UTC时间，这样我们在github中的提交列表中看到的提交时间就会晚8小时。我们需要在执行时将时区改为东八区。 这里通过在 .travis.yml 文件中添加如下代码解决： 12before_install: - export TZ=&apos;Asia/Shanghai&apos; 修改后的 .travis.yml 内容： 12345678910111213141516171819202122232425262728293031language: node_js # 设置语言node_js: stable # 设置相应版本cache: apt: true directories: - node_modules # 缓存不经常更改的内容before_install: - export TZ=&apos;Asia/Shanghai&apos; # 更改时区 - npm install hexo-cli -g - chmod +x ./publish-to-gh-pages.sh # 为shell文件添加可执行权限install: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - ./publish-to-gh-pages.shbranches: only: - hexo # 只监测hexo分支env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改成自己的仓库地址 将 after_script 段中的命令移到了单独的shell文件中： 文件 publish-to-gh-pages.sh 内容： 1234567891011121314151617181920#!/bin/bashset -evgit clone https://$&#123;GH_REF&#125; .deploy_gitcd .deploy_gitgit checkout mastercd ../mv .deploy_git/.git/ ./public/cd ./publicgit config user.name &quot;your name&quot;git config user.email &quot;your email&quot;# add commit timestampgit add .git commit -m &quot;Travis CI Auto Builder at `date +&quot;%Y-%m-%d %H:%M&quot;`&quot;git push --force --quiet &quot;https://$&#123;TravisCIToken&#125;@$&#123;GH_REF&#125;&quot; master:master 注意上面配置文件中的某些参数改为自己的。 Customizing the Build - Travis CI travis ci - Permission denied for build.sh file - Stack Overflow Shell中date命令用法 | Hom 问题五：使用 x-oauth-basic在网上看到一位网友解决 “master commit 树被清空” 的问题时采用了另外一种方法，即在 after_script 部分调用执行 hexo d 命令来发布。这样的方式遇到的问题是需要设置 SSH Key 或者必须获得权限才能进行 push 操作。 有一种授权的方式是通过https使用OAuth验证的方式将token添加到url中来提交。即需要更改 _config.yml 中的如下部分： 12345## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:Leafney/Leafney.github.io.git branch: master 为： 12345## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://&lt;token&gt;:x-oauth-basic@github.com/owner/repo.git branch: master 而这样一来 token 就暴露在配置文件中了。所以还需要在操作命令中使用替换的方式只在自动部署时更改该token。 这里仅做介绍，更详细可访问： 使用Travis Ci使hexo自动生成并部署 | xingo&#39;s private plot Easier builds and deployments using Git over HTTPS and OAuth · GitHub 问题六：git branch 分支操作相关命令1234567891011121314151617181920212223242526# 查看本地所有分支(分之名称前面带*表示当前分支)&gt; git branch# 查看远程所有分支&gt; git branch -r# 创建分支 blog&gt; git branch blog# 切换到 blog 分支&gt; git checkout blog# 创建并切换到新分支&gt; git checkout -b blog# 删除分支&gt; git branch -d blog# 提交本地test分支作为远程的test分支&gt; git push origin test:test# 合并分支(将名称为[blog]的分支与当前分支合并)&gt; git merge blog# 获取远程指定分支&gt; git pull origin blog 问题七：博客仓库源码如果没有耐心按照上面的步骤一步步操作的话，可以直接查看我的博客仓库源码： GitHub - Leafney/Leafney.github.io: blog 相关参考 手把手教你使用Travis CI自动部署你的Hexo博客到Github上 - 简书 使用 Travis CI 自动部署 Hexo - 简书 使用 Travis-CI 来自动化部署 Hexo · ZHOU 用TravisCI来做持续集成 | 进击的马斯特 Customizing the Build - Travis CI 该文章同步发表在： 使用Travis CI自动部署Hexo博客 - 酷小孩 - 博客园 使用Travis CI自动部署Hexo博客 | IT范儿]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Travis-CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reload-changed-without-restart-for-golang-web-gin]]></title>
    <url>%2F2017%2F08%2F01%2Freload-changed-without-restart-for-golang-web-gin%2F</url>
    <content type="text"><![CDATA[Gin is a HTTP web framework written in Go (Golang)。但是在调试Gin项目时，每次更改了文件内容后都需要重新运行 go run main.go 命令才能看到更改。项目 codegangsta/gin 和 pilu/fresh 是通过采用热更新的方式来调试Gin项目推荐度较高的两个，且看哪个在操作上更加的方便。 gingithub 地址GitHub - codegangsta/gin: Live reload utility for Go web servers 下载并安装1go get github.com/codegangsta/gin 将 GOPATH/bin 目录添加到系统的 PATH 中。 项目测试123456789101112131415package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world\n&quot;) &#125;) r.Run(&quot;:3001&quot;)&#125;# 运行&gt; gin run main.go# 浏览器访问http://localhost:3000 扩展 因为项目 codegangsta/gin 和 gin-gonic/gin 重名，所以这里我用 Reload gin 代指 codegangsta/gin;用 Web gin 代指 gin-gonic/gin。 默认情况下，Reload gin的默认监听端口为 3000,内部导向的go web项目端口为 3001。如果采用 Reload gin 的默认端口，则需要将 Web gin 的监听端口改为 3001,即：r.Run(&quot;:3001&quot;) 。 如果需要自定义端口，通过 gin -h 可以看到 Reload gin 的常用配置项。其中: 12--port value, -p value port for the proxy server (default: 3000)--appPort value, -a value port for the Go web server (default: 3001) 可以分别指定监听端口和映射端口。 不过，经过测试，自定义端口时报如下错误： 12345678λ gin run -p 8082 -a 8080 main.goIncorrect Usage: flag provided but not defined: -pNAME: gin run - Run the gin proxy in the current working directoryUSAGE: gin run [arguments...] 好像目前只能使用默认的 3000 和 3001 端口。 freshgithub地址GitHub - pilu/fresh: Build and (re)start go web apps after saving/creating/deleting source files. 下载及安装1go get github.com/pilu/fresh 将 GOPATH/bin 目录添加到系统的 PATH 中。 项目测试123456789101112131415161718package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world\n&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125;# 进入项目所在目录&gt; cd /path/to/myapp# 运行&gt; fresh# 浏览器访问http://localhost:8080 扩展原项目不需要做任何改动，只需要在原项目的目录下执行命令 fresh 即可。 经以上测试，推荐使用 fresh 来运行 Gin 项目。 相关链接 GitHub - codegangsta/gin: Live reload utility for Go web servers GitHub - pilu/fresh: Build and (re)start go web apps after saving/creating/deleting source files. GitHub - gin-gonic/gin: Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance – up to 40 times faster. If you need smashing performance, get yourself some Gin.]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang网站微框架Gin]]></title>
    <url>%2F2017%2F07%2F30%2Fgolang-web-framework-gin%2F</url>
    <content type="text"><![CDATA[Gin is a web framework written in Golang. 安装 Gin获取包： 1&gt; go get github.com/gin-gonic/gin 添加引用： 1import &quot;github.com/gin-gonic/gin&quot; Gin web 入门一个简单的示例12345678910111213141516171819202122232425package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; router := gin.Default() router.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world!&quot;) &#125;) //http://localhost:8081 postdata: name=tom router.POST(&quot;/&quot;, postHome) router.Run(&quot;:8081&quot;)&#125;func postHome(c *gin.Context) &#123; uName := c.PostForm(&quot;name&quot;) c.JSON(200, gin.H&#123; &quot;say&quot;: &quot;Hello &quot; + uName, &#125;)&#125; 请求方法名必须全部是大写字母1234567router.GET(&quot;/someGet&quot;, getting)router.POST(&quot;/somePost&quot;, posting)router.PUT(&quot;/somePut&quot;, putting)router.DELETE(&quot;/someDelete&quot;, deleting)router.PATCH(&quot;/somePatch&quot;, patching)router.HEAD(&quot;/someHead&quot;, head)router.OPTIONS(&quot;/someOptions&quot;, options) 获取路由参数通过 Context 的 Param 方法来获取： 12345678910111213141516171819...// http://localhost:8081/user/article/tommyrouter.GET(&quot;/user/:type/:name&quot;, getRouteStr)...func getRouteStr(c *gin.Context) &#123; ctype := c.Param(&quot;type&quot;) cname := c.Param(&quot;name&quot;) c.JSON(200, gin.H&#123; &quot;typeName&quot;: ctype, &quot;username&quot;: cname, &#125;)&#125;//result:&#123; &quot;typeName&quot;: &quot;article&quot;, &quot;username&quot;: &quot;tommy&quot;&#125; 获取url参数通过 DefaultQuery 或 Query 方法获取： Query(&#39;xxx&#39;) 如果没有相应值，默认为空字符串 DefaultQuery(&quot;xxx&quot;,&quot;defaultValue&quot;) 可设置默认值,string类型 1234567891011121314151617181920212223242526... router.GET(&quot;/user&quot;, getQueryStrs)...func getQueryStrs(c *gin.Context) &#123; name := c.Query(&quot;name&quot;) //如果没有相应值，默认为空字符串 age := c.DefaultQuery(&quot;age&quot;, &quot;0&quot;) //可设置默认值,string类型 c.JSON(200, gin.H&#123; &quot;name&quot;: name, &quot;age&quot;: age, &#125;)&#125;//result://http://localhost:8081/user?name=tom&amp;age=23&#123; &quot;age&quot;: &quot;23&quot;, &quot;name&quot;: &quot;tom&quot;&#125;//result2://http://localhost:8081/user?name=tom&#123; &quot;age&quot;: &quot;0&quot;, &quot;name&quot;: &quot;tom&quot;&#125; c.Request.URL.Query() 可获取所有url请求参数 map[] 集合： 1234567 //获取所有url请求参数 reqData := c.Request.URL.Query() fmt.Printf(&quot;[info] req url data is %s\n&quot;, reqData)//result://http://localhost:8080?id=3&amp;name=zhangsan&amp;address=beijing[info] req url data is map[name:[zhangsan] address:[beijing] id:[3]] 获取表单参数表单参数通过 PostForm 或 DefaultPostForm 方法获取： PostForm() DefaultPostForm(&quot;xxx&quot;,&quot;defaultValue&quot;) 12345678910111213141516171819 ... router.POST(&quot;/&quot;, getFormStr) ...func getFormStr(c *gin.Context) &#123; title := c.PostForm(&quot;title&quot;) cont := c.DefaultPostForm(&quot;cont&quot;, &quot;没有内容&quot;) c.JSON(200, gin.H&#123; &quot;title&quot;: title, &quot;cont&quot;: cont, &#125;)&#125;//result://http://localhost:8081 postData: title:这是一个标题&#123; &quot;cont&quot;: &quot;没有内容&quot;, &quot;title&quot;: &quot;这是一个标题&quot;&#125; c.Request.Body 获取所有 post body 数据： 1234567891011 //获取post body x, _ := ioutil.ReadAll(c.Request.Body) fmt.Printf(&quot;[info] %s&quot;, string(x))//result:// post body type :x-www-form-urlencoded (user=tom pwd=123)[info] user=tom&amp;pwd=123//result:// post body type: raw application/json[info] &#123;&quot;name&quot;:&quot;zhangfei&quot;,&quot;id&quot;:32&#125; go - gin/golang - Empty Req Body - Stack Overflow Print Request Body empty · Issue #401 · gin-gonic/gin · GitHub 获取所有 post data 数据 （map[] 类型） 1234567 c.Request.ParseForm() reqBodyData := c.Request.PostForm fmt.Printf(&quot;[info] req body data is %s \n&quot;, reqBodyData)//result:// post body type :x-www-form-urlencoded (user=tom pwd=123)[info] req body data is map[user:[tom] pwd:[123]] go - Gin Gonic array of values from PostForm - Stack Overflow 路由群组支持 一级 或 多级 分组的路由规则： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 ... //路由分组 articleGroup := router.Group(&quot;/article&quot;) &#123; articleGroup.GET(&quot;/one/:id&quot;, getArticleByid) articleGroup.GET(&quot;/list&quot;, getArticleList) &#125; //多级路由分组 apiGroup := router.Group(&quot;/api&quot;) apiv1Group := apiGroup.Group(&quot;/v1&quot;) &#123; apiv1Group.GET(&quot;/user&quot;, getApiV1User) &#125; apiv2Group := apiGroup.Group(&quot;/v2&quot;) &#123; apiv2Group.GET(&quot;/order&quot;, getApiV2Order) &#125; ...func getArticleByid(c *gin.Context) &#123; a_id := c.Param(&quot;id&quot;) c.String(200, a_id)&#125;//result://http://localhost:8081/article/one/33func getArticleList(c *gin.Context) &#123; c.JSON(200, gin.H&#123; &quot;a&quot;: &quot;1&quot;, &quot;b&quot;: &quot;2&quot;, &#125;)&#125;//result://http://localhost:8081/article/list&#123; &quot;a&quot;: &quot;1&quot;, &quot;b&quot;: &quot;2&quot;&#125;func getApiV1User(c *gin.Context) &#123; c.String(200, &quot;api/v1/user&quot;)&#125;//result://http://localhost:8081/api/v1/userapi/v1/userfunc getApiV2Order(c *gin.Context) &#123; c.String(200, &quot;api/v2/order&quot;)&#125;//result://http://localhost:8081/api/v2/orderapi/v2/order 数据绑定 Bind() BindJSON() 123456789101112131415161718192021222324252627282930 ... //绑定普通表单 (user=tom&amp;&amp;pwd=123) router.POST(&quot;/loginform&quot;, func(c *gin.Context) &#123; var form Login if c.Bind(&amp;form) == nil &#123; if form.User == &quot;tom&quot; &amp;&amp; form.Password == &quot;123&quot; &#123; c.JSON(200, gin.H&#123;&quot;status&quot;: &quot;form logined in&quot;&#125;) &#125; else &#123; c.JSON(201, gin.H&#123;&quot;status&quot;: &quot;form no login&quot;&#125;) &#125; &#125; &#125;) //绑定JSON (&#123;&quot;user&quot;:&quot;tom&quot;,&quot;pwd&quot;:&quot;123&quot;&#125;) Content-Type:application/json router.POST(&quot;/loginjson&quot;, func(c *gin.Context) &#123; var json Login if c.BindJSON(&amp;json) == nil &#123; if json.User == &quot;tom&quot; &amp;&amp; json.Password == &quot;123&quot; &#123; c.JSON(200, gin.H&#123;&quot;status&quot;: &quot;json logined in&quot;&#125;) &#125; else &#123; c.JSON(201, gin.H&#123;&quot;status&quot;: &quot;json no login&quot;&#125;) &#125; &#125; &#125;) ...type Login struct &#123; User string `form:&quot;user&quot; json:&quot;user&quot;` Password string `form:&quot;pwd&quot; json:&quot;pwd&quot;`&#125; POST上传文件12345678910111213141516...//表单上传文件 http://localhost:8081/upload // key:upload value: file....//result://&#123; //&quot;filename&quot;: &quot;1009e3ee4bc0919e11d32e00ccf55cdf.jpg&quot;//&#125;router.POST(&quot;/upload&quot;, func(c *gin.Context) &#123; _, header, _ := c.Request.FormFile(&quot;upload&quot;) filename := header.Filename c.JSON(200, gin.H&#123; &quot;filename&quot;: filename, &#125;)&#125;)... 根据客户端的请求类型，返回对应的响应格式1234567891011121314...router.GET(&quot;/getdata&quot;, func(c *gin.Context) &#123; contentType := c.Request.Header.Get(&quot;Content-Type&quot;) switch contentType &#123; case &quot;application/json&quot;: c.JSON(200, gin.H&#123;&quot;user&quot;: &quot;张飞&quot;, &quot;address&quot;: &quot;长坂坡&quot;&#125;) case &quot;application/xml&quot;: c.XML(200, gin.H&#123;&quot;user&quot;: &quot;张飞&quot;, &quot;address&quot;: &quot;长坂坡&quot;&#125;) case &quot;application/x-www-form-urlencoded&quot;: c.String(200, &quot;张飞 长坂坡&quot;) &#125;&#125;)... 字符串响应1234import &quot;net/http&quot;c.String(200, &quot;some string&quot;)c.String(http.StatusOK, &quot;some string&quot;) JSON/XML/YAML等格式响应12345...c.JSON(http.StatusOK, msg)c.XML(http.StatusOK, msg)c.YAML(http.StatusOK, msg)... 视图响应12345678910111213141516171819202122232425262728293031323334 ... //加载模板 router.LoadHTMLGlob(&quot;templates/*&quot;) // router.LoadHTMLFiles(&quot;templates/index.html&quot;,&quot;templates/article.html&quot;) router.GET(&quot;/&quot;, func(c *gin.Context) &#123; //根据完整文件名渲染模板，并传递参数 c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;Hello World!&quot;, &#125;) &#125;) ...//index.html:&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;//result:&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt;Hello World!&lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; 加载多层模板路径经测试：如果是多层级的模板文件，要在模板文件中使用1&#123;&#123;define xxx&#125;&#125; &#123;&#123;end&#125;&#125; 将该模板作为嵌套模板： 12345678910111213141516//加载模板router.LoadHTMLGlob(&quot;templates/**/*&quot;)// router.LoadHTMLFiles(&quot;templates/index.html&quot;,&quot;templates/article.html&quot;)router.GET(&quot;/articles/index&quot;, func(c *gin.Context) &#123; //根据完整文件名渲染模板，并传递参数 c.HTML(200, &quot;articles/index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;Article index!&quot;, &#125;)&#125;)router.GET(&quot;/users/index&quot;, func(c *gin.Context) &#123; c.HTML(200, &quot;/users/index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;User index!&quot;, &#125;)&#125;) templates/articles/index.html: 1234567891011&#123;&#123;define &quot;articles/index.html&quot;&#125;&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;&#123;&#123;end&#125;&#125; templates/users/index.html: 1234567891011&#123;&#123;define &quot;users/index.html&quot;&#125;&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;&#123;&#123;end&#125;&#125; 提供静态文件 Static() StaticFS() StatucFile() 示例: 123456789func main() &#123; router := gin.Default() router.Static(&quot;/assets&quot;, &quot;./assets&quot;) router.StaticFS(&quot;/more_static&quot;, http.Dir(&quot;my_file_system&quot;)) router.StaticFile(&quot;/favicon.ico&quot;, &quot;./resources/favicon.ico&quot;) // Listen and serve on 0.0.0.0:8080 router.Run(&quot;:8080&quot;)&#125; 待详细研究。 重定向支持 内部 和 外部 地址的重定向 123456789101112131415...//跳转到外部地址router.GET(&quot;/abc&quot;, func(c *gin.Context) &#123; c.Redirect(302, &quot;http://www.baidu.com&quot;)&#125;)//跳转到内部地址router.GET(&quot;def&quot;, func(c *gin.Context) &#123; c.Redirect(302, &quot;/home&quot;)&#125;)router.GET(&quot;/home&quot;, func(c *gin.Context) &#123; c.String(200, &quot;home page&quot;)&#125;)... 自定义中间件及中间件的使用方式12345678910111213141516171819202122232425262728293031323334353637383940414243 ...func main() &#123; // router := gin.Default() router := gin.New() //全局中间件 router.Use(MyLogger()) router.GET(&quot;/test&quot;, func(c *gin.Context) &#123; example := c.MustGet(&quot;example&quot;).(string) c.String(200, example) &#125;) //单路由中间件 router.GET(&quot;/abc&quot;,MyMiddelware(),getAbc) //群组路由中间件 aGroup:=router.Group(&quot;/&quot;,MyMiddelware()) //中间件可以同时添加多个 aGroup:=router.Group(&quot;/&quot;,MyMiddelware(),My2Middelware(),My3Middelware()) //或者：群组路由中间件 bGroup:=router.Group(&quot;/&quot;) bGroup.Use(MyMiddelware()) &#123; bGroup.GET(&quot;/v1&quot;,getV1) &#125; router.Run(&quot;:8081&quot;)&#125;func MyLogger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; c.Set(&quot;example&quot;, &quot;123465&quot;) c.Next() &#125;&#125; 异步处理goroutine 中只能使用只读的上下文 c.Copy() 1234567891011121314151617181920...//异步router.GET(&quot;/async&quot;, func(c *gin.Context) &#123; // goroutine 中只能使用只读的上下文 c.Copy() cCp := c.Copy() go func() &#123; time.Sleep(5 * time.Second) //需要使用只读上下文 log.Println(&quot;Done! in path &quot; + cCp.Request.URL.Path) &#125;()&#125;)//同步router.GET(&quot;/sync&quot;, func(c *gin.Context) &#123; time.Sleep(5 * time.Second) //可以使用原始上下文 log.Println(&quot;Done! in path &quot; + c.Request.URL.Path)&#125;)... 初始化不带中间件和带有默认中间件的路由 r := gin.New() 创建不带中间件的路由 r := gin.Default() 创建带有默认中间件的路由:日志与恢复中间件 Cookie http://www.grdtechs.com/2016/03/29/gin-setcookie/ 其他示例获取所有请求参数 获取所有URL请求参数 12reqData := c.Request.URL.Query()fmt.Printf(&quot;[info] req url data is %s\n&quot;, reqData) 获取所有Body请求参数 123c.Request.ParseForm()reqBodyData := c.Request.PostFormfmt.Printf(&quot;[info] req body data is %s \n&quot;, reqBodyData) 获取请求头信息123456789// 获取请求头Header中的 key sign timestamptoken := c.Request.Header.Get(&quot;X-Auth-Token&quot;)key := c.Request.Header.Get(&quot;X-Auth-Key&quot;)timestamp := c.Request.Header.Get(&quot;X-Auth-TimeStamp&quot;)fmt.Printf(&quot;[info] key is %s ,timestamp is %s\n&quot;, key, timestamp)//获取Post put请求模式下的Content-lengthconlength := c.Request.Header.Get(&quot;Content-Length&quot;)fmt.Printf(&quot;[info] Content-Length is %s\n&quot;, conlength) 获取请求 Method Host URL ContentLength1234567//判断请求Method// GET POST PUT DELETE OPTIONSfmt.Println(&quot;[info]&quot;, c.Request.Method)fmt.Println(&quot;[info]&quot;, c.Request.Host) // localhost:8080fmt.Println(&quot;[info]&quot;, c.Request.URL) ///?id=3&amp;name=zhangsan&amp;address=beijing//获取请求头中数据长度 ContentLengthfmt.Println(&quot;[info]&quot;, c.Request.ContentLength) // POST for 16 or GET for 0 CORS 跨域请求 (未测试)123456789101112131415 // CORS middleware g.Use(CORSMiddleware())func CORSMiddleware() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; c.Writer.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;) c.Writer.Header().Set(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization&quot;) if c.Request.Method == &quot;OPTIONS&quot; &#123; c.Abort(200) return &#125; c.Next() &#125;&#125; Json not work · Issue #149 · gin-gonic/gin · GitHub 定义 struct 时，参数的首字母要大写才能被访问到12345type ReturnMsg struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125; Go json.Marshal(struct) returns &quot;{}&quot; - Stack Overflow 输出一个struct对象123456789 ... c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) ...type ReturnMsg struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125; gin中间件阻止请求继续访问c.Abort() 1234567891011121314151617token := c.Request.Header.Get(&quot;X-Auth-Token&quot;)key := c.Request.Header.Get(&quot;X-Auth-Key&quot;)timestamp := c.Request.Header.Get(&quot;X-Auth-TimeStamp&quot;)//判断请求头中是否含有必须的三个参数if token == &quot;&quot; || key == &quot;&quot; || timestamp == &quot;&quot; &#123; //经测试，c.Abort() 在前在后均可 // c.Abort() // c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) c.Abort() return //一定要加return&#125;c.Next() go - Failed to Abort() context - gin - Stack Overflow gin安装报错安装 gin 包时可能会报 x/net 相关错误，可以先下载该必须包： 1234567$ mkdir -p $GOPATH/src/golang.org/x/$ cd $GOPATH/src/golang.org/x/$ git clone https://github.com/golang/net.git net$ go install net Gin 安装报错 - 简书 golang中相关易错点时间戳转换12345678910111213141516package mainimport ( &quot;fmt&quot; &quot;time&quot; &quot;strconv&quot;)func main() &#123; i, err := strconv.ParseInt(&quot;1405544146&quot;, 10, 64) if err != nil &#123; panic(err) &#125; tm := time.Unix(i, 0) fmt.Println(tm)&#125; date - How to parse unix timestamp in golang - Stack Overflow 什么类型可以声明为常量及在func外部声明变量时不能使用:=数字类型，字符串或布尔类型可以声明为 const 常量；array ,slice 或 map 不能声明为常量。 map类型不能声明为常量: 12345678const myString = &quot;hello&quot;const pi = 3.14 // untyped constantconst life int = 42 // typed constant (can use only with ints)const ( First = 1 Second = 2 Third = 4) 在函数func外部声明变量，要用完整模式： 1234var romanNumeralDict = map[int]string&#123; 1:&quot;a&quot;, 2:&quot;b&quot;,&#125; 在函数func内部声明变量，可以使用缩写模式： 123romanNumeralDict := map[int]string&#123;...&#125; go - How to declare constant map in golang - Stack Overflow 判断map中是否存在某值，可以写在一行123456// 查找键值是否存在if v, ok := m1[&quot;a&quot;]; ok &#123; fmt.Println(v)&#125; else &#123; fmt.Println(&quot;Key Not Found&quot;)&#125; map排序map 是无序的: 1234567891011121314151617181920212223242526272829import ( &quot;fmt&quot; &quot;sort&quot;)func main() &#123; // fmt.Printf(&quot;Hello,是按揭&quot;) // fmt.Printf(&quot;ni好呀&quot;) m := map[string]string&#123; &quot;sign&quot;: &quot;1399dke&quot;, &quot;user&quot;: &quot;zhangsan&quot;, &quot;timestamp&quot;: &quot;36644747373&quot;, &quot;id&quot;: &quot;3&quot;, &#125; fmt.Println(m) var keys []string for k := range m &#123; // fmt.Println(k) keys = append(keys, k) &#125; sort.Strings(keys) // fmt.Println(keys) for _, k := range keys &#123; fmt.Println(&quot;key:&quot;, k, &quot;Value :&quot;, m[k]) &#125;&#125; go - sort golang map values by keys - Stack Overflow for rangefor range 可以遍历 slice 或 map。并通过两个参数(index和value)，分别获取到slice或者map中某个元素所在的index以及其值。 在Go的 for…range 循环中，Go始终使用值拷贝的方式代替被遍历的元素本身。 1234for index, value := range mySlice &#123; fmt.Println(&quot;index: &quot; + index) fmt.Println(&quot;value: &quot; + value)&#125; go语言string、int、int64互相转换12345678#string到intint,err:=strconv.Atoi(string)#string到int64int64, err := strconv.ParseInt(string, 10, 64)#int到stringstring:=strconv.Itoa(int)#int64到stringstring:=strconv.FormatInt(int64,10) http.Request123func getURL(w http.ResponseWriter, r *http.Request) &#123; url := r.URL.String()&#125; How to convert *url.URL to string in GO, Google App Engine - Stack Overflow 中文 url 编码问题12345678910import &quot;net/url&quot; //url编码 str := &quot;中文-_.&quot; unstr := &quot;%2f&quot; fmt.Printf(&quot;url.QueryEscape:%s&quot;, url.QueryEscape(str)) fmt.Println() s, _ := url.QueryUnescape(unstr) fmt.Printf(&quot;url.QueryUnescape:%s&quot;, s) fmt.Println() go 中url编码和字符转码(类似php中的urlencode 和htmlspecialchars): 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;html&quot; &quot;net/url&quot; &quot;testing&quot;)func Test_Escape(t *testing.T) &#123;//url编码 str := &quot;中文-_.&quot; unstr := &quot;%2f&quot; fmt.Printf(&quot;url.QueryEscape:%s&quot;, url.QueryEscape(str)) fmt.Println() s, _ := url.QueryUnescape(unstr) fmt.Printf(&quot;url.QueryUnescape:%s&quot;, s) fmt.Println()//字符转码 hstr := &quot;&lt;&quot; hunstr := &quot;&amp;lt&quot; fmt.Printf(&quot;html.EscapeString:%s&quot;, html.EscapeString(hstr)) fmt.Println() fmt.Printf(&quot;html.UnescapeString:%s&quot;, html.UnescapeString(hunstr)) fmt.Println()&#125; go 中url编码和字符转码(类似php中的urlencode 和htmlspecialchars) - coolaf golang中字符串拼接一种说法： 如果是少量小文本拼接，用 “+” 就好如果是大量小文本拼接，用 strings.Join如果是大量大文本拼接，用 bytes.Buffer 字符串连接哪一种方式最高效 - Go 技术社区 - golang golang 高效字符串拼接 - Go语言中文网 - Golang中文社区 go语言中高效字符串拼接 strings 包 Go语言开发-字符串-strings包 | Plum Wine Blog - 青梅酒博客 获取字符串的MD5值12345678910import ( &quot;crypto/md5&quot; &quot;encoding/hex&quot;)func GetMD5Hash(text string) string &#123; hasher := md5.New() hasher.Write([]byte(text)) return hex.EncodeToString(hasher.Sum(nil))&#125; md5 example 相关链接 GitHub - gin-gonic/gin: Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance – up to 40 times faster. If you need smashing performance, get yourself some Gin. Gin Web Framework gin-doc-cn/README.md at master · ningskyer/gin-doc-cn · GitHub Go语言web框架 gin | shanshanpt Gin 安装报错 - 简书 Building Go Web Applications and Microservices Using Gin - Semaphore Build a RESTful API Server with Golang and MySQL - Jinchuriki Golang 微框架 Gin 简介 - 简书 How to create a basic Restful API in Go – Etienne Rouzeaud – Medium Gin middleware examples - Dan Sosedoff REST Microservices in Go with Gin Go: Templating with the Gin Web Framework 相关问题 关于数据绑定 how to bind query string? · Issue #742 · gin-gonic/gin · GitHub 关于模板文件 go - How to make templates work with gin framework? - Stack Overflow]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs关于使用SSH]]></title>
    <url>%2F2017%2F07%2F21%2Fdocker-ubuntu-gogs-ssh%2F</url>
    <content type="text"><![CDATA[记录在Docker容器中运行Gogs时，使用SSH操作遇到的git密码问题。 SSH key passphrases在本地电脑上(我这里是Windows系统)创建 SSH key 时，会要求你为key设置一个密码： 123456789λ ssh-keygen -t rsa -C &quot;xxxxx@qq.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/You/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/You/.ssh/id_rsa.Your public key has been saved in /c/Users/You/.ssh/id_rsa.pub.The key fingerprint is:... 即其中的： 12Enter passphrase (empty for no passphrase):Enter same passphrase again: 一般情况下我们可以选择直接回车即不设置密码。 如果没有设置key的密码，我们在通过SSH提交代码时，可以直接操作。如果设置了key的密码，那我们在每次 pull 或 push 时都会要求你输入key的密码： 12$ git pullEnter passphrase for key &apos;/c/Users/You/.ssh/id_rsa&apos;: Docker-Ubuntu-Gogs容器使用SSH提交时要求输入git密码在使用SSH获取或提交代码时，偶尔会遇到要求输入 git 密码的情况： 123456789101112$ git clone ssh://git@gogit.itfanr.cc/haha/wohaha.gitCloning into &apos;wohaha&apos;...git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied (publickey,password).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 或者： 12345678910$ git pullgit@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 但是我们通过Docker创建的gogs容器中，并没有为git账户设置密码，所以这里无论输入什么都是错误的。 通过查看 Issues · gogits/gogs · GitHub 中相关的 issues 可以了解到，但凡是要求输入git密码的问题，十有八九是 关于 .ssh/authorize_keys 文件的权限 问题。 gogs的文档中要求： .ssh/ 目录权限为 0700 .ssh/authorize_keys 文件的权限为 0600 相关的操作命令为： 12$ chmod 0700 /home/git/.ssh$ chmod 0600 /home/git/.ssh/* 方法一登陆gogs站点的管理员账户，选择 管理面板 访问 /admin 页面。在 管理员操作 区域选择 重新生成 &#39;.ssh/authorized_keys&#39; 文件（警告：不是 Gogs 的密钥也会被删除） 点击 执行 按钮。 然后再次尝试看是否能够成功操作。 方法二如果 方法一 的操作无效，那么我们需要登陆该gogs容器所在的服务器来进入如下操作： 进入该gogs容器，然后删除 .ssh/authorized_keys 文件 。 重复方法一的操作：登陆管理员账户，选择 管理面板 – 管理员操作 – 点击 重新生成 &#39;.ssh/authorized_keys&#39; 文件（警告：不是 Gogs 的密钥也会被删除） 后的 执行 按钮。 然后再次尝试看是否能够成功操作。 我的操作记录： 12345678910111213141516$ docker exec -it gogs /bin/bashroot@564c5628c7e9:/home/git/gogs# cd ..root@564c5628c7e9:/home/git# cd .ssh/root@564c5628c7e9:/home/git/.ssh# lsauthorized_keysroot@564c5628c7e9:/home/git/.ssh# rm authorized_keys root@564c5628c7e9:/home/git/.ssh# ls# 此时在管理后台重新生成 authorized_keysroot@564c5628c7e9:/home/git/.ssh# lsauthorized_keysroot@564c5628c7e9:/home/git/.ssh# ls -altotal 12drwx------ 2 git git 4096 Jul 21 14:20 .drwxr-xr-x 6 git git 4096 Jul 21 11:32 ..-rw------- 1 git git 549 Jul 21 14:20 authorized_keys 我在 git push 时遇到要求输入git密码的问题时，先将 authorized_keys 文件删除，然后重新生成，这样操作后就能正常获取和提交了。 相关参考 ssh 的链接地址不可以使用 · Issue #545 · gogits/gogs · GitHub]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Gogs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang连接MongoDB数据库]]></title>
    <url>%2F2017%2F06%2F28%2Fgolang-connect-to-mongodb%2F</url>
    <content type="text"><![CDATA[目前go支持MongoDB最好的驱动就是mgo。 下载与引用123go get gopkg.in/mgo.v2import &quot;gopkg.in/mgo.v2&quot; 123go get labix.org/v2/mgoimport &quot;labix.org/v2/mgo&quot; 安装时发现，地址 labix.org/v2/mgo 中的mgo版本中有些方法不全，而地址 gopkg.in/mgo.v2中的方法是全的，但是该地址下载超时而失败，必须翻墙才可以访问。如 labix.org/v2/mgo 中就没有 mongo, err := mgo.ParseURL(MongoDBUrl) 的 ParseURL() 方法。 如果无法翻墙，还可以从 github 下载： 因为我们要使用 mgo 的 v2 版本，所以需要迁出 branch:v2 分支，不能直接使用 master 分支。 在 go get 命令后添加 -d 参数可以只下载而不会执行安装命令。 操作步骤为： 执行命令 go get -d github.com/go-mgo/mgo 找到上面 clone 的目录，迁出分支 v2 再次运行 go get 命令，这时会在迁出的分支上执行命令 12345go get -d github.com/go-mgo/mgogit checkout v2go get github.com/go-mgo/mgo mgo - Rich MongoDB driver for Go mgo.v2 - gopkg.in/mgo.v2 git - How to do &quot;go get&quot; on a specific tag of a github repository - Stack Overflow 安装bzr工具Bazaar是一款开源的分布式版本控制工具。 安装mgo之前，需要先安装 bzr 工具，否则直接执行或报错： 123&gt; go get labix.org/v2/mgogo: missing Bazaar command. See https://golang.org/s/gogetcmdpackage labix.org/v2/mgo: exec: &quot;bzr&quot;: executable file not found in %PATH% Win从网址 http://bazaar.canonical.com/en/ 下载安装包，选择 Standalone版本或其他版本。 Ubuntu sudo apt-get install bzr 多平台系统下如何安装Bazzar工具 连接字符串1234MONGODB_URL=&quot;mongodb://user:pass@server.compose.io/db_name&quot;mongodb://localhost:27017/articles_demo_devmongodb://myuser:mypass@localhost:40001,otherhost:40001/mydb 或者： 12345session, err := mgo.Dial(&quot;&quot;) session, err := mgo.Dial(&quot;localhost&quot;) session, err := mgo.Dial(&quot;127.0.0.1&quot;) session, err := mgo.Dial(&quot;localhost:27017&quot;)session, err := mgo.Dial(&quot;127.0.0.1:27017&quot;) 创建连接通过Session.DB()来切换相应的数据库 1db := session.DB(&quot;xtest&quot;) //数据库名称 通过Database.C()方法切换集合（Collection）： 1collection := db.C(&quot;xtest&quot;) // 集合名称 或直接一步： 1c := session.DB(&quot;xtest&quot;).C(&quot;xtest&quot;) 查询通过func (c Collection) Find(query interface{}) Query来进行查询通过Query.All()可以获得所有结果通过Query.One()可以获得一个结果条件用 bson.M{key: value} ，注意key必须用MongoDB中的字段名，而不是struct的字段名。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package mainimport ( &quot;fmt&quot; &quot;labix.org/v2/mgo&quot; &quot;labix.org/v2/mgo/bson&quot;)const ( MONGODB_URL = &quot;127.0.0.1:27017&quot;)func main() &#123; //创建连接 session, err := mgo.Dial(MONGODB_URL) if err != nil &#123; panic(err) &#125; defer session.Close() session.SetMode(mgo.Monotonic, true) // db := session.DB(&quot;xtest&quot;) //数据库名称 // collection := db.C(&quot;xtest&quot;) // 集合名称 c := session.DB(&quot;xtest&quot;).C(&quot;xtest&quot;) // //插入数据 // err = c.Insert(&amp;Person&#123;&quot;Tommy&quot;, &quot;123456&quot;&#125;, &amp;Person&#123;&quot;Hanleilei&quot;, &quot;98765&quot;&#125;, // &amp;Person&#123;&quot;喜洋洋&quot;, &quot;98765&quot;&#125;, &amp;Person&#123;&quot;灰太狼&quot;, &quot;46577&quot;&#125;, // ) // if err != nil &#123; // panic(err) // &#125; // //查询并赋值 Find().One() // result := Person&#123;&#125; // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;result) // if err != nil &#123; // panic(err) // &#125; // //输出 // fmt.Println(&quot;Phone &quot;, result.Phone) // //集合中元素数量 Count() // countNum, err := c.Count() // fmt.Println(&quot;obj numbers &quot;, countNum) // //查询多条数据 Find().Iter() // var onep = Person&#123;&#125; // iter := c.Find(nil).Iter() // for iter.Next(&amp;onep) &#123; // fmt.Println(&quot;姓名 &quot;, onep.Name) // &#125; // //查询多条数据 Find().All() // var personAll []Person // err = c.Find(nil).All(&amp;personAll) // for i := 0; i &lt; len(personAll); i++ &#123; // fmt.Println(&quot;Person &quot;, personAll[i].Name, personAll[i].Phone) // &#125; // //更新数据 Update() // abc := Person&#123;&#125; // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;abc) // fmt.Println(&quot;Tommy phone is &quot;, abc.Phone) // err = c.Update(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;, bson.M&#123;&quot;$set&quot;: bson.M&#123;&quot;phone&quot;: &quot;10086&quot;&#125;&#125;) // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;abc) // fmt.Println(&quot;Tommy phone is &quot;, abc.Phone) // //删除数据 Remove() // fmt.Println(c.Count()) // err = c.Remove(bson.M&#123;&quot;phone&quot;: &quot;46577&quot;&#125;) // fmt.Println(c.Count()) fmt.Println(&quot;end&quot;)&#125;type Person struct &#123; Name string `bson:&quot;name&quot;` Phone string `bson:&quot;phone&quot;`&#125; 相关 GitHub - go-mgo/mgo: The MongoDB driver for Go. See http://labix.org/mgo for details. golang使用mgo连接MongoDB]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进京证办理]]></title>
    <url>%2F2017%2F06%2F22%2Fforeign-car-to-beijing%2F</url>
    <content type="text"><![CDATA[北京市公安局相关规定 适用范围：进入北京市六环路（不含）以内行驶的外埠车辆，以及前往昌平、怀柔、延庆城关镇行驶的外埠车辆，需办理进京通行证。 办理地点：本市任意进京检查站或办证处 北京市公安局公安交通管理局 办理时间：7*24小时 周末及法定节假日不休 携带资料： 驾驶人身份证 驾驶人驾驶证 车辆行驶证 交通事故责任强制保险凭证 安全技术检验合格标志 经北京市环保部门确认的车辆符合环保要求的凭证 有效期：进京通行证有效期为7天，可延期一次。 我是如何办理实体进京证的 驾驶人身份证 驾驶人驾驶证 车辆行驶证 我第一次办理实体进京证是在京港澳高速的兴礼检查站办理的 (2017-6-11)： 携带以上三个证件先用车辆行驶证去办理环保证明，然后拿着环保证明和三个证件去另一个窗口办理进京证。那里有指示牌可参考。 注意要仔细核对环保证明或进京证上的信息是否正确。 不需要保险单或其他材料。 实体进京证免费办理。 电子进京证–北京交警app优势 可提前1-4天在线申请办理进京通行证 电子进京证的效力与实体进京证相同，其有效期为2至7天 电子进京证所需证件、材料 车辆型号（见行驶证） 车辆发动机号（见行驶证） 进京车辆行驶证正面照片 车辆正面照片（需露出车辆号牌） 车主驾驶证正面照片 车主手持身份证的照片（必须是车主本人） 号牌类型 机动车类型 机动车号牌 车主姓名 车主驾驶证号（同身份证号） 进京日期（只能从后一天开始的7天内） 进京时长(可选2-7天) 进京路口（例如京津高速） 驾驶员信息 电子进京证注意事项 目前只允许外地小客车网上办理电子进京证，其它车辆仍需到检查站办证窗口办理。 电子进京证与实体进京证在同一时段内无法重复办理。 电子进京证无法在城区安监窗口续办。 目前，电子进京证一旦申请成功，无法更改日期。 注意事项 再次办理进京证的流程和所需的材料与初次办理相同。 在办理进京证之前，您需要将外地号牌车辆之前在北京产生的所有交通违法都处理完毕。 相关参考 外地车进京注意事项 关于驾驶证换新后因为我的驾照考的比较早，初次申请的驾照在6年后要换新。在换领到新的驾照之后申请进京证时要注意： 在旧驾照到期截止日期之前，申请进京证仍需要使用旧驾照的照片来申请。 举个例子来说： 比如你的驾照在 2018年6月1日 到期，规定是在驾照到期前的90天内都可申请换领新驾照。在90天之内，比如你在 2018年的5月1日 就已经更换了新驾照。那么在 5月1日到6月1日 这段时间内，你是不能使用新驾照的照片来申请进京证的。 当你用新驾照的照片去申请时，北京交警App 给出的错误提示信息为 “系统审核失败，请重新提交信息申请办理。 审核失败” 。 只有当你的旧版驾照过了到期日期之后，才能使用换新后的驾照来申请。 以上是我在换领新驾照之后在申请进京证时遇到的一个很迷惑的地方，特记录在此。 更新记录 2017-06-22 Created 2018-07-18 添加更换新驾驶证后申请进京证时的注意事项]]></content>
      <tags>
        <tag>人在帝都</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang实现http请求及代理设置]]></title>
    <url>%2F2017%2F06%2F15%2FGolang-implements-HTTP-request-and-proxy-settings%2F</url>
    <content type="text"><![CDATA[主要探究 1. 使用代理请求 2. 跳过https不安全验证 3. 自定义请求头User-Agent的实现 主要研究的技术点 使用代理请求 跳过https不安全验证 自定义请求头 User-Agent 静态数据请求并设置代理实例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( &quot;crypto/tls&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;net/http&quot; &quot;net/url&quot; &quot;time&quot;)func First() &#123; /* 1. 普通请求 */ webUrl := &quot;http://ip.gs/&quot; resp, err := http.Get(webUrl) if err != nil &#123; fmt.Println(err) return &#125; // if resp.StatusCode == http.StatusOK &#123; // fmt.Println(resp.StatusCode) // &#125; time.Sleep(time.Second * 3) defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func Second(webUrl, proxyUrl string) &#123; /* 1. 代理请求 2. 跳过https不安全验证 */ // webUrl := &quot;http://ip.gs/&quot; // proxyUrl := &quot;http://115.215.71.12:808&quot; proxy, _ := url.Parse(proxyUrl) tr := &amp;http.Transport&#123; Proxy: http.ProxyURL(proxy), TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: true&#125;, &#125; client := &amp;http.Client&#123; Transport: tr, Timeout: time.Second * 5, //超时时间 &#125; resp, err := client.Get(webUrl) if err != nil &#123; fmt.Println(&quot;出错了&quot;, err) return &#125; defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func Third(webUrl, proxyUrl string) &#123; /* 1. 代理请求 2. 跳过https不安全验证 3. 自定义请求头 User-Agent */ // webUrl := &quot;http://ip.gs/&quot; // proxyUrl := &quot;http://171.215.227.125:9000&quot; request, _ := http.NewRequest(&quot;GET&quot;, webUrl, nil) request.Header.Set(&quot;Connection&quot;, &quot;keep-alive&quot;) request.Header.Set(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot;) proxy, _ := url.Parse(proxyUrl) tr := &amp;http.Transport&#123; Proxy: http.ProxyURL(proxy), TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: true&#125;, &#125; client := &amp;http.Client&#123; Transport: tr, Timeout: time.Second * 5, //超时时间 &#125; resp, err := client.Do(request) if err != nil &#123; fmt.Println(&quot;出错了&quot;, err) return &#125; defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/user-agent&quot; //&quot;http://ip.gs/&quot; proxyUrl := &quot;http://119.5.0.75:808&quot; Second(webUrl, proxyUrl) // Third(webUrl, proxyUrl)&#125; 相关参考 Mocking a HTTP access with http.Transport in Golang - oinume journal Go http访问使用代理 GO HTTP client客户端使用 - 海运的博客 Making Tor HTTP Requests with Go | DevDungeon go - golang: How to do a https request with proxy - Stack Overflow go - Set UserAgent in http request - Stack Overflow 动态数据请求并设置代理动态数据请求使用golang调用phantomjs来请求网页数据内容实现。 通过命令参数方式： 1phantomjs [options] somescript.js [arg1 [arg2 [...]]] 代理相关的配置参数： --load-images=[true|false] (default is true) --proxy=address:port (eg --proxy=192.168.1.42:8080) --proxy-type=[http|socks5|none] (default is http) --proxy-auth (eg --proxy-auth=username:password) 其他常用配置参数： --load-images=[yes|no] Load all inlined images (default is ‘yes’). --load-plugins=[yes|no] Load all plugins (i.e. ‘Flash’, ‘Silverlight’, …) (default is ‘no’). --proxy=address:port Set the network proxy. --disk-cache=[yes|no] Enable disk cache (at desktop services cache storage location, default is ‘no’). --ignore-ssl-errors=[yes|no] Ignore SSL errors (i.e. expired or self-signed certificate errors). 也可以通过配置文件方式来设置： 1phantomjs --config=/path/to/config.json somescript.js [arg1 [...]] 常用配置相关参考 Command Line Interface | PhantomJS Proxy Auth In Phantomjs &middot; David Blooman 实例代码 经过测试，发现： phantomjs --proxy=address:port somescript.js [args] 这种方式无法执行成功。 经过测试，发现：在 somescript.js 中设置 page.setProxy(&quot;http://119.5.0.75:808/&quot;); 这种方式也无效。 经过测试，发现：在 somescript.js 中设置 phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &#39;manual&#39;, &#39;&#39;, &#39;&#39;); 这种方式可行。 不使用代理的动态数据请求dynamicproxy.go: 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)func First(webUrl, jsFileName string) &#123; cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) out, err := cmd.Output() if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(out))&#125;func Second(webUrl, jsFileName string) &#123; // cmd := exec.Command(&quot;phantomjs.exe&quot;, &quot;test.js&quot;, &quot;https://www.cnblogs.com/&quot;) cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) stdout, err := cmd.StdoutPipe() if err != nil &#123; fmt.Println(err) &#125; cmd.Start() content, err := ioutil.ReadAll(stdout) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(content))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/ip&quot; //&quot;http://httpbin.org/ip&quot; // &quot;http://ip.gs/&quot; // &quot;http://httpbin.org/user-agent&quot; jsfileName := &quot;somescript.js&quot; First(webUrl, jsfileName) // Second(webUrl, jsfileName)&#125; somescript.js: 123456789101112131415161718var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);url=system.args[1];page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; console.log(&apos;Loading &apos;+system.args[1]); if (status==&quot;success&quot;) &#123; // page.render(&apos;a.png&apos;); //网页截屏 system.stdout.writeLine(page.content); // 获取网页内容 // system.stdout.writeLine(page.title); // console.log(page.plainText); // 文本内容 // console.log(page.title); // 网页标题 &#125;else&#123; system.stdout.writeLine(&quot;request error&quot;); &#125;; phantom.exit();&#125;); 使用http代理的动态数据请求dynamicproxy.go: 1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)func Third(webUrl, jsFileName,proxyHost,proxyPort string) &#123; // cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName,proxyHost,proxyPort, webUrl) out, err := cmd.Output() if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(out))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/ip&quot; //&quot;http://httpbin.org/ip&quot; // &quot;http://ip.gs/&quot; // &quot;http://httpbin.org/user-agent&quot; jsfileName := &quot;somescript.js&quot; Third(webUrl, jsfileName,&quot;139.224.237.33&quot;, &quot;8888&quot;)&#125; somescript.js: 123456789101112131415161718192021222324252627var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);if (system.args.length&lt;4) &#123; system.stdout.writeLine(&quot;somescript.js &lt;proxyHost&gt; &lt;proxyPort&gt; &lt;URL&gt;&quot;); phantom.exit(1);&#125;else&#123; host=system.args[1]; port=system.args[2]; url = system.args[3];// page.setProxy(&quot;http://119.5.0.75:808/&quot;);//这样设置请求失败// phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &apos;manual&apos;, &apos;&apos;, &apos;&apos;);//这样设置可以phantom.setProxy(host, port, &apos;manual&apos;, &apos;&apos;, &apos;&apos;);page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; if (status==&quot;success&quot;) &#123; system.stdout.writeLine(page.content); // 获取网页内容 &#125;else&#123; console.log(status); system.stdout.writeLine(&quot;error&quot;); &#125;; phantom.exit();&#125;);&#125; 说明：phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &#39;manual&#39;, &#39;&#39;, &#39;&#39;); 参数1为代理host;参数2为代理port;参数3可以保持默认定值manual,参数4为代理类型http socket5等可为空;参数5不知道为空。 忽略https安全验证的动态数据请求 暂时只找到一种方法，直接请求https网址不使用代理能够请求成功。 即忽略https安全验证，又使用代理经测试请求失败。 直接在命令窗口中执行可以，通过golang调用请求失败。 使用参数：--ignore-ssl-errors=true --ssl-protocol=any 设置。 如下方式执行成功，示例代码： 1phantomjs.exe --ignore-ssl-errors=true --ssl-protocol=any test.js https://kyfw.12306.cn/otn/ test.js: 1234567891011121314var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);url=system.args[1];page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; console.log(&apos;Loading &apos;+system.args[1]); if (status==&quot;success&quot;) &#123; system.stdout.writeLine(page.content); // 获取网页内容 &#125;else&#123; console.log(&quot;request error&quot;); &#125;; phantom.exit();&#125;); 相关参考 –ignore-ssl-errors not working · Issue #12181 · ariya/phantomjs · GitHub phantomjs · GitHub phantomjs/examples at master · ariya/phantomjs · GitHub]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>数据抓取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从0到1学Golang之基础--Go 数组]]></title>
    <url>%2F2017%2F05%2F24%2Flearn-golang-from-0-to-1-of-go-array%2F</url>
    <content type="text"><![CDATA[《Go In Action》 中文版 《Go语言实战》 读书笔记 内部实现数组是切片和映射的基础数据结构。 在Go语言中，数组是长度固定的数据类型，用于存储一段具有相同类型的元素的连续块。 数组存储的类型可以是内置类型，如整型或字符串，也可以是某种结构类型。 数组占用的内存是连续分配的。由于内存连续，CPU能把正在使用的数据缓存更久的时间。而且内存连续很容易计算索引，可以快速迭代数组里的所有元素。 特点： 长度固定 类型相同 内存连续 声明和初始化声明数组声明的原则： 指明存储数据的类型 指明存储元素数量（指明数组长度） 12#声明一个包含5个元素的整型数组var array [5]int 数组一旦声明后，数组里存储的数据类型和数组长度就不能改变了。 当数组初始化时，数组内每个元素都初始化为对应类型的零值。 声明并初始化使用数组字面量声明并初始化数组。数组字面量允许声明数组里元素的数量同时指定每个元素的值。 Go为我们提供了 := 操作符，可以让我们在创建数组的时候直接初始化。 12# 声明并初始化array:=[5]int&#123;1,2,3,4,5&#125; 自动推导数组长度使用 ... 替代数组的长度，Go语言会根据初始化时数组元素的数量来确定该数组的长度。 12# 容量由初始化值的数量决定array:=[...]int&#123;1,2,3,4,5&#125; 用具体值初始化特定索引使用指定索引的方式初始化特定索引值。 12# 用具体值初始化索引为1和3的元素，其余元素保持零值array:=[5]int&#123;1:10,3:30&#125; 使用数组要访问数组里某个单独元素，使用索引操作符 [] 即可。因为内存是连续的，所以索引访问的效率非常高。 1234# 声明一个包含5个元素的整形数组array:=[5]int&#123;1,2,3,4,5&#125;# 修改索引为2的元素值array[2]=80 遍历访问数组使用 for 遍历访问数组 123456func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; for i := 0; i &lt; 5; i++ &#123; fmt.Printf(&quot;索引：%d,值：%d\n&quot;, i, array[i]) &#125;&#125; 使用 for range 遍历访问数组每个元素 123456func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; for k, v := range array &#123; fmt.Printf(&quot;索引：%d,值：%d\n&quot;, k, v) &#125;&#125; 数组相互赋值同样类型的数组是可以相互赋值的，不同类型的不行，会编译错误。 数组变量的类型包括数组长度和每个元素的类型。只有这两部分都相同的数组，才是类型相同的数组，才能相互赋值。 12345678910func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; //# 相同数组类型，能够互相赋值 // var array1 [5]int = array // fmt.Println(array1) //[1 2 3 4 5] //不同数组类型，不能互相赋值 var array2 [4]int = array //cannot use array (type [5]int) as type [4]int in assignment fmt.Println(array2)&#125; 指针数组在数组的类型前面加 * 声明为指针数组组。 使用 * 运算符可以访问指针数组元素指针所指向的值。 1234567891011func main() &#123; // # 声明指向整数的数组，用整形指针初始化索引为0和3的数组元素 array := [5]*int&#123;0: new(int), 3: new(int)&#125; // # 为索引为0和3的元素赋值 *array[0] = 10 *array[3] = 40 fmt.Println(array) // [0xc420070188 &lt;nil&gt; &lt;nil&gt; 0xc4200701b0 &lt;nil&gt;]&#125; 上面的示例要注意，我们只可以给索引0 和 3 赋值，因为只有它们分配了内存，才可以赋值。如果给其他索引赋值，运行时会提示无效内存或nil指针引用。要解决这个问题，需要先给这些索引分配内存，然后再进行赋值修改操作。 123456789101112......// # 为未分配内存的索引赋值，报错 *array[2] = 30// panic: runtime error: invalid memory address or nil pointer dereference// [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2199]// # 先分配内存再赋值array[2] = new(int)*array[2] = 35fmt.Println(array)// [0xc420074188 &lt;nil&gt; 0xc4200741d0 0xc4200741b0 &lt;nil&gt;] 指针数组相互赋值复制数组指针，只会复制指针的值，而不会复制指针所指向的值。 1234567891011121314151617181920212223func main() &#123; // # 声明第一个包含3个元素的指向字符串的指针数组 var array1 [3]*string // # 声明第一个包含3个元素的指向字符串的指针数组 var array2 [3]*string // # 使用字符串指针初始化这个数组 array2 = [3]*string&#123;new(string), new(string), new(string)&#125; // # 使用颜色为每个元素赋值 *array2[0] = &quot;red&quot; *array2[1] = &quot;blue&quot; *array2[2] = &quot;green&quot; // # 将array2 复制给 array1 array1 = array2 // # 复制之后，两个数组指向同一组字符串 fmt.Println(array1) fmt.Println(array2) // [0xc420074030 0xc420074040 0xc420074050] // [0xc420074030 0xc420074040 0xc420074050]&#125; 多维数组数组本身只有一个维度，可以组合多个数组创建多维数组。 声明多维数组1234567891011121314151617func main() &#123; // # 声明一个二维数组 var array1 [4][2]int fmt.Println(array1) // [[0 0] [0 0] [0 0] [0 0]] // # 使用数组字面量来声明并初始化一个二维数组 array2 := [4][2]int&#123;&#123;10, 11&#125;, &#123;20, 21&#125;, &#123;30, 31&#125;, &#123;40, 41&#125;&#125; fmt.Println(array2) // [[10 11] [20 21] [30 31] [40 41]] // # 声明并初始化外层数组中索引为1 和 3 的元素 array3 := [4][2]int&#123;1: &#123;20, 21&#125;, 3: &#123;40, 41&#125;&#125; fmt.Println(array3) // [[0 0] [20 21] [0 0] [40 41]] // # 声明并初始化外层数组和内层数组的当个元素 array4 := [4][2]int&#123;1: &#123;0: 20&#125;, 3: &#123;1: 41&#125;&#125; fmt.Println(array4) // [[0 0] [20 0] [0 0] [0 41]]&#125; 声明多维数组时，第一维度的数组长度也可以使用 ... 来根据数组值的个数来确定，但后面维度不能使用 ...来自动推测。 12345func main() &#123; b := [...][2]int&#123;&#123;1, 1&#125;, &#123;2, 2&#125;, &#123;3, 3&#125;&#125; fmt.Println(b) // [[1 1] [2 2] [3 3]] fmt.Println(len(b)) // 3&#125; 访问二维数组元素为了访问单个元素，需要反复组合使用 [] 运算符。 123456789101112func main() &#123; // # 声明一个二维数组 var array1 [4][2]int fmt.Println(array1) // [[0 0] [0 0] [0 0] [0 0]] // # 设置指定元素的值 array1[1][0] = 5 fmt.Println(array1) // [[0 0] [5 0] [0 0] [0 0]] // # 获取指定位置的元素 fmt.Println(array1[1][0]) //5&#125; 多维数组相互赋值多维数组的类型包括每一维度的藏毒以及最终存储在元素中的数据的类型。只要类型一致，就可以将多维数组互相赋值。 1234567func main() &#123; array1 := [2][2]int&#123;&#123;1, 2&#125;, &#123;3, 4&#125;&#125; var array2 [2][2]int array2 = array1 fmt.Println(array2) // [[1 2] [3 4]]&#125; 在函数间传递数组在函数间传递变量时，总是以值的形式传递。如果变量是个数组，那么就会整个复制，并传递给函数，如果数组非常大，对于内存是一个很大的开销。 12345678910func main() &#123; array := [5]int&#123;1: 2, 3: 4&#125; modify(array) fmt.Println(array) //[0 2 0 4 0]&#125;func modify(a [5]int) &#123; a[1] = 3 fmt.Println(a) // [0 3 0 4 0]&#125; 如示例，数组是复制的，原来的数组没有修改。如果复制的数组非常大，对内存是一个非常大的浪费。 可以通过传递数组的指针的方式来在函数间传递大数组。 使用指针在函数间传递大数组传递数组的指针，复制的大小只是一个数组类型的指针大小。 12345678910func main() &#123; array := [5]int&#123;1: 2, 3: 4&#125; modify(&amp;array) fmt.Println(array) //[0 3 0 4 0]&#125;func modify(a *[5]int) &#123; a[1] = 3 fmt.Println(*a) // [0 3 0 4 0]&#125; 如示例，通过传递数组的指针，会发现原来的数组也被修改了。要意识到的是，因为传递的是指针，所以如果改变指针指向的值，会改变共享的内存。 使用切片能更好的处理内存共享问题。 这里注意，数组的指针和指针数组是两个概念，数组的指针是 *[5]int,指针数组是 [5]*int，注意 * 的位置。 总结概括数组知识点 数组是值类型，赋值和传参会复制整个数组，而不是指针。 数组长度必须是常量，且是类型的组成部分。[2]int 和 [3]int 是不同类型。 支持 &quot;==&quot;、&quot;!=&quot; 操作符，因为内存总是被初始化过的。 指针数组 [n]*T，数组指针 *[n]T。 值拷贝行为会造成性能问题，通常会建议使用 slice，或数组指针。 声明并初始化12345func main() &#123; // a := [3]int&#123;1, 2&#125; //未初始化元素值未数组类型零值 // b := [...]int&#123;1, 2, 3, 4&#125; //通过初始化值确定数组长度 // c := [5]int&#123;2: 10, 4: 20&#125; // 使用索引号初始化元素&#125; 多维数组1234func main() &#123; d := [2][3]int&#123;&#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;&#125; //多维数组 e := [...][2]int&#123;&#123;1, 1&#125;, &#123;2, 2&#125;, &#123;3, 3&#125;, &#123;4, 4&#125;&#125; //第 2 维度不能用 &quot;...&quot;&#125; 内置函数 len 和 cap 都返回数组长度 (元素数量)1234func main() &#123; f := [2]int&#123;&#125; fmt.Println(len(f), cap(f)) // 2 2 &#125;]]></content>
      <categories>
        <category>从0到1学Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从0到1学Golang之基础--Go 包]]></title>
    <url>%2F2017%2F05%2F12%2Flearn-golang-from-0-to-1-of-go-package%2F</url>
    <content type="text"><![CDATA[《Go In Action》 中文版 《Go语言实战》 读书笔记 什么是包go语言的包其实就是我们计算机里的目录 包的命名所有的 .go 文件，除了空行和注释，都应该在第一行声明自己所属的包。 使用 package 关键字声明包。如： package main 。 每个包都在一个单独的目录里。也就是说，同一个目录下的所有 .go 文件必须声明同一个包名。 以 net/http 包为例，在 http 目录下的所有文件都属于 http 包。 go语言中给包及其目录命名，遵循 简洁 、清晰 、全小写 及 和所在目录同名 的原则。 1234567package mainimport &quot;net/http&quot;func main() &#123; http.ListenAndServe(&quot;127.0.0.1:80&quot;,handler);&#125; 如上 net/http，在导入包时采用 全路径 的方式，所以可以区分同名的不同包，只要保证全路径不同就可以。使用全路径的导入，也增加了包名命名的灵活性。 main 包在go语言中，命名为 main 的包会被尝试编译为一个二进制可执行文件。 所有用go语言编译的可执行程序都必须有一个名为 main 的包。 一个 main 的包，一定会包含一个 main() 函数。 在Go语言里同时要满足 main 包和包含 main() 函数，才会被编译成一个可执行文件。 Go程序编译时，会使用声明 main 包的代码所在的目录的目录名作为二进制可执行文件的文件名。 包的导入使用 import 关键字来导入包。导入的包必须是一个全路径的包，也就是包所在的位置。 导入单个包： 1import &quot;fmt&quot; 导入多个包时，使用一对括号包含的导入块，每个包独占一行。 12345import ( &quot;fmt&quot; &quot;net/http&quot; &quot;strings&quot;) 对于多于一个路径的包名，在代码中引用的时候，使用全路径最后一个包名作为引用的包名，比如 net/http ,我们在代码使用的是 http ，而不是 net 。 Go有两个很重要的环境变量 GOROOT 和 GOPATH ,这是两个定义路径的环境变量，GOROOT是安装Go的路径，比如/usr/local/go；GOPATH是我们自己定义的开发者个人的工作空间，比如 /home/myproject/go 。 标准库中的包会在 GOROOT 去查找，Go开发者创建的包会在 GOPATH 指定的目录中查找。 对于包的查找，是有优先级的，编译器会优先在 GOROOT 里搜索，其次是 GOPATH ,一旦找到，就会马上停止搜索。如果最终都没找到，就报编译异常了。 远程导入Go语言的工具链支持从Github、Bitbucket等类似网站获取源代码。 1import &quot;github.com/spf13/viper&quot; 用导入路径编译程序时，gobuild 命令会先在 GOPATH 下搜索这个包，如果没有找到，就会使用 go get 工具通过URL从网络获取，并把包的源代码保存在 GOPATH 目录下对应URL的目录里。 go get 工具可以递归获取依赖包。 命名导入如果要导入的多个包具有相同的名字，可以通过 命名导入 的方式来导入。 命名导入是指在 import 语句给出的包路径的左侧定义一个名字，将导入的包命名为新名字。 1234import ( &quot;fmt&quot; myfmt &quot;mylib/fmt&quot;) Go语言规定，导入的包必须要使用，否则会报编译错误。Go语言的这个特性可以防止导入了未被使用的包，避免代码变得臃肿。 但是有时候我们需要导入一个包，但是不需要引用这个包的标识符。这种情况下，可以使用空白标识符 _ 来重命名导入的包即可。 123456package mainimport ( &quot;fmt&quot; _ &quot;mylib/fmt&quot;) 空白标识符(_) 用来抛弃不想继续使用的值，如给导入的包赋予一个空名字，或忽略函数返回的不感兴趣的值。 init函数每个包都可以有任意多个init函数，这些init函数都会在main函数之前执行。init函数通常用来做初始化变量、设置包或者其他需要在程序执行前的引导工作。init函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作。 以数据库驱动为例， database 下的驱动在启动时执行 init 函数会将自身注册到 sql 包里，因为 sql 包在编译时并不知道这些驱动的存在，等启动之后 sql 才能调用这些驱动。 123456789package postgresimport ( &quot;database/sql&quot;)func init() &#123; sql.Register(&quot;postgres&quot;, new(PostgresDriver))&#125; 因为我们只是想执行这个 postgres 包的 init 方法，并不想使用这个包，所以我们在导入的时候，需要使用空白标识符 _ 来重命名包名，避免编译错误。 12345678910package mainimport ( &quot;database/sql&quot; _ &quot;github.com/goinaction/code/chapter3/dbdriver/postgres&quot;)func main() &#123; sql.Open(&quot;postgres&quot;, &quot;mydb&quot;)&#125; 如上非常简洁，剩下很对数据库的操作，都是使用 database/sql 标准接口。如果我们想换其他数据库驱动，只需要换个导入即可，灵活方便。]]></content>
      <categories>
        <category>从0到1学Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang运行环境配置]]></title>
    <url>%2F2017%2F04%2F02%2Fgolang-running-environment-configuration%2F</url>
    <content type="text"><![CDATA[Win系统下配置Go语言环境 从网站 Downloads - The Go Programming Language 下载 go1.6.3.windows-amd64.msi 安装包。 运行并安装到默认目录 C:\Go 目录下。 配置 GOROOT 和 GOPATH : 在 系统的环境变量中的 PATH 变量中添加Go的目录 C:\Go\bin; (通过安装包安装后已默认设置该项) 在 系统的环境变量中添加 GOROOT 变量，设置值为 C:\Go\ (通过安装包安装后已默认设置该项) 要验证 GOROOT 是否设置成功，我们可以在命令行窗口中输入 go version，如果输出了Go的版本信息则说明配置正确。 GOPATH 就需要我们手动配置一下，GOPATH 就是你的工作目录，用于存放项目和go依赖包等。假设目录 E:\GOProject 为我的Go项目工作目录，该工作目录下默认包含三个子目录：bin/ pkg/ src 。然后我们在 系统的环境变量中 新建 GOPATH 变量，设置值为 E:\GOProject;。默认情况下 GOPATH 目录可以设置多个，之间用分号 ; 分隔。 然后在命令行窗口中输入 echo %GOPATH% 如果打印出了上面设置的 GOPATH 的目录，则说明配置成功。 为了验证Go开发环境是否设置成功，我们可以在命令行下输入如下命令：(保证已经安装Git) 1go get github.com/golang/example/hello 然后执行命令： 1%GOPATH%/bin/hello 如果输出了 Hello,Go examples! 则说明Go语言的开发环境搭建成功。 参考自：Easy Go Programming Setup for Windows Wade Wegner Win下配置Golang开发环境添加多个工作目录我一般会设置两个目录用作我的工作项目。一般我会命名为 xgo 和 xgo_workspace ，一个用来存储网络上其他的Golang依赖项目，一个作为我自己的开发项目存放位置。 在Windows系统下安装上Go的msi安装包后，默认的 GOPATH 目录为当前管理员账户目录下的go文件夹：C:\Users\xxxx\go 中，在 Cmder 控制台中通过 go env 查看： 12345678910111213141516171819202122λ go env set GOARCH=amd64 set GOBIN= set GOEXE=.exe set GOHOSTARCH=amd64 set GOHOSTOS=windows set GOOS=windows set GOPATH=C:\Users\xxxx\go set GORACE= set GOROOT=C:\Go set GOTOOLDIR=C:\Go\pkg\tool\windows_amd64 set GCCGO=gccgo set CC=gcc set GOGCCFLAGS=-m64 -mthreads -fmessage-length=0 set CXX=g++ set CGO_ENABLED=1 set CGO_CFLAGS=-g -O2 set CGO_CPPFLAGS= set CGO_CXXFLAGS=-g -O2 set CGO_FFLAGS=-g -O2 set CGO_LDFLAGS=-g -O2 set PKG_CONFIG=pkg-config 在 环境变量 下新增 GOPATH 项，添加值为 E:\GOProject\xgo;E:\GOProject\xgo_workspace ，注意多个目录在windows下使用分号 ; 分隔，重启 Cmder 再次通过 go env 查看： 12345678910111213141516171819202122λ go envset GOARCH=amd64set GOBIN=set GOEXE=.exeset GOHOSTARCH=amd64set GOHOSTOS=windowsset GOOS=windowsset GOPATH=E:\GOProject\xgo;E:\GOProject\xgo_workspaceset GORACE=set GOROOT=C:\Goset GOTOOLDIR=C:\Go\pkg\tool\windows_amd64set GCCGO=gccgoset CC=gccset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0set CXX=g++set CGO_ENABLED=1set CGO_CFLAGS=-g -O2set CGO_CPPFLAGS=set CGO_CXXFLAGS=-g -O2set CGO_FFLAGS=-g -O2set CGO_LDFLAGS=-g -O2set PKG_CONFIG=pkg-config Mac下配置Golang开发环境通过brew安装1$ brew install go 通过pkg包安装从 golang官网 下载Mac下的pkg安装包直接安装. 环境变量配置GOPATH允许多个目录，当有多个目录时，请注意分隔符，多个目录的时候Windows是分号 ;，Linux系统及Mac下是冒号 :，当有多个GOPATH时，默认会将 go get 的内容放在第一个目录下。 123456789101112131415$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOEXE=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;CC=&quot;clang&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/mk/7c0w24ts0ps1g06q78gzd7dc0000gn/T/go-build098119519=/tmp/go-build -gno-record-gcc-switches -fno-common&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot; 假如我的go项目开发主目录为:/Users/xxx/Learn/Go在该目录下,第一个目录为 xgo 第二个目录为 xgo_workspace 12345# GOPATHexport GOPATH=$HOME/Learn/Go/xgo:$HOME/Learn/Go/xgo_workspace# GOPATH binexport PATH=$PATH:$GOPATH/bin 添加完成后,重启终端即可生效.如果想立即生效,则可执行如下命令: 1$ source ~/.bash_profile 再次查看go环境变量: 123456789101112131415$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOEXE=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;/Users/xxx/Learn/Go/xgo:/Users/xxx/Learn/Go/xgo_workspace&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;CC=&quot;clang&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/mk/7c0w24ts0ps1g06q78gzd7dc0000gn/T/go-build346222074=/tmp/go-build -gno-record-gcc-switches -fno-common&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot; http://blog.helloarron.com/2015/08/29/go/mac-install-go/ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/01.2.md http://blog.studygolang.com/2013/01/%E5%86%8D%E7%9C%8Bgopath/ (设置多个目录时只会将最后一个目录添加上bin 这里要说明) Update 2017-11-28 更新windows下设置多个工作目录的说明]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习资料整理]]></title>
    <url>%2F2017%2F03%2F31%2Flearning-golang%2F</url>
    <content type="text"><![CDATA[整理网上找到的Golang语言学习资料 基础基础教程 书籍在线版 Go 指南-A Tour of Go Go语言圣经（中文版） Effective Go中文版 Go Web编程 build-web-application-with-golang Go入门指南 The Way to Go 《The Way to Go》中文译本，中文正式名《Go入门指南》 Golang学习室 Go轻松学 TechDoc 《Go实战开发》 go-best-practice 基础教程 书籍离线版 GitHub - qyuhen/book: 学习笔记 基础教程 视频 Go编程基础 Go编程基础_免费高速下载|百度网盘-分享无限制 Web Go Web 基础 - 网易云课堂 beego开发文档 进阶 深入解析Go go-internals Go名库讲解 - 网易云课堂 Go语言标准库 GO 命令教程 : Golang command tutorial in Chinese. 理解Go语言的nil - 简书 工具 Go Walker - Go 语言在线 API 文档 Go 语言包管理 Rego - A Go regular expression tester 项目 Projects · golang/go Wiki · GitHub Golang大牛 Unknwon (无闻) · GitHub qyuhen (Q.yuhen) · GitHub Go 开发工具 gosublimetext 插件 GitHub - DisposaBoy/GoSublime: A Golang plugin collection for SublimeText 3, providing code completion and other IDE-like features. Wise Turtles - Go学习笔记3之打造Sublime Text&nbsp;3作为Go的集成开发环境 Go语言编辑器IDE之JetBrains篇(PyCharm+go插件plugin) Sublime Text3 &#43; Golang搭建开发环境_随笔 - Vckai的个人技术博客. - Vckai.com Sublime Text 2搭建Go开发环境（Windows） - Bill Yuan - 博客园 Ubuntu 配置 Go 语言开发环境（Sublime Text+GoSublime） - 抛弃世俗之浮躁，留我钻研之刻苦 - 开源中国社区 相关参考 Golang学习历程 - 简书 GitHub - Unknwon/go-study-index: Go 语言学习资料索引 Go 标准库介绍 ironxu GO语言学习资源整理 - 知乎专栏 GO-Start/Go语言中的闭包.md at master · carryxyh/GO-Start · GitHub Go的文件操作 - 谢权SELF Go语言并发机制初探-博客-云栖社区-阿里云 Go语言实战笔记 Go学习【二】学习资料 - 一起学习 go - SegmentFault GO语言零基础入门资料整理 - 简书 Go简明教程 电子书教程Go 语言基础 go语言入门 · GitBook go语言教程 《学习GO语言》中文版 《学习GO语言》GitHub - mikespook/Learning-Go-zh-cn: 一本学习 Go 语言的免费电子书。 GitHub - Unknwon/go-fundamental-programming: 《Go编程基础》是一套针对 Google 出品的 Go 语言的视频语音教程，主要面向新手级别的学习者。 GitHub - Unknwon/go-rock-libraries-showcases: 《Go名库讲解》是一套针对 Google 出品的 Go 语言的第三方库进行评测讲解的集博客、示例与语音视频为一体的综合教程，适合完成学习完成《Go编程基础》教程的学习者。 GitHub - Unknwon/the-way-to-go_ZH_CN: 《The Way to Go》中文译本，中文正式名《Go入门指南》 前言 | Go语言圣经 Go Web 开发 GitHub - Unknwon/go-web-foundation: 《Go Web基础》是一套针对 Google 出品的 Go 语言的视频语音教程，主要面向完成《Go编程基础》教程后希望进一步了解有关 Go Web 开发的学习者。 《GO WEB编程》 视频教程 跟无闻学Go语言：Go编程基础视频教程（共15课时）_在线自学视频教程_51CTO学院 跟无闻学Go语言：Go Web基础视频教程（共12课时）_在线自学视频教程_51CTO学院 Go语言第一课_Go语言视频教程-慕课网 Go编程基础 Golang编程基础 Go全套]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs个性化设置]]></title>
    <url>%2F2017%2F03%2F27%2Fdocker-ubuntu-gogs-custom%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 个性化的配置 Docker Gogs 首页样式。 Gogs MIT开源协议 Gogs 项目代码 100% 开源并可无条件免费使用。所有的源代码均通过 MIT 授权协议 托管在 GitHub 上。 准备工作在Docker宿主机和容器之间拷贝文件的命令以下命令均在 宿主机 上执行。 12345# 拷贝文件从宿主机至容器：$ docker cp localfile &lt;ConName&gt;:/app/confile# 拷贝文件从容器至宿主机：$ docker cp &lt;ConName&gt;:/app/confile localfile 将待处理文件进行备份操作使用 docker exec 命令进入运行中的容器： 1$ docker exec -it &lt;ConName&gt; /bin/bash 备份Gogs目录下的以下文件： templates/home.tmpl templates/base/head.tmpl templates/base/footer.tmpl 1docker@ConName/templates# cp ./home.tmpl ./home.tmpl.tmp 更改首页介绍 只保留Logo区域首页中部内容 – home.tmpl – 去除首页中下部分介绍，只保留Logo区域 将容器内的 home.tmpl 文件拷贝至宿主机本地： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl ./home.tmpl 修改首页站点介绍网站标题和介绍部分在页面中的 div.hero 部分： 123456&lt;div class="hero"&gt; &lt;h1 class="ui icon header title"&gt; ... &lt;/h1&gt; &lt;h2&gt;...&lt;/h2&gt;&lt;/div&gt; 这里我将站点介绍修改为了 ： 1&lt;h2&gt;用了雪哥Git库 从此编程不再吐&lt;/h2&gt; 隐藏首页站点说明部分说明部分我仅以 简体中文 和 English 两种语言的修改来说明： 中文说明部分：内容在页面中的1&#123;&#123;else if eq .Lang &quot;zh-CN&quot;&#125;&#125; 和1&#123;&#123;else if eq .Lang &quot;fr-FR&quot;&#125;&#125; 之间： 1234&#123;&#123;else if eq .Lang "zh-CN"&#125;&#125; ... ...&#123;&#123;else if eq .Lang "fr-FR"&#125;&#125; 英文说明部分：内容在页面中的1&#123;&#123;else&#125;&#125; 和1&#123;&#123;end&#125;&#125; 之间： 1234&#123;&#123;else&#125;&#125; ... ...&#123;&#123;end&#125;&#125; 将这两部分的内容删除或用 &lt;!-- --&gt; 隐藏。 更改完成后，保存，并更新回容器中： 1$ docker cp ./home.tmpl &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl 去除未登录用户左上角显示的“帮助”按钮及更换背景图案头部导航 – head.tmpl – 去除未登录用户左上角显示的“帮助”按钮 先从容器中获取该文件： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl ./head.tmpl 去除未登录用户左上角显示的“帮助”按钮将如下部分代码中的 &lt;a&gt;...&lt;/a&gt; 注释掉或删除，修改后如下： 1234&#123;&#123;else&#125;&#125; &lt;!--&lt;a class="item" target="_blank" href="https://gogs.io/docs" rel="noreferrer"&gt;&#123;&#123;.i18n.Tr "help"&#125;&#125;&lt;/a&gt;--&gt; &lt;div class="right menu"&gt; 更改首页背景图案仿照 https://gogs.io/ 首页在 head.tmpl 页面中找到如下部分: 123&lt;!-- Stylesheet --&gt;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/semantic-2.2.7.min.css"&gt;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/gogs.css?v=&#123;&#123;MD5 AppVer&#125;&#125;"&gt; 在这段下面添加如下代码: 123&#123;&#123;if .PageIsHome&#125;&#125;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/gghome.min.css"&gt;&#123;&#123;end&#125;&#125; 然后在本地新建名为 gghome.min.css 的样式文件，注意文件的格式为 UTF-8 且行结束标识为 Unix(LF) ，添加如下样式： 1.full.height&#123;background-color:#0F8DEC;background-image:url("data:image/svg+xml,%3Csvg width='304' height='304' viewBox='0 0 304 304' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M44.1 224c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H0v-2h44.1zm160 48c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H82v-2h122.1zm57.8-46c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H304v2h-42.1zm0 16c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H304v2h-42.1zm6.2-114c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4h-86.2c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h86.2zm-256-48c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H0v-2h12.1zm185.8 34c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h86.2c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4h-86.2zM258 12.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V0h2v12.1zm-64 208c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-54.2c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9v54.2zm48-198.2c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V82h64v-2h-62V21.9zm16 16c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V66h48v-2h-46V37.9zm-128 96c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V210h16v10.1c-2.282.463-4 2.48-4 4.9 0 2.76 2.24 5 5 5s5-2.24 5-5c0-2.42-1.718-4.437-4-4.9V208h-16v-74.1zm-5.9-21.9c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H114v48H85.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H112v-48h12.1zm-6.2 130c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H176v-74.1c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V242h-60.1zm-16-64c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H114v48h10.1c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H112v-48h-10.1zM66 284.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V274H50v30h-2v-32h18v12.1zM236.1 176c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H226v94h48v32h-2v-30h-48v-98h12.1zm25.8-30c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H274v44.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V146h-10.1zm-64 96c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H208v-80h16v-14h-42.1c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H226v18h-16v80h-12.1zm86.2-210c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H272V0h2v32h10.1zM98 101.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V144H53.9c-.463-2.282-2.48-4-4.9-4-2.76 0-5 2.24-5 5s2.24 5 5 5c2.42 0 4.437-1.718 4.9-4H98v-44.1zM53.9 34c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H80V0h2v34H53.9zm60.1 3.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V64H80v64H69.9c-.463-2.282-2.48-4-4.9-4-2.76 0-5 2.24-5 5s2.24 5 5 5c2.42 0 4.437-1.718 4.9-4H82V66h32V37.9zM101.9 82c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H128V37.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V82h-28.1zm16-64c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H146v44.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V18h-26.1zm102.2 270c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H98v14h-2v-16h124.1zM242 149.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V162h16v30h-16v66h48v46h2v-48h-48v-62h16v-34h-16v-10.1zM53.9 18c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H64V2H48V0h18v18H53.9zm112 32c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H192V0h50v2h-48v48h-28.1zm-48-48c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5 0-.342.034-.677.1-1h2.07c-.11.313-.17.65-.17 1 0 1.657 1.343 3 3 3s3-1.343 3-3c0-.35-.06-.687-.17-1H178v34h-18V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V32h14V2h-58.1zm0 96c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H137l32-32h39V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V66h-40.172l-32 32H117.9zm28.1 90.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-76.513L175.586 80H224V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V82h-49.586L146 112.414V188.1zm16 32c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-99.513L184.586 96H300.1c.398-1.96 1.94-3.502 3.9-3.9v2.07c-1.165.413-2 1.524-2 2.83s.835 2.417 2 2.83v2.07c-1.96-.398-3.502-1.94-3.9-3.9H185.414L162 121.414V220.1zm-144-64c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-3.513l48-48V48h32V0h2v50H66v55.413l-48 48v2.687zM50 53.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9v42.686l-48 48V210h28.1c.463 2.282 2.48 4 4.9 4 2.76 0 5-2.24 5-5s-2.24-5-5-5c-2.42 0-4.437 1.718-4.9 4H2v-62.586l48-48V53.9zm-16 16c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9v18.686l-32 32v2.828l34-34V69.9zM12.1 32c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H9.414L0 43.414v-2.828L8.586 32H12.1zm265.8 18c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h18.686L304 40.586v2.828L297.414 50H277.9zm-16 160c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H288V136.587l16-16v2.827l-14 14V210h-28.1zm-208 32c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H64v-22.586L40.586 194H21.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h19.513L66 216.586V242H53.9zm150.2 14c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H96v-56.598L56.598 162H37.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h19.502L98 200.598V256h106.1zm-150.2 2c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H80v-46.586L48.586 178H21.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h27.513L82 208.586V258H53.9zM97 100c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-48 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 96c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-144c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-96 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm96 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-32 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM49 36c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-32 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM33 68c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 240c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm80-176c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm112 176c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM17 180c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM17 84c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM34 39.793V0h-2v40.586L8.586 64H0v2h9.413L34 41.414v-1.62zM2 300.1V258h14v46h2v-48H0V302.17c.313-.11.65-.17 1-.17 1.306 0 2.417.835 2.83 2H5.9c-.398-1.96-1.94-3.502-3.9-3.9zM34 241v63h-2v-62H0v-2h34v1zM17 18h1V0h-2v16H0v2h17zm273-2V0h-2v18h16v-2h-14zm-32 273v15h-2v-14h-14v14h-2v-16h18v1zM0 92.1c.323-.066.658-.1 1-.1 2.76 0 5 2.24 5 5s-2.24 5-5 5c-.342 0-.677-.034-1-.1v-2.07c.313.11.65.17 1 .17 1.657 0 3-1.343 3-3s-1.343-3-3-3c-.35 0-.687.06-1 .17V92.1zM80 272h2v32h-2v-32zm37.9 32c-.463-2.282-2.48-4-4.9-4-2.42 0-4.437 1.718-4.9 4h2.07c.413-1.165 1.524-2 2.83-2s2.417.835 2.83 2h2.07zM5.9 0c.066.323.1.658.1 1 0 2.76-2.24 5-5 5-.342 0-.677-.034-1-.1V3.83C.313 3.94.65 4 1 4c1.657 0 3-1.343 3-3 0-.35-.06-.687-.17-1H5.9zm294.2 0c-.066.323-.1.658-.1 1 0 2.42 1.718 4.437 4 4.9V3.83c-1.165-.413-2-1.524-2-2.83 0-.35.06-.687.17-1h-2.07zm3.9 300.1c-1.96.398-3.502 1.94-3.9 3.9h2.07c.302-.852.978-1.528 1.83-1.83v-2.07z' fill='%23afcfe1' fill-opacity='0.23' fill-rule='evenodd'/%3E%3C/svg%3E")&#125;.hero&#123;color:#fff&#125;.hero .ui.header&#123;color:#fff&#125; 然后将该文件 gghome.min.css 添加到容器中： 1$ docker cp ./gghome.min.css &lt;ConName&gt;:/home/git/gogs/public/css/gghome.min.css 待以上步骤操作完成后，更新回容器中： 1$ docker cp ./head.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl 更改底栏“官方网站”字样为“Gogs官方网站”底部 – footer.tmpl – 更改底栏“官方网站”字样为“Gogs官方网站” 从容器中获取该文件： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl ./footer.tmpl 更改底栏“官方网站”字样为“Gogs官方网站”将以下部分： 1&lt;a target="_blank" href="https://gogs.io"&gt;&#123;&#123;.i18n.Tr "website"&#125;&#125;&lt;/a&gt; 更改为： 1&lt;a target="_blank" href="https://gogs.io"&gt;Gogs&#123;&#123;.i18n.Tr "website"&#125;&#125;&lt;/a&gt; Markdown文档中的链接跳转加上target标签底部 – footer.tmpl – Markdown文档中的链接跳转加上target标签 默认情况下，Gogs项目中的Markdown文档中的链接是在当前页面跳转的，但个人习惯还是喜欢在新页面打开链接。 找到 footer.tmpl 页面中如下代码： 123&lt;script src="&#123;&#123;AppSubUrl&#125;&#125;/js/libs/clipboard-1.5.9.min.js"&gt;&lt;/script&gt;&#123;&#123;template "inject/footer" .&#125;&#125; 在中间位置添加一行： 1&lt;script src="&#123;&#123;AppSubUrl&#125;&#125;/js/mdlinktarget.min.js"&gt;&lt;/script&gt; 在本地创建一个js文件，注意文件的格式为 UTF-8 且行结束标识为 Unix(LF) 并命名为 mdlinktarget.min.js ，内容如下： 1$(document).ready(function()&#123;$('#file-content a[href^="http"]').each(function()&#123;$(this).attr("target","_blank")&#125;)&#125;); 将该js文件拷贝添加到容器中的项目目录下，执行如下命令： 1$ docker cp ./mdlinktarget.min.js &lt;ConName&gt;:/home/git/gogs/public/js/mdlinktarget.min.js 然后将更改后的 footer.tmpl 更新回容器中： 1$ docker cp ./footer.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl 修改完成 重启容器待以上各步骤操作完成后，重启容器。 1$ docker restart gogs 命令整理示例命令123456$ docker cp ./home.tmpl &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl$ docker cp ./footer.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl$ docker cp ./head.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl$ docker cp ./mdlinktarget.min.js &lt;ConName&gt;:/home/git/gogs/public/js/mdlinktarget.min.js$ docker cp ./gghome.min.css &lt;ConName&gt;:/home/git/gogs/public/css/gghome.min.css$ docker restart &lt;ConName&gt; 操作命令123456$ docker cp ./home.tmpl gogs:/home/git/gogs/templates/home.tmpl$ docker cp ./footer.tmpl gogs:/home/git/gogs/templates/base/footer.tmpl$ docker cp ./head.tmpl gogs:/home/git/gogs/templates/base/head.tmpl$ docker cp ./mdlinktarget.min.js gogs:/home/git/gogs/public/js/mdlinktarget.min.js$ docker cp ./gghome.min.css gogs:/home/git/gogs/public/css/gghome.min.css$ docker restart gogs 获取文件以上操作的所有文件可以从 Docker Gogs custom files 或 GitHub - Leafney/ubuntu-gogs: Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 中获取。]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Gogs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs部署及配置时遇到的问题]]></title>
    <url>%2F2017%2F03%2F24%2Fdocker-ubuntu-gogs-problems%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 这里主要记录在Docker下部署Gogs项目过程中遇到的问题及解决方法。 目录 Install页面中的注意问题 Connection timed out 问题 hooks/update: No such file or directory 添加 SSH key 时显示报错页面 500 要求输入git账户密码 SSH Connection refused 问题 Git SSH 使用非默认22端口时，如何隐藏端口号 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! echo 输出 Docker Gogs 使用 HTTPS 上传文件遇到 413 Request Entity Too Large 错误 Install页面中的注意问题 domain: ensure that is the IP address of your docker host SSH port: that is the forwarded ssh port. So if you forward 22 to 10022, it’s 10022. HTTP port: my error, here, you must enter the HTTP in the container. So it’s 3000. Even if you forward it to 10080 ;) Application URL: this is a combination of domain + forwarded HTTP port (I got this one wrong too). So, if you’re forwarding 3000 to 10080, then it’s http://domain:10080. ssh端口使用外部端口，而http端口使用的是容器内部端口. 着重需要说明的是： Domain 填写Docker宿主机的物理IP地址，或者域名地址,注意这里是不带 http的 如： 192.168.137.140 或 git.mydomain.com SSH port 假如Docker映射的端口是 10022:22 那么这里就填写宿主机开放的端口 10022 HTTP port 假如Docker映射的端口是 10080:3000 这里要填容器内的监听端口 3000 Application URL 这里要填写的格式为 http(s):// + Domain + HTTP port ，比如：http://git.mydomain.com/10080 。还需要注意的一点是，如果你用了nginx来映射宿主机的 10080 端口，这里要去掉后面的端口，即 http://git.mydomain.com/，说白了就是你在外部浏览器上访问的地址。 Docker gogs web/ssh does not restart after reboot · Issue #3039 · gogits/gogs · GitHub Connection timed out 问题使用HTTP方式 Push 代码时报错？使用HTTP方式获取： 1234567$ git clone http://gogit.itfanr.cc/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...remote: Counting objects: 8, done.remote: Compressing objects: 100% (6/6), done.remote: Total 8 (delta 1), reused 0 (delta 0)Unpacking objects: 100% (8/8), done.Checking connectivity... done. 使用HTTP方式提交： 12345678$ git pushCounting objects: 3, done.Writing objects: 100% (3/3), 379 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)error: RPC failed; HTTP 504 curl 22 The requested URL returned error: 504 Gateway Time-outfatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyEverything up-to-date 使用SSH方式获取代码时报错？使用SSH方式获取： 1234567$ git clone ssh://git@gogit.itfanr.cc:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...ssh: connect to host gogit.itfanr.cc port 10022: Connection timed outfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 对于 Connection timed out 的问题，可能是使用的端口已经被其他程序占用导致，也可能是缓存文件导致。 最后的解决方法是将 data/sessions 中的 session 文件删除，然后更换了其他端口后再次运行则能够提交数据了。 报错 hooks/update: No such file or directory将旧的配置和数据库拷贝到新的Gogs项目下（我这里是从v0.8.25.0129版本迁移到v0.10.18.0313版本），提交代码时会报如下错误： 123456789$ git push origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 432 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: hooks/update: line 2: /home/git/gogs/goapp/gogs/gogs: No such file or directoryremote: error: hook declined to update refs/heads/masterTo http://gogit.itfanr.cc/xueer/HelloWorld.git ! [remote rejected] master -&gt; master (hook declined)error: failed to push some refs to &apos;http://gogit.itfanr.cc/xueer/HelloWorld.git&apos; 解决方法： 根据Gogs官网中的故障排查的说明： 123456Update 钩子指向错误的二进制路径可能原因：您升级 `Gogs` 后将其移动到了和之前安装位置不同的目录解决方案：到管理员控制面板（`/admin`）执行以下操作：重新生成 &apos;.ssh/authorized_keys&apos; 文件重新同步所有仓库的 `pre-receive`、`update` 和 `post-receive` 钩子 所以直接使用管理员账户在管理后台中操作即可解决。 详见：故障排查 之前的解决方法： 在新的Gogs位置执行 gogs fix location &lt;old Gogs path&gt; 经测试，该方法似乎已过时，执行时会报如下错误： 12/home/git/gogs# ./gogs fix location /home/git/gogs/goapp/gogsNo help topic for &apos;fix&apos; remote: hooks/update: line 2: /path/to/dir: No such file or directory · Issue #659 · gogits/gogs · GitHub Question: How do I move servers? · Issue #654 · gogits/gogs · GitHub 添加 SSH key 时显示报错页面 error 500查看日志，找到如下错误信息： 1AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 按照如下说法操作成功： So I changed the .ssh/ folder to 0700 and .ssh/authorize_keys to 0600. It works. 详细来源见：ssh 的链接地址不可以使用 修改 /home/git/.ssh 的权限为 700修改 /home/git/.ssh/authorized_keys 的权限为 600 我的操作： 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run 报错：open /home/git/.ssh/authorized_keys.tmp: permission denied 。 查看日志 gogs.log 文件，发现错误信息：AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 。 进入容器内部：docker exec -it gogs /bin/bash ,切换至git用户：su git,然后进入 /home/git/ 目录，更改 .ssh 目录权限：chmod 0700 .ssh 。（此时，该 .ssh 目录内为空） 然后再次访问 /admin 页面，再次执行 Run 操作，提示“所有公钥重新生成成功！”信息。查看容器内的 .ssh/ 目录下生成了一个 authorized_keys 文件。然后更改该文件权限：chmod 0600 authorized_keys 。 然后重启该容器。 重启容器后该问题解决。 要求输入git账户密码添加成功SSH密钥后，git clone 项目会报如下错误： 12345678910111213$ git clone ssh://git@gogit.itfanr.cc:10022/xueer/HelloWorld.gitCloning into &apos;Hello&apos;...The authenticity of host &apos;[gogit.itfanr.cc]:10022 ([gogit.itfanr.cc]:10022)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:+LHU3V00S0g9kNnpByc9ysAM5n6DWutT51YOldIcf88.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;[gogit.itfanr.cc]:10022&apos; (ECDSA) to the list of known hosts.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 一种可能的解决方式是 Check if /home/git/.ssh/.authorized_keys&#39;s permission is 600. 这个问题还是关于 .ssh/authorize_keys 的权限问题。 我的解决方法： 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run ，会提示更新成功。 重启该容器即可。 2017-7-21 add: 如果以上方法无效，可以进入容器后将 authorize_keys 文件删除，然后在管理员操作页面中重新生成。这样应该能解决。 ssh 的链接地址不可以使用 · Issue #545 · gogits/gogs · GitHub SSH prompts for password in Docker · Issue #2409 · gogits/gogs · GitHub How troubleshoot SSHd on Docker ? SSH Connection refused 问题添加成功SSH密钥后，git clone 项目会报如下错误： 1234567$ git clone ssh://git@192.168.137.140:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...ssh: connect to host 192.168.137.140 port 10022: Connection refusedfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 我的探索： 进入容器内部：docker exec -it gogs /bin/bash 查看ssh连接： 12root@b48dfa9583f9:/home/git/gogs# ssh localhostssh: connect to host localhost port 22: Connection refused 那现在这个问题就是在ubuntu下配置ssh链接的问题了。 发现问题的原因是安装 openssh 后，并没有启动 SSH 服务。执行如下命令启动： 1234/etc/init.d/ssh start# 或service ssh startservice ssh status 通过如下命令查看ssh服务是否启动：ps -e |grep ssh 12root@b48dfa9583f9:/home/git/gogs# ps -e |grep ssh 81 ? 00:00:00 sshd 然后使用 ssh localhost 命令查看是否能够连接本地： 12345root@b48dfa9583f9:/home/git/gogs# ssh localhostThe authenticity of host &apos;localhost (::1)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:eKk78mnEXpwvFhbzC6BgM70jZx3be4Fz8okyagHA6QA.Are you sure you want to continue connecting (yes/no)? noHost key verification failed. 可以看到SSH服务已经正常运行了。 然后在回到宿主机下，再次执行 git clone 命令，测试是否能够连通。 这里我整理了两种连接方法： 连接方法一： git clone ssh://git@192.168.137.140:10022/qqq/Xweixin.git Pull and Push Test Ok. 连接方法二： 如果嫌上面带有端口号的链接太不极客范儿，可以在客户端电脑上当前用户主目录的 .ssh 目录下创建一个没有扩展名的 config 文件（注意文件格式为 UTF-8 且行结束标识为 Unix(LF)），填写如下内容： ~/.ssh/config: 1234Host 192.168.137.140HostName 192.168.137.140Port 10022User git 这里， Host 是远程git仓库所在宿主机的IP地址或域名； HostName 不太重要，仅起到标识的作用； Port 表示远程git仓库使用的端口号； User 表示远程git仓库的默认用户，这里填写默认的 git 即可。 然后就可以直接请求不带端口号的ssh仓库地址了： git clone ssh://git@192.168.137.140/qqq/Xweixin.git Pull and Push Test Ok. 相关参考 ssh: connect to host localhost port 22: Connection refused 问题 ubuntu下如何安装使用SSH？ How to Enable SSH in Ubuntu 16.04 LTS | UbuntuHandbook SSH doesn’t work on ports other than 22 in dockerized gogs Git SSH 使用非默认22端口时，如何隐藏端口号Note that you can also add an entry to your ~/.ssh/config file: 123Host git.example.comPort 2222User git and then use the normal git clone git@git.example.com:myuser/myproject.git command. 相关参考 git - Using a remote repository with non-standard port - Stack Overflow Change port git is using for ssh Specify SSH Port for Git - Server Fault 报错 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!使用 SSH 获取时报错： 12345678910111213141516171819$ git clone ssh://git@192.168.137.140:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:+LHU3V00S0g9kNnpByc9ysAM5n6DWutT51YOldIcf88.Please contact your system administrator.Add correct host key in /c/Users/Yx/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /c/Users/Yx/.ssh/known_hosts:5ECDSA host key for [192.168.137.140]:10022 has changed and you have requested strict checking.Host key verification failed.fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 该问题是由于客户端电脑上的 .ssh/known_hosts 文件中记录了重复或冲突的ssh信息，删除该文件重新设置ssh连接即解决。 echo 输出下面两行命令的输出结果是不一样的： 123ab=$(service ssh status);echo $ab;ab=$(service ssh status);echo &quot;$ab&quot;; 123456you can get output of third solution in good way:echo &quot;$var&quot;and also in nasty way:echo $var 当 echo 后面的内容带有引号时，只会输出变量值的内容。当没有引号时，如果当前所在目录下有其他文件，这些文件的文件名也会被输出： 12ab=$(service ssh status);echo $ab;LICENSE README.md README_ZH.md custom data gogs log public scripts templates sshd is running linux - How to set a variable to the output from a command in Bash? - Stack Overflow Gogs 使用 HTTPS详细可见我的系列文章：HTTPS泛域名证书申请之二-Nginx配置 | IT范儿 使用 HTTPS 部署 Gogs · Issue #12 · Unknwon/wuwen.org · GitHub gogsi/gogs-nginx-ssl.conf at master · richardskumat/gogsi · GitHub 413 Request Entity Too Large出现这个问题是因为我在服务器上使用Nginx对Gogs做反向代理，上传文件的大小超出了Nginx的限制。 我的Nginx配置如下： 123456789server &#123; listen 80; server_name gogit.itfanr.cc; location / &#123; # 3000 是 Gogs 运行的端口 proxy_pass http://localhost:3000; &#125;&#125; Nginx允许的最大请求数据大小默认为 1m ，我们可以通过参数 client_max_body_size 来自定义： 123456789101112server &#123; listen 80; server_name gogit.itfanr.cc; # 设置最大为 100 M client_max_body_size 100m; location / &#123; # 3000 是 Gogs 运行的端口 proxy_pass http://localhost:3000; &#125;&#125; 如我设置的是 100m 大小。 之后，重启nginx服务即可：sudo systemctl reload nginx 。 One More Thing…根据以上遇到的问题，这里主要提一点： 但凡是SSH相关的问题，就是要保证目录 /home/git/.ssh 具有 0700 的权限，目录 /home/git/.ssh/ 下的文件具有 0600 的权限。 或者直接尝试如下操作: 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run 按钮，如果报错：open /home/git/.ssh/authorized_keys.tmp: permission denied 。否则直接跳至步骤5。 查看日志 gogs.log 文件，发现错误信息：AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 。 进入容器内部：docker exec -it gogs /bin/bash ,切换至git用户：su git,然后进入 /home/git/ 目录，更改 .ssh 目录权限：chmod 0700 .ssh 。（此时，该 .ssh 目录内为空） 然后再次访问 /admin 页面，再次执行 Run 操作，提示“所有公钥重新生成成功！”信息。查看容器内的 .ssh/ 目录下生成了一个 authorized_keys 文件。然后更改该文件权限：chmod 0600 authorized_keys 。 最后重启该容器。]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Gogs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs部署gogs容器过程记录]]></title>
    <url>%2F2017%2F03%2F23%2Fdocker-ubuntu-gogs-deploy%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 Docker-Ubuntu-Gogs 系列文章主要记录我在Docker下部署Gogs代码管理项目的过程。系列文章包括Gogs容器的部署过程，部署时遇到的问题及解决方法，个性化配置等。 这里底层系统选择了 Ubuntu16.04 版本，之前也曾尝试在 Alpine 系统下来部署Gogs，但安装完成后会报 ./gogs web is not found 之类的错误，暂未找到解决方法。遂最后决定采用Ubuntu来部署。 对于 Alpine 系统下的部署方法，待后期再来完善。 另外，Gogs作者在Github中发布的Gogs容器版本是用Alpine系统来做的，如果比较在意容器的大小，可以直接用之。 测试操作步骤操作记录：Ubuntu16.04 系统 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768docker run -it --name ugg1 -p 3000:3000 -p 8080:22 ubuntu /bin/bashRUN echo "deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse" &gt;&gt; /etc/apt/sources.listapt-get updateapt-get install -y git wget openssh-serveradduser git (and set pwd git)# 拷贝本地的gogs项目zip包到容器中docker cp linux_amd64.zip ugg1:/home/git/gogs.zipunzip gogs.zip#***************cd gogsmkdir -p custom/confmkdir -p logchmod -R 777 customchmod -R 777 logcd ..chown -R git:git gogs#*******************# gosudocker cp gosu-amd64 ugg1:/usr/local/bin/gosuchmod +x /usr/local/bin/gosu# 启动项目cd gogs./gogs web# 启动ssh服务（之前测试时把这项丢了，所以ssh功能一直无法使用）service ssh start service ssh restartgosu git /home/git/gogs/gogs web# 项目文件目录/app gogs-repositories gogs log ssh conf data# 创建数据文件mkdir -p /app/gogs-repositories /app/gogs/log /app/gogs/ssh /app/gogs/data /app/gogs/confchown -R git:git /appln -sf /home/git/gogs/custom/conf/app.ini /app/gogs/conf/app.inichown -R git:git /app$ docker run --name ugg1 -d -p 3002:3000 -p 8090:22 -v /home/tiger/xdk/dfile:/app gg1 123# Link volumed data with app dataln -sf /data/gogs/log ./logln -sf /data/gogs/data ./data 参考自gogs官方github中的dockerfile，使用gosu调用git用户： 12export USER=gitexec gosu $USER /app/gogs/gogs web 问题一：不能使用 gosu 调用 git 用户来启动发现不能使用 gosu 调用 git 用户来启动，gosu git /home/git/gogs/gogs web 会报如下错误： 1gogs 运行系统用户非当前用户：git &gt; 不推荐的解决方法是： 切换到git账户下执行：su - git $ ./gogs web 通过测试，可以采用如下的方式来使用 gosu 调用 git 用户（参考自gogs官方github中的dockerfile）： 12export USER=gitexec gosu $USER /app/gogs/gogs web 问题二：Fail to start SSH server: listen tcp 0.0.0.0:22: bind: permission denied启用内置SSH服务器会报该错误，暂未找到解决方法。 通过测试，将默认的 22 端口改成其他端口即可。 但是 gogs官方的docker配置中建议不要在Docker容器中使用内置的SSH服务器。 问题三：PANIC: session(start): mkdir data: permission denied详细错误信息如下： 1234567891011[Macaron] 2017-03-21 06:05:40: Started GET / for 192.168.137.1[Macaron] PANIC: session(start): mkdir data: permission denied/usr/local/go/src/runtime/panic.go:489 (0x4340bf)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/session/session.go:156 (0x8f478e)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:79 (0x89ba01)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/inject/inject.go:157 (0x87dc92)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/inject/inject.go:135 (0x87da8b)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:121 (0x89bc62)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:112 (0x89bb86)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/recovery.go:161 (0x8af50b)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/logger.go:40 (0x89f118) 该问题导致的原因是，当 git 用户运行 ./gogs web 时，会在 gogs 项目的主目录下 ( 这里是 /home/git/gogs）创建一个 data 目录用于存放session缓存等临时文件。如果当前工作的主目录不是在 /home/git/gogs 目录，则git账户就没有权限来创建目录，从而导致权限错误。解决方法是在Dockerfile中指定工作目录 WORKDIR /home/git/gogs 即可。 后经查证，在 Gogs 项目目录下的 custom data 和 log 三个目录是用来存放项目运行期间产生的日志、配置文件、数据等信息的。当Gogs项目需要升级时，直接拷贝这三个目录到新项目目录下即可。这里的 data 目录需要提前创建好。 相关参考 在ubuntu上安装gogs 用Gogs搭建自己的Git服务器 - LibHappy How To Set Up Gogs on Ubuntu 14.04 | DigitalOcean chmod 777 修改权限 - 日光之下无新事 - 博客园 linux - 安装gogs时报错：运行系统用户非当前用户：git -&gt; root。 不知道是什么意思 - SegmentFault Install时注意事项 Database Type 选择 SQLite3 （目前仅测试了sqlite3数据库） Sqlite Database Path 使用固定路径 /app/gogs/data/gogs.db （后期改成默认目录也可以，详见Github） Repository Root Path 使用固定路径 /app/gogs-repositories Run User 使用默认的 git Domain 填写Docker宿主机的主机名或物理地址 类似于 192.168.137.140 SSH Port 不要勾选使用内置SSH服务器（Don’t user Use Builtin SSH Server） 如果你映射Docker外部端口如 10022:22 那么这里填写 10022 HTTP Port 如果映射外部端口 10080:3000 这里仍然使用 3000 Application URL 使用域和公开的HTTP端口值的组合 如 http://192.168.137.140:10080 Log Path 填写固定路径 /app/gogs/log （后期改成默认目录也可以，详见Github） 注意： Dockerfile中必需添加 WORKDIR /home/git/gogs 即必需指定当前工作目录为 gogs 目录下，因为gogs在install完成后会在当前目录下创建一个 data 目录保存 sessions 信息。如果当前目录不是这里，则会报 [Macaron] PANIC: session(start): mkdir data: permission denied 的错误。 成果最终项目见：GitHub - Leafney/ubuntu-gogs: Docker + Ubuntu + Gogs]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Gogs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker下配置Elasticsearch容器过程记录]]></title>
    <url>%2F2017%2F03%2F22%2Felasticsearch-container-in-alpine%2F</url>
    <content type="text"><![CDATA[主要记录 Elasticsearch 容器创建流程 目标 Elasticsearch 2.4.x Elasticsearch 5.x alpine 下配置java环境参考自 https://github.com/docker-library/openjdk/blob/master/8-jdk/alpine/Dockerfile 后期创建一个java环境的基础容器。 测试记录下载 elasticsearch.tar.gz 文件并解压到指定目录： 1$ curl -sSL https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz | tar -zxv -C /usr/share/elasticsearch --strip-components 1 只在 docker run 时执行安装 elasticsearch-analysis-ik 插件在 dockerfile 中的 ENTRYPOINT 命令会在 docker run 或 docker restart 时都执行，这样就导致重复安装插件的问题。 目前采用的方法是在 shell script 文件中 通过判断 plugins 目录下是否存在 elasticsearch-analysis-ik-${IK_ANALYSIS_VERSION}.zip 文件来判断是否已经添加该插件。 另一种方式: 考虑通过 docker exec 在容器启动后来安装。 使用 docker exec 命令执行 shell script 时，有一个疑惑：需要执行的 shell script 文件应该放在容器内部还是可以调用外部即宿主机上的。(后经测试，放在容器内部。) Elasticsearch 集群其中有一台被作为Master，其他为Slave。 配置 elasticsearch.yml （注意配置文件冒号“：”后要有一个空格，否则报错） 12345678910network.host: 10.0.0.1cluster.name: elasticsearch # 集群名称node.name: es-node1 # 节点名称 （同一集群下多个节点名称不同）bootstrap.mlockall: true # node.master: true # 是否作为主节点，每个节点都可以被配置成为主节点，默认值为truenode.data: true # 是否存储数据，即存储索引片段，默认值为truediscovery.zen.ping.unicast.hosts: [&quot;10.0.0.1:9300&quot;, &quot;10.0.0.2:9300&quot;]discovery.zen.minimum_master_nodes: 2 1234567network.host: [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]cluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125; # es_node_1discovery.zen.ping.unicast.hosts: [&quot;10.0.0.1&quot;, &quot;10.0.0.2&quot;, &quot;10.0.0.3&quot;]node.master: truenode.data: false 如何指定自定义配置文件自定义配置文件和默认配置文件的关系指定 配置文件路径： ./bin/elasticsearch -Des.path.conf=/my/conf.yaml 注意： Des.config=/path/to/config/file doesn’t replace $ES_HOME/elasticsearch.conf, just appends to it 详见：-Des.config=/path/to/config/file doesn&#39;t replace $ES_HOME/elasticsearch.conf, just appends to it · Issue #588 · elastic/elasticsearch · GitHub ES 2.4.0 使用如下方式启动 CMD gosu elasticsearch elasticsearch -Epath.conf=&quot;${ELASTICSEARCH_DATA}/config/elastic.yml&quot; 报下面的错误： 1ERROR: Parameter [-Epath.conf=&quot;$&#123;ELASTICSEARCH_DATA&#125;/config/elastic.yml&quot;]does not start with -- 123-Des.path.confbin/elasticsearch -Des.path.conf=/etc/elasticsearch/node1 总结 ：使用 --path.conf=configdir 来指定配置文件所在目录，并且配置文件必需命名为 elasticsearch.yml 才可以。 1$ ./bin/elasticsearch --path.conf=/path/to/conf/dir 详细分析过程如下： 报错分析启动时报如下错误： 12345678910111213141516/ # gosu elasticsearch elasticsearch -Des.path.conf=/app/config/elastic.ymllog4j:WARN No appenders could be found for logger (bootstrap).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.Exception in thread &quot;main&quot; java.lang.IllegalStateException: Unable to access &apos;path.conf&apos; (/app/config/elastic.yml)Likely root cause: java.nio.file.NotDirectoryException: /app/config/elastic.yml at org.elasticsearch.bootstrap.Security.ensureDirectoryExists(Security.java:340) at org.elasticsearch.bootstrap.Security.addPath(Security.java:314) at org.elasticsearch.bootstrap.Security.addFilePermissions(Security.java:247) at org.elasticsearch.bootstrap.Security.createPermissions(Security.java:212) at org.elasticsearch.bootstrap.Security.configure(Security.java:118) at org.elasticsearch.bootstrap.Bootstrap.setupSecurity(Bootstrap.java:212) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:183) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:286) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 解决方法： 找到一个讨论中的回答： 123It is no longer possible to specify a custom config file with the CONF_FILE environment variable, or the -Des.config, -Des.default.config, or -Delasticsearch.config parameters.Instead, the config file must be named elasticsearch.yml and must be located in the default config/ directory, unless a custom config directory is specified. Problem in starting a node in ES 2.2.1 - Elasticsearch - Discuss the Elastic Stack Setting changes | Elasticsearch Reference 2.2 | Elastic 找到解决方案： 从文章 Setting changes | Elasticsearch Reference 2.4 中这段： Custom config fileeditIt is no longer possible to specify a custom config file with the CONF_FILE environment variable, or the -Des.config, -Des.default.config, or -Delasticsearch.config parameters.Instead, the config file must be named elasticsearch.yml and must be located in the default config/ directory, unless a custom config directory is specified.The location of a custom config directory may be specified as follows:./bin/elasticsearch –path.conf=/path/to/conf/dir./bin/plugin -Des.path.conf=/path/to/conf/dir install analysis-icuWhen using the RPM or debian packages, the plugin script and the init/service scripts will consult &gt; the CONF_DIR environment variable to check for a custom config location. The value of the CONF_DIR &gt; variable can be set in the environment config file which is located either in /etc/default/elasticsearch or /etc/sysconfig/elasticsearch. 得知，之前的自定义配置文件方法 -Des.path.conf 改为了这种方式 --path.conf ，而且，只需要指定到配置文件所在目录即可。另外，配置文件的名称必须为 elasticsearch.yml 。 1$ gosu elasticsearch elasticsearch --path.conf=/app/config network.host 同时支持 IPV4 和 IPV6 报错报如下错误： 1234567891011Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: bind address: &#123;0.0.0.0&#125; is wildcard, but multiple addresses specified: this makes no sense at org.elasticsearch.common.network.NetworkService.resolveBindHostAddresses(NetworkService.java:132) at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:435) at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:332) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68) at org.elasticsearch.transport.TransportService.doStart(TransportService.java:182) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68) at org.elasticsearch.node.Node.start(Node.java:278) at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:222) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:288) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35) 配置文件内容： 123456789101112# defaultnetwork.host: [&quot;0.0.0.0&quot;, &quot;[::1]&quot;]path.data: /app/datapath.logs: /app/logs# clustercluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125;node.master: truenode.data: true# bootstrap.mlockall: truediscovery.zen.ping.unicast.hosts: [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;] 改为 network.host: 0.0.0.0 后 启动成功。 可查看该讨论: Binding to the wildcard of one address family should not prevent binding to addresses in another family · Issue #20703 · elastic/elasticsearch · GitHub 当加上 bootstrap.mlockall: true 这行时，也会报错。 待探究原因！！！ elasticsearch cluster 配置 unicast.hosts探究上面的配置文件中，设置的 unicast.hosts 值如下 ： 1234discovery.zen.ping.unicast.hosts: [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;]discovery.zen.ping.unicast.hosts: [&quot;172.17.0.4:9300&quot;, &quot;172.17.0.5:9301&quot;] 经测试，使用 [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;] 无效。必须使用明确的IP地址 [&quot;172.17.0.4:9300&quot;, &quot;172.17.0.5:9301&quot;] 后才能互相发现。 通过 访问 http://59.188.76.112:9200/_cluster/health?pretty 能看到是否组成集群模式： 1234567891011121314151617&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 0, &quot;active_shards&quot;: 0, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0, &quot;delayed_unassigned_shards&quot;: 0, &quot;number_of_pending_tasks&quot;: 0, &quot;number_of_in_flight_fetch&quot;: 0, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;active_shards_percent_as_number&quot;: 100&#125; 考虑到Docker下容器的ip地址是随机的，容器重启后可能会改变，需要考虑其他确定的方式。 设置成 localhost 参考自 如何使用一个IP搭建ES集群——Docker如你所愿 - 简书 可能的一种方法是在 docker run 时 指定 --add-host=[] 参数 ，待研究！！！ 经测试，使用 localhsot 127.0.0.1 0.0.0.0 docker name 均无效。 经测试，可以设置为相应容器的IP 如 172.17.0.5:9300 。通过命令 : 1docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; $CONTAINER_ID 可以获得指定容器的ip地址。但这里的问题是 容器的ip每次重启后都会改变，知道容器ip没什么意义。所以这种方式也失败。 如果不指定容器的IP,但可以指定容器所在宿主机的IP 120.121.xx.xx:9300 ，这样能发现集群。 以下issure中，可以通过docker-compores 来指定容器ip ：待研究！！！ Cannot set up an elasticsearch:2 cluster in docker any more · Issue #68 · docker-library/elasticsearch · GitHub Problems in getting single node cluster working as per your docs · Issue #19 · spujadas/elk-docker · GitHub 另外一种方式，通过 --link 来设置：参考自：dockerfiles/elasticsearch at master · itzg/dockerfiles · GitHub 123456789docker run --name es5 -d -p 9230:9200 -p 9330:9300 e2docker run --name es6 -d --link es5 e2docker run --name es7 -d --link es5 e2docker cp elasticsearch.yml es5:/app/config/elasticsearch.ymldocker cp elasticsearch.yml es6:/app/config/elasticsearch.ymldocker cp elasticsearch.yml es7:/app/config/elasticsearch.ymldocker restart es5 es6 es7 配置文件： 1234567891011# defaultnetwork.host: 0.0.0.0path.data: /app/datapath.logs: /app/logs# clustercluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125;node.master: truenode.data: truediscovery.zen.ping.unicast.hosts: [&quot;es5:9330&quot;] 这种方式经测试，无效。 报如下错误： 12345678910111213java.net.NoRouteToHostException: Host is unreachable at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152) at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Docker elasticsearch 集群 https://hub.docker.com/r/itzg/elasticsearch/ https://github.com/Khezen/docker-elasticsearch/tree/2.4 看到网上大部分人都是将集群配置参数通过环境变量的形式在 docker run 时配置，考虑将配置文件暴露在主机目录下是否安全？ 查看集群状态查看集群状态: curl -XGET &#39;http://172.16.212.102:9200/_cluster/health?pretty&#39; 相关参考Elasticsearch集群搭建相关参考 ElasticSearch集群部署文档 elasticsearch2.3.1 集群安装 - 尚浩宇的博客 五角星 配置 How To Set Up a Production Elasticsearch Cluster on Ubuntu 14.04 | DigitalOcean Easy Elasticsearch cluster with docker 1.12 swarm? - General - Docker Forums Running an Elasticsearch cluster with Docker 如何使用一个IP搭建ES集群——Docker如你所愿 - 简书 五角星 docker-elasticsearch-cn/docker-start at master · hangxin1940/docker-elasticsearch-cn · GitHub elasticsearch 集群 宿主机上如何获得 docker container 容器的 ip 地址？ - SegmentFault Elasticsearch容器创建相关参考 GitHub - soldair/docker-alpine-elasticsearch: 130mb ish Elasticsearch container based on alpine linux. GitHub - docker-library/elasticsearch: Docker Official Image packaging for elasticsearch GitHub - kiasaki/docker-alpine-elasticsearch: ElasticSearch container based on Alpine Linux GitHub - docker-library/openjdk: Docker Official Image packaging for Java (openJDK) docker elasticsearch GitHub - itzg/dockerfiles: Contains the various Dockerfile definitions I&#39;m maintaining. 成果源码见：GitHub - Leafney/alpine-elasticsearch: Docker + Alpine + Elasticsearch]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用SSH密钥连接Github]]></title>
    <url>%2F2017%2F03%2F03%2Fusing-ssh-key-connection-github-in-linux%2F</url>
    <content type="text"><![CDATA[在 Linux 系统下如何通过 SSH 密钥来连接 GitHub (Mac系统下设置方法相同)。 引申 Linux下 ：Linux下使用SSH密钥连接Github Windows下：使用SSH密钥连接Github Ubuntu 系统初始化配置git环境测试系统版本 : Ubuntu 16.04 LTS 更新软件源123$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list &amp;&amp; \echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list &amp;&amp; \echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 安装git依赖12$ apt-get update$ apt-get install git 设置时区123$ ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime$ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone$ dpkg-reconfigure -f noninteractive tzdata Alpine 系统初始化配置git环境测试系统版本 : Alpine 3.5 更新软件源12$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.5/main&quot; &gt;&gt; /etc/apk/repositories$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.5/community&quot; &gt;&gt; /etc/apk/repositories 安装依赖The ssh-keygen command is part of OpenSSH (package “openssh”). 12$ apk update$ apk add git openssh 设置时区123$ apk add tzdata$ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime$ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone Mac 系统初始化配置git环境Mac系统上安装git,可以直接从git网站下载安装包,访问 Git - Downloads 安装. 也可以通过 homebrew 进行安装: 1$ brew install git 设置git账户执行如下两条命令设置git账户的用户名和密码： 1234$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;youremail@domain.com&quot;$ git config --list 生成SSH公钥SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。先确认是否已经有一个公钥了： 12$ cd ~/.ssh/bin/sh: cd: can&apos;t cd to /root/.ssh 主要是看是否存在 id_dsa 或 id_rsa 文件。有 .pub 后缀的文件就是 公钥，另一个文件则是密钥。 创建新的SSH密钥如果已经存在公钥，可跳过这步。如果没有，使用 ssh-keygen 来创建： 12$ cd ~$ ssh-keygen -t rsa -C &quot;youremail@domain.com&quot; 示例：(xxxxxx@126.com 为我的账户邮箱) 12345678910111213141516171819202122~ # ssh-keygen -t rsa -C &quot;xxxxxx@126.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): # 直接回车，则将密钥按默认路径及文件名进行存储。此时也可以输入特定的文件名Created directory &apos;/root/.ssh&apos;.Enter passphrase (empty for no passphrase): # 根据提示，你需要输入密码和确认密码。可以不填，设置为空值，直接回车Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:yFt14TcP0H+ixy9VKiILPPJ6DVevkKgrbxVFqk7mn5k xxxxxx@126.comThe key&apos;s randomart image is:+---[RSA 2048]----+| o. || . . o. || o . o +. || .... ... ..++|| . o .So . o+|| + o Bo= . + + .|| = *.* + o o || ++o o o . . .|| E=++ . |+----[SHA256]-----+ 查看生成的文件： 123$ cd ~/.ssh~/.ssh $ lsid_rsa id_rsa.pub 文件 id_rsa.pub 就是公钥。 在 GibHub 中添加你的公钥复制公钥 id_rsa.pub 文件中的内容。 我这里使用 XShell 来登录的linux服务器，可以直接复制出来。或在 vim 下，可通过命令 ggVG 全选，+y 复制选中内容到+寄存器，也就是系统的剪贴板，供其他程序使用。 登陆Github网站，选择 Settings –&gt; SSH and GPG keys 菜单，点击 New SSH key 按钮。粘贴你的密钥到 Key 输入框中并设置 Title 信息，点击 Add SSH key 按钮完成。 连接测试测试 SSH keys 是否设置成功，执行如下命令： 1$ ssh -T git@github.com 当提示如下信息时，说明正常连通了github: 1Hi xxxxxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 如果你是第一次设置连接github.com,会询问你是否继续,输入 yes 即可,这样就会将连接地址记录在本地: 123456$ ssh -T git@github.comThe authenticity of host &apos;github.com (192.30.253.112)&apos; can&apos;t be established.RSA key fingerprint is SHA256:nThbg6kXUpxxxxxxxxARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;github.com,192.30.253.112&apos; (RSA) to the list of known hosts.Hi xxxxxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 然后就可以将本地的项目用github来管理了。 更新日志 2017-10-27 - 完善”连接测试”内容; 添加Mac系统下安装git配置]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>GitHub</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下修改时区]]></title>
    <url>%2F2017%2F02%2F23%2Fmodify-timezone%2F</url>
    <content type="text"><![CDATA[一般通过默认方式安装的linux系统显示的都是UTC时间，这样导致一些依赖时间的程序就会出现时差问题。下面介绍在Ubuntu和Alpine系统下如何更改UTC时区为CST时区。 Alpinealpine 下修改UTC时间为CST时间 (测试通过)123$ apk add tzdata $ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime $ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone Docker + Alpine 下修改utc时间为cst时间Dockerfile : 1234RUN apk update &amp;&amp; apk add ca-certificates &amp;&amp; \ apk add tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone UbuntuUbuntu 下手动修改配置 (图形化界面)1$ sudo dpkg-reconfigure tzdata 或： 1$ sudo tzselect Ubuntu下通过命令更改（已测试）123$ sudo ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime$ sudo echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone$ sudo dpkg-reconfigure -f noninteractive tzdata 经测试，如果不加第一行，系统重启后又恢复UTC时间了 Docker + Ubuntu 下修改UTC时间为CST时间Dockerfile: 1234# Setting timezoneRUN ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone &amp;&amp; \ dpkg-reconfigure -f noninteractive tzdata 相关参考 docker 中设置时区 | 水能载舟 亦可赛艇 Ubuntu: 以命令行方式修改时区 docker 中设置时区 - 作业部落 Cmd Markdown 编辑阅读器]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04配置RabbitMQ运行环境]]></title>
    <url>%2F2017%2F02%2F21%2Finstallation-rabbitmq-on-ubuntu%2F</url>
    <content type="text"><![CDATA[该文章主要记录在 Ubuntu 16.04.1 LTS 系统下安装及配置 RabbitMQ 的方法。 更新软件源1234sudo echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt; /etc/apt/sources.listsudo echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.listsudo apt-get update 安装Erlang依赖123456cd /tmpwget http://packages.erlang-solutions.com/ubuntu/erlang_solutions.ascsudo apt-key add erlang_solutions.ascsudo apt-get updatesudo apt-get install erlangsudo apt-get install erlang-nox 安装RabbitMQ12345sudo echo &quot;deb http://www.rabbitmq.com/debian/ testing main&quot; &gt;&gt; /etc/apt/sources.listsudo wget https://www.rabbitmq.com/rabbitmq-release-signing-key.ascsudo apt-key add rabbitmq-release-signing-key.ascsudo apt-get updatesudo apt-get install rabbitmq-server 管理RabbitMQ服务管理服务可以使用 rabbitmqctl 或系统服务 service 或者 systemctl 来管理. rabbitmqctl : 1$ sudo rabbitmqctl [status|start|stop|reset] systemctl : 1$ sudo systemctl [status|start|stop|restart] rabbitmq-server service : 1$ sudo service rabbitmq-server [status|start|stop|restart] 如果 status 状态显示无法连接rabbitmq服务，需要先启动该服务。 12345678910111213141516171819202122$ sudo rabbitmqctl statusStatus of node rabbit@localhost ...Error: unable to connect to node rabbit@localhost: nodedown$ sudo rabbitmqctl start# 或者$ sudo service rabbitmq-server start/restart$ sudo rabbitmqctl statusStatus of node rabbit@localhost ...[&#123;pid,9286&#125;, &#123;running_applications,[&#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.6.6&quot;&#125;, &#123;mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.13.3&quot;&#125;, &#123;os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.4&quot;&#125;, &#123;rabbit_common,[],&quot;3.6.6&quot;&#125;, &#123;xmerl,&quot;XML parser&quot;,&quot;1.3.10&quot;&#125;, &#123;ranch,&quot;Socket acceptor pool for TCP protocols.&quot;, &quot;1.2.1&quot;&#125;, ... ... 在Docker下管理注意：在Ubuntu系统的 Docker 下 ，使用 systemctl 命令会报错，所以在docker下还是推荐使用 service 来管理。 12345678910111213141516root@6b16517eab27:/tmp# systemctlFailed to connect to bus: No such file or directoryroot@6b16517eab27:/tmp# service rabbitmq-server statusStatus of node rabbit@6b16517eab27 ...[&#123;pid,12184&#125;, &#123;running_applications, [&#123;rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.6.6&quot;&#125;, &#123;webmachine,&quot;webmachine&quot;,&quot;1.10.3&quot;&#125;, &#123;mochiweb,&quot;MochiMedia Web Server&quot;,&quot;2.13.1&quot;&#125;, &#123;amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.6.6&quot;&#125;, ... ... So the systemctl can not run inside docker, right? thanks! Running systemctl in container fails with &quot;Failed to get D-Bus connection&quot; · Issue #2296 · docker/docker · GitHub systemd and systemctl within Ubuntu Docker images - Stack Overflow RabbitMQ Web管理接口启用rabbitmq-management启用rabbitmq-management插件： 1$ sudo rabbitmq-plugins enable rabbitmq_management 12345678910$ sudo rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@6b16517eab27... started 6 plugins. 重启RabbitMQ: 1$ sudo systemctl restart rabbitmq-server 使用浏览器访问 http://localhost:15672 ，使用默认的 guest/guest 用户登录。 使用guest账户远程访问注意：使用远程访问或在Ubuntu系统的Docker下使用所在服务器的地址访问时会报权限错误： 1&#123;error: &quot;not_authorised&quot;, reason: &quot;User can only log in via localhost&quot;&#125; 这是因为 rabbitmq从3.3.0开始禁止使用 guest/guest 权限通过除 localhost 外的访问。 如果想使用 guest/guest 通过远程机器访问，需要在rabbitmq配置文件 (/etc/rabbitmq/rabbitmq.config) 中设置 loopback_users为[] 。 /etc/rabbitmq/rabbitmq.config (不存在先创建) 文件完整内容如下（注意后面的半角句号）： 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 操作步骤如下： 1234567# ls /etc/rabbitmq/enabled_plugins$ sudo vim /etc/rabbitmq/rabbitmq.config [&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].$ sudo service rabbitmq-server restart 创建新账户如果不想使用默认的 guest 账户，可以创建一个新的具有管理员权限的账户，如创建一个 test/test 账户操作如下： 123rabbitmqctl add_user test testrabbitmqctl set_user_tags test administratorrabbitmqctl set_permissions -p / test &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; RabbitMQ - Access Control (Authentication, Authorisation) in RabbitMQ Can&#39;t access RabbitMQ web management interface after fresh install - Stack Overflow RabbitMQ 3.3.1 can not login with guest/guest - Stack Overflow rabbitmq问题之HTTP access denied: user &#39;guest&#39; - User can only log in via localhost - 布雷泽 - 博客园 相关链接 How To Install RabbitMQ on Ubuntu 16.04 - idroot Ubuntu 16.04 安装 RabbitMQ]]></content>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git使用技巧整理]]></title>
    <url>%2F2017%2F02%2F07%2Fgit-use-skills%2F</url>
    <content type="text"><![CDATA[一次添加多个文件1$ git add . 为什么用 . 不用 * In order to add the files that are not in the gitignore file, use git add . in the place of git add * This will stop confusing the unix system since means all ( including the ignored ones ) while . means the ones relative to the active action 强制添加文件1git add -f aaa.exe 一般在添加一个被忽略的文件时，会提示如下错误： 1234$ git add phantomjs.exeThe following paths are ignored by one of your .gitignore files:phantomjs.exeUse -f if you really want to add them. 遇到这种情况时候需要使用 git add -f 命令强制添加这个文件。 详见：git强制添加(add)文件]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04安装Docker及配置镜像加速器]]></title>
    <url>%2F2017%2F01%2F14%2Fubuntu-install-docker-and-configure-mirror-accelerator%2F</url>
    <content type="text"><![CDATA[最近将虚拟机中的Ubuntu系统从14.04更新到了16.04.1版本，又要重新安装Docker服务，在安装的时候发现Docker的官方安装教程又有了更新，之前的安装方法已经过时。 过时的安装方法之前官网中提供的安装方法为： 1$ curl -sSL https://get.docker.com/ | sudo sh 现在如果再执行该命令，会直接报错。 官方推荐安装方法查看系统内核Docker需要安装在Linux 64位系统下，内核版本在 3.10 以上。可以通过 uname -r 来查看内核信息： 12$ uname -r4.4.0-31-generic 更新源，安装CA证书12$ sudo apt-get update$ sudo apt-get install apt-transport-https ca-certificates 导入 GPG 密钥123$ sudo apt-key adv \ --keyserver hkp://ha.pool.sks-keyservers.net:80 \ --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 添加docker源根据当前系统版本，添加docker源命令： 1$ echo &quot;&lt;REPO&gt;&quot; | sudo tee /etc/apt/sources.list.d/docker.list 只要将 &lt;REPO&gt; 替换成相应系统的源地址即可。 我这里当前系统Ubuntu16.04，源地址为：deb https://apt.dockerproject.org/repo ubuntu-xenial main，所以只需如下命令： 1$ echo &quot;deb https://apt.dockerproject.org/repo ubuntu-xenial main&quot; | sudo tee /etc/apt/sources.list.d/docker.list 其他版本系统源地址如下： Ubuntu version Repository Precise 12.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-precise main Trusty 14.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-trusty main Wily 15.10 deb https://apt.dockerproject.org/repo ubuntu-wily main Xenial 16.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-xenial main 更新源列表1$ sudo apt-get update 验证 APT 能否正确获取执行如下命令会从docker官方仓库中列出所有docker的可安装版本： 12345678910111213141516$ apt-cache policy docker-enginedocker-engine: Installed: null Candidate: 1.12.6-0~ubuntu-xenial Version table: *** 1.12.6-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 100 /var/lib/dpkg/status 1.12.5-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 1.12.4-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 1.12.3-0~xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages ... ... 安装docker默认会安装推荐的版本 Candidate 项列出的，也是最新的版本 1$ sudo apt-get install -y docker-engine 启动docker服务1$ sudo service docker start 验证在命令行下输入 docker ,如提示docker的 [OPTIONS] 说明，则表示docker服务已经安装成功了。 12345678910111213141516171819$ dockerUsage: docker [OPTIONS] COMMAND [arg...] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file ... ... 将当前用户添加到docker的用户组Docker安装成功后，如果想查看docker的信息，执行 docker info 命令时可能会提示如下信息： 12$ docker infoCannot connect to the Docker daemon. Is the docker daemon running on this host? 这是因为必需以管理员权限或使用 sudo 来运行命令才可以。为了以后执行命令时不用每次都必需添加 sudo，可以将当前用户加入到docker用户组中。 创建 docker 分组1$ sudo groupadd docker 将当前用户添加到组1$ sudo usermod -aG docker $USER 注意：这里不用更改 $USER 这个参数，$USER 这个环境变量就是指当前用户名 重启系统更改完成后，还需要重启系统才能看到效果。 1$ sudo reboot 创建一个测试容器可通过如下命令来创建一个测试容器： 1$ docker run hello-world 输出： 123Hello from Docker.This message shows that your installation appears to be working correctly.... 配置阿里云Docker镜像加速器打开 开发者平台 – 管理中心 – 加速器 。可以看到 “您的专属加速器地址” 即 https://xxxxxxx.mirror.aliyuncs.com 。 注意：这里以 Ubuntu 16.04 系统为例，其他系统请到上述页面中查看相应操作命令。 配置Docker加速器通过 docker info 命令可以知道上面安装好的Docker的版本为 1.12.6 。所以请通过修改daemon配置文件 /etc/docker/daemon.json (没有时新建该文件) 来使用加速器： 12345678910sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxxxx.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 注意事项针对于Docker版本在1.10以下的情况，可以使用如下的配置方法： 12345678sudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/mirror.conf &lt;&lt;-&apos;EOF&apos;[Service]ExecStart=/usr/bin/docker daemon -H fd:// --registry-mirror=https://xxxxxxx.mirror.aliyuncs.comEOFsudo systemctl daemon-reloadsudo systemctl restart docker 但是该方法并不适用于1.12.0版本之后的Docker上。因为Docker的可执行文件名称从 docker 改成了 dockerd。如果使用了以上脚本，可能会报如下的错误： 12$ sudo systemctl restart dockerJob for docker.service failed because the control process exited with error code. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details. 所以在配置加速器时一定要按照相应版本来设置。 还要注意一点：上文代码段中给出的镜像加速器地址中的 xxxxxxx 为阿里云在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关参考 Install Docker on Ubuntu - Docker How To Install and Use Docker on Ubuntu 16.04 | DigitalOcean ubuntu16.04安装docker - 程序园 Ubuntu 16.04安装docker加速器后无法启动docker-问答-云栖社区-阿里云]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Flask中使用SQLAlchemy]]></title>
    <url>%2F2017%2F01%2F06%2Fuse-sqlalchemy-by-flask%2F</url>
    <content type="text"><![CDATA[在Flask中使用SQLAlchemy操作数据库。 安装 flask-sqlalchemy1$ pip install flask 1$ pip install flask-sqlalchemy 基础你所有模型的基类叫做 db.Model 。它存储在你必须创建的 SQLAlchemy 实例上。 在 Flask-sqlalchemy中，表名已自动设置好，除非自己重载它：eg: 1__tablename__ = &apos;students&apos; #指定表名 Column类型 类型名 Python 类型 说明 Integer int 整数 String(size) str 有最大长度的字符串 Text str 长 unicode 文本 Float float 存储浮点值 Boolean bool 存储布尔值 Date datetime.date 日期 Time datetime.time 时间 DateTime datetime.datetime 日期和时间 PickleType 任何python对象 存储一个持久化 Python 对象 LargeBinary str 存储任意大的二进制数据 常用字段 选项名 说明 示例 primary_key 设置主键 primary_key=True unique 是否唯一 unique=True index 是否创建索引 index=True nullable 是否允许为空 nullable=True default 设置默认值 default=datetime.datetime.utcnow 更详细的配置可参考 Flask Web Development —— 数据库（上） - young - SegmentFault 连接URI格式1dialect+driver://username:password@host:port/database Mysql mysql://scott:tiger@localhost/mydatabase Postgres postgresql://scott:tiger@localhost/mydatabase SQLite sqlite:////absolute/path/to/foo.db Flask-SQLAlchemy Sqlite连接路径问题1sqlite:////tmp/test.db Sqlite连接字符串中的/斜杠说明：三斜杠为相对路径，四斜杠为绝对路径。 12&apos;sqlite:////tmp/test.db&apos; #表示指向绝对路径在Ｔｍｐ目录的test.db文件&apos;sqlite:///Data/test.db&apos; #表示指向相对路径在当前Py文件同目录的Data目录下test.db文件 Flask小记一：Flask-SQLAlchemy Sqlite连接路径问题 - 不折腾难受斯基 过滤器 过滤器 说明 filter 把过滤器添加到原查询上，返回一个新查询 filter_by 把等值过滤器添加到原查询上，返回一个新查询 limit 使用指定的值限制返回的结果数量，返回一个新查询 offset 便宜原查询返回的结果， 返回一个新查询 order_by 根据指定条件对原查询结果进行排序，返回一个新查询 group_by 根据指定条件对原查询结构进行分组，返回一个新查询 执行器 方法 说明 all 以列表形式返回查询的所有结果 first 返回查询的第一个结果，如果没有结果，则返回 None first_or_404 返回查询的第一个结果，如果没有结果，则终止请求，返回 404 错误输出 get 返回指定主键对应的行，如果没有对应的行，则返回 None get_or_404 返回指定主键对应的行，如果没找到指定的主键，则终止请求，返回 404 错误输出 count 返回查询结果的数量 paginate 返回一个 Paginate 对象，它包含指定范围内的结果 简单示例入门示例参考自官方入门教程示例代码 Quickstart Flask-SQLAlchemy Documentation (2.1) flsksql.py 1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyapp=Flask(__name__)app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;]=&apos;sqlite:///test.db&apos; # 连接当前项目同目录下的test.db数据库文件app.config[&apos;SQLALCHEMY_TRACK_MODIFICATIONS&apos;]=Truedb=SQLAlchemy(app)class User(db.Model): &quot;&quot;&quot;docstring for User&quot;&quot;&quot; __tablename__=&apos;users&apos; id=db.Column(db.Integer,primary_key=True) username=db.Column(db.String(80),unique=True) email=db.Column(db.String(64),unique=True) def __init__(self, username,email): self.username=username self.email=email def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.username app.py 123456789101112131415161718192021222324252627282930313233343536373839404142# coding:utf-8from flask import Flaskfrom flsksql import dbfrom flsksql import Userif __name__ == &apos;__main__&apos;: # 初始化数据库 # db.create_all() # 新增 # user1=User(&apos;abc&apos;,&apos;abc@124.com&apos;) # user2=User(&apos;def&apos;,&apos;def@129.com&apos;) # db.session.add(user1) # db.session.add(user2) # 使用commit提交更改 # db.session.commit() # 查询所有数据信息 # users=User.query.all() # print(users) # 条件查询 # admin=User.query.filter_by(username=&apos;abc&apos;).first() # print(admin) # 模糊查询 # user2_query=User.query.filter(User.username.endswith(&apos;f&apos;)).first() # print(user2_query) # 删除 # u3=User.query.first() # print(u3.username) # db.session.delete(u3) # db.session.commit() # 更改 # u4=User.query.first() # u4.username=u&apos;专升本&apos; # 中文必须为unicode类型，而不是str类型 # db.session.commit() 通过上下文的方式-init_app()database.py–数据操作方法1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom flask_sqlalchemy import SQLAlchemydb=SQLAlchemy()def create_app(config_name=None): app=Flask(__name__) # 在此处加载配置文件 if config_name is not None: # app.config.from_object() # 默认的config.py app.config.from_pyfile(config_name) # 通过配置文件名称加载配置文件 db.init_app(app) # 在此处加载蓝图设置 with app.app_context(): # 添加数据对象的引用 from models import * # 初始化数据库 db.create_all() return app models.py–Model实体123456789101112131415161718192021222324# coding:utf-8from database import dbclass User(db.Model): &quot;&quot;&quot;docstring for User&quot;&quot;&quot; __tablename__=&apos;users&apos; id=db.Column(db.Integer,primary_key=True) username=db.Column(db.String(80)) email=db.Column(db.String(64)) def __init__(self, username,email): self.username=username self.email=emailclass Address(db.Model): &quot;&quot;&quot;docstring for Address&quot;&quot;&quot; id=db.Column(db.Integer,primary_key=True) name=db.Column(db.String(32)) def __init__(self, name): self.name=name config.py–sql配置文件123DEBUG=TrueSQLALCHEMY_DATABASE_URI=&apos;sqlite:///testabc.db&apos;SQLALCHEMY_TRACK_MODIFICATIONS=True app.py–项目1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom database import dbfrom database import create_appfrom models import User,Addressapp=create_app(&apos;config.py&apos;)@app.route(&apos;/&apos;)def index(): # user1=User(&apos;aaa&apos;,&apos;aaa@124.com&apos;) # user2=User(u&apos;马云&apos;,&apos;mayun@111.com&apos;) add1=Address(&apos;beijing motuoluola&apos;) # db.session.add(user1) db.session.add(add1) db.session.commit() return &quot;create complate&quot;@app.route(&apos;/show&apos;)def show(): u=User.query.filter(User.email.startswith(&apos;m&apos;)).first() return u.usernameif __name__ == &apos;__main__&apos;: app.run() 项目目录123456flaskdemo app.py database.py models.py config.py testabc.db init_app() 相关参考 【Flask】Flask和SQLAlchemy：init_app - 阿秀的学习笔记 - 博客频道 - CSDN.NET Flask and SQLAlchemy: init_app &middot; Blog Introduction into Contexts &#8212; Flask-SQLAlchemy Documentation (2.1) 一对多、多对多关系一对多待完善。 多对多待完善。 文中所用各类库版本1234Flask==0.12Flask-SQLAlchemy==2.1Jinja2==2.8.1SQLAlchemy==1.1.4 相关参考 Flask-SQLAlchemy &mdash; Flask-SQLAlchemy 0.16 documentation–中文版 Flask-SQLAlchemy &mdash; Flask-SQLAlchemy Documentation (2.1)–英文版 （这两个文档比对着参考，0.16版中有些方法已经过时了，代码按照2.1的来，中文释义参考0.16版的） 在 Flask 中使用 SQLAlchemy &mdash; Flask 0.10 documentation flask-sqlalchemy 简单笔记 - 简书 Flask学习记录之Flask-SQLAlchemy - agmcs - 博客园 Flask-SQLAlchemy 学习总结 - python 学习 - SegmentFault Flask Web Development —— 数据库（上） - young - SegmentFault 这个配置说明比较详细 使用 Flask 框架写用户登录功能的Demo时碰到的各种坑（一）——创建应用 - cjnmy36723 - 博客园 Flask-SQLAlchemy–GitBook]]></content>
      <tags>
        <tag>Flask</tag>
        <tag>SQLAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python下操作SQLAlchemy]]></title>
    <url>%2F2017%2F01%2F06%2Fuse-sqlalchemy-by-python%2F</url>
    <content type="text"><![CDATA[Python中通过SQLAlchemy操作数据库。 安装通过pip安装SQLAlchemy 1$ pip install sqlalchemy 初始化数据库连接12# 初始化数据库连接engine=create_engine(&apos;sqlite:///./cnblogblog.db&apos;,echo=True) 其中，echo=True 表示 是否将执行过程中的sql语句进行输出显示 常用数据库连接写法整理常用-直接拷贝 sqlite内存：engine = create_engine(&#39;sqlite:///:memory:&#39;, echo=True) sqlite文件: engine=create_engine(&#39;sqlite:///./cnblogblog.db&#39;,echo=True) mysql+pymysql：engine = create_engine(&quot;mysql+pymysql://username:password@hostname:port/dbname&quot;,echo=True) mssql+pymssql: engine = create_engine(&#39;mssql+pymssql://username:password@hostname:port/dbname&#39;,echo=True) 1&gt;&gt;&gt; from sqlalchemy import create_engine create_engine() 用来初始化数据库连接。SQLAlchemy用一个字符串表示连接信息： 1&apos;数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名&apos; sqlite 内存 示例 engine = create_engine(&#39;sqlite:///:memory:&#39;, echo=True) sqlite 文件 示例 engine=create_engine(&#39;sqlite:///./cnblogblog.db&#39;,echo=True) mysql通用 engine = create_engine(&#39;mysql+mysqlconnector://root:password@localhost:3306/test&#39;) mysql+pymysql 示例 engine = create_engine(&quot;mysql+pymysql://username:password@hostname/dbname&quot;, encoding=&quot;utf8&quot;, echo=True) postgresql 示例 engine = create_engine(&#39;postgresql://scott:tiger@localhost:5432/mydatabase&#39;) PostgreSQL 12345678# defaultengine = create_engine(&apos;postgresql://scott:tiger@localhost/mydatabase&apos;)# psycopg2engine = create_engine(&apos;postgresql+psycopg2://scott:tiger@localhost/mydatabase&apos;)# pg8000engine = create_engine(&apos;postgresql+pg8000://scott:tiger@localhost/mydatabase&apos;) MySQL 1234567891011# defaultengine = create_engine(&apos;mysql://scott:tiger@localhost/foo&apos;)# mysql-pythonengine = create_engine(&apos;mysql+mysqldb://scott:tiger@localhost/foo&apos;)# MySQL-connector-pythonengine = create_engine(&apos;mysql+mysqlconnector://scott:tiger@localhost/foo&apos;)# OurSQLengine = create_engine(&apos;mysql+oursql://scott:tiger@localhost/foo&apos;) Oracle 123engine = create_engine(&apos;oracle://scott:tiger@127.0.0.1:1521/sidname&apos;)engine = create_engine(&apos;oracle+cx_oracle://scott:tiger@tnsname&apos;) MS SQL 12345# pyodbcengine = create_engine(&apos;mssql+pyodbc://scott:tiger@mydsn&apos;)# pymssqlengine = create_engine(&apos;mssql+pymssql://scott:tiger@hostname:port/dbname&apos;) SQLite 12345678910111213# sqlite://&lt;nohostname&gt;/&lt;path&gt;# where &lt;path&gt; is relative:engine = create_engine(&apos;sqlite:///foo.db&apos;)#Unix/Mac - 4 initial slashes in totalengine = create_engine(&apos;sqlite:////absolute/path/to/foo.db&apos;)#Windowsengine = create_engine(&apos;sqlite:///C:\\path\\to\\foo.db&apos;)#Windows alternative using raw stringengine = create_engine(r&apos;sqlite:///C:\path\to\foo.db&apos;)#memoryengine = create_engine(&apos;sqlite://&apos;) 详见官网文档：Engine Configuration 如何设置初始化表结构时字段的 主键 自增 等属性sqlite中如果设置主键自增，还需要添加 __table_args__ 参数，示例如下： 12345class Person(Base): __tablename__ = &quot;person&quot; __table_args__ = &#123;&apos;sqlite_autoincrement&apos;: True&#125; id=Column(Integer,primary_key=True,autoincrement=True) sqlalchemy - Pylons, SQlite and autoincrementing fields - Stack Overflow 设置表结构的 不可空 默认值 唯一 等属性1234567891011# 定义User对象class User(Base): &quot;&quot;&quot;Users table&quot;&quot;&quot; # 表的名字 __tablename__=&apos;users&apos; __table_args__=&#123;&apos;sqlite_autoincrement&apos;: True&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name=Column(String(32),nullable=False) age=Column(Integer,default=0) password=Column(String(64),unique=True) 插入中文数据直接插入中文数据，可能会报如下错误信息： sqlalchemy.exc.ProgrammingError: (sqlite3.ProgrammingError) You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings. 相应的解决方法是：将 str 类型的中文转成 unicode 类型再插入即可。 示例代码如下: 1234567# 添加一条数据def addUserForZhCn(): session=DBSession() new_user=User(name=u&apos;关羽2&apos;,password=&apos;12322233&apos;) session.add(new_user) session.commit() session.close() 参考自： Python 官方文档中不建议使用这种方式：use of sys.setdefaultencoding() has always been discouraged，在文件头写上 # coding: utf-8 之类的注释并且在 Unicode 字符串前加上 u 就可以了。 Flask Sqlalchemy中文模糊搜索错误 Mysql 指定表的引擎和编码格式123456789101112from sqlalchemy import Column, Integer, Stringclass User(BaseModel): __tablename__=&apos;users&apos; __table_args__=&#123; &quot;mysql_engine&quot;:&quot;InnoDB&quot;, # 表的引擎 &quot;mysql_charset&quot;:&quot;utf8&quot; # 表的编码格式 &#125; id=Column(&quot;id&quot;,Integer,primary_key=True,autoincrement=True) name=Column(&quot;name&quot;,String(50),nullable=False) age=Column(&quot;age&quot;,Integer,default=0) 如果记录存在则修改，不存在则添加1session.merge() 模型的属性名称和表的字段名称不一致12id=Column(&quot;id&quot;,Integer,primary_key=True,autoincrement=True)name=Column(&quot;name&quot;,String(50),nullable=False) 增删改 查询增删改需要 commit 操作 : 1234session=DBSession()duser=session.query(User).filter(User.id==2).delete()session.commit()session.close() 查询不需要 commit 操作: 1234session=DBSession()quser=session.query(User).filter(User.id==4).one()print(&apos;name:&apos;,quser.name)session.close() first() 和 one() 的区别query.first()：返回第一个元素query.one()有且只有一个元素时才正确返回 first()方法限制并仅作为标量返回结果集的第一条记录 one()方法，完整的提取所有的记录行，并且如果没有明确的一条记录行(没有找到这条记录)或者结果中存在多条记录行，将会引发错误异常NoResultFound或者MultipleResultsFound。 当没有数据行返回时，使用 one() 方法会报错，可以使用 one_or_none() 方法来代替，当没有数据时，会返回 None 而不是异常。 执行sql语句绑定参数也可以用基于字符串的SQL指派，使用冒号来标记替代参数，然后再使用params()方法指定相应的值。 12session.query(User).filter(&quot;id&lt;:value and name=:name&quot;).\params(value=224, name=&apos;fred&apos;).order_by(User.id).one() execute() 方法 1234567891011121314151617s=DBSession()# 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数# s.execute(&apos;INSERT INTO users (name, age, password) VALUES (?, ?, ?)&apos;,(&apos;bigpang&apos;,2,&apos;1122121&apos;)) # 这样执行报错 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (:aa, :bb, :cc)&apos;,(&#123;&apos;aa&apos;:&apos;bigpang2&apos;,&apos;bb&apos;:22,&apos;cc&apos;:&apos;998&apos;&#125;))# s.commit()# 这样执行成功res=s.execute(&apos;select * from users where age=:aaa&apos;,&#123;&apos;aaa&apos;:4&#125;)# print(res[&apos;name&apos;]) # 错误# print(res.name) # 错误# print(type(res)) # 错误for r in res: print(r[&apos;name&apos;]) s.close() 可参考：python - How to execute raw SQL in SQLAlchemy-flask app - Stack Overflow 执行sql语句 高级 执行sql语句，可以使用传统的 connection 方式，也可以使用 session 方式 sqlalchemy下的传统connection方式，执行sql语句时不需要 cursor 光标，执行增删改直接生效，执行sql语句不需要 commit 操作。 sqlalchemy下的传统connection方式，参数形式与传统方式相同，使用 ? 占位，元祖形式传值 sqlalchemy下的session方式，执行增删改需要 commit 操作。 sqlalchemy下的session方式，参数形式为 dict, 在sql语句中使用 :key 占位，dict形式传值 示例代码123456789101112131415161718192021222324252627282930313233# **传统 connection方式**# 创建一个connection对象，使用方法与调用python自带的sqlite使用方式类似# 使用with 来创建 conn，不需要显示执行关闭连接# with engine.connect() as conn:# res=conn.execute(&apos;select * from users&apos;)# data=res.fetchone()# print(&apos;user is %s&apos; %data[1])# 与python自带的sqlite不同，这里不需要 cursor 光标，执行sql语句不需要commit。如果是增删改，则直接生效，也不需要commit.# **传统 connection 事务**with engine.connect() as conn: trans=conn.begin() try: r1=conn.execute(&quot;select * from users&quot;) print(r1.fetchone()[1]) r2=conn.execute(&quot;insert into users (name,age,password) values (?,?,?)&quot;,(&apos;tang&apos;,5,&apos;133444&apos;)) trans.commit() except: trans.rollback() raise# **session**session=DBSession()session.execute(&apos;select * from users&apos;)session.execute(&apos;insert into users (name,age,password) values (:name,:age,:password)&apos;,&#123;&quot;name&quot;:&apos;dayuzhishui&apos;,&apos;age&apos;:6,&apos;password&apos;:&apos;887&apos;&#125;)# 注意参数使用dict，并在sql语句中使用:key占位# 如果是增删改，需要 commitsession.commit()# 用完记得关闭，也可以用 withsession.close() 详情可见：sqlalchemy学习笔记 - python学习笔记 - SegmentFault 完整测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228# coding:utf-8from sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy import Column, Integer, Stringfrom sqlalchemy.orm import sessionmaker# ***************************# 初始化数据库连接engine=create_engine(&apos;sqlite:///./cnblogblog.db&apos;,echo=True)# 创建对象的基类Base=declarative_base()# 创建会话类DBSession=sessionmaker(bind=engine)# ******************# 定义User对象class User(Base): &quot;&quot;&quot;Users table&quot;&quot;&quot; # 表的名字 __tablename__=&apos;users&apos; __table_args__=&#123;&apos;sqlite_autoincrement&apos;: True&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name=Column(String(32),nullable=False) age=Column(Integer,default=0) password=Column(String(64),unique=True)class Blog(Base): &quot;&quot;&quot;docstring for Blog&quot;&quot;&quot; __tablename__=&apos;blogs&apos; id=Column(Integer,primary_key=True) title=Column(String(100)) desc=Column(String(500))class Tips(Base): &quot;&quot;&quot;docstring for Tips&quot;&quot;&quot; __tablename__=&apos;tips&apos; id=Column(Integer,primary_key=True) name=Column(String(32))# ***********************# 添加一条数据def newUser(): # 创建会话对象 session=DBSession() new_user=User(name=&apos;Jery&apos;,password=&apos;123&apos;) session.add(new_user) session.commit() session.close()# 添加一条数据def addUserForZhCn(): session=DBSession() new_user=User(name=u&apos;关羽2&apos;,password=&apos;12322233&apos;) session.add(new_user) session.commit() session.close()# 新增多条数据def addmoreUser(): session=DBSession() session.add_all([ User(name=&apos;guanyu&apos;,age=4,password=&apos;11111&apos;), User(name=&apos;zhangfei&apos;,password=&apos;2233&apos;), User(name=&apos;zhenji&apos;,password=&apos;44556&apos;) ]) session.commit() session.close()# 查询def queryUser(): session=DBSession() quser=session.query(User).filter(User.id==4).one() print(&apos;name:&apos;,quser.name) session.close()# 删除def deleteUser(): session=DBSession() duser=session.query(User).filter(User.id==2).delete() session.commit() session.close()# 执行sql语句def SQlUser(): s=DBSession() # 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (?, ?, ?)&apos;,(&apos;bigpang&apos;,2,&apos;1122121&apos;)) # 这样执行报错 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (:aa, :bb, :cc)&apos;,(&#123;&apos;aa&apos;:&apos;bigpang2&apos;,&apos;bb&apos;:22,&apos;cc&apos;:&apos;998&apos;&#125;)) # s.commit() # 这样执行成功 res=s.execute(&apos;select * from users where age=:aaa&apos;,&#123;&apos;aaa&apos;:4&#125;) # print(res[&apos;name&apos;]) # 错误 # print(res.name) # 错误 # print(type(res)) # 错误 for r in res: print(r[&apos;name&apos;]) s.close()# 执行sql语句def SQlUser2(): # **传统 connection方式** # 创建一个connection对象，使用方法与调用python自带的sqlite使用方式类似 # 使用with 来创建 conn，不需要显示执行关闭连接 # with engine.connect() as conn: # res=conn.execute(&apos;select * from users&apos;) # data=res.fetchone() # print(&apos;user is %s&apos; %data[1]) # 与python自带的sqlite不同，这里不需要 cursor 光标，执行sql语句不需要commit。如果是增删改，则直接生效，也不需要commit. # **传统 connection 事务** with engine.connect() as conn: trans=conn.begin() try: r1=conn.execute(&quot;select * from users&quot;) print(r1.fetchone()[1]) r2=conn.execute(&quot;insert into users (name,age,password) values (?,?,?)&quot;,(&apos;tang&apos;,5,&apos;133444&apos;)) trans.commit() except: trans.rollback() raise # **session** session=DBSession() session.execute(&apos;select * from users&apos;) session.execute(&apos;insert into users (name,age,password) values (:name,:age,:password)&apos;,&#123;&quot;name&quot;:&apos;dayuzhishui&apos;,&apos;age&apos;:6,&apos;password&apos;:&apos;887&apos;&#125;) # 注意参数使用dict，并在sql语句中使用:key占位 # 如果是增删改，需要 commit session.commit() # 用完记得关闭，也可以用 with session.close()# 更多操作def TestUser(): session=DBSession() # test1 # 使用merge方法，如果存在则修改，如果不存在则插入（只判断主键，不判断unique列） # t1=session.query(User).filter(User.name==&apos;zhenji&apos;).first() # t1.age=34 # session.merge(t1) # session.commit() # test2 # merge方法，如果数据库中没有则添加 # t2=User() # t2.name=&apos;haha&apos; # session.merge(t2) # session.commit() # test3 # 获取第2-3项 # tUser=session.query(User)[1:3] # for u in tUser: # print(u.id) # test4 # if __name__ == &apos;__main__&apos;: # 删除全部数据库 # Base.metadata.drop_all(engine) # 初始化数据库 # Base.metadata.create_all(engine) # 删除全部数据库 # Base.metadata.drop_all(engine) # 删除指定的数据库 # 如删除 Blogs表 # 详见 ：http://stackoverflow.com/questions/35918605/how-to-delete-a-table-in-sqlalchemy # Blog.__table__.drop(engine) # 新增数据 # newUser() # 新增多条数据 # addmoreUser() # 新增数据含中文 # addUserForZhCn() # 查询数据 # queryUser() # 删除 # deleteUser() # 测试 # TestUser() # 执行sql语句 # SQlUser() # 执行sql语句2 SQlUser2() print(&apos;ok&apos;) sqlalchemy 教程入门 Test.py 作为一个Pythoner，不会SQLAlchemy ☆ SQLAlchemy ORM教程之一：Create - 简书 ☆ SQLAlchemy ORM教程之二：Query - 简书 ☆ SQLAlchemy ORM教程之三：Relationship - 简书 ☆ 增删改查常用命令 sqlalchemy学习笔记 - python学习笔记 - SegmentFault ☆ SQLAlchemy 使用经验 note/sqlalchemy.md at master · lzjun567/note · GitHub]]></content>
      <tags>
        <tag>Python</tag>
        <tag>SQLAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统实时监控工具-Glances]]></title>
    <url>%2F2017%2F01%2F05%2Flinux-real-time-monitoring-glances%2F</url>
    <content type="text"><![CDATA[Ubuntu系统下安装通过 apt-get 方式来安装12$ sudo apt-get update$ sudo apt-get install glances 通过 pip 方式来安装(推荐)12$ sudo pip install python-dev$ sudo pip install glances 建议通过 pip 的方式来安装，因为我通过 apt-get 方式安装的 glances 版本为 Glances version 1.7.3 with PsUtil 1.2.1 ，而通过 pip 安装的为 Glances v2.7.1 with psutil v4.3.1 ，旧版本的功能比较简单。 在安装过程中可能出现报错： 1warning: no previously-included files matching &apos;*&apos; found under directory &apos;docs/_build&apos; 首先执行如下命令并尝试再次安装： 1sudo apt-get install libpq-dev python-dev 通过官方给出的方式安装1$ curl -L https://bit.ly/glances | /bin/bash or: 1$ wget -O- https://bit.ly/glances | /bin/bash Alpine系统下安装执行如下命令安装123$ apk update$ apk add python-dev py-pip py2-psutil$ pip install glances 使用安装完成后，可以执行下面的命令启动 Glances： 1$ glances 可以看到类似下面的输出： 12345678910111213141516171819MyServer (Ubuntu 14.04 64bit / Linux 4.4.0-38-generic) Uptime: 1:41:59CPU [ 3.0%] CPU 3.0% nice: 0.0% ctx_sw: 193 MEM 6.5% SWAP 0.0% LOAD 2-coreMEM [ 6.5%] user: 1.3% irq: 0.0% inter: 266 total: 1.95G total: 2.24G 1 min: 0.00SWAP [ 0%] system: 1.3% iowait: 0.0% sw_int: 372 used: 129M used: 0 5 min: 0.00 idle: 97.1% steal: 0.2% free: 1.82G free: 2.24G 15 min: 0.00NETWORK Rx/s Tx/s TASKS 114 (140 thr), 1 run, 113 slp, 0 oth sorted automaticallydocker0 0b 0beth0 75Kb 44Kb CPU% MEM% VIRT RES PID USER NI S TIME+ R/s W/s Command lo 0b 0b 4.7 1.2 377M 23.2M 11918 tiger 0 R 0:01.90 0 0 /usr/bin/python / 0.3 0.1 250M 2.63M 556 syslog 0 S 0:00.18 0 0 rsyslogdDISK I/O R/s W/s 0.0 0.0 0 0 18 root -20 S 0:00.00 0 0 perfdm-0 0 19K 0.0 0.1 23.1M 2.12M 915 root 0 S 0:00.00 0 0 crondm-1 0 0 0.0 0.2 42.4M 3.22M 630 root 0 S 0:00.10 0 0 /lib/systemd/systxvda1 0 0 0.0 0.0 0 0 19 root 0 S 0:00.00 0 0 xenwatchxvda2 0 0 0.0 0.0 0 0 81 root -20 S 0:00.00 0 0 biosetxvda5 0 19K 0.0 0.0 0 0 2 root 0 S 0:00.00 0 0 kthreaddxvdb 0 0 0.0 0.0 0 0 71 root -20 S 0:00.00 0 0 bioset 要退出 Glances 终端，按 ESC 键或 Ctrl + C。 通过browser查看先安装 bottle ，然后通过 -w 参数启动浏览器服务，默认会监听 61208 端口。 更多命令可通过命令 glances --help 查看帮助。 1234$ sudo pip install bottle$ glances -wGlances web server started on http://0.0.0.0:61208/ 然后在浏览器端输入网址即可查看。 相关参考 glances GitHub - nicolargo/glances: Glances an Eye on your system. A top/htop alternative. Glances &mdash; Glances 2.7.1 documentation]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Glances</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序开发体验]]></title>
    <url>%2F2017%2F01%2F05%2Fwx-xiaochengxu-development-experience%2F</url>
    <content type="text"><![CDATA[简易教程官方文档 简易教程-小程序 app.js、app.json、app.wxss 这三个，.js后缀的是脚本文件，.json后缀的文件是配置文件，.wxss后缀的是样式表文件。 app.js是小程序的脚本代码。我们可以在这个文件中监听并处理小程序的生命周期函数、声明全局变量。调用框架提供的丰富的 API，如本例的同步存储及同步读取本地数据。 app.json 是对整个小程序的全局配置。我们可以在这个文件中配置小程序是由哪些页面组成，配置小程序的窗口背景色，配置导航条样式，配置默认标题。注意该文件不可添加任何注释。详见：配置 app.wxss 是整个小程序的公共样式表。 创建页面页面都在 pages 目录下。 微信小程序中的每一个页面的【路径+页面名】都需要写在 app.json 的 pages 中，且 pages 中的第一个页面是小程序的首页。 每一个小程序页面是由同路径下同名的四个不同后缀文件的组成，如：index.js、index.wxml、index.wxss、index.json。.js后缀的文件是脚本文件，.json后缀的文件是配置文件，.wxss后缀的是样式表文件，.wxml后缀的文件是页面结构文件。 页面的样式表是非必要的。当有页面样式表时，页面的样式表中的样式规则会层叠覆盖 app.wxss 中的样式规则。 框架框架提供了自己的视图层描述语言 WXML 和 WXSS，以及基于 JavaScript 的逻辑层框架，并在视图层与逻辑层间提供了数据传输和事件系统，可以让开发者可以方便的聚焦于数据与逻辑上。 响应的数据绑定框架的核心是一个响应的数据绑定系统。 整个系统分为两块视图层（View）和逻辑层（App Service） 文件结构框架程序包含一个描述整体程序的 app 和多个描述各自页面的 page。 一个框架程序主体部分由三个文件组成，必须放在项目的根目录：app.js app.json app.wxss 一个框架页面由四个文件组成，分别是：.js .wxml .wxss .json 配置使用app.json文件来对微信小程序进行全局配置，决定页面文件的路径、窗口表现、设置网络超时时间、设置多 tab 等。 app.json 配置项列表 pages 设置页面路径 window 设置默认页面的窗口表现 tabBar 设置底部 tab 的表现 networkTimeout 设置网络超时时间 debug 设置是否开启 debug 模式 pages 接受一个数组，每一项都是字符串，来指定小程序由哪些页面组成。 对应页面的【路径+文件名】信息 数组的第一项代表小程序的初始页面。 小程序中新增/减少页面，都需要对 pages 数组进行修改 文件名不需要写文件后缀 window设置小程序的状态栏、导航条、标题、窗口背景色。 navigationBarBackgroundColor 导航栏背景颜色，如”#000000” navigationBarTextStyle 导航栏标题颜色，仅支持 black/white navigationBarTitleText 导航栏标题文字内容 backgroundColor 窗口的背景色 backgroundTextStyle 下拉背景字体、loading 图的样式，仅支持 dark/light enablePullDownRefresh 是否开启下拉刷新 false/true tabBar多 tab 应用（客户端窗口的底部有tab栏可以切换页面）, 可以通过 tabBar 配置项指定 tab 栏的表现，以及 tab 切换时显示的对应页面。 tabBar 是一个数组，只能配置最少2个、最多5个 tab，tab 按数组的顺序排序。 color tab 上的文字默认颜色 selectedColor tab 上的文字选中时的颜色 backgroundColor tab 的背景色 borderStyle tabbar上边框的颜色， 仅支持 black/white list tab 的列表，最少2个、最多5个 tab list 属性值： pagePath 页面路径，必须在 pages 中先定义 text tab 上按钮文字 iconPath 图片路径，icon 大小限制为40kb selectedIconPath 选中时的图片路径，icon 大小限制为40kb networkTimeout设置各种网络请求的超时时间。 request wx.request的超时时间，单位毫秒 connectSocket wx.connectSocket的超时时间，单位毫秒 uploadFile wx.uploadFile的超时时间，单位毫秒 downloadFile wx.downloadFile的超时时间，单位毫秒 debug在控制台面板中调试信息以 info 的形式给出，其信息有Page的注册，页面路由，数据更新，事件触发 。 page.json每一个小程序页面也可以使用.json文件来对本页面的窗口表现进行配置。 页面的配置比app.json全局配置简单得多，只是设置 app.json 中的 window 配置项的内容，页面中配置项会覆盖 app.json 的 window 中相同的配置项。 页面的.json只能设置 window 相关的配置项,以决定本页面的窗口表现，无需写 window 这个键。 逻辑层AppApp()App() 函数用来注册一个小程序。接受一个 object 参数，其指定小程序的生命周期函数等。 object 参数说明： onLaunch 当小程序初始化完成时，会触发 onLaunch（全局只触发一次） onShow 当小程序启动，或从后台进入前台显示，会触发 onShow onHide 当小程序从前台进入后台，会触发 onHide 其他 开发者可以添加任意的函数或数据到 Object 参数中，用 this 可以访问 前台、后台定义： 当用户点击左上角关闭，或者按了设备 Home 键离开微信，小程序并没有直接销毁，而是进入了后台；当再次进入微信或再次打开小程序，又会从后台进入前台。 123456789101112App(&#123; onLaunch: function() &#123; // Do something initial when launch. &#125;, onShow: function() &#123; // Do something when show. &#125;, onHide: function() &#123; // Do something when hide. &#125;, globalData: &apos;I am global data&apos;&#125;) App.prototype.getCurrentPage()getCurrentPage() 函数用户获取当前页面的实例。 getApp()全局的 getApp() 函数，可以获取到小程序实例。 注意： App() 必须在 app.js 中注册，且不能注册多个。 不要在定义于 App() 内的函数中调用 getApp() ，使用 this 就可以拿到 app 实例。 不要在 onLaunch 的时候调用 getCurrentPage()，此时 page 还没有生成。 通过 getApp() 获取实例之后，不要私自调用生命周期函数。 PagePage() 函数用来注册一个页面。接受一个 object 参数，其指定页面的初始数据、生命周期函数、事件处理函数等。 object参数说明： data 页面的初始数据 onLoad 生命周期函数–监听页面加载 onReady 生命周期函数–监听页面初次渲染完成 onShow 生命周期函数–监听页面显示 onHide 生命周期函数–监听页面隐藏 onUnload 生命周期函数–监听页面卸载 onPullDownRefreash 页面相关事件处理函数–监听用户下拉动作 其他 开发者可以添加任意的函数或数据到 object 参数中，用 this 可以访问 初始化数据初始化数据将作为页面的第一次渲染。数据必须是可以转成 JSON 的格式：字符串，数字，布尔值，对象，数组。 Page.prototype.setData()setData 函数用于将数据从逻辑层发送到视图层，同时改变对应的 this.data 的值。 注意： 直接修改 this.data 无效 单次设置的数据不能超过 1024 KB setData() 参数格式接受一个对象，以 key，value 的形式表示将 this.data 中的 key 对应的值改变成 value。 页面的路由 文件作用域 在 JavaScript 文件中声明的变量和函数只在该文件中有效； 不同的文件中可以声明相同名字的变量和函数，不会互相影响。 通过全局函数 getApp() 可以获取全局的应用实例 如果需要全局的数据可以在 App() 中设置 模块化模块只有通过 module.exports 才能对外暴露接口。 1234567// common.jsfunction sayHello(name) &#123; console.log(&apos;Hello &apos; + name + &apos;!&apos;)&#125;module.exports = &#123; sayHello: sayHello&#125; 在需要使用这些模块的文件中，使用 require(path) 将公共代码引入。 123456var common = require(&apos;common.js&apos;)Page(&#123; helloMINA: function() &#123; common.sayHello(&apos;MINA&apos;) &#125;&#125;)]]></content>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 413 curl 22 The requested URL returned error 413 Request Entity Too Large]]></title>
    <url>%2F2016%2F12%2F30%2Fnginx-request-entity-too-large%2F</url>
    <content type="text"><![CDATA[问题原因在使用gogs时，git push 代码报如下错误： 1error: RPC failed; HTTP 413 curl 22 The requested URL returned error: 413 Request Entity Too Large 经查证，是服务器上的nginx默认情况下只允许上传最大 1m 大小的文件。nginx默认配置如下： 123Syntax: client_max_body_size size;Default: client_max_body_size 1m;Context: http, server, location 解决方法在 nginx 的配置文件 nginx.conf 中的 http 段内，添加 client_max_body_size 配置： 12345http &#123; ... client_max_body_size 50m; ... &#125; 后面的 50m 表示最大允许上传 50M 大小的文件。 然后重新加载 nginx 配置信息： 1$ sudo service nginx reload 相关参考 Module ngx_http_core_module nginx client_max_body_size 的问题 | yanghao&#039;s blog git - Github Push Error: RPC failed; result=22, HTTP code = 413 - Stack Overflow]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python独立运行环境Virtualenv]]></title>
    <url>%2F2016%2F12%2F28%2Fpython-independent-operating-environment-virtualenv%2F</url>
    <content type="text"><![CDATA[Virtualenv可以为每个Python应用创建独立的开发环境，使他们互不影响，Virtualenv能够做到： 在没有权限的情况下安装新套件 不同应用可以使用不同的套件版本 套件升级不影响其他应用 安装virtualenv使用pip安装（推荐）1$ sudo pip install virtualenv 使用 easy_install 安装：1$ sudo easy_install virtualenv 初始化我通常创建一个包含虚拟名称为 venv 文件夹的项目文件夹: 123456$ mkdir myproject$ cd myproject$ virtualenv venvNew python executable in venv/bin/python2Also creating executable in venv/bin/pythonInstalling setuptools, pip...done. 激活虚拟环境现在，每次需要使用项目时，必须先激活相应的环境。 在Linux系统下执行123456$ ls-- venv$ source ./venv/bin/activate//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ 在Win系统下执行1234&gt; lsvenv/&gt; venv\Scripts\activate.bat(venv) D:\YYYY 你现在就进入你的 virtualenv 虚拟环境了（注意查看你的 shell 提示符已经改变了）。 退出虚拟环境通过 deactivate 命令退出虚拟环境。 virtualenv 命令整理安装1pip install virtualenv 创建1virtualenv &lt;EnvName&gt; *nix1$ source ./venv/bin/activate 此处 venv 为 &lt;EnvName&gt; Win1&gt; venv\Scripts\activate 此处 venv 为 &lt;EnvName&gt; 退出1deactivate 相关参考 virtualenv &mdash; virtualenv 1.7.1.2.post1 documentation]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统下使用Gogs搭建Git Service]]></title>
    <url>%2F2016%2F12%2F26%2Fuse-gogs-to-build-yourself-git-server%2F</url>
    <content type="text"><![CDATA[基本环境搭建 新建用户 Gogs 默认以 git 用户运行（你应该也不会想一个能修改 ssh 配置的程序以 root 用户运行吧？）。运行 sudo adduser git 新建好 git 用户并设置密码。 然后 su - git 切换至 git 用户登录。 具体操作如下： 1$ sudo adduser git 根据提示信息，输入新账户 git 密码，其他用户信息直接敲回车即可。 安装git 因为新创建的用户 git 没有设置管理员权限，所以我们先在 root 账户或其他管理员账户下安装 git : 123$ sudo apt-get update$ sudo apt-get install git$ git --version //检查git是否安装成功 切换到新创建的git用户： 1$ su - git 进入用户git的根目录下： 1$ cd ~ 下载解包 我使用的是预编译的二进制安装包。需要从源码编译的话，请参考一般 Go 语言项目的编译。 数据库采用 Sqlite3 数据库，如想使用Mysql 获取其他数据库，请参考官网的安装方法。 创建gogs应用的解压目录： 1234$ mkdir goapp$ cd goapp$ pwd/home/git/goapp 从 官网 或从 GitHub Tags 下载当前最新的版本 v0.9.13 版，linux amd64 并解压： 1234$ wget https://dl.gogs.io/gogs_v0.9.13_linux_amd64.zip$ unzip gogs_v0.9.13_linux_amd64.zip$ lsgogs gogs_v0.9.13_linux_amd64.zip 进入 gogs 目录： 123$ cd gogs$ lsgogs LICENSE public README.md README_ZH.md scripts templates 创建自定义配置文件目录并修改文件夹权限： 1234$ mkdir custom$ mkdir custom/conf$ sudo chmod -R 777 custom 在当前 git 用户下，如果提示没有 sudo 权限，可以先临时更新为其他用户，更改目录读写权限，改完后再切换回 git 用户： 123$ su root$ sudo chmod -R 777 custom$ su - git 创建日志目录并修改文件夹权限： 123$ mkdir log$ sudo chmod -R 777 log 启动gogs: 1234$ pwd/home/git/goapp/gogs$ ./gogs web 执行命令后，出现 Listen:http://0.0.0.0:3000 提示信息，表示 gogs 启动成功。 然后访问 http://服务器IP:3000/ 来进行安装，填写好表单之后提交就可以了。默认第一个创建的账户为管理员账户。 表单中指定了 Database Settings – Path 为数据库的存放目录。Application General Settings – Repository Root Path 为仓库文件的存放目录。 配置Nginx在管理员账户下执行： 1$ sudo apt-get install nginx 在 /etc/nginx/conf.d 目录下添加 gogsweb.conf 文件，填入如下内容： 12345678server &#123; server_name git.****.com; listen 80; location / &#123; proxy_pass http://127.0.0.1:3000/; &#125;&#125; 然后通过 sudo service nginx restart 重启 nginx 服务。 配置 supervisor 启动在管理员账户下执行： 1$ sudo apt-get install supervisor 在 /etc/supervisor/conf.d 目录下添加 gogsweb.conf 文件，填入如下内容： 12345678910111213141516[program:gogs]directory=/home/git/goapp/gogs/command=/home/git/goapp/gogs/gogs webautostart=trueautorestart=truestartsecs=10stdout_logfile=/home/git/goapp/gogs/log/stdout.logstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstderr_logfile=/home/git/goapp/gogs/log/stderr.logstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBuser = gitenvironment = HOME=&quot;/home/git&quot;, USER=&quot;git&quot; 以上的配置信息在 gogs 目录下的 Scripts 文件夹下有给出，可参考。 开启 supervisor UI 管理台编辑 /etc/supervisor/supervisor.conf 主配置文件，修改或添加(通过apt-get的方式安装后不包含该配置) 以下内容： 1234[inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; (ip_address:port specifier, *:port for all iface)username=user ; (default is no username (open server))password=123 ; (default is no password (open server)) port 中 *.9001 表示接受任意网络的请求，如果设置成 127.0.0.1 则只接受本地访问请求。 通过通过 sudo supervisorctl reload 重启服务。 重启之后，如果之前的配置也没有问题的话，现在在浏览器上通过域名即可浏览该站点了。 在浏览器中输入 服务器IP:9001 来访问 supervisor UI 的管理端页面。 Gogs的个性化配置 顶部导航菜单中 “帮助” 链接文字，未登录用户不显示 “帮助” 按钮： 目录: gogs\templates\base\head.tmpl 位置： 1&lt;a class=&quot;item&quot; target=&quot;_blank&quot; href=&quot;http://gogs.io/docs&quot; rel=&quot;noreferrer&quot;&gt;&#123;&#123;.i18n.Tr &quot;help&quot;&#125;&#125;&lt;/a&gt; 将 标签下面的改行注释掉。 底部右下角显示 “官方网站” 字样，修改为 “Gogs官方网站”： 目录： gogs\templates\base\footer.tmpl 位置： 1&lt;a target=&quot;_blank&quot; href=&quot;http://gogs.io&quot;&gt;&#123;&#123;.i18n.Tr &quot;website&quot;&#125;&#125;&lt;/a&gt; 更改为：1&lt;a target=&quot;_blank&quot; href=&quot;https://gogs.io&quot;&gt;Gogs&#123;&#123;.i18n.Tr &quot;website&quot;&#125;&#125;&lt;/a&gt; 首页，首页样式改版： 目录： gogs\templates\home.tmpl 为md文件中的a标签链接添加target属性，在新页面打开 在 goapp/gogs/public/js/ 目录下，添加名为 mdlinktarget-1.0.min.js 内容如下： 1$(document).ready(function()&#123;$(&apos;#file-content a[href^=&quot;http&quot;]&apos;).each(function()&#123;$(this).attr(&quot;target&quot;,&quot;_blank&quot;)&#125;)&#125;); 在项目目录 gogs\templates\base 下找到 footer.tmpl 文件，在最下面添加js引用： 1&lt;script src=&quot;&#123;&#123;AppSubUrl&#125;&#125;/js/mdlinktarget-1.0.min.js&quot;&gt;&lt;/script&gt; 参考 Installation - Gogs - Go Git Service 使用 Gogs 搭建自己的 Git 服务器 - My Nook]]></content>
      <tags>
        <tag>Gogs</tag>
        <tag>Git Server</tag>
        <tag>代码管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Docker镜像加速器]]></title>
    <url>%2F2016%2F12%2F26%2Fsetting-docker-mirror-image-accelerator%2F</url>
    <content type="text"><![CDATA[由于“你懂得”的原因，在国内获取Docker镜像时经常因为网络原因而下载失败，有些人会选择“番茄”，但是配置起来着实麻烦。所以选择国内的镜像加速器是目前解决该问题的最好方法。这里我主要介绍阿里云的Docker镜像加速器和DaoCload的镜像加速器的配置方法。 注意：针对于 Ubunt16.04系统下的Docker配置镜像加速器，可直接参考整理的最新文章：Ubuntu16.04安装Docker及配置镜像加速器 注意：由于该文章写于2016年12月，其中的一些配置方法可能已过时，建议搜索本站其他相关文章中的最新设置方法。 配置阿里云Docker镜像加速器打开 官方地址 开发者平台 – 管理中心 – 加速器 。可以看到 “您的专属加速器地址” 即 https://xxxxxxx.mirror.aliyuncs.com 。 Ubuntu系统下如何配置因为我的系统为 Ubuntu 15.04 , 所以这里仅以Ubuntu系统下的配置方法为例，其他系统可参考官网中的说明。 安装或升级Docker这里要求必须是 1.6.0 以上版本的Docker。可以从阿里云的镜像仓库下载 mirrors.aliyun.com/help/docker-engine 1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - 配置Docker加速器如果Ubuntu系统是 12.04 14.04 ，Docker 1.9 以上， 执行： 12echo &quot;DOCKER_OPTS=\&quot;\$DOCKER_OPTS --registry-mirror=https://xxxxxxx.mirror.aliyuncs.com\&quot;&quot; | sudo tee -a /etc/default/dockersudo service docker restart 如果Ubuntu系统是 15.04 16.04 ，Docker 1.9 以上， 执行： 12345678sudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/mirror.conf &lt;&lt;-&apos;EOF&apos;[Service]ExecStart=ExecStart=/usr/bin/docker daemon -H fd:// --registry-mirror=https://xxxxxxx.mirror.aliyuncs.comEOFsudo systemctl daemon-reloadsudo systemctl restart docker 等待Docker服务重启后，再次下载镜像则非常快了。 配置DaoCload的镜像加速器打开 官方地址 DaoCloud – 产品 – 加速器 – 立即使用 。 Linux系统配置 Docker 加速器命令脚本自动配置 （推荐）DaoCloud也会为你分配一个专属的加速器地址，可以直接拷贝页面中给出的代码： 1# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://xxxxxx.m.daocloud.io 该脚本可以将 --registry-mirror 加入到你的 Docker 配置文件 /etc/default/docker 中。适用于 Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同。 手动配置也可以自己手动修改。 在 /etc/default/docker 文件底部添加如下内容： 1$ sudo vim /etc/default/docker 添加： 1DOCKER_OPTS=&quot;$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io&quot; 重启Docker服务配置完成后需要重启docker服务。 1$ sudo service docker restart 注意事项 如果你的系统当前登陆用户不是管理员账户的话，记得添加 sudo 以免执行失败。 上文代码段中给出的镜像加速器地址中的 xxxxxxx 为阿里云或DaoCloud在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关链接 阿里云开发者平台 DaoCloud Docker 镜像加速器-博客-云栖社区-阿里云 使用DaoCloud安装Docker和镜像 - 简书]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alpine下配置Selenium运行环境]]></title>
    <url>%2F2016%2F10%2F19%2Fconfiguration-the-selenium-running-environment-in-alpine%2F</url>
    <content type="text"><![CDATA[配置环境 Alpine Linux 3.4 安装依赖设置软件安装源1$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.4/main&quot; &gt;&gt; /etc/apk/repositories 安装依赖包执行以下命令： 123$ apk update$ apk add python py-pip curl unzip$ pip install selenium 支持的浏览器及 WebDriver 驱动这里我以常用的Chrome 和 Firefox 为例，来配置运行环境。 Selenium调用Chrome浏览器Alpine系统下面使用Chrome推荐安装开源的 Chromium 浏览器 安装 Chromium因为在软件库中存在 Chromium 的包，所以可以直接通过 apk 来安装： 1$ apk add chromium 然后还要安装 chromium 的依赖包： 1$ apk add libexif udev 如果没有安装 libexif udev 这两个依赖包，会报如下错误，Chromium浏览器会无法启动： selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed 上面命令执行完成后，chromium 浏览器就安装好了。可以通过命令 chromium-browser 来测试： 12$ chromium-browser[54:54:1019/081743:ERROR:browser_main_loop.cc(261)] Gtk: cannot open display: 因为在 Server 系统下没有显示窗口，提示上面的信息说明 chromium 程序可以调用的到，只是无法显示。 安装 ChromeDriverChromeDriver是一个实现了WebDriver与Chromium联接协议的独立服务。 通过 apk 安装我们可以直接通过如下命令来安装 chromedriver 程序： 1$ apk add chromium-chromedriver 测试 ChromeDriver执行 chromedriver 查看是否能正常运行。 123$ chromedriverStarting ChromeDriver 2.22 (5e2d5494d735a71aa5c2e7ef9bf5ce96945e92e9) on port 9515Only local connections are allowed. 当提示 Starting ChromeDriver xxx on port 9515 信息时，说明 ChromeDriver 设置成功。 Selenium调用Firefox浏览器安装 Firefox 浏览器可以通过 apk 直接安装 Firefox 浏览器： 1$ apk add firefox-esr 然后还要安装 firefox 的依赖包： 1$ apk add dbus-x11 ttf-freefont 其中 dbus-x11 中 x11 中是数字1，D-Bus 是一个消息总线，用于在应用程序间发送消息。 如果不安装会报如下错误信息： selenium.common.exceptions.WebDriverException: Message: connection refused 在 geckodriver.log 文件中查看到如下信息: process 116: D-Bus library appears to be incorrectly set up; failed to read machine uuid: Failed to open “/etc/machine-id”: No such file or directorySee the manual page for dbus-uuidgen to correct this issue. D-Bus not compiled with backtrace support so unable to print a backtraceRedirecting call to abort() to mozalloc_abort 其中 ttf-freefont 是一个字体相关的依赖包，如果不安装会报如下错： selenium.common.exceptions.WebDriverException: Message: Failed to decode response from marionette 在 geckodriver.log 文件中查看到如下信息: Crash Annotation GraphicsCriticalError: |[0][GFX1]: no fonts - init: 1 fonts: 0 loader: 0[GFX1]: no fonts - init: 1 fonts: 0 loader: 0^G[162] ###!!! ABORT: unable to find a usable font (serif): file /home/buildozer/aports/community/firefox-esr/src/firefox-45.4.0esr/gfx/thebes/gfxTextRun.cpp[162] ###!!! ABORT: unable to find a usable font (serif): file /home/buildozer/aports/community/firefox-esr/src/firefox-45.4.0esr/gfx/thebes/gfxTextRun.cpp, 可通过命令 firefox 测试 firefox浏览器是否安装成功： 12$ firefoxError: no display specified 同样的，由于没有显示窗口，也会提示 no display 的错误。 安装 geckodriver下载 geckodriver访问站点 geckodriver 下载当前系统对应 geckodriver 程序。 执行如下命令： 123456$ curl https://github.com/mozilla/geckodriver/releases/download/v0.11.1/geckodriver-v0.11.1-linux64.tar.gz -O$ tar -zxvf geckodriver-v0.11.1-linux64.tar.gz$ lsgeckodriver 解压后我们得到了一个 geckodriver 执行程序。 该 geckodriver 压缩包可能由于网络原因下载失败，可通过迅雷等软件下载后拷贝到Linux系统中。 将 geckodriver 放到系统 PATH 目录下我们可以在程序中指定具体的 geckodriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ mv ./geckodriver /usr/local/bin/$ chmod a+x /usr/local/bin/geckodriver 测试 geckodriver执行 geckodriver 查看是否能正常运行。 12$ geckodriver 1476443497207 geckodriver INFO Listening on 127.0.0.1:4444 当提示 Listening on 127.0.0.1:4444 信息时，说明 geckodriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 geckodriver : selenium.common.exceptions.WebDriverException: Message: ‘geckodriver’ executable needs to be in PATH. 安装虚拟显示器 xvfb为什么要用 xvfb??xvfb 这个工具相当于一个wrapper，给应用程序提供虚拟的 X server 执行如下命令安装12$ apk add xvfb$ pip install pyvirtualdisplay 测试 selenium 调用浏览器获取网页Chrome 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 chrome.py ，执行： 12$ python chrome.py博客园 - 开发者的网上家园 Firefox 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Firefox()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 firefox.py ，执行： 12$ python firefox.py博客园 - 开发者的网上家园 Docker实现详情请参考开源项目： Leafney/alpine-selenium-chrome leafney/alpine-selenium-chrome Leafney/alpine-selenium-firefox leafney/alpine-selenium-firefox]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Alpine</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下配置Selenium运行环境]]></title>
    <url>%2F2016%2F10%2F19%2Fconfiguration-the-selenium-running-environment-in-ubuntu%2F</url>
    <content type="text"><![CDATA[Selenium，自动化测试工具。 配置环境 Ubuntu 16.04 TLS 安装依赖设置软件安装源1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 也可以改成： 1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt; /etc/apt/sources.list 安装依赖包执行以下命令： 123$ sudo apt-get update$ sudo apt-get install python python-pip curl unzip -y$ sudo pip install selenium 支持的浏览器及 WebDriver 驱动Selenium可以调用Chrome 、Firefox 、Safari 等浏览器。 WebDriver 支持以下的 ChromeDriver EventFiringWebDriver FirefoxDriver HtmlUnitDriver InternetExplorerDriver PhantomJSDriver RemoteWebDriver SafariDriver 这里我以常用的Chrome 和 Firefox 为例，来配置运行环境。 我们需要安装相对应的浏览器和浏览器驱动 WebDriver 。比如 Selenium 无法直接启动 Chrome ，需要用第三方插件 ChromeDriver 来调用。 Selenium调用Chrome浏览器Chrome浏览器我们可以使用官方的 Google Chrome 浏览器 或者 开源的 Chromium 浏览器 安装 Google Chrome执行如下命令安装，这里我们选择的是 google-chrome-stable 版本： 123456$ wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -$ sudo sh -c &apos;echo &quot;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&quot; &gt;&gt; /etc/apt/sources.list.d/google.list&apos;sudo apt-get updatesudo apt-get install google-chrome-stable 详细可访问： UbuntuUpdates-Google Chrome All “google-chrome-stable” versions 或者可以通过以下命令直接下载 *.deb 安装包： x64 – $ curl http://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_54.0.2840.59-1_amd64.deb -O x32 – 32位版本已不可用 安装deb安装包： 1$ dpkg -i google-chrome-stable_54.0.2840.59-1_amd64.deb 安装过程中可能会安装失败，缺少依赖： 12345dpkg: error processing package google-chrome-stable (--install): dependency problems - leaving unconfiguredProcessing triggers for mime-support (3.59ubuntu1) ...Errors were encountered while processing: google-chrome-stable 通过如下命令解决： 1$ apt-get -f install software installation - How to install Google Chrome? - Ask Ubuntu 安装 ChromiumGoogle Chrome isn’t in the repositories - however, Chromium is. 因为在软件库中存在 Chromium 的包，所以可以直接通过 apt-get 来安装： 12$ sudo apt-get update$ sudo apt-get install chromium-browser 未安装Chrome浏览器异常如果未安装 Google-Chrome 或 Chromium 浏览器，会提示如下错误信息： 1selenium.common.exceptions.WebDriverException: Message: unknown error: cannot find Chrome binary 安装 ChromeDriverChromeDriver是一个实现了WebDriver与Chromium联接协议的独立服务。 下载 ChromeDriver访问站点 chromedriver 下载当前系统对应的 chromedriver 程序, 页面中给出了不同Chrome版本对应的 ChromeDriver 程序。 执行命令如下，下载并解压： 123456$ curl http://chromedriver.storage.googleapis.com/2.24/chromedriver_linux64.zip -O$ unzip chromedriver_linux64.zip$ lschromedriver 解压后我们得到了一个 chromedriver 执行程序。 将 ChromeDriver 放到系统 PATH 目录下我们可以在程序中指定具体的 ChromeDriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ sudo mv ./chromedriver /usr/local/bin/$ sudo chmod a+x /usr/local/bin/chromedriver 测试 ChromeDriver执行 chromedriver 查看是否能正常运行。 123$ chromedriver Starting ChromeDriver 2.24.417424 (c5c5ea873213ee72e3d0929b47482681555340c3) on port 9515Only local connections are allowed. 当提示 Starting ChromeDriver xxx on port 9515 信息时，说明 ChromeDriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 ChromeDriver : selenium.common.exceptions.WebDriverException: Message: ‘chromedriver’ executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home Selenium调用Firefox浏览器安装 Firefox 浏览器可以通过 apt-get 直接安装 Firefox 浏览器： 1$ sudo apt-get install firefox 未安装Firefox浏览器异常如果未安装 Firefox 浏览器程序，则会提示如下错误： selenium.common.exceptions.WebDriverException: Message: Expected browser binary location, but unable to find binary in default location, no ‘moz:firefoxOptions.binary’ capability provided, and no binary flag set on the command line 安装 geckodriver下载 geckodriver访问站点 geckodriver 下载当前系统对应 geckodriver 程序。 执行如下命令： 123456$ curl https://github.com/mozilla/geckodriver/releases/download/v0.11.1/geckodriver-v0.11.1-linux64.tar.gz -O$ tar -zxvf geckodriver-v0.11.1-linux64.tar.gz$ lsgeckodriver 解压后我们得到了一个 geckodriver 执行程序。 该 geckodriver 压缩包可能由于网络原因下载失败，可通过迅雷等软件下载后拷贝到Linux系统中。 将 geckodriver 放到系统 PATH 目录下我们可以在程序中指定具体的 geckodriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ sudo mv ./geckodriver /usr/local/bin/$ sudo chmod a+x /usr/local/bin/geckodriver 测试 geckodriver执行 geckodriver 查看是否能正常运行。 12$ geckodriver 1476443497207 geckodriver INFO Listening on 127.0.0.1:4444 当提示 Listening on 127.0.0.1:4444 信息时，说明 geckodriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 geckodriver : selenium.common.exceptions.WebDriverException: Message: ‘geckodriver’ executable needs to be in PATH. 安装虚拟显示器 xvfb为什么要用 xvfb??xvfb 这个工具相当于一个wrapper，给应用程序提供虚拟的 X server 执行如下命令安装12$ sudo apt-get install xvfb$ sudo pip install pyvirtualdisplay 测试selenium调用浏览器获取网页Chrome 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 chrome.py ，执行： 12$ python chrome.py博客园 - 开发者的网上家园 Firefox 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Firefox()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 firefox.py ，执行： 12$ python firefox.py博客园 - 开发者的网上家园 代码详解12345678910111213141516171819202122#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Display# 设置虚拟显示器的窗口大小display=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)# 打印网页的标题title=driver.titleprint(title.encode(&apos;utf-8&apos;))# 退出浏览器driver.close()# 关闭虚拟显示器窗口display.stop() Docker实现详情请参考开源项目： 相关参考 ChromeDriver WebDriver - Mozilla | MDN GitHub - mozilla/geckodriver: WebDriver &lt;-&gt; Marionette proxy ☆ python - How do I run Selenium in Xvfb? - Stack Overflow ☆ Selenium2.0]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Selenium</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下安装及配置MySql数据库]]></title>
    <url>%2F2016%2F10%2F06%2Fubuntu-install-mysql-db%2F</url>
    <content type="text"><![CDATA[安装过程测试系统为 Ubuntu 16.04 LTS 更新Ubuntu软件安装源1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 安装mysql-server执行如下命令安装mysql: 12$ sudo apt-get update$ sudo apt-get install mysql-server 安装过程会弹出提示框，输入root用户的密码，这里设置密码为 mysql 。 安装完成后，通过命令 mysql -V 查看mysql版本信息： 12# mysql -Vmysql Ver 14.14 Distrib 5.7.15, for Linux (x86_64) using EditLine wrapper 解决mysql连接错误 ERROR 2002 (HY000)在使用 root 账户连接mysql时，报了如下的 2002 错误： 123# mysql -uroot -pEnter password: ERROR 2002 (HY000): Can&apos;t connect to local MySQL server through socket &apos;/var/run/mysqld/mysqld.sock&apos; (2) 查看 mysql 服务是否启动，执行如下命令查看： 1234# ps -aux |grep mysqldroot 984 0.0 0.0 11276 728 ? S+ 07:23 0:00 grep --color=auto mysqld# ps -aux |grep mysql root 986 0.0 0.0 11276 728 ? S+ 07:23 0:00 grep --color=auto mysql 可见mysql的服务并没有启动，然后我们尝试启动服务： 1234$ sudo service mysql start# service mysql start * Starting MySQL database server mysqld No directory, logging in with HOME=/ mysql的服务居然无法启动。 最终找到原因是当前用户对 /var/run/mysqld 目录没有操作权限导致的。 先查看 /var/run/ 下是否存在 mysqld目录，没有先创建。 执行如下命令： 1$ sudo chown -R mysql:mysql /var/run/mysqld 然后再次尝试启动mysql服务： 1234567891011121314151617$ sudo service mysql start# service mysql status * /usr/bin/mysqladmin Ver 8.42 Distrib 5.7.15, for Linux on x86_64Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Server version 5.7.15-0ubuntu0.16.04.1Protocol version 10Connection Localhost via UNIX socketUNIX socket /var/run/mysqld/mysqld.sockUptime: 7 secThreads: 1 Questions: 8 Slow queries: 0 Opens: 105 Flush tables: 1 Open tables: 98 Queries per second avg: 1.142 可以看到mysql服务启动成功了。 网上查找各种解决该问题的方法，也只有这一种方法是根本原因。 所以当再次遇到该问题的时候，先查看一下目录是否有操作权限： 1$ ls -al /var/run/mysqld/ chown命令将指定文件的拥有者改为指定的用户或组 Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’的解决 新增账户及权限设置第一种方法以管理员身份登陆mysql1$ mysql -uroot -p 输入之前设置的密码，登陆mysql命令模式。 选择 mysql 数据库1mysql&gt; use mysql; 创建用户并设定密码先查看默认存在哪些账户： 12345678910mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root |+-----------+------------------+3 rows in set (0.00 sec) 执行以下命令来创建新用户账户及密码： 1mysql&gt; create user &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;testpassword&apos;; 将 testpassword 替换为你自己的密码。 执行如下命令使操作生效： 1mysql&gt; flush privileges; 示例操作如下： 12345678910111213141516mysql&gt; create user &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 |+-----------+------------------+4 rows in set (0.00 sec) 为新账户创建数据库12mysql&gt; create database testdb;Query OK, 1 row affected (0.03 sec) 为新账户赋予操作新建数据库 testdb 的权限12345mysql&gt; grant all privileges on testdb.* to &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) testdb.* 表示操作 testdb 这个数据库中所有的表 &#39;testuser1&#39;@&#39;localhost&#39; 表示使用账户 testuser1 登陆到 localhost &#39;123456&#39; 表示登陆密码 使用新账户登陆我们在上面的步骤中创建的新用户为 testuse1 密码为 123456 管理的数据库为 testdb。 使用 exit 退出 root 账户的登陆，然后使用新账户登陆： 123456mysql&gt; exitBye$ mysql -u testuser1 -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g. 登陆成功后，查看数据库列表： 12345678mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || testdb |+--------------------+2 rows in set (0.00 sec) 第二种方法 通过GRANT授权的方式新增用户以root账户登录：123$ mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. 新增数据库为新账户创建数据库 testdb2 12mysql&gt; create database testdb2;Query OK, 1 row affected (0.00 sec) 新增账户并设置密码新增账户 testuser2 密码为 123456 管理 testdb2 数据库。 通过 grant all privileges on 语句来操作： 123456789101112131415mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || testdb || testdb2 |+--------------------+6 rows in set (0.00 sec)mysql&gt; grant all privileges on testdb2.* to &apos;testuser2&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec) grant all 语句不需要使用 flush privilege; 刷新系统权限表，该操作立即生效。 使用新账户 testuser2 登陆123456789101112131415mysql&gt; exitBye$ mysql -utestuser2 -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || testdb2 |+--------------------+2 rows in set (0.00 sec) 将默认编码改为utf8默认情况下，MySQL的字符集是 latin1 ，因此在存储中文的时候，会出现乱码的情况，所以我们需要把字符集统一改成 UTF-8 。 mysql 默认编码通过如下命令查看mysql默认编码： 123456789101112131415161718192021222324mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.01 sec)+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | latin1_swedish_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+3 rows in set (0.00 sec) 更改配置文件一般情况下，在 Ubuntu 14.04 系统中，mysql的配置文件目录为： 1/etc/mysql/my.cnf 在 Ubuntu 16.04 系统下，mysql的配置文件目录为： 123/etc/mysql/my.cnf/etc/mysql/mysql.conf.d/mysqld.cnf 我当前的系统为 Ubuntu16.04 。其实在 ubuntu 16.04 系统中，mysql的配置文件路径也为 /etc/mysql/my.cnf ，只不过这个 my.cnf 是全局配置文件，在该文件内部可以看到如下配置： 123# !includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 具体的配置文件是存放在上面两个目录下的。所以我们可以更改 /etc/mysql/my.cnf 这个文件，也可以更改 /etc/mysql/mysql.conf.d/mysqld.cnf 这个文件。或者也可以自己新增一个扩展名为 *.cnf 的配置文件放在上面包含的两个目录内。 从网上找到各种说法的修改编码为utf-8的方法，经测试后需要修改的配置如下： 12345678910[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect=&apos;SET NAMES utf8&apos;character-set-server=utf8collation-server=utf8_unicode_ci 编辑 /etc/mysql/my.cnf 配置文件，依次添加上面的编码设置。 12345678910111213141516#[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect=&apos;SET NAMES utf8&apos;character-set-server=utf8collation-server=utf8_unicode_ci!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 然后重启 mysql 服务： 1$ service mysql restart 再次登录mysql命令模式查看默认编码： 123456789101112131415161718192021222324252627$ mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_general_ci || collation_database | utf8_unicode_ci || collation_server | utf8_unicode_ci |+----------------------+-----------------+3 rows in set (0.00 sec) 可见，我们已经更改成功了。 Change MySQL default character set to UTF-8 in my.cnf? - Stack Overflow 让MySQL服务器被远程访问默认情况下，root账户只能从 localhost 即本机下来访问mysql的服务。而在正式使用时，mysql数据库都是放在远程的数据库服务器上，这样也就需要我们通过远程的方式能够访问到mysql服务。 开启绑定端口编辑配置文件 /etc/mysql/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf ，将绑定地址行注释掉或者修改为指定IP： 12#注释bind-address# bind-address = 127.0.0.1 注释掉则允许所有ip都能够访问，也可以设置成 0.0.0.0 修改为指定的IP地址，则只允许该IP网段可以访问 修改配置文件后，重启 mysql 服务生效： 1$ service mysql restart 如果这时通过外网连接mysql，在连接时会出现错误 “’Host XXX is not allowed to connect to this MySQL server’ ” ，则还需要修改数据库中用户的访问权限。 修改数据库中账户访问权限这里以 root 账户为例来设置远程访问。 查看root账户可访问权限以 root 账户登录： 12mysql -u root -pEnter password: &lt;enter password&gt; 切换到 mysql 数据库，并查询 user 表中的账户设置： 1234567891011121314151617mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 || localhost | testuser2 |+-----------+------------------+5 rows in set (0.00 sec) 可以看到，root账户默认下不允许从远程登陆，只能从 localhost 来访问，我们还要为 root 账户添加访问权限。 添加远程访问授权这里有两种方法，一种是将上面的 mysql 数据库中的 user 表里的 host 项，将 localhost 改为 %， 12mysql&gt; use mysql;mysql&gt; update user set host =&apos;%&apos; where user =&apos;root&apos;; 另外一种是为账号 root 添加一个新的远程访问授权。 这里我们采用第二种方法。 通过命令 GRANT ALL PRIVILEGES ON *.* to root@&#39;%&#39; IDENTIFIED BY &#39;put-your-password&#39; WITH GRANT OPTION; 来操作。 执行如下命令： 123456mysql -u root -pEnter password: &lt;enter password&gt;mysql&gt; GRANT ALL PRIVILEGES ON *.* to root@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos; WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES; 再次查看： 123456789101112mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | root || localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 || localhost | testuser2 |+-----------+------------------+6 rows in set (0.00 sec) 现在再尝试通过外网来连接 mysql 数据库，就能连接成功了。 本地和远程访问使用不同权限或密码在上面的表中我们可以知道，root 账户有两个 host 配置项，一个本地的，一个远程的。其实我们可以将两项设置成不同的密码，以防止本地或远程的密码泄露问题。也可以在 grant 后跟详细的查询条件 select,delete 等，为本地或远程访问设置不同的访问权限。比如： 1mysql&gt; GRANT SELECT,UPDATE,INSERT,DELETE on *.* to root@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos; WITH GRANT OPTION; mysql grant 命令三种常用 - redfox - 博客园 mysql Grant 语法详解 添加特定远程访问权限假设账户 myuser 密码 mypwd grant all privileges on *.* to &#39;myuser&#39;@&#39;localhost&#39; identified by &#39;mypwd&#39; grant all privileges on *.* to &#39;myuser&#39;@&#39;%&#39; identified by &#39;mypwd&#39; grant all privileges on *.* to &#39;myuser&#39;@&#39;10.22.255.18&#39; identified by &#39;mypwd&#39; 说明： 添加一个本地用户 myuser ,一般用于web服务器和数据库服务器在一起的情况 添加一个用户 myuser ,只要能连接数据库服务器的机器都可以使用，这个比较危险，一般不用 在数据库服务器上给 10.22.255.18 机器添加一个用户 myuser，一般用于web服务器和数据库服务器分离的情况 注意：真正使用的时候不会用 grant all PRIVILEGES on *.* ，而是根据实际需要设定相关的权限。 特定访问权限 如果想让账户 myuser 使用 mypwd 从任何主机连接到 mysql 服务器，执行： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;%&apos; IDENTIFIED BY &apos;mypwd&apos; WITH GRANT OPTION; 如果想让账户 myuser 使用密码 123456 从 ip为 123.123.123.123 的主机连接到 mysql 服务器，执行： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;123.123.123.123&apos; IDENTIFIED BY &apos;123456&apos; WITH GRANT OPTION; 即 ‘%’ 表示任何主机。 WITH GRANT OPTION 是啥意思WITH GRANT OPTION 表示具有授予权限的权利。比如 上面的： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;%&apos; IDENTIFIED BY &apos;mypwd&apos; WITH GRANT OPTION; 为 root 用户赋予了 ALL PRIVILEGES 的权限，那么 root 账户就可以为其他的账户比如 testuser1 设置不同的权限。]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统下安装终极Shell-zsh]]></title>
    <url>%2F2016%2F10%2F05%2Fubuntu-install-zsh%2F</url>
    <content type="text"><![CDATA[查看系统 shell终端输入 echo $SHELL ，可以输出当前使用的shell。 终端输入 cat /etc/shells ，可以输出当前系统已经安装的shell。 安装 zsh安装 zsh 需要 git 环境支持，请先确保已安装 git 环境： 1$ sudo apt-get install git 安装 zsh12$ sudo apt-get update$ sudo apt-get install zsh 安装增强插件 oh-my-zsh可以通过 wget 或者 curl 来安装。下面的命令是在 Oh My Zsh 官网中查看到的最新安装命令，建议用官网中的推荐安装方法： 12// wget$ sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 12// curl$ sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 执行完上面的命令后，可能会出现两种情况。 输入密码后立即生效当提示停留在 Password 处要求输入当前账户的密码时，直接输入密码，等待自动配置完成即可。oh-my-zsh 会立即生效。 12345678910111213141516171819202122232425262728ubuntu@VM-46-228-ubuntu:~$ sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;Cloning Oh My Zsh...Cloning into &apos;/home/ubuntu/.oh-my-zsh&apos;...remote: Counting objects: 891, done.remote: Compressing objects: 100% (756/756), done.remote: Total 891 (delta 20), reused 708 (delta 7), pack-reused 0Receiving objects: 100% (891/891), 590.35 KiB | 111.00 KiB/s, done.Resolving deltas: 100% (20/20), done.Checking connectivity... done.Looking for an existing zsh config...Using the Oh My Zsh template file and adding it to ~/.zshrcTime to change your default shell to zsh!Password: __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \/ __ \ / __ `__ \/ / / / /_ / / ___/ __ \/ /_/ / / / / / / / / / / /_/ / / /_(__ ) / / /\____/_/ /_/ /_/ /_/ /_/\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options.p.s. Follow us at https://twitter.com/ohmyzsh.p.p.s. Get stickers and t-shirts at https://shop.planetargon.com.➜ ~ 可以看到前面的提示符已经变了。 需要重启生效如果提示如下信息，则直接忽略即可，继续执行下面的步骤。 1234Looking for an existing zsh config...Using the Oh My Zsh template file and adding it to ~/.zshrcTime to change your default shell to zsh!Password: chsh: PAM: Authentication failure 如果提示 Authentication failure，则还需要执行如下命令将zsh更改为默认shell,根据提示输入当前用户的密码,重新登录终端或重启后生效： 123456$ chsh -s /bin/zsh//或:$ chsh -s `which zsh`$ sudo reboot zsh 主题zsh的默认配置项都在 ~/.zshrc 文件中，例如里面的ZSH_THEME=&quot;robbyrussell&quot; 表示当前zsh的主题为robbyrussell. 配置完之后，我们需要重启终端或打开新的标签，或者用以下命令刷新配置：1source ~/.zshrc oh-my-zsh 提供了数十种主题，我们可以在目录 ~/.oh-my-zsh/themes 中看到他们： 1~/.oh-my-zsh/themes 如果你不知道选哪个好，我们可以设置成随机项： 1ZSH_THEME=&quot;random&quot; oh-my-zsh官方提供的主题如下：Themes · robbyrussell/oh-my-zsh Wiki · GitHub zsh 下的后台程序在 zsh 下，如果有后台运行的程序，此时执行 exit 会提示如下： 12➜ ~ exitzsh: you have running jobs. 在一般的 Bash 下，我们设置后台运行程序用 &amp;: 1$ python cnblog.py &amp; 而在 zsh 下，我们设置后台运行程序则需要用 &amp;!: 1$ python cnblog.py &amp;! StackOverflow上的提示： 123Start the program with—dolphin &amp;!The &amp;! (or equivalently, &amp;|) is a zsh-specific shortcut to both background and disown the process, such that exiting the shell will leave it running. 详见：bash - Exit zsh, but leave running jobs open? - Stack Overflow 相关参考 在Ubuntu上安装zsh Ubuntu 上安装 zsh [Linux] ubuntu安装zsh - TangShangWen - SegmentFault oh-my-zsh]]></content>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下进程管理Supervisor]]></title>
    <url>%2F2016%2F10%2F04%2Fsupervisor-process-management%2F</url>
    <content type="text"><![CDATA[Supervisor Supervisor,是一个进程控制系统，是一个客户端/服务器端系统允许用户在UNIX-LIKE 操作系统中去监控，控制一些进程。Supervisor作为主进程，Supervisor下管理的时一些子进程，当某一个子进程异常退出时，Supervisor会立马对此做处理，通常会守护进程，重启该进程。 Supervisor 有两个主要的组成部分： supervisord，运行 Supervisor 时会启动一个进程 supervisord，它负责启动所管理的进程，并将所管理的进程作为自己的子进程来启动，而且可以在所管理的进程出现崩溃时自动重启。 supervisorctl，是命令行管理工具，可以用来执行 stop、start、restart 等命令，来对这些子进程进行管理。 Supervisor 安装通常除了通过源码的 setup.py 的方式来安装(详见官网文档 Supervisor: A Process Control System &mdash; Supervisor 3.3.0 documentation )，还有以下两种方式： 12$ sudo apt-get install supervisor$ sudo pip install supervisor 但这两种安装方式是有区别的。 通过 pip 的方式安装后不会安装为默认服务，还需要自己将supervisor程序设置为后台服务。而通过 apt-get 的方式安装后就默认创建为了后台服务，可以直接通过 service supervisor restart 的方式来管理。 可见：python - supervisor.conf default location - Stack Overflow 配置文件supervisor的配置文件通常命名为 supervisord.conf。 配置文件检测顺序如下(默认会使用找到的第一个): $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) 通过 apt-get install supervisor 方式安装执行 ： 1$ sudo apt-get install supervisor 安装完成后会默认将 supervisord 启动为后台服务： 123$ ps -ef|grep supervisorroot 1455 1 0 15:46 ? 00:00:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisor/supervisord.conftiger 1470 1298 0 15:46 pts/1 00:00:00 grep --color=auto supervisor 通过 apt-get 安装的 supervisord 程序位于 /usr/bin/ 目录下： 123$ sudo whereis supervisord[sudo] password for tiger:supervisord: /usr/bin/supervisord 安装完成后查看 ls /etc/supervisor/ : 12$ ls /etc/supervisor/conf.d supervisord.conf 我们看到会生成一个默认的 supervisord.conf 配置文件，也可以在 conf.d 目录下创建自己的配置文件。 查看文件 supervisord.conf 内容： 12345678910111213141516171819202122232425262728; supervisor config file[unix_http_server]file=/var/run/supervisor.sock ; (the path to the socket file)chmod=0700 ; sockef file mode (default 0700)[supervisord]logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)childlogdir=/var/log/supervisor ; (&apos;AUTO&apos; child log dir, default $TEMP); the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL for a unix socket; The [include] section can just contain the &quot;files&quot; setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.[include]files = /etc/supervisor/conf.d/*.conf 该默认配置文件中是包含着 conf.d 目录下的所有 *.conf 文件的。我们可以对于不同的项目，使用各自独立的配置文件，放置在 /etc/supervisor/conf.d 目录下。 我们在 conf.d 目录下使用 echo_supervisord_conf 命令来创建一个 hello.conf 配置文件(或者直接通过 vim 创建一个空的 .conf 文件也可)： 12$ tiger@localhost:/etc/supervisor/conf.d$ echo_supervisord_conf &gt; hello.conf-bash: Hello.conf: 权限不够 如果提示没有权限的问题，可以使用下面的命令： 1$ sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisor/conf.d/hello.conf&quot; 查看生成的 hello.conf : 123456789101112131415161718192021222324252627282930;[program:theprogramname];command=/bin/cat ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=999 ; the relative start priority (default 999);autostart=true ; start at supervisord start (default: true);autorestart=unexpected ; whether/when to restart (default: unexpected);startsecs=1 ; number of secs prog must stay running (def. 1);startretries=3 ; max # of serial start failures (default 3);exitcodes=0,2 ; &apos;expected&apos; exit codes for process (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (default 10);stdout_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (default 10);stderr_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=1,B=2 ; process environment additions (def no adds);serverurl=AUTO ; override serverurl computation (childutils) 我们需要管理的程序只要依照上面的说明进行配置即可： 假如在目录 /home/tiger/py 下有一个需要在后台运行的 Python 程序 hello.py 。日志文件保存在 /home/tiger/py/logs 下。 123456789101112# coding:utf-8import timedef make_log(): while True: time.sleep(2) with open(&apos;hello.log&apos;,&apos;a&apos;) as f: f.write(&apos;hello_&apos;+time.strftime(&quot;%H:%M:%S&quot;)+&apos;\r&apos;)if __name__ == &apos;__main__&apos;: make_log() 我们向上面创建的配置文件 /etc/supervisor/conf.d/hello.conf 中写入如下数据(可把已有的数据清空，分号 ; 开头的表示注释信息)： 12345678910[program:hello] ;服务的名称command=python hello.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/hellopy.log ; log 日志stderr_logfile=/home/tiger/py/logs/hellopy.err ; 错误日志 使文件具有可写权限: 1$ sudo chmod 777 /etc/supervisor/conf.d/hello.conf 通过如下命令启动 supervisor： 1$ sudo supervisord -c /etc/supervisor/supervisord.conf 通过 apt-get 安装的 supervisor 在安装完成后已经作为了后台服务启动了，修改了配置文件后只需要重新加载即可生效。 重新加载配置文件使用命令： 1$ sudo supervisorctl reload 其他操作命令： 1234$ sudo supervisorctl -c /etc/supervisor/supervisord.conf status 查看管理进程状态$ sudo supervisorctl -c /etc/supervisor/supervisord.conf reload 重新载入配置项$ sudo supervisorctl -c /etc/supervisor/supervisord.conf start [all]|[appname] 启动指定/所有程序进程$ sudo supervisorctl -c /etc/supervisor/supervisord.conf stop [all]|[appname] 关闭指定/所有程序进程 注意： supervisor 默认情况下如果不指定要执行的配置文件路径会按照默认的顺序去查询相应的配置文件，按找到的第一个为准。所以，执行以上代码时，精简的代码为： 1$ sudo supervisorctl status 完整的代码为： 1$ sudo supervisorctl -c /etc/supervisor/supervisord.conf status -c 参数指定使用的配置文件目录 更多参数请通过 supervisorctl -h/--help 查看。 测试时发现在 Ubuntu 16.04 系统下通过 apt-get 方式安装的 Supervisor 3.3.0 之前版本(eg:3.2.0.x) 默认不会注册为后台服务，3.3.0.x后的版本会默认注册为后台服务。 待考证 通过 pip install supervisor 的方式安装通过 sudo pip install supervisor 安装完成后不会在 /etc/ 下生成 supervisor 目录及其下的文件。应用程序是存在于 /usr/local/bin/ 目录中: 12$ ls /usr/local/bin/echo_supervisord_conf pidproxy supervisorctl supervisord 可见安装时的脚本如下： 1234567............Installing /usr/local/lib/python2.7/dist-packages/supervisor-3.3.0-nspkg.pth Installing echo_supervisord_conf script to /usr/local/bin Installing pidproxy script to /usr/local/bin Installing supervisorctl script to /usr/local/bin Installing supervisord script to /usr/local/bin 可见通过 pip 安装的 supervisord 程序位于 /usr/local/bin/ 目录下(或者通过如下命令查找)。 123$ sudo whereis supervisord[sudo] password for tiger:supervisord: /usr/local/bin/supervisord 配置文件通常默认配置文件位于 /etc/supervisord.conf。 通过以下命令来创建默认配置文件： 1$ echo_supervisord_conf &gt; /etc/supervisord.conf 如果出现没有权限的问题，可以使用这条命令: 1$ sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisord.conf&quot; 默认的配置文件是下面这样的，但是这里有个坑需要注意：supervisord.pid 以及 supervisor.sock 是放在 /tmp 目录下，但是 /tmp 目录是存放临时文件，里面的文件会被linux系统删除的，一旦这些文件丢失，就无法再通过 supervisorctl 来执行 restart 和 stop 命令了，将只会得到 unix:///tmp/supervisor.sock 不存在的错误。(通过 apt-get 方式安装的配置文件中不是 /tmp 而是/var/run) 1234567891011121314151617181920212223242526272829303132333435363738394041424344[unix_http_server]file=/tmp/supervisor.sock ; (the path to the socket file);chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; (default is no username (open server));password=123 ; (default is no password (open server));[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface);username=user ; (default is no username (open server));password=123 ; (default is no password (open server))[supervisord]logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200);umask=022 ; (process file creation umask;default 022);user=chrism ; (default is current user, required if root);identifier=supervisor ; (supervisord identifier, default is &apos;supervisor&apos;);directory=/tmp ; (default is not to cd during start);nocleanup=true ; (don&apos;t clean up tempfiles at start;default false);childlogdir=/tmp ; (&apos;AUTO&apos; child log dir, default $TEMP);environment=KEY=&quot;value&quot; ; (key value pairs to add to environment);strip_ansi=false ; (strip ansi escape codes in logs; def. false); the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set;prompt=mysupervisor ; cmd line prompt (default &quot;supervisor&quot;)...... 将默认配置文件中的以下项进行修改： 123456789101112131415;file=/tmp/supervisor.sock;修改为 `/var/run` 目录file=/var/run/supervisor.sock;logfile=/tmp/supervisord.log;修改为 `/var/log` 目录logfile=/var/log/supervisord.log;pidfile=/tmp/supervisord.pid;修改为 `/var/run` 目录pidfile=/var/run/supervisord.pid;serverurl=unix:///tmp/supervisor.sock;修改为 `/var/run` 目录serverurl=unix:///var/run/supervisor.sock 然后在配置文件中添加启动的程序配置项： 12345678910[program:hello] ;服务的名称command=python hello.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/hellopy.log ; log 日志stderr_logfile=/home/tiger/py/logs/hellopy.err ; 错误日志 启动 supervisord执行 supervisord 命令，将会启动 supervisord 进程，同时我们在配置文件中设置的进程也会相应启动。 使用如下命令来启动: 1$ sudo supervisord -c /etc/supervisord.conf 示例操作命令： 123456789tiger@localhost:~/py$ ps -ef | grep supervisortiger@localhost:~/py$ sudo supervisord -c /etc/supervisord.conftiger@localhost:~/py$ ps -ef | grep supervisorroot 7363 1 0 11:42 ? 00:00:00 /usr/bin/python /usr/local/bin/supervisord -c /etc/supervisord.conftiger@localhost:~/py$ ps -ef | grep hellotiger 7364 7363 0 11:42 ? 00:00:00 python hello.py 我们使用 supervisord 来启动管理进程，之后所有的操作都用 supervisorctl 来控制。 (default /etc/supervisord.conf) supervisorctl 命令介绍123456789101112# appname 为 [program:x] 里的 x$ sudo supervisorctl start [appname]|[all] 启动指定/所有程序进程$ sudo supervisorctl stop [appname]|[all] 停止指定/所有程序进程$ sudo supervisorctl status 查看管理所有进程状态$ sudo supervisorctl status [appname] 查看管理指定进程状态$ sudo supervisorctl reload 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程$ sudo supervisorctl update 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启$ sudo supervisorctl restart [appname] 重启某个进程$ sudo supervisorctl shutdown 关闭所有管理进程$ sudo supervisorctl start/stop/restart/status groupworker: 管理所有属于名为 groupworker 这个分组的进程$ sudo supervisorctl start/stop/restart/status groupworker:name1 管理分组里指定的进程 注意：显示用 stop 停止掉的进程，用 reload 或者 update 都不会自动重启。 该问题待考证 示例操作命令： 123456tiger@localhost:~/py$ sudo supervisorctl statushello RUNNING pid 7382, uptime 0:01:50tiger@localhost:~/py$ sudo supervisorctl stop hellohello: stoppedtiger@localhost:~/py$ sudo supervisorctl statushello STOPPED Jul 27 11:47 AM 开机自动启动 Supervisord通过 pip 安装的 Supervisord 默认情况下并没有被安装成服务，它本身也是一个进程。我们可以使用安装脚本将supervisord设置为服务。 1234567891011# 下载脚本 (需要root权限)$ sudo su - root -c &quot;sudo curl https://gist.githubusercontent.com/howthebodyworks/176149/raw/d60b505a585dda836fadecca8f6b03884153196b/supervisord.sh &gt; /etc/init.d/supervisord&quot;# 设置该脚本为可以执行$ sudo chmod +x /etc/init.d/supervisord# 设置为开机自动运行% sudo update-rc.d supervisord defaults# 试一下，是否工作正常$ sudo service supervisord stop$ sudo service supervisord start# 查看supervisord进程$ sudo ps -ef| grep supervisor 注意：下载了 supervisord.sh 文件后，请核对好里面的配置参数和本地文件所在目录是否一致(主要是以下部分)： 12345678910 ...# PATH should only include /usr/* if it runs after the mountnfs.sh scriptPATH=/sbin:/usr/sbin:/bin:/usr/binDESC=&quot;Description of the service&quot;NAME=supervisordDAEMON=/usr/local/bin/supervisordDAEMON_ARGS=&quot;&quot;PIDFILE=/var/run/$NAME.pidSCRIPTNAME=/etc/init.d/$NAME ... 详细安装方法及脚本文件见下面两个链接说明： python - How to automatically start supervisord on Linux (Ubuntu) - Server Fault an init.d script for supervisord · GitHub 还有第二种方法将supervisor随系统启动而启动，Linux 在启动的时候会执行 /etc/rc.local 里面的脚本，所以只要在这里添加执行命令即可： 12345# 如果是 Ubuntu 添加以下内容（这里要写全路径，因为此时PATH的环境变量未必设置）/usr/local/bin/supervisord -c /etc/supervisord.conf# 如果是 Centos 添加以下内容/usr/bin/supervisord -c /etc/supervisord.conf 测试 supervisor 管理的进程能自动重启将 supervisor 管理的进程用 kill 命令杀掉，看是否能够自动重启。 1234567tiger@localhost:~/py$ ps -ef | grep hellotiger 7364 7363 0 11:42 ? 00:00:00 python hello.pytiger 7368 1255 0 11:42 pts/0 00:00:00 grep --color=auto hellotiger@localhost:~/py$ kill 7364tiger@localhost:~/py$ ps -ef | grep hellotiger 7382 7363 2 11:45 ? 00:00:00 python hello.pytiger 7384 1255 0 11:45 pts/0 00:00:00 grep --color=auto hello 使用 include在配置文件的最后，有一个 [include] 的配置项。我们可以 include 某个文件夹下的所有配置文件，这样就能为每个进程或相关的几个进程的配置单独写成一个文件。 配置文件的后缀名可以为 .conf 或 .ini。 在 /etc/supervisord.conf 末尾添加如下： 12[include]files = /etc/supervisord.d/*.conf 我们在 /home/tiger/py 目录下再建立一个 world.py 的python程序来做测试。 然后在 /etc 目录下创建 supervisord.d 目录，添加一个 world.conf 配置文件，写入如下配置信息。 12345678910[program:world] ;服务的名称，后面操作会用到command=python world.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/worldpy.log ; log 日志stderr_logfile=/home/tiger/py/logs/worldpy.err ; 错误日志 然后重新加载配置文件： 1$ sudo supervisorctl reload 查看运行状态： 12345678$ sudo supervisorctl statushello RUNNING pid 1549, uptime 0:00:28world RUNNING pid 1548, uptime 0:00:28$ sudo supervisorctl stop hellohello: stopped$ sudo supervisorctl statushello STOPPED Jul 27 04:53 PMworld RUNNING pid 1573, uptime 0:00:21 这样我们就通过不同的配置文件来管理不同的程序进程了。 Supervisor UI 管理台：在默认配置文件中我们可以找到下面的配置项： 1234;[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface);username=user ; (default is no username (open server));password=123 ; (default is no password (open server)) 去除 [inet_http_server] 和 port=127.0.0.1:9001 前面的分号，然后执行 sudo supervisorctl reload 重新加载配置文件。之后在浏览器中访问 http://localhost:9001 就能查看到Web版的进程管理界面了。 注意：如果设置为 port=127.0.0.1:9001，则只能在本机访问；如果为 port=*:9001 则可以在外网进行访问。 注意：;[inet_http_server] 这个前面的分号必须去掉，要不然不管用。 Supervisor 集群管理集中进程管理，可在一台机器下管理多台机器的进程。 详见：Supervisor集群管理开发 文档 XML-RPC API Documentation &mdash; Supervisor 3.3.0 documentation supervisord 的 XML-RPC API 使用说明 - yexiaoxiaobai - SegmentFault Supervisor集群管理WEB UI (monitor) - WisZhou的想到啥写啥 - 博客频道 - CSDN.NET GitHub - WisZhou/supervisord-monitor: Supervisord Monitoring Tool GitHub - luxbet/supervisorui: Supervisor multi-server dashboard unix:///var/run/supervisor.sock no such file某些情况下，可能会出现如下错误：unix:///var/run/supervisor.sock no such file 对于该问题，我的操作是，执行命令： 1$ sudo supervisord unix:///var/run/supervisor.sock no such file #480 注意：被监控的进程要以非daemon方式运行该问题暂未研究。略。 supervisor深入研究之 多进程略。 supervisor深入研究之 group 分组管理略。 supervisor调用 virtualenv 环境中的python项目配置 .conf 文件时，加上 environment 参数，指定 virtualenv 的目录: 123456789command = /home/www/flasky/env/bin/gunicorn -w 2 -b 0.0.0.0:8080 --max-requests 2000 --log-level debug --name %(program_name)s &quot;app:create_app(&apos;development&apos;)&quot;directory = /home/www/flaskyenvironment=PATH=&quot;/home/www/flasky/env/bin&quot;, GEVENT_RESOLVER=&quot;ares&quot;user = rootnumprocs=1autostart=falseautorestart=true...... 相关链接 Python 进程管理工具 Supervisor 使用教程 - restran - 博客园 Python 进程管理工具 Supervisor 使用教程 | 淡水网志 python - How to automatically start supervisord on Linux (Ubuntu) - Server Fault ubuntu下supervisor安装与使用笔记 - 为程序员服务 使用 supervisor 管理进程 - 李林克斯 使用Supervisor简化进程管理工作 - EverET.org python - supervisor.conf default location - Stack Overflow supervisor的配置文件查询目录 linux 后台进程管理利器supervisor - youxin - 博客园 Supervisor使用教程 | Snow Memory ☆ Linux进程管理工具supervisor安装及使用 | cpper ☆ Supervisor: A Process Control System &mdash; Supervisor 3.3.0 documentation 官方文档 How To Install and Manage Supervisor on Ubuntu and Debian VPS | DigitalOcean supervisor初体验 - 简书 使用 supervisor 管理进程 - 李林克斯 排版好看 supervisord 部署 Flask &#8211; Angiris Council 好 Supervisor手册 - GitBook supervisord 部署 Flask virtualenv wrapper]]></content>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Shadowsocks轻松实现科学上网]]></title>
    <url>%2F2016%2F10%2F02%2Fuse-shadowsocks-to-have-better-internet-experience%2F</url>
    <content type="text"><![CDATA[由于个人对百度的厌恶，平时上网很少用百度搜索。而又因为众所周知的原因，在国内要想用Google来上网着实是要费一翻心思的。所以也只能退而求其次，用微软的Bing来查询一些资料。 前几天刚刚把我在香港的云服务器进行了系统更换，从Windows Server换成了Linux系统，想起之前曾看过的使用Shadowsocks实现代理上网的文章，所以就想要亲自实现一下。 shadowsocks是一个著名的轻量级socket代理，原始版本是基于Python编写，后来又有了Go语言版本。不过该版本在Github上的源代码由于“你懂得”的原因，已经被开发者删除了。 这里我推荐安装的是 shadowsocks-libev 版本。shadowsocks-libev 是一个 shadowsocks 协议的轻量级实现，是 shadowsocks-android, shadowsocks-ios 以及 shadowsocks-openwrt 的上游项目。其特点如下： 体积小巧，静态编译并打包后只有 100 KB 高并发，基于 libev 实现的异步 I/O，以及基于线程池的异步 DNS，同时连接数可上万。 基于C语言实现，内存占用小（600k左右），低 CPU 消耗 shadowsocks-libev 的安装我的云服务器系统为 Ubuntu 14.04 TFS 通常 shadowsocks-libev 版本有两种安装方式，从源码安装和通过软件源来安装。这里我推荐使用源码安装的方式。 从源码安装 (Ubuntu/Debian系统下)安装必须的包12345$ sudo apt-get udpate$ mkdir shadowsocks-libev &amp;&amp; cd shadowsocks-libev$ sudo apt-get install build-essential autoconf libtool libssl-dev gawk debhelper dh-systemd init-system-helpers pkg-config asciidoc xmlto apg libpcre3-dev 安装过程会需要一些时间。 通过Git下载源码1$ git clone https://github.com/shadowsocks/shadowsocks-libev.git 然后生成deb包并安装，依照以下步骤依次执行(如果出错请检查系统或者之前的步骤)： 1234567$ cd shadowsocks-libev$ dpkg-buildpackage -b -us -uc -i$ cd ..$ sudo dpkg -i shadowsocks-libev*.deb 在上面的第三步 cd .. 后，可以看到目录下编译生成了三个 *.deb 文件，我这里的是： libshadowsocks-libev-dev_2.5.3-1_amd64.deb libshadowsocks-libev2_2.5.3-1_amd64.deb shadowsocks-libev_2.5.3-1_amd64.deb 上面的步骤操作完成后，我们就已经安装成功了 shadowsocks-libev 。 通过如下命令来查看运行状态： 12$ sudo service shadowsocks-libev status * shadowsocks-libev is not running 通过deb包安装的方式默认会开启自启。 直接从作者提供的软件源安装（Ubuntu/Debian）由于作者更新源码后并不一定及时更新这些预编译的包，所以无法保证最新版本，但操作步骤比较简单。 先添加GPG Key1$ wget -O- http://shadowsocks.org/debian/1D27208A.gpg | sudo apt-key add - 配置安装源，在/etc/apt/sources.list末尾添加12345# Ubuntu 14.04 or above$ deb http://shadowsocks.org/ubuntu trusty main# Debian Wheezy, Ubuntu 12.04 or any distribution with libssl &gt; 1.0.1$ deb http://shadowsocks.org/debian wheezy main 执行安装12$ apt-get update$ apt-get install shadowsocks-libev 这里我在 配置 wget -O- http://shadowsocks.org/debian/1D27208A.gpg | sudo apt-key add - 时无法连接到 http://shadowsocks.org 站点，所以这种方法我就没有继续测试。 shadowsocks-libev 一键安装待完善，详见：https://github.com/iMeiji/shadowsocks_install/wiki/shadowsocks-libev-%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85 配置与启动配置文件shadowsocks-divev 生成的默认配置文件在目录 /etc/shadowsocks-libev 下，找到 config.json 文件并编辑： 将配置信息： 12345678&#123; &quot;server&quot;:&quot;127.0.0.1&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIryahoa&quot;, &quot;timeout&quot;:60, &quot;method&quot;:null&#125; 修改为如下： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIryahoa&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 其中： server ：主机域名或者IP地址，尽量填IP (可以为服务器实际的IP地址或 0.0.0.0 ) server_port ：服务器监听端口 local_port: 客户端连接端口 password ：密码 timeout ：连接超时时间，单位秒。要适中 method ：加密方式 默认为table,其他有rc4,rc4-md5,aes-128-cfb, aes-192-cfb, aes-256-cfb,bf-cfb, camellia-128-cfb, camellia-192-cfb,camellia-256-cfb, cast5-cfb, des-cfb 注意： 如果客户端有OpenWRT路由器等设备，推荐 rc4-md5 ，性能更好；否则可以选用安全性更好的 aes-256-cfb 等。 server 配置项表示主机的域名或IP地址，这里默认情况下是 127.0.0.1 但不建议设置成 127.0.0.1 ，测试时发现无法正确连通。你可以设置成 0.0.0.0 或 真实的服务器所在的IP地址。修改配置文件重启后生效。 默认的客户端的IP地址为 127.0.0.1 启动上面有提到，通过deb包安装后就默认启动了，通过如下命令来控制： 1234$ sudo service shadowsocks-libev start$ sudo service shadowsocks-libev stop$ sudo service shadowsocks-libev status$ sudo service shadowsocks-libev restart 安装后的shadowsocks程序名为 ss-server ，程序目录为 /usr/bin/ss-server 。 查看 ss-server 的启动信息： 123456$ sudo service shadowsocks-libev status * shadowsocks-libev is not running$ ps ax |grep ss-server40160 ? Ss 0:00 /usr/bin/ss-server -c /etc/shadowsocks-libev/config.json -a root -u -f /var/run/shadowsocks-libev/shadowsocks-libev.pid -u40162 ? S+ 0:00 grep --color=auto ss-server 注意其中有 -u，表示会通过udp的方式进行连接。 通过 netstat -lnp 可以查看 ss-server 监听的端口： 12345678910$ netstat -lnp(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:8388 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::80 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - udp 0 0 0.0.0.0:8388 0.0.0.0:* - 可以看到 ss-server 通过 tcp 和 udp 两种方式监听了 8388 端口。 shadowsocks 客户端的设置shadowsocks 默认支持多种客户端。可以从 Shadowsocks - Clients 下载对应平台的客户端软件。 windows 客户端windows用户可以从 Releases · shadowsocks/shadowsocks-windows · GitHub 下载安装包。解压后得到 Shadowsocks.exe 程序。 运行，配置 服务器地址 服务器端口 密码 加密方式 即可。按照配置文件中的设置，默认监听客户端所在本地系统 127.0.0.1 的 1080 端口。 更加详细的内容可以参考如下文章： Shadowsocks Windows 使用说明 · shadowsocks/shadowsocks-windows Wiki · GitHub Chrome+SwitchyOmega实现科学上网详见另一篇文章：Chrome浏览器通过SwitchyOmega实现自动代理切换 | IT范儿 shadowsocks-libev 的多用户配置C语言编写的shadowsocks客户端/服务端软件shadowsocks-libev并不像go版本或python版本的shadowsocks客户端/服务端软件那样直接支持多实例配置，具体可以查看如下说明： please support multi-port config.json · Issue #5 shadowsocks-libev 版本默认不支持在同一个配置文件 config.json 中一次设置多个端口和密码，如果想要设置多个，可以通过添加多个配置文件来实现。 方式一先停止 ss-server 服务： 12345$ sudo service shadowsocks-libev status * shadowsocks-libev is running$ sudo service shadowsocks-libev stop$ sudo service shadowsocks-libev status * shadowsocks-libev is not running 然后，拷贝一份原来的配置文件，自定义新的文件名，只要保证扩展名为 .json 即可，我这里命名为 configuser1.json ： 123$ cd /etc/shadowsocks-libev$ sudo cp config.json configuser1.json$ sudo vim configuser1.json 修改配置参数中的端口号，密码等： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8398, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIrya3oyt&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 然后启动 ss-server 服务： 123$ sudo service shadowsocks-libev start$ sudo service shadowsocks-libev status * shadowsocks-libev is running 执行如下命令添加新的配置文件设置 ： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 注意将其中的 *** 替换为你的配置文件名称。 方式二如果你嫌上面的“停止-拷贝已有配置文件-重启”操作太麻烦，也可以直接新建一个json配置文件，然后填入如下配置信息： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8398, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIrya3oyt&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 注意 server_port 要设置成新的端口号。 然后直接执行如下命令即可： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 查看启动信息： 1234$ ps ax |grep ss-server40103 ? Ss 0:00 ss-server -c /etc/shadowsocks-libev/configuser1.json -u40160 ? Ss 0:00 /usr/bin/ss-server -c /etc/shadowsocks-libev/config.json -a root -u -f /var/run/shadowsocks-libev/shadowsocks-libev.pid -u40162 ? S+ 0:00 grep --color=auto ss-server 可以看到比之前多了一条后台服务。 通过 netstat -lnp 来查看 ss-server 是否监听了多个端口： 123456789101112$ netstat -lnp(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:8388 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:8398 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::80 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - udp 0 0 0.0.0.0:8388 0.0.0.0:* - udp 0 0 0.0.0.0:8398 0.0.0.0:* - 这样，就实现了监听多个端口，实现多用户连接了。如果想要停止新增的监听端口，只需要重启shadowsocks服务就又恢复默认，只会监听的 config.json 中配置的端口了。 相关链接 shadowsocks libev ☆ shadowsocks client Shadowsocks Windows 使用说明]]></content>
      <tags>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新安装Ubuntu系统后的必要设置]]></title>
    <url>%2F2016%2F10%2F01%2Ffirst-install-ubuntu-need-config%2F</url>
    <content type="text"><![CDATA[以下为我在重装Linux系统后进行的一些必要的操作，特此记录。 ubuntu 14.04 升级到 16.04如果直接执行 # do-release-upgrade 升级命令，会遇到：需要的依赖关系未安装 的报错信息： 1The required dependency &apos;apt (&gt;= 1.0.1ubuntu2.13)&apos; is not installed. 我们需要先更新 apt 到 1.0.1ubuntu2.13 以上才能进行升级操作。 通过以下操作来更新： 保持软件源指向 14.04(trusty) 不变 sudo apt-get update &amp;&amp; sudo apt-get upgrade 此时 apt 应已升级到 1.0.1ubuntu2.13，可以继续 do-release-upgrade 了。 总结需要执行的命令如下： 123# sudo apt-get update# sudo apt-get upgrade# sudo do-release-upgrade 操作完成后，重启系统即可：# sudo reboot 。 更新软件包及升级系统到最新的内核更新软件包刚装完linux系统后，软件及内核版本都比较低，需要先更新一下： 刚装完后系统版本为： Ubuntu 16.04.1 LTS 因为我的服务器在香港，所以能连接到ubuntu官方的软件源，如果你的系统是在国内，可能需要更新一下软件源，以免下载太慢或更新失败，设置软件源： 1# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 其他系统可参考 ：Ubuntu 源列表 执行如下命令进行更新： 12# sudo apt-get update# sudo apt-get upgrade 更新后的系统显示： 1Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.16.0-30-generic x86_64) 升级系统内核升级内核版本，执行如下命令： 1# sudo apt-get install linux-generic-lts-xenial linux-image-generic-lts-xenial 安装完成后重启： 1# sudo reboot 登陆后我们可以看到，内核已经更新了： 1Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-38-generic x86_64) Ubuntu新增普通管理员账户并设置管理员权限在Linux系统下，$ 是普通管理员命令标识，# 是系统管理员命令标识 更改已有用户账户密码我们可以使用 passwd 命令来更改账户的命令，执行后输入两次新密码即可。例如为 root 账户修改密码： 1$ sudo passwd root 新增用户账户可以通过 adduser 命令来新增账户： 1$ sudo adduser username 同样的需要输入两次密码，其他的设置项直接按回车即可。 新创建的用户只有普通用户权限，如果想要安装软件或更新软件包，还需要赋予账户管理员权限才行。 使新增用户具有 root 权限–命令法(不推荐)在网上查看为新增用户账户可以通过如下的命令来添加管理员权限，但我在实际操作后并没有生效，所以这里暂不推荐该方法。 1sudo usermod -G root username 要添加新用户到 sudo，最简单的方式就是使用 usermod 命令。运行 : 1$sudo usermod -G root username 然而，如果用户已经是其他组的成员，你需要添加 -a 这个选项，象这样： 1$sudo usermod -a -G root username 这里暂作记录，待以后找到为何无效的原因再来修改。 使新增用户具有 root 权限–修改文件法(推荐)使用新创建的用户账户登陆。这里我新建的用户是 tiger 账户。执行更新命令： 123456789tiger@MyServer:~$ apt-get updateE: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)E: Unable to lock directory /var/lib/apt/lists/E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?tiger@MyServer:~$ sudo apt-get update[sudo] password for tiger: tiger is not in the sudoers file. This incident will be reported.tiger@MyServer:~$ 报错信息：tiger is not in the sudoers file. This incident will be reported. 表名我们新建的账户 tiger 在 sudoers 文件中并没有指定权限，所以也就无法以管理员权限执行命令。 执行下面的操作： 先切换回 root 账户下(注意 su - 后面的 - 和后面的账户名之间有一个空格)： 1tiger@MyServer:~$ su - root 为文件 /etc/sudoers 添加写权限，默认情况下该文件为只读属性。执行命令：# chmod u+w /etc/sudoers 。 然后编辑该文件，找到这一行 : 1root ALL=(ALL:ALL) ALL 在下面按照同样的格式添加: 1xxx ALL=(ALL:ALL) ALL (这里的xxx是你要设置的用户名)，然后保存退出。 撤销文件的写权限，执行命令：# chmod u-w /etc/sudoers 。 完整的命令如下： 1234567891011121314151617181920212223242526root@MyCloudServer:/home/tiger# chmod u+w /etc/sudoersroot@MyCloudServer:/home/tiger# vim /etc/sudoersroot@MyCloudServer:/home/tiger# ls -al /etc/sudoers -rw-r----- 1 root root 770 Sep 28 02:15 /etc/sudoersroot@MyCloudServer:/home/tiger# chmod u-w /etc/sudoersroot@MyCloudServer:/home/tiger# su - tigertiger@MyCloudServer:~$ apt-get updateE: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)E: Unable to lock directory /var/lib/apt/lists/E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?tiger@MyCloudServer:~$ sudo apt-get updateGet:1 http://security.ubuntu.com trusty-security InRelease [65.9 kB]Ign http://us.archive.ubuntu.com trusty InRelease Get:2 http://us.archive.ubuntu.com trusty-updates InRelease [65.9 kB]Get:3 http://security.ubuntu.com trusty-security/main Sources [120 kB] Get:4 http://us.archive.ubuntu.com trusty-backports InRelease [65.9 kB] Get:5 http://security.ubuntu.com trusty-security/restricted Sources [4,064 B] Hit http://us.archive.ubuntu.com trusty Release.gpg Get:6 http://security.ubuntu.com trusty-security/universe Sources [42.5 kB]Get:7 http://us.archive.ubuntu.com trusty-updates/main Sources [383 kB]Get:8 http://security.ubuntu.com trusty-security/multiverse Sources [2,749 B]...... 这样，我们就为新创建的账户 tiger 设置了管理员权限，执行命令时就可以通过 sudo 来提权了。 参考： xx is not in the sudoers file 问题解决【转载】 - evasnowind - 博客园 Ubuntu技巧之 is not in the sudoers file解决方法_Linux教程_Linux公社-Linux系统门户网站 Ubuntu sudo Error:unable to resolve host为新增用户设置了管理员权限后，每次执行 $ sudo xxxx 命令时都会弹出下面一条信息： 1Ubuntu sudo Error:unable to resolve host 这种情况是 系统的主机名和配置文件中的主机名不一致造成的。 编辑 /etc/hostname 更改主机名(hostname)主机名是在命令行中 tiger@MyServer:~$ @符合后面的。 编辑 /etc/hosts 文件中： 123127.0.0.1 localhost127.0.1.1 ubuntu 更改 ubuntu 为你的 hostname 的名称。 结果为： 1234567127.0.0.1 localhost127.0.1.1 myhostname# The following lines are desirable for IPv6 capable hosts::1 localhost ip6-localhost ip6-loopbackff02::1 ip6-allnodesff02::2 ip6-allrouters 然后重启系统。sudo reboot 。必需重启之后才有效。 ubuntu 下修复使用sudo命令后出现主机名字不能解析的错误：Fix Ubuntu sudo Error:unable to resolve host - wzb56的资料库 - 博客频道 - CSDN.NET Ubuntu 14.04 修改时区在系统下通过 date 命令查看时间，可能会与本地的之间不一致。 比如 我当前系统的时间为 2016-10-5 15:53:54 而 服务器的时间为 Wed Oct 5 03:58:37 EDT 2016 。按理说，Linux系统在重启后会自动同步时间的，而这种情况可能是时区不一致的原因。 执行下面命令，并按照提示选择 “Asia/Shanghai”： 1# sudo dpkg-reconfigure tzdata 选择完成后，会输出如下结果： 123Current default time zone: &apos;Asia/Shanghai&apos;Local time is now: Wed Oct 5 16:01:12 CST 2016.Universal Time is now: Wed Oct 5 08:01:12 UTC 2016. 再次查看时间： 12tiger@MyServer:~$ dateWed Oct 5 16:02:13 CST 2016 Ubuntu 14.04 修改时区 - MyPy的个人页面 - 开源中国社区 Linux 下切换用户su 和 su - 的区别 12su abcsu - abc 注意，su - 在 - 和账户名后面还有一个空格分隔。 （总结）Linux下su与su -命令的本质区别 linux - Why do we use su - and not just su? - Unix &amp; Linux Stack Exchange Ubuntu下SSH能连接而SFTP不能连接ssh能够连接而sftp不能连接的解决方法 用FileZilla一直不能登录远程的服务器，ssh的登录就OK 1# locate sftp-server locate一下ftp-server，发现目录跟配置文件中的不同 1# vi /etc/ssh/sshd_config 1234# Allow client to pass locale environment variablesAcceptEnv LANG LC_*#Subsystem sftp /usr/lib/openssh/sftp-server 上面的 locate 查看到的列表，我更改成了如下的设置： 1234# Allow client to pass locale environment variablesAcceptEnv LANG LC_*Subsystem sftp /usr/lib/sftp-server 即把它默认成第二个改成了列表中的第一项。 然后重启ssh服务： 1sudo service ssh restart 再次尝试，则能够正常连接了。]]></content>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker+Flask搭建微信公众平台之一]]></title>
    <url>%2F2016%2F09%2F24%2Fdocker-and-flask-build-wechat-public-platform-first%2F</url>
    <content type="text"><![CDATA[之前申请的个人公众号在申请通过后用.NET开发了一版比较简单的交互逻辑功能，最近在知乎中看到有关Python开发微信公众号的文章，正好前几天也在学习Docker技术，所以就想研究一下在Docker下如何用Flask配置微信公众平台的开发环境。 因为我的公众号是 个人号且是未认证 的，可获得的权限有限，所以目前我只做了消息的发送和接收相关的功能，更多功能后期再考虑加入。 下面测试Demo是申请的微信公众平台的测试号来开发的。 环境配置 主系统 为 Win10 宿主机 为 在 Win10 下的 Hyper-V 虚拟机中安装的 Ubuntu 14.04 LTS 系统 宿主机ip地址为 http://192.168.137.219/ 测试Docker容器 为在 宿主机 下安装的 Ubuntu 14.04 LTS 系统 使用的软件是 Sublime Text 和 Xshell 4 、FileZilla Python环境为 2.7.12 这里提一点，如果你不知如何配置Docker环境，或从未接触过Docker技术，在我之后的文章中我会有详细的介绍，欢迎关注。 安装流程配置 Flask 运行环境在 宿主机中，当前的账户为 tiger。在主目录下创建 xweixin 目录，添加的 Flask 程序为 app.py 文件。 启动一个前台运行的容器，将宿主机目录 xweixin 映射到容器的 weixin 目录： 1docker run -it --name weixin01 -p 80:80 -v /home/tiger/xweixin:/weixin ubuntu /bin/bash 查看容器中主目录下是否存在 weixin 目录，及该目录下是否存在 app.py 文件： 12$ ls ****** weixin 注意： 下面的操作主要在 测试Docker容器 中进行，因为在Docker中默认是 root 账户，所以下面的命令前面都没有加 sudo 。 设置安装源： 1$ echo &quot;deb http://archive.ubuntu.com/ubuntu/ precise universe&quot; &gt;&gt; /etc/apt/sources.list 更新，安装python ： 123$ apt-get update$ apt-get install python -y # 默认安装的是 2.7.12 安装 virtualenv : (由于是在容器内操作，只用来搭建Flask的运行环境，所以可以不安装虚拟环境) 1$ apt-get install python-virtualenv 安装 pip ： 1$ apt-get install python-pip -y 安装 flask: 1$ pip install Flask 安装 vim ：(主要用于查看) 1$ apt-get install vim 总结上面的操作：从 Win10 系统创建 flask 程序 app.py 后，通过 SFTP 传输到 宿主计算机的 /home/tiger/xweixin 目录下，该目录直接映射到了容器的 /weixin 目录。 app.py 内容 ： 123456789from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) 在容器中执行 python app.py 运行。 在 主系统Win10 下访问 宿主机 的ip地址 http://192.168.137.219/，看到输出 Hello World! 说明Flask配置成功。 使用 ngrok 实现外网访问ngrok.exe 程序可以从 ngrok - download 下载。 在 主系统Win10 下使用 CMD 命令运行 ngrok 工具，执行如下命令： 1&gt; ngrok http 192.168.137.219:80 后面的 ip地址不要带 http:// , 端口号不要丢。 可以看到 ngrok 生成了一个 外网可以访问到的地址 http://c62f4a09.ngrok.io/ ,在浏览器中打开，看到输出 Hello World! 说明可以实现外网访问了。 搭建微信公众平台处理逻辑准备工作由于 ngrok 每次重新启动就会重新分配一个新的域名地址，所以我们在启动ngrok之后，就不需要再去管它了。Flask中启用了 debug=True 的选项后，每次更新文件 app.py 都会自动重新加载(除非程序报错导致异常退出)，所以这样下来我们只需要负责修改 app.py 改完了上传到宿主机，直接刷新即可，不需要再进行重启ngrok，重新执行 python app.py启动程序等操作，非常方便。 修改 app.py 的框架，假设网站的二级目录 /weixin 来实现我们的微信公众平台的接口操作。 123456789101112131415161718# coding:utf-8&quot;&quot;&quot;微信公众平台&quot;&quot;&quot;from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;# 微信公众平台接口@app.route(&apos;/weixin&apos;)def weixin_interface(): return &quot;这是微信接口&quot;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) 通过 ngrok 分配的域名为 http://d0dd1f96.ngrok.io/weixin ,该域名用于之后填入 微信公众平台 的接口配置的URL处(此时如果尝试添加，在微信公众平台页面一直会报配置错误的问题，因为在点击确定后微信会向我们的服务器发送验证消息，只有验证通过后才能保存)。 处理逻辑在 Flask 中通过不同的 method 处理微信的验证请求和交互请求12345678# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 else: # 处理逻辑交互 设置微信验证请求 - 验证消息的确来自微信服务器修改 weixin_interface 代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546....省略....from flask import Flaskfrom flask import requestimport hashlibimport time# 配置参数X_TOKEN=&apos;leafney&apos; #这里改写你在微信公众平台里输入的token....省略....# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 # 接收参数 wx_signature=request.args.get(&apos;signature&apos;) wx_timestamp=request.args.get(&apos;timestamp&apos;) wx_nonce=request.args.get(&apos;nonce&apos;) wx_echostr=request.args.get(&apos;echostr&apos;) # 自己的token wx_token=X_TOKEN # 字典序排序 w_list=[wx_token,wx_timestamp,wx_nonce] w_list.sort() # sha1加密算法 w_sha1=hashlib.sha1() map(w_sha1.update,w_list) w_hashcode=w_sha1.hexdigest() # 如果是来自微信的请求，则返回echostr if w_hashcode == wx_signature: return wx_echostr else: # 处理逻辑交互 pass 因为我用的是微信的测试号来进行配置，将程序上传并启动之后，在 “测试号配置” 页面中的 “接口配置信息” 处 填入 URL 和 Token 然后点击 “确定” 。 如果程序接入成功，会提示 “配置成功” ，否则可以在之前配置的 测试Docker容器 下查看调试信息，来进行相应的修改。 实现业务逻辑​当普通微信用户向公众账号发消息时，微信服务器将POST消息的XML数据包到开发者填写的URL上。 接收消息内容，在 Flask 中可以使用 request.data 来获取： 1xml_data=request.data 根据微信公众平台开发文档的说明 接收普通消息 - 微信公众平台开发者文档 我们可以通过 MsgType 参数来区分接收的消息的类型， 例如文本消息的数据包如下： 12345678&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; ToUserName 表示消息的接收者 FromUserName 表示消息的发送者 CreateTime 表示消息创建的时间戳 MsgType 表示消息的类型 Content 表示消息的内容 MsgId 表示消息的id，可以用来对消息排重 我们可以使用 lxml 来解析xml文档，获取相应的参数值。 添加引用： 12import lxmlfrom lxml import etree 解析得到所需的参数： 1234567wx_xml=etree.fromstring(xml_data) # 进行xml解析print(etree.tostring(wx_xml,pretty_print=True)) # 获取请求内容# 获取请求参数wx_msgType=wx_xml.find(&apos;MsgType&apos;).textwx_fromUser=wx_xml.find(&apos;FromUserName&apos;).text # 微信公众号wx_toUser=wx_xml.find(&apos;ToUserName&apos;).text # 用户 在向微信服务器回复消息时，也要按照微信的规定来返回特定XML结构的数据，详细可见 被动回复用户消息 - 微信公众平台开发者文档 ，比如回复文本消息格式如下： 1234567&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[你好]]&gt;&lt;/Content&gt;&lt;/xml&gt; 在向微信端回复消息时，ToUserName 和 FromUserName 我们可以从接收时的消息内容中来得到，只需要把接收者和发送者的角色互换一下即可，Content 为我们要回复的内容。 详细的处理代码如下： 123456789101112131415161718192021# 根据请求类型来返回不同的处理结果if wx_msgType == &apos;text&apos;: # 文本消息 # 获取文本消息内容 wx_content=wx_xml.find(&apos;Content&apos;).text content=wx_content.encode(&apos;utf-8&apos;) print(content) if content == &apos;天气&apos;: # return &apos;北京天气挺好的！&apos; # 注意回复消息时，接收者和发送者的位置要互换一下 return TextReply(wx_fromUser,wx_toUser,u&apos;北京天气挺好的！&apos;).render() else: return TextReply(wx_fromUser,wx_toUser,wx_content).render()elif wx_msgType == &apos;image&apos;: return &apos;success&apos;else: return &apos;success&apos; 消息模板： 123456789101112131415161718192021class TextReply(object): &quot;&quot;&quot;回复文本消息&quot;&quot;&quot; TEMPLATE=u&quot;&quot;&quot; &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[&#123;target&#125;]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[&#123;source&#125;]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;&#123;time&#125;&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[&#123;content&#125;]]&gt;&lt;/Content&gt; &lt;/xml&gt; &quot;&quot;&quot; def __init__(self, target,source,content): self.target=target self.source=source self.content=content self.time=int(time.time()) def render(self): return TextReply.TEMPLATE.format(target=self.target,source=self.source,time=self.time,content=self.content) 至此，接收回复文本消息的功能我们就做好了，上传到 宿主机 的 xweixin 目录下即可。 在运行代码之前，先要安装依赖包 lxml ,不然会报 No module named lxml 的错误。 安装 lxml先安装 lxml 的依赖包： 1$ apt-get install python-dev libxml2-dev libxslt1-dev zlib1g-dev 再安装 lxml : 1$ pip install lxml 完整的代码实现app.py (主程序) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# coding:utf-8&quot;&quot;&quot;微信公众平台&quot;&quot;&quot;from flask import Flaskfrom flask import requestimport hashlibimport lxmlfrom lxml import etreeimport time # 消息返回模板from reply import TextReply# 配置参数X_TOKEN=&apos;leafney&apos; #这里改写你在微信公众平台里输入的tokenapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 # 接收参数 wx_signature=request.args.get(&apos;signature&apos;) wx_timestamp=request.args.get(&apos;timestamp&apos;) wx_nonce=request.args.get(&apos;nonce&apos;) wx_echostr=request.args.get(&apos;echostr&apos;) # 自己的token wx_token=X_TOKEN # 字典序排序 w_list=[wx_token,wx_timestamp,wx_nonce] w_list.sort() # sha1加密算法 w_sha1=hashlib.sha1() map(w_sha1.update,w_list) w_hashcode=w_sha1.hexdigest() # 如果是来自微信的请求，则返回echostr if w_hashcode == wx_signature: return wx_echostr else: # 处理逻辑交互 xml_data=request.data # 获得post来的数据 wx_xml=etree.fromstring(xml_data) # 进行xml解析 # print(etree.tostring(wx_xml,pretty_print=True)) # 获取请求内容 # 获取请求参数 wx_msgType=wx_xml.find(&apos;MsgType&apos;).text wx_fromUser=wx_xml.find(&apos;FromUserName&apos;).text # 微信公众号 wx_toUser=wx_xml.find(&apos;ToUserName&apos;).text # 用户 # 根据请求类型来返回不同的处理结果 if wx_msgType == &apos;text&apos;: # 文本消息 # 获取文本消息内容 wx_content=wx_xml.find(&apos;Content&apos;).text content=wx_content.encode(&apos;utf-8&apos;) print(content) if content == &apos;天气&apos;: # return &apos;北京天气挺好的！&apos; # 注意回复消息时，接收者和发送者的位置要互换一下 return TextReply(wx_fromUser,wx_toUser,u&apos;北京天气挺好的！&apos;).render() else: return TextReply(wx_fromUser,wx_toUser,wx_content).render() elif wx_msgType == &apos;image&apos;: return &apos;success&apos; else: return &apos;success&apos;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) reply.py (消息模板) 123456789101112131415161718192021222324252627# coding:utf-8&quot;&quot;&quot;微信公众平台 消息回复模板&quot;&quot;&quot;import timeclass TextReply(object): &quot;&quot;&quot;回复文本消息&quot;&quot;&quot; TEMPLATE=u&quot;&quot;&quot; &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[&#123;target&#125;]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[&#123;source&#125;]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;&#123;time&#125;&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[&#123;content&#125;]]&gt;&lt;/Content&gt; &lt;/xml&gt; &quot;&quot;&quot; def __init__(self, target,source,content): self.target=target self.source=source self.content=content self.time=int(time.time()) def render(self): return TextReply.TEMPLATE.format(target=self.target,source=self.source,time=self.time,content=self.content) 未完待续至此，上面我们就实现了最基本的微信公众号的验证和简单文本消息的接收和回复功能。 之后我会介绍如何来处理复杂的消息内容，图片、语音、图文等等。然后通过一些有趣的小功能来让我们这即使没有特殊权限的公众号也能玩得更有意思，欢迎关注！ PublishTime: 2016-9-24 22:35:16]]></content>
      <categories>
        <category>微信公众平台</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSH密钥连接Github]]></title>
    <url>%2F2016%2F09%2F24%2Fusing-ssh-key-connection-github%2F</url>
    <content type="text"><![CDATA[每次向GitHub签入代码时，都要输入用户名和密码，让人感觉非常麻烦。如果使用SSH，通过密钥的方式来连接GitHub，每次提交代码就可以享受不用输入密码的快感了！ 下面我主要介绍在Windows下如何通过 SSH密钥 来连接GitHub。 引申 Linux下：Linux下使用SSH密钥连接Github Windows下：使用SSH密钥连接Github 第一步 查看是否已经存在SSH秘钥(keys)右键打开 Git Bash ,并运行： 1$ cd ~/.ssh 如果提示如下信息为 No such file or directory，则说明不存在SSH秘钥，如果已经存在，可以直接进入第三步。 12$ cd ~/.sshsh.exe&quot;: cd: /c/Users/Xue/.ssh: No such file or directory 如果无提示信息，进入 .ssh 目录执行 ls 命令，可查看本机已经存在的SSH的公钥和私钥。 第二步 创建新的SSH密钥(keys)输入如下命令： 12$ cd ~ # 保证当前路径在 `~` 下，即 `C:/Users/用户名` 目录$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot; # 这将根据你提供的邮箱地址，创建一对密钥 提示信息如下： 12345678910111213141516171819202122$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/用户名/.ssh/id_rsa): # 直接回车，则将密钥按默认路径及文件名进行存储。此时也可以输入特定的文件名Created directory &apos;/c/Users/用户名/.ssh&apos;.Enter passphrase (empty for no passphrase): # 根据提示，你需要输入密码和确认密码。可以不填，设置为空值，直接回车Enter same passphrase again:Your identification has been saved in /c/Users/用户名/.ssh/id_rsa.Your public key has been saved in /c/Users/用户名/.ssh/id_rsa.pub.The key fingerprint is:6d:40:da:xx:xx:xx:xx:b8:60:4a:bd:61:5f:c5:d6:db your_email@example.comThe key&apos;s randomart image is:+--[ RSA 2048]----+| . .=oo. || . * .=.*o . || . + =oo+.. o || . ..o. o . E || . S o || . || || || |+-----------------+ 然后在目录 ~/.ssh 下，就新创建了两个文件： 123$ cd ~/.ssh$ lsid_rsa id_rsa.pub 第三步 在GitHub账户中添加你的公钥执行如下命令，将公钥的内容复制到系统剪切板中(或直接打开该文件进行复制操作)： 1clip &lt; ~/.ssh/id_rsa.pub 登陆Github网站，选择 Settings –&gt; SSH and GPG keys 菜单，点击 New SSH key 按钮。粘贴你的密钥到 Key 输入框中并设置 Title 信息，点击 Add SSH key 按钮完成。 至此，添加完毕。 第四步 连接测试先保证本地 Git 已设置好git账户的 用户名 和 邮箱 信息： 12$ git config --global user.name &quot;your_username&quot; # 设置用户名$ git config --global user.email &quot;your_email@example.com&quot; # 设置邮箱地址 测试SSH keys 是否设置成功，执行如下命令： 1$ ssh -T git@github.com 提示信息如下： 12345678$ ssh -T git@github.comThe authenticity of host &apos;github.com (192.30.253.113)&apos; can&apos;t be established.RSA key fingerprint is 16:27:xx:xx:xx:xx:xx:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yes # 确认你是否继续连接，输入yesWarning: Permanently added &apos;github.com,192.30.253.113&apos; (RSA) to the list of known hosts.Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. # 出现这句话，说明设置成功 当提示如下信息，说明连通Github成功： 12Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 第五步 将本地项目通过 SSH push 到 GitHub在github新建一个仓库，如 test_ssh 。 执行以下命令： 123456789101112131415## 创建目录$ mkdir test$ cd test## 初始化git仓库$ git init## 创建readme.md文件$ echo &quot;this is a test ssh keys&quot; &gt; README.md## 提交到本地## 提交当前目录下的所有文件$ git add .## 提交记录说明$ git commit -m &quot;add readme.md&quot;## 提交到github$ git remote add origin git@github.com:your_github_name/test_ssh.git$ git push -u origin master 刷新 test_ssh 仓库，就能看到提交的文件了。 如果是本地已经存在的git项目，只需要执行以下命令即可： 123## 提交到github$ git remote add origin git@github.com:your_github_name/test_ssh.git$ git push -u origin master 相关参考文章 使用SSH密钥连接Github【图文教程】 - 轩枫阁 – 前端开发 | web前端技术博客]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用GitHub搭建Hexo静态博客]]></title>
    <url>%2F2016%2F09%2F24%2Fuse-github-to-build-hexo-static-blog%2F</url>
    <content type="text"><![CDATA[说明之前一直在用自己创建的.Net网站来写博客文章，只有简单的CRUD的功能，数据也是从数据库中直接查询的。自从接触了markdown之后，渐渐习惯了用markdown来记录自己在开发过程中遇到的问题和学到的新知识。但由于之前博客中是通过百度的 ueditor 编辑器来编辑文章，不能直接处理markdown，所以后来就一直考虑有没有其他的方法来更方便的管理和发布博客。 自从发现了 Hexo，不得不说这不就是我一直想要找的博客工具吗？ 静态博客的特点如下： 不用数据库 访问速度快 支持markdown，更加注重博客内容 而且部署到 GitHub 上，我们还不需要去配置服务器，非常的方便。 下面详细记录我这个博客的搭建部署流程，希望能帮到有需要的朋友们！ 搭建流程开始前保证已安装： Node.js Linux 下执行如下命令来安装： $ curl https://raw.github.com/creationix/nvm/master/install.sh | sh $ nvm install stable Windows 下可以从 Node.js Download 处选择 Windows Installer 下载msi安装包 Git Linux(Ubuntu) 下执行如下命令来安装： $ sudo apt-get install git-core Windows 下可以从 Git Download 处下载 Git for Windows 安装包 安装Hexo选择一个用来创建博客的目录，在该目录下使用 CMD 命令行窗口，这里推荐使用 Cmder 来代替Windows上默认的命令行。 通过 npm 命令执行： 1&gt; npm install -g hexo-cli 建站执行如下命令，Hexo 将会在指定文件夹中新建所需要的文件 123&gt; hexo init &lt;folder&gt;&gt; cd &lt;folder&gt;&gt; npm install 这里假设我要创建的博客所在目录名为 xblog ,则命令为： 123&gt; hexo init xblog&gt; cd xblog&gt; npm install 生成静态页1&gt; hexo g 该命令的完整格式为: hexo generate 启动服务1&gt; hexo s 该命令的完整格式为： hexo server hexo默认使用 4000 端口进行预览，可以通过浏览器打开 http://localhost:4000/ 查看。如果端口被占用，可以用 hexo s -p 5000 指定端口号为 5000 或者其他未被占用的端口。使用 Ctrl+C 来停止预览。 查看Hexo版本可以通过命令 hexo -v 查看当前hexo的版本信息： 12345678910111213&gt; hexo -vhexo: 3.2.2hexo-cli: 1.0.2os: Windows_NT 10.0.10586 win32 x64http_parser: 2.5.2node: 4.4.0v8: 4.5.103.35uv: 1.8.0zlib: 1.2.8ares: 1.10.1-DEVicu: 56.1modules: 46openssl: 1.0.2g Hexo配置更换主题 theme以主题 NexT 为例，首先下载该主题： 12&gt; cd your-hexo-site (我这里是 `cd xblog`)&gt; git clone https://github.com/iissnan/hexo-theme-next themes/next 在站点站点根目录下打开 _config.yml，找到 theme 字段，将 theme: landscape 改为 theme: next ，然后再次执行 hexo g 来重新生成。 主题设置关于主题的配置可直接参考NexT官网的配置流程 开始使用-NexT ，这里我会把自己在配置时的操作简单记录，仅供大家参考。 在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。 选择Scheme借助于 Scheme，NexT 提供了多种不同的外观。目前 NexT 支持三种 Scheme ： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Scheme 的切换通过更改 主题配置文件 ，搜索 scheme 关键字。 你会看到有三行 scheme 的配置，将你需要启用的 scheme 前面注释 # 去掉即可。 123#scheme: Muse#scheme: Mistscheme: Pisces 设置 语言编辑 站点配置文件， 将 language 设置成你所需要的语言。这里我选择了简体中文，配置如下： 1language: zh-Hans 设置 菜单菜单即是你的导航菜单，我们可以设置菜单项的 显示名称和 链接 以及 菜单项对应的图标 。 我们可以在 主题配置文件 中来修改，对应的字段是 menu 。我的配置如下： 123456menu: home: / # 主页 categories: /categories # 分类页 tags: /tags # 标签页 archives: /archives # 归档页 about: /about # 关于页面 菜单项的显示文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。 菜单项的图标，对应的字段是 menu_icons。我们可以通过 enable 来控制是否显示图标。 我们也可以添加自己的链接，只要把上面的 名称-链接-图标 三者对应好即可。 请注意键值（如 home）的大小写要严格匹配 设置 头像编辑 站点配置文件， 新增字段 avatar， 值设置成头像的链接地址。 我们可以将自己的头像图片文件上传到主题目录下的 source/uploads/ 目录下(新建uploads目录若不存在) 或 source/images/ 目录下。完整的目录就是 your-hexo-site\themes\next\source\images\ 下。 然后将 avatar 字段配置如下： 12# avatar 个人头像avatar: /images/avatar.jpg 或者也可以使用网络上的头像来进行设置： 1avatar: http://example.com/avatar.png 设置 作者昵称及站点描述编辑 站点配置文件， 设置 author 为你的昵称。 编辑 站点配置文件， 设置 description 字段为你的站点描述。 设置代码高亮主题NexT共提供了5款主题可以选择，默认使用白色的 normal 主题。 normal，night， night blue， night bright， night eighties 在 主题配置文件 中找到 highlight_theme 字段，更改即可。 1highlight_theme: night eighties 开启打赏功能NexT可以支持微信打赏和支付宝打赏，在 主题配置文件 中添加如下字段即可： 1234# 打赏功能reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /images/wechat-reward-image.jpgalipay: /images/alipay-reward-image.jpg 微信个人收款二维码可以从微信APP右上角“+”处，选择 收付款 – 我要收款 – 长按二维码 来获取。支付宝个人收款二维码可以从支付宝APP的右上角“+”处，选择 我的二维码/收款 来获取。 二维码图片可以和头像一样保存在 source/images/ 目录下。 主题栏目设置在上面设置导航菜单时我们已经添加了导航菜单: categories 和 tags ，但在预览时会直接报错，因为我们还没有创建这两个分类页面。 添加「标签」页面「标签」页面将展示站点的所有标签，若你的所有文章都未包含标签，此页面将是空的。 这里先详细介绍两个命令： 123&gt; hexo n about&gt; hexo n page about hexo n 的完整格式为 hexo new ，所以上面的命令也可以写成： 123&gt; hexo new about&gt; hexo new page about 两者的区别是： hexo new xxxx 表示创建一个新的文章页面。在Hexo中, 你写的博客文章会默认存储在 your-hexo-site/source/_posts 下。比如上面的命令 hexo new about 我们就在 your-hexo-site\source\_posts 目录下新建了一个 about.md 的文件。 hexo new page xxxx 表示创建一个新的分类主页面。比如上面的命令 hexo new page about 我们就在 your-hexo-site\source\ 目录下创建了一个名为 about 的目录，该目录下有一个名为 index.md 的文件。 在命令行窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个分类主页面，命名为 tags ： 12&gt; cd your-hexo-site&gt; hexo new page tags 然后打开 your-hexo-site\source\tags 目录下的 index.md 文件，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。 12345---title: 标签date: 2016-09-24 01:05:02type: &quot;tags&quot;--- 注意：如果有启用 多说 或者 Disqus 评论，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false ，如： 123456---title: 标签date: 2016-09-24 01:05:02type: &quot;tags&quot;comments: false--- 那么我们在新创建的文章页面中要如何来显示标签呢？ 我们可以在文章页面中通过添加 tags 标记来设置文章要显示的标签。 Hexo 中有 Front-matter 这个概念，是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 Front-matter 支持 “数组” 方式或 “yaml” 方式来设置，如下： 123title: hexo indexdate: 2016-09-24 01:05:02tags: [github,html5,css3] 123456title: hexo indexdate: 2016-09-24 01:05:02tags: - github- html5- css3 添加「分类」页面「分类」页面将展示站点的所有分类，若你的所有文章都未包含分类，此页面将是空的。 和上面配置 tags 的方法一样，我们可以通过命令 hexo new page xxxx 来创建： 12&gt; cd your-hexo-site&gt; hexo new page categories 这里需要注意的一点是，我们命令中的名称 tags 和 categories 是在之前配置导航菜单时在 menu 字段下指定的名称，大小写不能错。 相应的页面类型设置如下： 123456---title: 分类date: 2016-09-24 01:08:49type: &quot;categories&quot;comments: false--- 同样的，在文章页面中，我们可以通过 categories 字段来为文章指定所属的分类： 1234---title: 分类测试文章categories: Testing--- 关于 Hexo 下的文章页面上面已经提到过，我们可以通过 hexo n xxxx 或 hexo new xxxx 来创建新的文章页面，默认会保存在 your-hexo-site\source\_posts 目录下。 一般的文章页面头部的 Front-matter 格式如下： 12345678910111213---title: hexo next # 文章标题date: 2016-09-24 01:08:49 # 文章发布日期tags: [github,html5]tags: - github - html5 # tags 文章的标签，可以通过数组方式或yaml方式指定categories: 前端 # 文章所属分类description: 这里是文章描述，大概140个字左右 # 文章描述---下面是文章正文 ... 需要注意的是 冒号后面与内容直接要有一个空格，否则无法编译生成 正文与 Front-matter 之间要有一个空行 为文章添加描述文字除了指定 description 之外，还可以在正文中通过添加 &lt;!--more--&gt; 标签分隔内容 常见问题 修改配置文件时注意YAML语法，参数冒号:后一定要留一空格 中文乱码请修改文件编码格式为UTF-8 yml文件中所有有空格的字段都用双引号括起来 默认情况下，新建文章的文件名和标题名是相同的，需要注意的是如果文件名是中文，那么生成的链接后面会自动添加末尾斜杠 http://localhost:4000/2016/09/xxxxxxx/ 如果手动去掉该斜杠 / 会直接报错。所以推荐文件名最好用 英文 来写，文章内的标题可以改成中文。 另外，文章文件名中文末尾斜杠 的问题也可以通过配置 Nginx 来解决。(这里暂不讨论该方法) Hexo 中常用命令123456hexo generate (hexo g) # 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹hexo server (hexo s) # 启动本地web服务，用于博客的预览hexo deploy (hexo d) # 部署播客到远端（比如github, heroku等平台）hexo new &quot;postName&quot; # 新建文章hexo new page &quot;pageName&quot; # 新建页面hexo clean # 清理public文件夹 简写形式： 123456hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deployhexo d -g # 生成部署hexo s -g # 生成预览 将 Hexo 部署到 Github到 GitHub 新建一个项目，项目名为：你的用户名.github.io 必须为这个名字 Hexo 目前没有自带 Git 部署模块，需手动安装: 1&gt; npm install hexo-deployer-git --save 然后，在 站点配置文件 _config.yml 中设置 deploy 字段： 1234deploy: type: git repository: git@github.com:你的帐号/你的帐号.github.io.git #例如我的：repository: git@github.com:Leafney/Leafney.github.io.git branch: master 注意：这个respository的地址你在GitHub创建同名仓库后，会在页面中给出，直接复制即可。另外，branch 要设置为 master 分支。 在此之前，还要注意你本地的 Git 已经通过 SSH 和你的 GitHub 连接起来了。 如何通过SSH连接GitHub可以查看我的另一篇文章 使用SSH密钥连接Github 来进行设置。 然后执行命令： 123456&gt; hexo clean # 先清理public文件夹&gt; hexo g # 生成&gt; hexo d # 部署# 或通过下面一条命令直接生成并部署&gt; hexo g -d 执行完成之后会在你的博客根目录下生成一个文件夹：.deploy_git， 该目录下的文件会自动被发布到你的 GitHub 上，页面文件在 master 分支下。 然后打开浏览器，输入你的 GitHub pages 的地址 xxxxx.github.io 即可。 PublishTime: 2016-9-24 14:06:00]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F09%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello Firends! 现在是北京时间 2016-9-24 1:45:58 ,酝酿了很久的个人博客Hexo版终于要发布上线了！此处应该有掌声！！！ 之前写博客一直用的自己搭建的.net版的网站，只有简单的CRUD的功能，当时只是考虑用来作为自己的一个可以记事的地方，记下自己在开发过程中遇到的问题，学到的新知识等等，并没有考虑要去写一些技术类的文章，去分享。毕竟自己的能力还是有限的。 随着接触越来越多的开源项目，逐渐意识到“分享”确实是一个很有意义的事情。所以决定把自己平时学到的知识、技巧等记录于此，以便能帮助到遇到相关问题的开发朋友们。 博客中的文章会涉及.Net 、Python 、Golang、Linux、前端等相关方面，基本属于全栈，也会涉及到一些前沿的技术。 希望大家多多支持！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx初级入门]]></title>
    <url>%2F2016%2F07%2F03%2Fnginx-introduction%2F</url>
    <content type="text"><![CDATA[安装 1$ sudo apt-get install nginx 在Ubuntu下安装后的文件结构： 所有的配置文件都在 /etc/nginx/ 下 nginx.conf 为主配置文件 sites-available/default 为默认配置文件 程序文件在 /usr/sbin/nginx 下 日志放在了 /var/log/nginx 下 启动脚本 /etc/init.d/nginx 默认的虚拟主机的目录设置在了 /var/www/ 下（参考默认配置文件） 在 nginx.conf 配置文件中，可看到下面两行： 12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 网上找到的自定义配置文件的设置方法为： 我们可以在 /etc/nginx/sites-available 目录下添加自定义配置文件，然后为该文件创建软链接到 /etc/nginx/sites-enabled 目录中。 也可以在 /etc/nginx/conf.d 目录下创建自定义配置文件并以 .conf 为扩展名。 nginx 的启动 暂停 重启 启动 sudo /etc/init.d/nginx start 暂停 sudo /etc/init.d/nginx stop 重启 sudo /etc/init.d/nginx restart nginx 基本的配置文件写法： 123456789101112sever &#123; listen 8080; server_name _; root /home/tiger/myweb/site; index index.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 示例文件 web.conf ,所在目录为 /etc/nginx/conf.d : 12345678910111213141516171819202122232425sever &#123; listen 8081; server_name _; root /home/tiger/myweb/site2; index index.html aaa.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125;server &#123; listen 8082; server_name _; # 访问 localhost error_page 404 /404.html; # 指定404错误页 root /home/tiger/myweb/site2/aaa; index abc.html; location / &#123; allow all; &#125;&#125; 查看目录下文件： 1234$ ls /home/tiger/myweb/site2aaa aaa.html$ ls /home/tiger/myweb/site2/aaa404.html abc.html]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy爬虫初探]]></title>
    <url>%2F2016%2F06%2F27%2Fscrapy-introduction%2F</url>
    <content type="text"><![CDATA[Scrapy 是一个快速的高层次的屏幕抓取和网页爬虫框架，爬取网站，从网站页面得到结构化的数据，它有着广泛的用途，从数据挖掘到监测和自动测试，Scrapy完全用Python实现，完全开源，代码托管在Github上，可运行在Linux，Windows，Mac和BSD平台上，基于Twisted的异步网络库来处理网络通讯，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片。 安装Scrapy1$ sudo pip install Scrapy scrapy依赖 lxml ,请保证已经安装了 lxml 库。 创建初始化项目框架 这里以抓取 http://www.cnbeta.com/topics/9.htm 页面中的文章标题和简介为例，创建项目名称为 cnbetaSpider 。 1$ scrapy startproject cnbetaSpider 该命令将会创建包含下列内容的 cnbetaSpider 目录: 12345678910cnbetaSpider/ scrapy.cfg cnbetaSpider/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... 这些文件分别是: scrapy.cfg : 项目的配置文件 cnbetaSpider/ : 该项目的python模块。之后您将在此加入代码。 cnbetaSpider/items.py : 项目中的item文件. cnbetaSpider/pipelines.py : 项目中的pipelines文件. cnbetaSpider/settings.py : 项目的设置文件. cnbetaSpider/spiders/ : 放置spider代码的目录. 定义ItemItem 是保存爬取到的数据的容器。我们需要从网页中提取 文章的标题，链接，描述，对此，在 item 中定义相应的字段。编辑 cnbetaSpider 目录中的 items.py 文件: 123456789import scrapyclass CnbetaspiderItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title=scrapy.Field() link=scrapy.Field() desc=scrapy.Field() pass 创建SpiderSpider 是用户编写用于从单个网站(或者一些网站)爬取数据的类。其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。 为了创建一个 Spider ，您必须继承 scrapy.Spider 类， 且定义以下三个属性: name 指定Spider的名称，唯一 start_urls 包含了Spider在启动时进行爬取的url列表 parse() 接收完成下载后生成的 Response 对象，该方法负责解析返回的数据，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。 在目录 cnbetaSpider/spiders 下创建文件 cnbetaspider.py: 12345678910111213141516# coding:utf-8import scrapyclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): filename=response.url.split(&quot;/&quot;)[-2] with open(filename,&apos;wb&apos;) as f: f.write(response.body) 爬取进入项目根目录，执行下列命令启动spider: 1234$ lscnbetaSpider scrapy.cfg# 执行命令$ scrapy crawl cnbeta 第三个参数为 cnbetaspider.py 中的 name 属性值。 执行完成后可在当前目录下看到生成的文件 topics,里面保存的获取到的网页的内容。 提取Scrapy使用了一种基于 XPath 和 CSS 表达式机制: Scrapy Selectors 。详见：选择器(Selectors) &mdash; Scrapy 0.24.1 文档 选择器方法( .xpath() or .css() ) 为了提取真实的原文数据，你需要调用 .extract() 方法： 12&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract()[u&apos;Example website&apos;] 这里给出XPath表达式的例子及对应的含义: /html/head/title : 选择HTML文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素 /html/head/title/text() : 选择上面提到的 &lt;title&gt; 元素的文字 //td : 选择所有的 &lt;td&gt; 元素 //div[@class=&quot;mine&quot;] : 选择所有具有 class=&quot;mine&quot; 属性的 div 元素 Selector有四个基本的方法: xpath() : 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 。 css() : 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表. extract() : 序列化该节点为unicode字符串并返回list。 re() : 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。 分析网页 http://www.cnbeta.com/topics/9.htm 中的文章： 文章列表在 item 元素： 1//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;] 标题： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() 链接： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() 描述： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() 修改我们之前定义的 cnbetaspider.py 中的 parse() 方法如下： 12345678910111213141516import scrapyclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): for sel in response.xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]&apos;): title=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() link=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() desc=sel.xpath(&apos;*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() print(title,link,desc) 再次执行，能看到爬取到的网站信息被成功输出: 1$ scapy crawl cnbeta 结果将之前设置的 Item 对象引入，使用标准的字典语法来保持获取到的每个字段的值。最终的代码为： 123456789101112131415161718192021222324# coding:utf-8import scrapyfrom cnbetaSpider.items import CnbetaspiderItemclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): items=[] for sel in response.xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]&apos;): item=CnbetaspiderItem() item[&apos;title&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() item[&apos;link&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() item[&apos;desc&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() # yield item items.append(item) return items 如果想把得到的结果保存在临时文件中，可以： 1$ scrapy crawl cnbeta &gt; abc.html 这样就把结果保存在当前目录下的 abc.html 中了。 Scrapy爬虫运行时报错 “Forbidden by robots.txt”解决该问题只需要将 settings.py 文件中的 ROBOTSTXT_OBEY 值改为 False 即可。 1ROBOTSTXT_OBEY = False 相关链接 Scrapy 0.25 文档 &mdash; Scrapy 0.24.1 文档 Scrapy 1.0 文档(未完成,只更新了intro部分,请谨慎参考) &mdash; Scrapy 1.0.5 文档 使用Scrapy抓取数据 爬虫出现Forbidden by robots.txt - 菜鸡瞎讲- 博客频道 - CSDN.NET Scrapy用Cookie实现模拟登录 - 简书]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>数据抓取</tag>
        <tag>Python</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式搜索引擎ElasticSearch初探]]></title>
    <url>%2F2016%2F06%2F20%2Fdistributed-search-engine-elasticsearch%2F</url>
    <content type="text"><![CDATA[ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。 任务点 在Ubuntu下安装 在Windows下安装 使用Restful API实现搜索引擎的CURD操作 在Python网站Flask下使用ElasticSearch实现文章搜索 ElasticSearch的Python连接器：Pyes 安装Java (JVM) versionedit Elasticsearch is built using Java, and requires at least Java 7 in order to run. Only Oracle’s Java and the OpenJDK are supported. The same JVM version should be used on all Elasticsearch nodes and clients.We recommend installing the Java 8 update 20 or later, or Java 7 update 55 or later. Previous versions of Java 7 are known to have bugs that can cause index corruption and data loss. Elasticsearch will refuse to start if a known-bad version of Java is used.The version of Java to use can be configured by setting the JAVA_HOME environment variable. Linux(Ubuntu)下安装Installing the oracle JDK1234sudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installerjava -version RPM based distributions123sudo /bin/systemctl daemon-reloadsudo /bin/systemctl enable elasticsearch.servicesudo /bin/systemctl start elasticsearch.service Windows下安装从网站 下载windows下的msi安装包，在cmd命令行进入安装目录，再进入 bin 目录，运行 elasticsearch.bat 。 Ubuntu下配置ElasticSearch环境实录安装Java环境由于ElasticSearch的运行需要Java环境的支持，先安装java环境。由于Ubuntu系统中由于授权问题，默认只安装了OpenJDK的包，通过java和javac可以看到：1234567* default-jdk* ecj* gcj-4.9-jdk* openjdk-8-jdk-headless* gcj-4.8-jdk* gcj-5-jdk* openjdk-9-jdk 根据ElasticSearch官方推荐安装方法： 1234sudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installerjava -version 如果出现如下提示信息，并有进度条显示，则说明运行顺利并正在下载所需文件： 1234567891011HTTP request sent, awaiting response... 200 OKLength: 181367942 (173M) [application/x-gzip]Saving to: ‘jdk-8u91-linux-x64.tar.gz’ 0K ........ ........ ........ ........ ........ ........ 1% 566K 5m8s 3072K ........ ........ ........ ........ ........ ........ 3% 1.15M 3m44s 6144K ........ ........ ........ ........ ........ ........ 5% 1.10M 3m16s 9216K ........ ........ ........ ........ ........ ........ 6% 1002K 3m5s 12288K ........ ........ ........ ........ ........ ........ 8% 715K 3m11s 15360K ........ ........ ........ ........ ........ ........ 10% 624K 3m18s 18432K ........ ........ ........ ........ ........ ........ 12% 417K 3m40s 否则可能由于网络原因或其他问题，会中断下载或报错。 错误一：安装时出现错误：12345678sha256sum mismatch jdk-8u91-linux-x64.tar.gzOracle JDK 8 is NOT installed.dpkg: 处理软件包 oracle-java8-installer (--configure)时出错： 子进程 已安装 post-installation 脚本 返回错误状态 1正在设置 gsfonts-x11 (0.24) ...在处理时有错误发生： oracle-java8-installerE: Sub-process /usr/bin/dpkg returned an error code (1) 可以用该文章中介绍的方法解决，亲测有效：http://www.miaoqiyuan.cn/p/ubuntu-e-sub-process-dpkg-returned-an-error-code 错误二：根据上面的方法执行完命令后，执行 java -version 时只会显示下列输出信息： 123456789tiger@vbox:~$ java -version程序 &apos;java&apos; 已包含在下列软件包中： * default-jre * gcj-4.9-jre-headless * gcj-5-jre-headless * openjdk-8-jre-headless * gcj-4.8-jre-headless * openjdk-9-jre-headless请尝试：sudo apt install &lt;选定的软件包&gt; 即使是重复执行上面的安装方法，结果仍是如此： 123456789101112tiger@vbox:~$ sudo apt-get install oracle-java8-installer正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 oracle-java8-installer 已经是最新版 (8u92+8u91arm-2~really8u91~webupd8~0)。升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 196 个软件包未被升级。tiger@vbox:~$ sudo apt-get install oracle-java8-set-default正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 oracle-java8-set-default 已经是最新版 (8u92+8u91arm-2~really8u91~webupd8~0)。升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 196 个软件包未被升级。 根本问题是什么 转到目录/usr/lib/jvm/ 下，可以看到一个名为 java-8-oracle 的目录，但查看该目录却发现里面是空的。所以虽然提示是安装成功了，但却没有可执行的文件，可能是在下载文件时出错了。 由于直接安装错误，下面尝试手动进行安装。 什么情况下表示安装成功，什么情况下表示安装失败通过 java -version 来查看 如果输出如下，则说明 Orancel JDK 安装失败： 12345678root@ubuntu:~# java -versionThe program &apos;java&apos; can be found in the following packages: * default-jre * gcj-4.8-jre-headless * openjdk-7-jre-headless * gcj-4.6-jre-headless * openjdk-6-jre-headlessTry: apt-get install &lt;selected package&gt; 如果输出如下，则说明安装成功： 1234tiger@vbox:/usr/lib/jvm$ java -versionjava version &quot;1.8.0_91&quot;Java(TM) SE Runtime Environment (build 1.8.0_91-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode) Ubuntu下手动安装JDK 到Oracle官网下载对应当前系统的jdk版本 Java SE Development Kit 8 Downloads ： 123456// 下载对应版本jdk压缩包，这里选择 `Linux64`wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.tar.gz// 等待下载完成后，执行：tar zxvf jdk-8u91-linux-x64.tar.gz// 查看 `ls`jdk1.8.0_91 jdk-8u91-linux-x64.tar.gz 将解压后的目录 jdk1.8.0_91 复制到 /usr/lib/jvm 目录里，1sudo cp -r jdk1.8.0_91/ /usr/lib/jvm 配置环境变量： 1sudo vim /etc/profile 在文件的末尾添加以下内容：(注意对应自己的目录路径和jdk的版本号) 1234JAVA_HOME=/usr/lib/jvm/jdk1.8.0_91export JRE_HOME=/usr/lib/jvm/jdk1.8.0_91/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 修改完后，执行 :wq 退出vim ，使用source刷新一下： 1source /etc/profile 然后执行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849java -version//看到如下信息表示安装成功：tiger@vbox:/usr/lib/jvm$ java -versionjava version &quot;1.8.0_91&quot;Java(TM) SE Runtime Environment (build 1.8.0_91-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)//执行 `java`tiger@vbox:/usr/lib/jvm$ java用法: java [-options] class [args...] (执行类) 或 java [-options] -jar jarfile [args...] (执行 jar 文件)其中选项包括: -d32 使用 32 位数据模型 (如果可用) -d64 使用 64 位数据模型 (如果可用) -server 选择 &quot;server&quot; VM 默认 VM 是 server. -cp &lt;目录和 zip/jar 文件的类搜索路径&gt; -classpath &lt;目录和 zip/jar 文件的类搜索路径&gt; 用 : 分隔的目录, JAR 档案 和 ZIP 档案列表, 用于搜索类文件。 -D&lt;名称&gt;=&lt;值&gt; 设置系统属性 -verbose:[class|gc|jni] 启用详细输出 -version 输出产品版本并退出........//执行 `javac`tiger@vbox:/usr/lib/jvm$ javac用法: javac &lt;options&gt; &lt;source files&gt;其中, 可能的选项包括: -g 生成所有调试信息 -g:none 不生成任何调试信息 -g:&#123;lines,vars,source&#125; 只生成某些调试信息 -nowarn 不生成任何警告 -verbose 输出有关编译器正在执行的操作的消息 -deprecation 输出使用已过时的 API 的源位置 -classpath &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -cp &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -sourcepath &lt;路径&gt; 指定查找输入源文件的位置 -bootclasspath &lt;路径&gt; 覆盖引导类文件的位置.... .... 下面的步骤未测试，仅供参考 如果到这一步，任然不成功的话，则属于手动配置默认的JDK版本： 1234567891011sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java/bin/javac 300 sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/java/bin/jar 300 sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/java/bin/javah 300 sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/java/bin/javap 300 //然后执行sudo update-alternatives --config java// 在通过 java -version 来判断java -version 参考 ： Running as a Service on Linux | Elasticsearch Reference [2.3] | Elastic ubuntu 13.04 安装 JDK - plinx - 博客园 在 Ubuntu 系统上安装 Oracle Java 8 | 半瓶 安装ElasticSearch下载最新安装包： 从 download Elasticsearch free 下载Linux的安装包：1234// 下载$ wget -c https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/zip/elasticsearch/2.3.3/elasticsearch-2.3.3.zip// 解压安装unzip elasticsearch-2.3.3.zip 进入解压后得到的目录 elasticsearch-2.3.3 ，参考官网安装教程 Setup 执行如下命令来运行:1$ bin/elasticsearch 如果上一步的java环境没有安装成功，执行该命令会报如下错误： 1Could not find any executable java binary. Please install java in your PATH or set JAVA_HOME 如果没有出现错误，提示信息中输出 如 [INFO] ..... 等信息，说明运行成功。 再新开一个命令行终端，执行： 1234567891011121314tiger@vbox:~$ curl http://localhost:9200/&#123; &quot;name&quot; : &quot;Rune&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.3.3&quot;, &quot;build_hash&quot; : &quot;218bdf10790eef486ff2c41a3df5cfa32dadcfde&quot;, &quot;build_timestamp&quot; : &quot;2016-05-17T15:40:04Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;tiger@vbox:~$ 出现上面的提示则说明ElasticSearch安装成功。 ElasticSearch - kid551 - 博客园 默认情况下 Elasticsearch 的 RESTful 服务只有本机才能访问。也就是说无法从主机访问虚拟机中的服务。为了方便调试，可以修改 /config/elasticsarch.yml 文件，加入以下两行： 12network.bind_host: &quot;0.0.0.0&quot;network.publish_host: _non_loopback:ipv4_ 但线上环境切忌不要这样配置，否则任何人都可以通过这个接口修改你的数据。 安装 IK Analysis 处理中文搜索Elasticsearch 自带的分词器会粗暴地把每个汉字直接分开，没有根据词库来分词。为了处理中文搜索，还需要安装中文分词插件。我使用的是 elasticsearch-analysis-ik，支持自定义词库。 首先，下载与 Elasticsearch 匹配的 elasticsearch-analysis-ik 插件：{2.3.3–1.9.3} 12345678// 从github 下载内容git clone https://github.com/medcl/elasticsearch-analysis-ik.gitcd elasticsearch-analysis-ik// 进入指定的 tag v1.9.3git checkout v1.9.3// 当前目录lsconfig LICENSE.txt pom.xml README.md src 要编译 elasticsearch-analysis-ik ,需要安装 Apache Maven 工具： 12345sudo apt-get updatesudo apt-get install maven//查看是否正确安装mvn -v 执行编译： 12345// 当前目录lsconfig LICENSE.txt pom.xml README.md src// 编译mvn package 等待直到出现如下提示时，表示编译成功： 1234567891011[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 7:43.935s[INFO] Finished at: Sun Jun 19 18:36:59 CST 2016[INFO] Final Memory: 15M/56M[INFO] ------------------------------------------------------------------------//查看目录lsconfig LICENSE.txt pom.xml README.md src target 发现会多出了一个 target 目录，copy and unzip 目录下的文件 target/releases/elasticsearch-analysis-ik-{version}.zip 到 上面安装的 elasticsearch/plugins/ik 目录中，需要新建 ik 目录： 12345// target 目录$ pwdelasticsearch-analysis-ik/target/releases$ ls elasticsearch-analysis-ik-1.9.3.zip 在 elasticsearch-2.3.3/plugins/ 下新建目录ik : 1234$ ls /elastic/elasticsearch-2.3.3/plugins$ mkdir /elastic/elasticsearch-2.3.3/plugins/ik$ ls /elastic/elasticsearch-2.3.3/pluginsik 将上面编译完成的 elasticsearch-analysis-ik-1.9.3.zip 拷贝到 ik 目录并解压： 1234567891011$ cp elasticsearch-analysis-ik-1.9.3.zip ~/elastic/elasticsearch-2.3.3/plugins/ik$ ls /elastic/elasticsearch-2.3.3/plugins/ikelasticsearch-analysis-ik-1.9.3.zip// 解压$ unzip elasticsearch-analysis-ik-1.9.3.zip// 得到如下内容：$ lscommons-codec-1.9.jar elasticsearch-analysis-ik-1.9.3.zipcommons-logging-1.2.jar httpclient-4.4.1.jarconfig httpcore-4.4.1.jarelasticsearch-analysis-ik-1.9.3.jar plugin-descriptor.properties 注意：上面的操作目录请根据个人的目录和所下载的版本号进行修改 如果你觉得上面的编译步骤太繁琐，也可以直接在github页面的release中下载已经编译好的zip文件，直接解压到 ik 目录下即可： 123wget -c https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v1.9.3/elasticsearch-analysis-ik-1.9.3.zipunzip elasticsearch-analysis-ik-1.9.3.zip 重启 elasticsearch 服务即可。 如果看到类似于下面的信息，说明 IK Analysis 插件已经装好了: 1plugins [analysis-ik] 如何以root 账户运行elasticSearch默认情况下，ElasticSearch不允许以root账户运行，会报 don&#39;t run elasticsearch as root. 错误。不过我们也可以强制让其以 root 账户来运行： 1bin/elasticsearch -Des.insecure.allow.root=true 配置同义词 (该部分待测试)Elasticsearch 自带一个名为 synonym 的同义词 filter。为了能让 IK 和 synonym 同时工作，我们需要定义新的 analyzer，用 IK 做 tokenizer，synonym 做 filter。听上去很复杂，实际上要做的只是加一段配置。 打开 ~/elasticsearch-2.3.3/config/elasticsearch.yml 文件，加入以下配置： 123456789101112131415index: analysis: analyzer: ik_syno: type: custom tokenizer: ik_max_word filter: [my_synonym_filter] ik_syno_smart: type: custom tokenizer: ik_smart filter: [my_synonym_filter] filter: my_synonym_filter: type: synonym synonyms_path: analysis/synonym.txt 以上配置定义了 ik_syno 和 ik_syno_smart 这两个新的 analyzer，分别对应 IK 的 ik_max_word 和 ik_smart 两种分词策略。根据 IK 的文档，二者区别如下： ik_max_word：会将文本做最细粒度的拆分，例如「中华人民共和国国歌」会被拆分为「中华人民共和国、中华人民、中华、华人、人民共和国、人民、人、民、共和国、共和、和、国国、国歌」，会穷尽各种可能的组合； ik_smart：会将文本做最粗粒度的拆分，例如「中华人民共和国国歌」会被拆分为「中华人民共和国、国歌」； ik_syno 和 ik_syno_smart 都会使用 synonym filter 实现同义词转换。为了方便后续测试，建议创建 ~/elasticsearch-2.3.3/config/analysis/synonym.txt 文件，输入一些同义词并存为 utf-8 格式。例如： 123ua,user-agent,userAgentjs,javascriptinternet explore=&gt;ie 用Restful api 测试搜索(1) 查看集群健康信息： 1$ curl -X GET http://localhost:9200/_cat/health?v 返回结果为： 12epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1466352115 00:01:55 elasticsearch green 1 1 0 0 0 0 0 0 - 100.0% 返回结果的主要字段意义： cluster：集群名，是在ES的配置文件中配置的cluster.name的值。 status：集群状态。集群共有green、yellow或red中的三种状态。green代表一切正常（集群功能齐全），yellow意味着所有的数据都是可用的，但是某些复制没有被分配（集群功能齐全），red则代表因为某些原因，某些数据不可用。如果是red状态，则要引起高度注意，数据很有可能已经丢失。 node.total：集群中的节点数。 node.data：集群中的数据节点数。 shards：集群中总的分片数量。 pri：主分片数量，英文全称为private。 relo：复制分片总数。 unassign：未指定的分片数量，是应有分片数和现有的分片数的差值（包括主分片和复制分片）。 我们也可以在请求中添加help参数来查看每个操作返回结果字段的意义。 1$ curl -X GET http://localhost:9200/_cat/health?help 1234567891011121314epoch | t,time | seconds since 1970-01-01 00:00:00 timestamp | ts,hms,hhmmss | time in HH:MM:SS cluster | cl | cluster name status | st | health status node.total | nt,nodeTotal | total number of nodes node.data | nd,nodeData | number of nodes that can store datashards | t,sh,shards.total,shardsTotal | total number of shards pri | p,shards.primary,shardsPrimary | number of primary shards relo | r,shards.relocating,shardsRelocating | number of relocating nodes init | i,shards.initializing,shardsInitializing | number of initializing nodes unassign | u,shards.unassigned,shardsUnassigned | number of unassigned shards pending_tasks | pt,pendingTasks | number of pending tasks max_task_wait_time | mtwt,maxTaskWaitTime | wait time of longest task pending active_shards_percent | asp,activeShardsPercent | active number of shards in percent 有了这个东东，就可以减少看文档的时间。ES中许多API都可以添加help参数来显示字段含义，哪些可以这么做呢？每个API都试试就知道了。 当然，如果你觉得返回的东西太多，看着眼烦，我们也可以人为地指定返回的字段。 1elasticsearch green 0 (2) 查看集群中的节点信息 1tiger@vbox:~$ curl -XGET http://localhost:9200/_cat/nodes?v 返回节点的详细信息如下： 123host ip heap.percent ram.percent load node.role master name 10.0.2.15 10.0.2.15 9 90 0.15 d * Bullseye tiger@vbox:~$ (3) 查看集群中的索引信息 123tiger@vbox:~$ curl -XGET http://localhost:9200/_cat/indices?vhealth status index pri rep docs.count docs.deleted store.size pri.store.size yellow open twitter 5 1 1 0 4.1kb 4.1kb 索引（Index）相关API需要一个索引 index 和 type (1) 创建一个新的索引 使用自定义id索引文档 使用PUT请求创建一个索引为twitter类型为tweet的文档。其文档编号为1，文档内容包含title和content : 1234tiger@tiger-vbox:~$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/1?pretty&apos; -d &apos;&#123; &quot;title&quot;:&quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot;:&quot;三星无线充电器为圆行造型&quot;&#125;&apos; 返回信息 123456789101112&#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;created&quot; : true&#125; 再添加一篇： 1234$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/2?pretty&apos; -d &apos;&#123; &quot;title&quot;:&quot;范冰冰着花裙亮相青岛，侧颜精致&quot;, &quot;content&quot;:&quot;6月19日，范冰冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot;&#125;&apos; 返回结果： 12345678910111213tiger@vbox:~$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/2?pretty&apos; -d &apos;&#123;&quot;title&quot;:&quot;范冰冰着花裙亮相青岛，侧颜精致&quot;,&quot;content&quot;:&quot;6月19日，范冰 冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot;&#125;&apos;&#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 2, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;created&quot; : false&#125; 查看所有文章： 1$ curl -XGET &apos;http://localhost:9200/twitter/tweet/_search?pretty=true&apos; -d &apos;&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125;&apos; 返回结果： 1234567891011121314151617181920212223242526272829303132&#123; &quot;took&quot; : 147, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;范冰冰着花裙亮相青岛，侧颜精致&quot;, &quot;content&quot; : &quot;6月19日，范冰冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot; &#125; &#125;, &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot; : &quot;三星无线充电器为圆行造型&quot; &#125; &#125; ] &#125;&#125; 这样会把刚才添加的文章都列出来。 搜索关键词“无线”： 1tiger@vbox:~$ curl -XGET &quot;http://localhost:9200/twitter/tweet/_search?pretty=true&quot; -d &apos;&#123;&quot;query&quot;:&#123;&quot;query_string&quot;:&#123;&quot;query&quot;:&quot;无线&quot;&#125;&#125;&#125;&apos; 1234567891011121314151617181920212223&#123; &quot;took&quot; : 49, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 1, &quot;max_score&quot; : 0.0958915, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 0.0958915, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot; : &quot;三星无线充电器为圆行造型&quot; &#125; &#125; ] &#125;&#125; 检查ik的切词效果，可以执行： 1tiger@tiger-vbox:~$ curl &apos;http://localhost:9200/twitter/_analyze?analyzer=ik_max_word&amp;pretty=true&apos; -d &apos;&#123;&quot;text&quot;:&quot;中华人民共和国国歌&quot;&#125;&apos; 返回结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;中华人民共和国&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;中华人民&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;中华&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;华人&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;人民共和国&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;人民&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;共和国&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;共和&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;国&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 8 &#125;, &#123; &quot;token&quot; : &quot;国歌&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 9 &#125; ]&#125; 说明一下pretty 参数就是让返回的json有换行和缩进，容易阅读，调试时可以加上，开发到程序里就可以去掉了。 相关链接依赖包 GitHub - medcl/elasticsearch-analysis-ik: The IK Analysis plugin integrates Lucene IK analyzer into elasticsearch, support customized dictionary. Linux下安装 使用 Elasticsearch 实现博客站内搜索 | JerryQu 的小站 ☆ 教你成为全栈工程师(Full Stack Developer) 二十四-ES(elasticsearch)搜索引擎安装和使用 - SharEDITor - 关注大数据技术 Running as a Service on Linux | Elasticsearch Reference [2.3] | Elastic The Elastic Stack Download · Get Started in Minutes | Elastic Windows下安装 windows下安装elasticsearch-1.7.1 | 教程网 Running as a Service on Windows | Elasticsearch Reference [2.3] | Elastic Windows下安装Maven参考 Restful Api Python Elasticsearch api - letong - 博客园 ElasticSearch教程（4）——ElasticSearch基于REST的CRUD API - 为程序员服务 实时搜索引擎Elasticsearch（2）——Rest API的使用 - HinyLover的专栏 - 博客频道 - CSDN.NET Document APIs | Elasticsearch Reference [2.3] | Elastic elasticsearch rest api 快速上手 · Issue #5 · sxyx2008/elasticsearch · GitHub 文档 Elasticsearch - 随笔分类 - xingoo - 博客园 使用Python进行Elasticsearch数据索引 | Silent River 安装和使用 Elasticsearch | vpsee.com 实时搜索引擎Elasticsearch（1）——基础概念、安装和运行 - HinyLover的专栏 - 博客频道 - CSDN.NET ☆ Introduction | Elasticsearch权威指南（中文版） ☆ AAAAAAA https://github.com/medcl/elasticsearch-analysis-ik http://blog.csdn.net/xialei199023/article/details/48085125 http://blog.csdn.net/xialei199023/article/details/48227247 https://github.com/elastic/elasticsearch https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html https://github.com/sxyx2008/elasticsearch/issues/5 http://www.shareditor.com/blogshow/?blogId=36]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python操作SQLServer数据库]]></title>
    <url>%2F2016%2F06%2F20%2Fpython-connect-sqlserver%2F</url>
    <content type="text"><![CDATA[pymssqlPython操作SQLServer需要使用 pymssql 模块 Windows系统下的Python类库文件 *.whl文件，需要用 pip install *.whl 的方式来安装。 下载pymssql2.7 library ：pythonlibs 第一次下载了 pymssql-2.1.2-cp27-cp27m-win_amd64.whl 文件，安装时报错，提示如下错误： 12λ pip install pymssql-2.1.2-cp27-cp27m-win_amd64.whlpymssql-2.1.2-cp27-cp27m-win_amd64.whl is not a supported wheel on this platform. 即使成功安装了 pymssql，但是 import pymssql 还是会报错 12import pymssqlImportError: DLL load failed: 找不到指定的模块。 所以又再次下载了 pymssql-1.0.3-cp27-none-win32.whl 文件，再次安装成功。具体原因可能和操作系统或python版本有关，具体待深入研究。 Demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# coding:utf-8&quot;&quot;&quot;http://www.pymssql.org/en/stable/http://www.lfd.uci.edu/~gohlke/pythonlibs/#pymssql pymssql-1.0.3-cp27-none-win32.whl # 只有这个才能在windows下执行pymssql-2.1.2-cp27-cp27m-win_amd64.whl # 这个不能执行安装 whl文件 执行 `pip install *.whl`异常：不能用 DB-Library (如 ISQL)或 ODBC 3.7 或更早版本将 ntext 数据或仅使用 Unicode 排序规则的 Unicode 数据发送到客 户端。这个问题是数据库中字段为ntext类型，这种类型目前的c-library不支持，需要转为nvchar或text类型才可以。1. 建议：将ntext修改为nvarchar或text.2. 既然不支持ntext但支持text，那么我们只需要在输出时将ntext转换为text就好了 `SELECT cast ( field_name AS TEXT ) AS field_name``select convert(varchar(50),guid) as guid, convert(text,content) as content from news`&quot;&quot;&quot;import pymssqlclass MSSQL: def __init__(self,host,user,pwd,db): self.host=host self.user=user self.pwd=pwd self.db=db def __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) self.conn=pymssql.connect(host=self.host,user=self.user,password=self.pwd,database=self.db,charset=&quot;utf-8&quot;) cur=self.conn.cursor() if not cur: raise(NameError,&quot;连接数据库失败&quot;) else: return cur def ExecQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) resList=cur.fetchall() # 查询完毕后关闭连接 self.conn.close() return resList def ExecNonQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) self.conn.commit() self.conn.close()if __name__==&quot;__main__&quot;: ms=MSSQL(host=&quot;Test-FPC\sqlexpress&quot;,user=&quot;sa&quot;,pwd=&quot;1&quot;,db=&quot;its&quot;) resList=ms.ExecQuery(&quot;select * from [SchemeCategory] where IsShow=1&quot;) for i in resList: print(i[&quot;Name&quot;]) 错误处理在操作是报出了如下异常信息： 不能用 DB-Library (如 ISQL)或 ODBC 3.7 或更早版本将 ntext 数据或仅使用 Unicode 排序规则的 Unicode 数据发送到客 户端。 这个问题是数据库中字段为ntext类型，这种类型目前的 c-library 不支持，需要转为 nvchar 或 text 类型才可以。 建议：将ntext修改为nvarchar或text. 既然不支持ntext但支持text，那么我们只需要在输出时将ntext转换为text就好了 12SELECT cast ( field_name AS TEXT ) AS field_nameselect convert(varchar(50),guid) as guid, convert(text,content) as content from news 使用另一个类库 pyodbc 来操作，未遇到该问题。 相关链接Python操作SQLServer示例 | 大爱利用python简化sql server数据导入导出 - qianlifeng - 博客园 python 使用pymssql连接sql server数据库 - Hello World! pymssql &mdash; pymssql 2.2.0.dev documentationFreeTDS &mdash; pymssql 2.2.0.dev documentationGitHub - pymssql/pymssql: Official home for the pymssql source code.FreeTDS.orgPython Extension Packages for Windows - Christoph Gohlke pyodbcSQL Server ODBC drivers {SQL Server} - released with SQL Server 2000 {SQL Native Client} - released with SQL Server 2005 (also known as version 9.0) {SQL Server Native Client 10.0} - released with SQL Server 2008 {SQL Server Native Client 11.0} - released with SQL Server 2012 [sqlservertests]connection-string=DRIVER={SQL Server};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db The connection string above will use the 2000/2005 driver, even if SQL Server 2008is installed: 2000: DRIVER={SQL Server} 2005: DRIVER={SQL Server} 2008: DRIVER={SQL Server Native Client 10.0} connection strings1DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password in Python: 1conn = pyodbc.connect(r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos;) 连接字符串的两种写法字符串方式123connSqlServer = pyodbc.connect(&apos;DRIVER=&#123;SQL Server Native Client 10.0&#125;;SERVER=192.106.0.102\instance1;DATABASE=master;UID=sql2008;PWD=password123&apos;)connSqlServer = pyodbc.connect(&apos;DRIVER=&#123;SQL Server Native Client 10.0&#125;;SERVER=192.106.0.102,1443;DATABASE=master;UID=sql2008;PWD=password123&apos;) 关键字方式123456789connSqlServer = pyodbc.connect(driver=&apos;&#123;SQL Server Native Client 10.0&#125;&apos;, server=&apos;192.106.0.102\instance1&apos;, database=&apos;master&apos;, uid=&apos;sql2008&apos;,pwd=&apos;password123&apos;)connSqlServer = pyodbc.connect(driver=&apos;&#123;SQL Server Native Client 10.0&#125;&apos;, server=&apos;192.106.0.102,1443&apos;, database=&apos;master&apos;, uid=&apos;sql2008&apos;,pwd=&apos;password123&apos;) 详见：sql - python pyodbc : how to connect to a specific instance - Stack Overflow 我的写法第一种方式123456789101112131415def __init__(self,driver,server,db,uid,pwd): self.driver=&quot;&#123;&#123;&#123;0&#125;&#125;&#125;&quot;.format(driver) # 两个&#123;表示一个 self.server=server self.db=db self.uid=uid self.pwd=pwddef __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) # r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos; self.conn=pyodbc.connect(driver=self.driver,server=self.server,database=self.db,uid=self.uid,pwd=self.pwd)ms=MSSQLODBC(driver=&quot;SQL Server&quot;,server=&quot;Test-FPC\sqlexpress&quot;,db=&quot;its&quot;,uid=&quot;sa&quot;,pwd=&quot;1&quot;) 第二种方式1self.conn = pyodbc.connect(&apos;DRIVER=&#123;SQL Server&#125;;SERVER=Test-FPC\sqlexpress;PORT=1433;DATABASE=its;UID=sa;PWD=1&apos;) pyodbc Connecting to SQL Server from Windows · mkleehammer/pyodbc Wiki · GitHub sql - python pyodbc : how to connect to a specific instance - Stack Overflow Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# coding:utf-8&quot;&quot;&quot;&quot;&quot;&quot;import pyodbcclass MSSQLODBC: def __init__(self,driver,server,db,uid,pwd): self.driver=&quot;&#123;&#123;&#123;0&#125;&#125;&#125;&quot;.format(driver) # 两个&#123;表示一个 self.server=server self.db=db self.uid=uid self.pwd=pwd def __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) # r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos; self.conn=pyodbc.connect(driver=self.driver,server=self.server,database=self.db,uid=self.uid,pwd=self.pwd) # self.conn = pyodbc.connect(&apos;DRIVER=&#123;SQL Server&#125;;SERVER=Test-FPC\sqlexpress;PORT=1433;DATABASE=its;UID=sa;PWD=1&apos;) cur=self.conn.cursor() if not cur: raise(NameError,&quot;连接数据库失败&quot;) else: return cur def ExecQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) resList=cur.fetchall() # 查询完毕后关闭连接 self.conn.close() return resList def ExecNonQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) self.conn.commit() self.conn.close()if __name__==&quot;__main__&quot;: ms=MSSQLODBC(driver=&quot;SQL Server&quot;,server=&quot;Test-FPC\sqlexpress&quot;,db=&quot;its&quot;,uid=&quot;sa&quot;,pwd=&quot;1&quot;) resList=ms.ExecQuery(&quot;select top 10 * from [MallProductItem]&quot;) for m in resList: print(m[4])]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#脱离IronPython中执行python脚本]]></title>
    <url>%2F2016%2F06%2F10%2Fcsharp-call-python-without-ironpython-environment%2F</url>
    <content type="text"><![CDATA[给客户安装程序时除了安装 .net framework 还要安装 IronPython ，是不是觉得很麻烦？ 上面这一切都弱爆了，下面我来介绍一种不安装 IronPython 只需要引入几个 IronPython 的 dll 就可以在c#中执行 python 脚本的方法。 1：引入IronPython中的几个dll * `IronPython.dll` * `IronPython.Modules.dll` * `Microsoft.Dynamic.dll` * `Microsoft.Scripting.dll` * `Microsoft.Scripting.Metadata.dll` 2：进入IronPython的Lib文件夹，把Lib中的内容打包成zip，名字任意既可。打包好后放到c#项目下我把它放到了和py文件同一个目录中 3：很关键的一步，程序初始化时执行下段代码 12345678ScriptEngine engine = Python.CreateEngine(); ScriptScope scope = engine.CreateScope(); ScriptSource source = engine.CreateScriptSourceFromString( @&quot;import sys&quot; &quot;\n&quot; @&quot;sys.path.append(&quot;&quot;.\scripts\pythonlib.zip&quot;&quot;)&quot; &quot;\n&quot; @&quot;sys.path.append(&quot;&quot;.\scripts&quot;&quot;)&quot; &quot;\n&quot;); source.Execute(scope); 将zip文件加入python库路径。这样能保证py脚本可以正确搜索到python库的位置。 4：尽情享用脚本语言带来的便利吧。为其他人安装程序时也不用安装讨厌的IronPython环境了。 链接 C#脱离IronPython中执行python脚本-gsbhzh 的个人空间 - 开源中国社区]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[O2O地图应用之判断用户订单地址是否在服务范围内]]></title>
    <url>%2F2016%2F05%2F18%2Fwhether-user-order-address-is-within-service-range%2F</url>
    <content type="text"><![CDATA[需求分析在o2o项目中，经常要用到在用户下单时判断用户所填地址的坐标点是否在服务范围内的情况，这里参考网上的实现方式，用C#来实现，经测试后有效，特此记录。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class MapHelper &#123; /// &lt;summary&gt; /// 判断一个坐标点在多边形坐标点的内部还是外部 /// &lt;/summary&gt; /// &lt;param name=&quot;point&quot;&gt;要判断的坐标点&lt;/param&gt; /// &lt;param name=&quot;pts&quot;&gt;多边形坐标点集合&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static bool IsPointInPolygon(Point point, List&lt;Point&gt; pts) &#123; int N = pts.Count; //如果点位于多边形的顶点或边上，也算做点在多边形内，直接返回true bool boundOrVertex = true; //经过点的次数 int intersectCount = 0; double precision = 2e-10; Point p1, p2; Point p = point;//当前点 p1 = pts[0]; for (int i = 1; i &lt;= N; i++) &#123; //如果点在多边形上 if (p.Equals(p1)) &#123; return boundOrVertex; &#125; p2 = pts[(i % N)]; if (p.Lng&lt;Math.Min(p1.Lng,p2.Lng)||p.Lng&gt;Math.Max(p1.Lng,p2.Lng)) &#123; p1 = p2; continue; &#125; if (p.Lng&gt;Math.Min(p1.Lng,p2.Lng)&amp;&amp;p.Lng&lt;Math.Max(p1.Lng,p2.Lng)) &#123; if (p.Lat&lt;=Math.Max(p1.Lat,p2.Lat)) &#123; if (p1.Lng==p2.Lng&amp;&amp;p.Lat&gt;=Math.Min(p1.Lat,p2.Lat)) &#123; return boundOrVertex; &#125; if (p1.Lat==p2.Lat) &#123; if (p1.Lat==p.Lat) &#123; return boundOrVertex; &#125; else &#123; intersectCount++; &#125; &#125; else &#123; double xinters = (p.Lng - p1.Lng) * (p2.Lat - p1.Lat) / (p2.Lng - p1.Lng) + p1.Lat; if (Math.Abs(p.Lat-xinters)&lt;precision) &#123; return boundOrVertex; &#125; if (p.Lat&lt;xinters) &#123; intersectCount++; &#125; &#125; &#125; &#125; else &#123; if (p.Lng==p2.Lng&amp;&amp;p.Lat&lt;=p2.Lat) &#123; Point p3 = pts[(i+1)%N]; if (p.Lng&gt;=Math.Min(p1.Lng,p3.Lng)&amp;&amp;p.Lng&lt;=Math.Max(p1.Lng,p3.Lng)) &#123; intersectCount++; &#125; else &#123; intersectCount += 2; &#125; &#125; &#125; p1 = p2; &#125; if (intersectCount%2==0) &#123; //偶数在多边形外 return false; &#125; else &#123; //奇数在多边形内 return true; &#125; &#125; &#125; public class Point &#123; /// &lt;summary&gt; /// 经度 /// &lt;/summary&gt; public double Lng &#123; get; set; &#125; /// &lt;summary&gt; /// 纬度 /// &lt;/summary&gt; public double Lat &#123; get; set; &#125; &#125; 测试这里我用高德地图标出了北京五环范围的坐标点集合，然后随意选择一个坐标点来进行判断： 坐标点可以用这个工具来获取：高德地图API 五环范围： 香泉桥 116.222208,39.992436 箭亭桥 116.327147,40.02046 上清桥 116.353948,40.02299 顾家庄桥 116.44128,40.020526 东北五环 116.48441,40.013624 平房桥 116.541101,39.942393 东南五环 116.549202,39.851595 旧宫新桥 116.43082,39.785968 狼垈东桥 116.296044,39.777442 宛平桥 116.225062,39.845517 衙门口桥 116.211308,39.894396 西五环 116.212595,39.944705 随机坐标： 林萃桥地铁站 116.37297,40.021857 望京西园四区 116.47086,39.99648 观音禅寺 116.533811,39.880533 俏狐国际 116.299713,39.772619 芳园里小区 116.416336,39.78394 润枫锦尚小区 116.429039,39.790535 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Program&#123; static void Main(string[] args) &#123; var Plist = new List&lt;Point&gt; &#123; new Point &#123;Lng=116.222208,Lat= 39.992436&#125;, new Point &#123;Lng=116.327147,Lat= 40.02046&#125;, new Point &#123;Lng=116.353948,Lat= 40.02299&#125;, new Point &#123;Lng=116.44128,Lat= 40.020526&#125;, new Point &#123;Lng=116.48441,Lat=40.013624 &#125;, new Point &#123;Lng=116.541101,Lat= 39.942393&#125;, new Point &#123;Lng=116.549202,Lat= 39.851595&#125;, new Point &#123;Lng=116.43082,Lat=39.785968&#125;, new Point &#123;Lng=116.296044,Lat=39.777442 &#125;, new Point &#123;Lng=116.225062,Lat=39.845517 &#125;, new Point &#123;Lng=116.211308,Lat= 39.894396&#125;, new Point &#123;Lng=116.212595,Lat=39.944705&#125; &#125;; //var p = new Point &#123; Lng = 116.37297, Lat = 40.021857 &#125;; //林萃桥地铁站 内 //var p = new Point &#123; Lng = 116.47086, Lat = 39.99648 &#125;; //望京西园四区 内 //var p = new Point &#123; Lng = 116.533811, Lat = 39.880533 &#125;; //观音禅寺 内 //var p = new Point &#123; Lng = 116.299713, Lat = 39.772619 &#125;; //俏狐国际 外 //var p = new Point &#123; Lng = 116.416336, Lat = 39.78394 &#125;; //芳园里小区 外 var p = new Point &#123; Lng = 116.429039, Lat = 39.790535 &#125;; //润枫锦尚小区 内 bool isin = MapHelper.IsPointInPolygon(p, Plist); if (isin) &#123; Console.WriteLine(&quot;随机点在五环范围内，可以派单&quot;); &#125; else &#123; Console.WriteLine(&quot;随机点不在五环范围内&quot;); &#125; Console.ReadKey(); &#125;&#125; 总结 北京的五环范围毕竟不是一个规则的多边形，可以尽量选择有标志性的坐标点来规范多边形 参考自：百度地图——判断用户是否在配送范围内解决方案 - aheizi - 博客园]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中时间格式转换]]></title>
    <url>%2F2016%2F05%2F17%2Ftime-format-conversion-in-python%2F</url>
    <content type="text"><![CDATA[1234YYYY-MM-DDTHH:MM:SS+HH:MM2016-04-05T13:31:00+08:002014-09-18T10:42:16.126Z 123$ time = &apos;2012-03-01T00:05:55+00:00&apos;$ datetime.strptime(time, &quot;%Y-%m-%dT%H:%M:%S+00:00&quot;)# =&gt; datetime.datetime(2012, 3, 1, 0, 5, 55) strftime() 用于时间格式转换strptime() 用于字符串格式转换 代码段123456789101112131415161718192021222324# 将UTC时间转换为本地时间# 2016-04-04T23:58:00+08:00def _utc_datetime(value): # value为传入的值为UTC时间，如：2016-04-04T23:58:00+08:00 format=&apos;%Y-%m-%d %H:%M:%S&apos; utc_format=&apos;%Y-%m-%dT%H:%M:%S+08:00&apos; local= datetime.strptime(value,utc_format) dt= datetime.strftime(local,format) return dt&apos;&apos;&apos;将unix时间戳转为标准时间格式&apos;&apos;&apos;def _timestamp_datetime(value): format = &apos;%Y-%m-%d %H:%M:%S&apos; # value为传入的值为时间戳(整形)，如：1332888820 value = time.localtime(value) ## 经过localtime转换后变成 ## time.struct_time(tm_year=2012, tm_mon=3, tm_mday=28, tm_hour=6, tm_min=53, tm_sec=40, tm_wday=2, tm_yday=88, tm_isdst=0) # 最后再经过strftime函数转换为正常日期格式。 dt = time.strftime(format, value) return dt 相关链接 答案见这里：Convert UTC time to python datetime - Stack Overflow datetime - [ Python 3零起点教程 ] - 看云 Python中Timestamp、Datetime和UTC时间相互转化的方法 - OPEN 开发经验库 SQLite 日期类型(转) - 深海的小鱼儿 - 博客园 python本地时间与UTC时间转换丶Source新浪博客 Python将UTC时间转化为Local时间 - 降龍 - 博客频道 - CSDN.NET python时间处理之datetime - 码农老毕的学习笔记 - 博客频道 - CSDN.NET Python 时间戳和日期相互转换 - 李林克斯 ☆ Python中Timestamp、Datetime和UTC时间相互转化的方法_python_ThinkSAAS]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python时间差]]></title>
    <url>%2F2016%2F05%2F17%2Ftime-difference-in-python%2F</url>
    <content type="text"><![CDATA[datetime.timedeltadatetime.timedelta对象代表两个时间之间的的时间差，两个date或datetime对象相减时可以返回一个timedelta对象。 构造函数: 1class datetime.timedelta([days[, seconds[, microseconds[, milliseconds[, minutes[, hours[, weeks]]]]]]]) 所有参数可选，且默认都是0，参数的值可以是整数，浮点数，正数或负数。 timedelta 可以和 date，datetime 对象进行加减操作 timedelta.total_seconds() 用于计算秒数。 当前的时间上加一天或一年减一天等操作1234567891011#!/usr/bin/env python # -*- coding:utf-8 -*- from datetime import datetime,timedelta now = datetime.now() yestoday = now - timedelta(days=1) tommorow = now + timedelta(days=1) next_year = now + timedelta(days = 365) 相关链接 Python中时间的处理之——timedelta篇 - Goodspeed - 博客园]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下配置Flask运行环境]]></title>
    <url>%2F2016%2F05%2F09%2Fconfiguring-flask-running-environment-under-ubuntu%2F</url>
    <content type="text"><![CDATA[Virtualenv + Flask + Gunicorn + Supervisor + Nginx 配置假设我所在的当前账户名为 tiger 。 准备python环境123$ sudo apt-get udpate// 安装python 和 pip (如果已经安装可以忽略)$ sudo apt-get install python-dev python-pip -y 创建virtualenv虚拟环境Virtualenv可以为每个Python应用创建独立的开发环境，使他们互不影响，Virtualenv能够做到： 在没有权限的情况下安装新套件 不同应用可以使用不同的套件版本 套件升级不影响其他应用 12//安装或通过执行：$ sudo pip install virtualenv 我通常创建一个包含 venv 文件夹的项目文件夹: 123456$ mkdir myproject$ cd myproject$ virtualenv venvNew python executable in venv/bin/python2Also creating executable in venv/bin/pythonInstalling setuptools, pip...done. 现在，每次需要使用项目时，必须先激活相应的环境。 123456$ ls-- venv$ . venv/bin/activate//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ 你现在进入你的 virtualenv （注意查看你的 shell 提示符已经改变了）。 安装Flask现在可以开始在你的 virtualenv 中安装 Flask 了: 123456789$ pip install Flask//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ pip install FlaskDownloading/unpacking Flask Downloading Flask-0.10.1.tar.gz (544kB): 544kB downloaded ...... Successfully installed Flask Werkzeug Jinja2 itsdangerous MarkupSafeCleaning up... 几秒钟后就安装好了。 退出虚拟环境可通过deactivate退出虚拟环境： 12(venv)tiger@VirtualBox:~/xbox/myflask$ deactivatetiger@VirtualBox:~/xbox/myflask$ 具体可详见：Flask-安装 启动falsk在当前目录下新建一个 hello.py 的文件： 123(venv) $ vim hello.py(venv) $ lsvenv hello.py 创建一个简单的Flask程序： 123456789from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;if __name__ == &apos;__main__&apos;: app.run() 修改hello.py 的权限： 1(venv) $ chmod a+x hello.py 启动 flask: 1(venv) $ python hello.py 此时，用浏览器访问 http://127.0.0.1:5000 就能看到网页显示 hello world。 配置GunicornGunicorn是用于部署WSGI应用的，任何支持WSGI的都可以，虽说直接执行 python hello.py 这样网站也能跑起来，但那是方便开发而已，在线上环境，还是需要更高效的组件来做。 安装1(venv)$ pip install gunicorn 然后可以执行： 1234567891011gunicorn -w 4 -b 127.0.0.1:8000 hello:app//结果：(venv) $ gunicorn -w 4 -b 127.0.0.1:8000 hello:app[2016-05-08 16:07:36 +0000] [1337] [INFO] Starting gunicorn 19.4.5[2016-05-08 16:07:36 +0000] [1337] [INFO] Listening at: http://127.0.0.1:8000 (1337)[2016-05-08 16:07:36 +0000] [1337] [INFO] Using worker: sync[2016-05-08 16:07:36 +0000] [1342] [INFO] Booting worker with pid: 1342[2016-05-08 16:07:36 +0000] [1343] [INFO] Booting worker with pid: 1343[2016-05-08 16:07:36 +0000] [1344] [INFO] Booting worker with pid: 1344[2016-05-08 16:07:36 +0000] [1345] [INFO] Booting worker with pid: 1345 “hello” is the name of the file (without extension). And “app” is the name of the Flask object. 这里 “hello” 是python文件的名称(不包含扩展名)，冒号后面的”app” 是flask程序中app = Flask(__name__)创建的这个Flask对象的名称。 这里我们用了 8000 的端口进行访问，原先的 5000 并没有启用。 -w表示开启多少个 worker，-b 表示 gunicorn 开发的访问地址 想要结束 gunicorn 只需执行 pkill gunicorn : 123456789(venv) $ pkill gunicorn//结果：[2016-05-08 16:09:28 +0000] [1337] [INFO] Handling signal: term[2016-05-08 16:09:28 +0000] [1344] [INFO] Worker exiting (pid: 1344)[2016-05-08 16:09:28 +0000] [1342] [INFO] Worker exiting (pid: 1342)[2016-05-08 16:09:28 +0000] [1343] [INFO] Worker exiting (pid: 1343)[2016-05-08 16:09:28 +0000] [1345] [INFO] Worker exiting (pid: 1345)[2016-05-08 16:09:29 +0000] [1337] [INFO] Shutting down: Master 我们还可以在一个独立的配置文件中来设置，新增配置文件 gunicorn.conf： 1234567(venv) $ ls-- hello.py hello.pyc venv(venv) $ vim gunicorn.conf//写入下列内容：workers=4bind=&apos;127.0.0.1:8000&apos; 上面使用pkill gunicorn的方式来停止进程，太过于繁琐，因此出现了另外一个神器—supervisor，一个专门用来管理进程的工具，还可以管理系统的工具进程。 SupervisorSupervisor 是用Python实现的一款非常实用的进程管理工具。 安装supervisor1(venv) $ pip install supervisor 常用操作123456## 启动服务$ sudo service supervisor start## 停止服务$ sudo service supervisor stop## 也可以直接 kill pid$ ps -A | grep supervisor 生成supervisor默认配置文件123456(venv) $ echo_supervisord_conf &gt; supervisor.conf## 添加一个`logs`目录，用来后面存放日志：(venv) $ mkdir logs(venv) $ lsgunicorn.conf hello.py hello.pyc logs supervisor.conf venv 修改supervisor配置文件，添加gunicorn进程管理1(venv) $ vim supervisor.conf 在 supervisor.conf 配置文件底部添加：(假设我的工作目录为： /home/tiger/myflask/myproject/ ) 12345678910##文件内容[program:hello] ## 服务的名称，后面操作会用到command=/home/tiger/myflask/myproject/venv/bin/gunicorn hello:app -c /home/tiger/myflask/myproject/gunicorn.conf ; supervisor启动命令directory=/home/tiger/myflask/myproject ; 项目的文件夹路径user=tigerautostart=true ; 是否自动启动autorestart=true ; 是否自动重启##log文件的位置stdout_logfile=/home/tiger/myflask/myproject/logs/gunicorn_supervisor.log ; log 日志stderr_logfile=/home/tiger/myflask/myproject/logs/gunicorn_supervisor.err ; 错误日志 supervisor的基本使用命令 12345supervisord -c supervisor.conf 通过配置文件启动supervisorsupervisorctl -c supervisor.conf status 查看supervisor的状态supervisorctl -c supervisor.conf reload 重新载入 配置文件supervisorctl -c supervisor.conf start [all]|[appname] 启动指定/所有 supervisor管理的程序进程supervisorctl -c supervisor.conf stop [all]|[appname] 关闭指定/所有 supervisor管理的程序进程 添加完上面的内容后，保存退出。执行操作： 当前目录： 12(venv) $ ls-- gunicorn.conf hello.py hello.pyc logs supervisor.conf venv 通过配置文件 启动 supervisor : 1(venv) $ supervisord -c supervisor.conf 查看 supervisor 的状态： 12(venv) $ supervisorctl -c supervisor.conf status-- hello RUNNING pid 1550, uptime 0:04:08 停止 设置的 服务 hello ： 12(venv) $ supervisorctl -c supervisor.conf stop hello -- hello: stopped 再次查看 服务 hello 的状态 ： 12(venv) $ supervisorctl -c supervisor.conf status-- hello STOPPED May 08 05:23 PM 自动启动： 那么，如果想开机时自动启动怎么办呢？或者说，如果机器重启了，那WEB服务就断了。其实呢，也很简单，只要在 /etc/rc.d/rc.local 中加入一句就可以了： 1supervisord -c /home/tiger/myflask/myproject/supervisor.conf 有了Gunicorn、Supervisor，本地的环境的算是搭好了，但是我们需要让VPS上的网站从外网可以访问，这时候需要Nginx。 现在，我们只能在本机上通过http://127.0.0.1:8000 的方式来访问的，但在外网上是无法访问到的。 配置Nginx在安装Nginx之前，要先退出上面步骤中操作所在的venv环境，执行： 1(venv) $ deactivate 安装nginx1$ sudo apt-get install nginx 安装完成后访问localhost可以看到 Welcome to nginx on Ubuntu! 的页面。 nginx 的默认网站目录 /usr/share/nginx/html 常用配置命令1234567##启动服务$ sudo service nginx start##重启和暂停服务$ sudo service nginx restart$ sudo service nginx stop##查看状态$ sudo service nginx status 或下面的命令： 1234$ sudo /etc/init.d/nginx start$ sudo /etc/init.d/nginx stop$ sudo /etc/init.d/nginx restart$ sudo /etc/init.d/nginx status Nginx的配置文件和Supervisor类似，不同的程序可以分别配置，然后被总配置文件include： 123456789101112131415161718192021222324## Nginx的主配置文件地址/etc/nginx/nginx.conf## 新建单独的配置文件## 在conf.d目录下$ sudo vim /etc/nginx/conf.d/helloweb.conf## 然后写入下列内容：server &#123; listen 80; //端口 server_name 192.168.1.144; //访问域名 root /home/tiger/myflack/myproject; access_log /home/tiger/myflask/myproject/logs/nginx_access.log; error_log /home/tiger/myflask/myproject/logs/nginx_error.log; location / &#123; proxy_set_header X-Forward-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; if (!-f $request_filename) &#123; proxy_pass http://127.0.0.1:8000; //这里是flask的gunicorn端口 break; &#125; &#125;&#125; 也可以用下面的最简配置： 12345678910server &#123; listen 80; server_name _; # _表示 localhost root /home/tiger/myflack/myproject; # hello.py 文件所在的目录 location / &#123; proxy_pass http://127.0.0.1:8000; //这里是flask的gunicorn端口 &#125;&#125; 配置完成之后，sudo service nginx restart 重启一下服务。 现在，在浏览器中输入 http://127.0.0.1 即可正常访问。 总结 Flask应用的基本部署依赖包括一个应用容器（比如Gunicorn）和一个反向代理（比如Nginx）。 Gunicorn应该退居Nginx幕后并监听127.0.0.1（内部请求）而非0.0.0.0（外部请求）。 仍有疑问的地方：在虚拟环境下安装的supervisor 并非是全局的，经测试 kill 掉 supervisor 进程后也不会自动重启，或如何随系统启动？该问题待进一步测试 相关链接 virtualenv &mdash; virtualenv 1.7.1.2.post1 documentation GitHub - defshine/flaskblog: Learn python and flask,just a tony blog system Gunicorn - Python WSGI HTTP Server for UNIX 安装 Flask 0.10 documentation Flask + Gunicorn + Nginx 部署 - Ray Liang - 博客园 阿里云ECS上环境搭建(virtualenv+flask+gunicorn+supervisor+nginx) - 菩提本无树 - 博客园 阿里云部署 Flask + WSGI + Nginx 详解 - Ray Liang - 博客园 Supervisor 管理后台守护进程 python web 部署：nginx + gunicorn + supervisor + flask 部署笔记 - 简书 VPS环境搭建详解 (Virtualenv+Gunicorn+Supervisor+Nginx) | BeiYuu.com 基于 Flask 实现 RESTful API | Ross’s Page Ubuntu 14.04 系统基于 Gunicorn 和 Nginx 部署 Flask 应用 | Ross’s Page Flask+Nginx+Gunicorn+Redis+Mysql搭建一个小站 | Alex&#039;s Blog How to Run Flask Applications with Nginx Using Gunicorn &#8211; Onur Güzel * dnsmasq配置域名重定向和dns缓存 | Alex&#039;s Blog 在阿里云CentOS7中配置基于Nginx+Supervisor+Gunicorn的Flask项目 - simpleapples virtualenv 环境下 Django + Nginx + Gunicorn+ Supervisor 搭建 Python Web 部署 | Flask之旅 CentOS 6 下使用 Nginx，Gunicorn 以及 Supervisor 部署 Flask 应用 - 杜顺帆的个人博客 在 Ubuntu 中 Nginx,Gunicorn 部署 Flask | autarch * 阿里云Python+Flask环境搭建]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netdata-Linux下性能监视工具]]></title>
    <url>%2F2016%2F05%2F06%2Flinux-performance-monitoring-tool-netdata%2F</url>
    <content type="text"><![CDATA[编译依赖12# Debian/Ubuntu$ sudo apt-get install zlib1g-dev gcc make git autoconf autogen automake pkg-config Install netdata123456# download it - the directory &apos;netdata.git&apos; will be created$ git clone https://github.com/firehol/netdata.git --depth=1cd netdata# build it./netdata-installer.sh 一旦编译安装完毕，netdata 将执行 /usr/sbin/netdata 启动 daemon 程序，并监听本机的 19999 端口。 直接访问：127.0.0.1:19999 即可打开监控界面。 链接 官方安装教程：Installation · firehol/netdata Wiki · GitHub GitHub - firehol/netdata: Real-time performance monitoring, done right! netdata：实时监视 Linux 系统性能]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cURL-命令行下工作的文件传输工具]]></title>
    <url>%2F2016%2F05%2F04%2Flinux-curl%2F</url>
    <content type="text"><![CDATA[cURL是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在”标准输出”（stdout）上面。 Linux下安装cURL1$ sudo apt-get install -y curl Windows下安装cURL Windows下默认没有cURL命令，需要安装后才能使用 到网址 curl download 下载curl安装包，我下载的是 curl-7.33.0-win64-ssl-sspi.zip 2013-10-16 04:24 698K 。 解压安装包，只有一个curl.exe文件，在 curl.exe 所在目录下打开 cmd 命令行窗口，就可以直接使用 curl 命令了。 为了让 curl 支持访问 https 的网址，需要下载 OpenSSL ,到 Win32OpenSSL 下载 Win32 OpenSSL v1.0.1t Light 文件。 上面的 2、3、4 步，如果你觉得太麻烦的话，也可以到 cURL - Download 下载 Win64 x86_64 7zip 7.49.0 binary SSL SSH Viktor Szakáts 这一项，下载后压缩包里的bin目录下有三个文件：curl.exe，curl-ca-bundle.crt，libcurl.dll，里面自带了SSL的证书文件。 cURL常用命令整理格式： curl [参数] [URL地址] 参数介绍 缩写 完整命令 示例 释意 -A --user-agent &lt;agent string&gt; demo 指定User-Agent的值 -b --cookie &lt;name=data/file&gt; demo cookie字符串或文件读取位置，使用option来把上次的cookie信息追加到http request里面去 -c --cookie-jar &lt;file name&gt; demo 操作结束后把cookie写入到这个文件中 -C --continue-at &lt;offset&gt; demo 断点续传 -d --data &lt;data&gt; demo HTTP POST方式传送数据 application/x-www-url-encoded -D --dump-header &lt;file&gt; demo 将请求返回的响应信息保存到指定的文件中 -e --referer &lt;URL&gt; demo 指定引用地址，表示从哪里跳转过来的 -E --cert &lt;certificate[:password]&gt; -F --form &lt;name=content&gt; demo HTTP 表单方式提交数据 multipart/form-data -G --get 使用GET方式请求，并将参数拼接在URL的?后面 -H --header &lt;header&gt; demo 指定请求头参数 -I --head demo 仅返回头部信息，使用HEAD请求 -L --location demo 执行重定向操作 3xx --limit-rate &lt;speed&gt; 限制最大传输率 -m --max-time &lt;seconds&gt; 指定处理的最大时长 --max-filesize &lt;bytes&gt; 指定要下载的文件的最大长度，如果超过bytes值，下载并不开始、返回退出码63 -o --output &lt;file&gt; demo 将文件保存为命令行中指定的文件名的文件中 &gt; &gt; 等同于-o,对输出进行转向输出 -O --remote-name demo 使用URL中默认的文件名保存文件到本地 -r --range &lt;range&gt; demo 检索来自HTTP/1.1或FTP服务器字节范围;分块下载 -s --silent demo 减少输出信息,比如进度显示或错误信息 --ssl 使用SSL/TLS方式创建连接请求 -T --upload-file &lt;file&gt; demo 使用PUT方法上传，-T参数指定上传文件 -u --user &lt;user:password&gt; demo 设置服务器的用户和密码 -v --verbose demo 小写的v参数，用于打印更多信息，包括发送的请求信息，这在调试脚本是特别有用 --trace demo 查看更详细的通信过程 --trace-ascii demo 查看更详细的通信过程 -w --write-out &lt;format&gt; demo -x --proxy &lt;[protocol://][user:password@]proxyhost[:port]&gt; demo 指定代理服务器地址和端口，端口默认为1080 -X --request &lt;command&gt; demo 指定GET,HEAD,POST,PUT,DELETE等请求协议 -h --help 使用帮助 -V --version 版本信息 --retry &lt;num&gt; 指定重试次数 示例 -A 指定User-Agent的值 Back To Top1$ curl -A &quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)&quot; -o page.html http://www.www.baidu.com -b 使用cookie文件(当前目录下的cookie.txt文件) Back To Top 1234// 指定 cookie信息 访问$ curl -b &quot;name=data&quot; http://www.baidu.com// 使用 本地文件中的cookie信息 访问$ curl -b cookie.txt http://www.xxxx.com/api -c 将请求得到的cookie信息保存到本地的 cookie.txt文件中 Back To Top 1$ curl -c cookie.txt http://www.alibaba.com -C 选项可对大文件使用断点续传功能 Back To Top 123456// 当文件在下载完成之前结束该进程$ curl -O http://www.xxx.com/gettext.html// ############# 20.1%// 通过添加-C选项继续对该文件进行下载，已经下载过的文件不会被重新下载$ curl -C -O http://www.xxx.com/gettext.html// ############# 20.1% -d 通过 application/x-www-url-encoded 方式发送POST请求，-d参数以name=value的方式指定参数内容 Back To Top 1234//多个参数用&amp;连接$ curl -d &quot;q=hello&amp;param2=test&quot; http://www.google.com //多个参数分别指定 $ curl -d &quot;action=del&quot; -d &quot;id=12&quot; http://localhost/action.php 注意：-d 后面post 的参数必须用双引号&quot;而不是单引号&#39;括起来，否则会报错 -D 将请求返回的响应信息保存到指定的文件中 Back To Top 1$ curl -D cookie.txt http://www.alibaba.com 注意：-c 仅包含响应头中的cookie信息 -D 包含响应头中的所有响应信息 -e 设置Referer引用地址 Back To Top 1$ curl -e http://localhost http://www.XXXX.com/wp-login.php -F 通过 multipart/form-data 方式发送POST请求，-F参数以name=value的方式指定参数内容；如果值是一个文件，使用name=@file的方式来指定;需要指定上传文件类型时，用type=来指定 Back To Top 123$ curl -F &quot;action=upload&quot; -F &quot;filename=@file.tar.gz&quot; http://localhost/action.php//如果通过代理，上述命令可能会被代理拒绝，需要指定上传文件的MIME类型：$ curl -x proxy.com:8080 -F &quot;action=upload&quot; -F &quot;filename=@file.tar.gz; type=application/octet-stream&quot; http://localhost/action.php -H 指定请求头参数 Back To Top 1$ curl -H &quot;Content-Type:application/json&quot; http://example.com -I 仅返回头部信息，使用HEAD请求 Back To Top 1$ curl -I http://www.baidu.com 注意：使用-I时，接口需要支持Method=HEAD请求，否则会返回405 Method Not Allowed -L 执行重定向操作 Back To Top 1$ curl -L www.baidu.com -o 将文件保存为命令行中指定的文件名的文件中 Back To Top 1234// 将百度首页内容抓到 home.html 中$ curl -o home.html http://baidu.com// 符号`&gt;`和`-o`效果相同$ curl &gt; home.html http://baidu.com -O 使用URL中默认的文件名保存文件到本地 Back To Top 12//将内容保存到 gettext.html 中$ curl -O http://www.xxx.com/gettext.html -r 分段下载 Back To Top 1234//获取前100字节的数据$ curl -r 0-99 http://www.get.this///获取最后500字节的数据$ curl -r -500 http://www.get.this/ -s 减少输出信息 Back To Top 1$ curl -s http://www.get.this/ -T 指定上传文件路径；可以一个-T对应一条Url来表示将一个文件上传到指定的Url;或者同时向一条Url上传多个文件 Back To Top 1234// ftp 上传$ curl -T test.sql ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files///同时上传多个文件$ curl -T &quot;&#123;file1,file2&#125;&quot; http://www.example.com -u 设置服务器的用户和密码 Back To Top 12$ curl -u 用户名:密码 http://www.example.com$ curl -u 用户名:密码 -O http://www.XXXX.com/demo/curtain/bbstudy_files/style.css -v 用于打印更多信息，可以显示一次http通信的整个过程，包括端口连接和http request头信息 Back To Top 1$ curl -v www.baidu.com --trace 查看更详细的通信过程 Back To Top 123$ curl --trace output.txt www.baidu.com//或$ curl --trace-ascii output.txt www.baidu.com -w 获取指定输出内容 Back To Top 1$ curl -m 10 -w &apos;%&#123;http_code&#125;\n&apos; http://wyh.life/ -so /dev/null -x 指定代理服务器地址和端口 Back To Top 1$ curl -u &lt;user&gt;:&lt;passwd&gt; -x &lt;proxy&gt;:&lt;port&gt; http://www.get.this/ -X -X参数可以支持其他动词 Back To Top 12$ curl -X POST www.example.com$ curl -X DELETE www.example.com 相关链接 curl网站开发指南 - 阮一峰的网络日志 CURL常用命令 - 张贺 - 博客园 Curl使用 - 简书 linux curl - 简书 提升开发效率小工具之-curl - 简书 curl命令常用操作 - web开发 - SegmentFault cURL备忘 - 脸滚键盘教™ - SegmentFault Curl使用 · Issue #42 · dongjun111111/blog · GitHub curl - zheng-ji’s Wiki help123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181$ curl --helpUsage: curl [options...] &lt;url&gt;Options: (H) means HTTP/HTTPS only, (F) means FTP only --anyauth Pick &quot;any&quot; authentication method (H) -a, --append Append to target file when uploading (F/SFTP) --basic Use HTTP Basic Authentication (H) --cacert FILE CA certificate to verify peer against (SSL) --capath DIR CA directory to verify peer against (SSL) -E, --cert CERT[:PASSWD] Client certificate file and password (SSL) --cert-status Verify the status of the server certificate (SSL) --cert-type TYPE Certificate file type (DER/PEM/ENG) (SSL) --ciphers LIST SSL ciphers to use (SSL) --compressed Request compressed response (using deflate or gzip) -K, --config FILE Read config from FILE --connect-timeout SECONDS Maximum time allowed for connection -C, --continue-at OFFSET Resumed transfer OFFSET -b, --cookie STRING/FILE Read cookies from STRING/FILE (H) -c, --cookie-jar FILE Write cookies to FILE after operation (H) --create-dirs Create necessary local directory hierarchy --crlf Convert LF to CRLF in upload --crlfile FILE Get a CRL list in PEM format from the given file -d, --data DATA HTTP POST data (H) --data-raw DATA HTTP POST data, &apos;@&apos; allowed (H) --data-ascii DATA HTTP POST ASCII data (H) --data-binary DATA HTTP POST binary data (H) --data-urlencode DATA HTTP POST data url encoded (H) --delegation STRING GSS-API delegation permission --digest Use HTTP Digest Authentication (H) --disable-eprt Inhibit using EPRT or LPRT (F) --disable-epsv Inhibit using EPSV (F) --dns-servers DNS server addrs to use: 1.1.1.1;2.2.2.2 --dns-interface Interface to use for DNS requests --dns-ipv4-addr IPv4 address to use for DNS requests, dot notation --dns-ipv6-addr IPv6 address to use for DNS requests, dot notation -D, --dump-header FILE Write the headers to FILE --egd-file FILE EGD socket path for random data (SSL) --engine ENGINE Crypto engine (use &quot;--engine list&quot; for list) (SSL) -f, --fail Fail silently (no output at all) on HTTP errors (H) --false-start Enable TLS False Start. -F, --form CONTENT Specify HTTP multipart POST data (H) --form-string STRING Specify HTTP multipart POST data (H) --ftp-account DATA Account data string (F) --ftp-alternative-to-user COMMAND String to replace &quot;USER [name]&quot; (F) --ftp-create-dirs Create the remote dirs if not present (F) --ftp-method [MULTICWD/NOCWD/SINGLECWD] Control CWD usage (F) --ftp-pasv Use PASV/EPSV instead of PORT (F) -P, --ftp-port ADR Use PORT with given address instead of PASV (F) --ftp-skip-pasv-ip Skip the IP address for PASV (F) --ftp-pret Send PRET before PASV (for drftpd) (F) --ftp-ssl-ccc Send CCC after authenticating (F) --ftp-ssl-ccc-mode ACTIVE/PASSIVE Set CCC mode (F) --ftp-ssl-control Require SSL/TLS for FTP login, clear for transfer (F) -G, --get Send the -d data with a HTTP GET (H) -g, --globoff Disable URL sequences and ranges using &#123;&#125; and [] -H, --header LINE Pass custom header LINE to server (H) -I, --head Show document info only -h, --help This help text --hostpubmd5 MD5 Hex-encoded MD5 string of the host public key. (SSH) -0, --http1.0 Use HTTP 1.0 (H) --http1.1 Use HTTP 1.1 (H) --http2 Use HTTP 2 (H) --ignore-content-length Ignore the HTTP Content-Length header -i, --include Include protocol headers in the output (H/F) -k, --insecure Allow connections to SSL sites without certs (H) --interface INTERFACE Use network INTERFACE (or address) -4, --ipv4 Resolve name to IPv4 address -6, --ipv6 Resolve name to IPv6 address -j, --junk-session-cookies Ignore session cookies read from file (H) --keepalive-time SECONDS Wait SECONDS between keepalive probes --key KEY Private key file name (SSL/SSH) --key-type TYPE Private key file type (DER/PEM/ENG) (SSL) --krb LEVEL Enable Kerberos with security LEVEL (F) --libcurl FILE Dump libcurl equivalent code of this command line --limit-rate RATE Limit transfer speed to RATE -l, --list-only List only mode (F/POP3) --local-port RANGE Force use of RANGE for local port numbers -L, --location Follow redirects (H) --location-trusted Like &apos;--location&apos;, and send auth to other hosts (H) --login-options OPTIONS Server login options (IMAP, POP3, SMTP) -M, --manual Display the full manual --mail-from FROM Mail from this address (SMTP) --mail-rcpt TO Mail to this/these addresses (SMTP) --mail-auth AUTH Originator address of the original email (SMTP) --max-filesize BYTES Maximum file size to download (H/F) --max-redirs NUM Maximum number of redirects allowed (H) -m, --max-time SECONDS Maximum time allowed for the transfer --metalink Process given URLs as metalink XML file --negotiate Use HTTP Negotiate (SPNEGO) authentication (H) -n, --netrc Must read .netrc for user name and password --netrc-optional Use either .netrc or URL; overrides -n --netrc-file FILE Specify FILE for netrc -:, --next Allows the following URL to use a separate set of options --no-alpn Disable the ALPN TLS extension (H) -N, --no-buffer Disable buffering of the output stream --no-keepalive Disable keepalive use on the connection --no-npn Disable the NPN TLS extension (H) --no-sessionid Disable SSL session-ID reusing (SSL) --noproxy List of hosts which do not use proxy --ntlm Use HTTP NTLM authentication (H) --oauth2-bearer TOKEN OAuth 2 Bearer Token (IMAP, POP3, SMTP) -o, --output FILE Write to FILE instead of stdout --pass PASS Pass phrase for the private key (SSL/SSH) --path-as-is Do not squash .. sequences in URL path --pinnedpubkey FILE/HASHES Public key to verify peer against (SSL) --post301 Do not switch to GET after following a 301 redirect (H) --post302 Do not switch to GET after following a 302 redirect (H) --post303 Do not switch to GET after following a 303 redirect (H) -#, --progress-bar Display transfer progress as a progress bar --proto PROTOCOLS Enable/disable PROTOCOLS --proto-default PROTOCOL Use PROTOCOL for any URL missing a scheme --proto-redir PROTOCOLS Enable/disable PROTOCOLS on redirect -x, --proxy [PROTOCOL://]HOST[:PORT] Use proxy on given port --proxy-anyauth Pick &quot;any&quot; proxy authentication method (H) --proxy-basic Use Basic authentication on the proxy (H) --proxy-digest Use Digest authentication on the proxy (H) --proxy-negotiate Use HTTP Negotiate (SPNEGO) authentication on the proxy (H) --proxy-ntlm Use NTLM authentication on the proxy (H) --proxy-service-name NAME SPNEGO proxy service name --service-name NAME SPNEGO service name -U, --proxy-user USER[:PASSWORD] Proxy user and password --proxy1.0 HOST[:PORT] Use HTTP/1.0 proxy on given port -p, --proxytunnel Operate through a HTTP proxy tunnel (using CONNECT) --pubkey KEY Public key file name (SSH) -Q, --quote CMD Send command(s) to server before transfer (F/SFTP) --random-file FILE File for reading random data from (SSL) -r, --range RANGE Retrieve only the bytes within RANGE --raw Do HTTP &quot;raw&quot;; no transfer decoding (H) -e, --referer Referer URL (H) -J, --remote-header-name Use the header-provided filename (H) -O, --remote-name Write output to a file named as the remote file --remote-name-all Use the remote file name for all URLs -R, --remote-time Set the remote file&apos;s time on the local output -X, --request COMMAND Specify request command to use --resolve HOST:PORT:ADDRESS Force resolve of HOST:PORT to ADDRESS --retry NUM Retry request NUM times if transient problems occur --retry-delay SECONDS Wait SECONDS between retries --retry-max-time SECONDS Retry only within this period --sasl-ir Enable initial response in SASL authentication -S, --show-error Show error. With -s, make curl show errors when they occur -s, --silent Silent mode (don&apos;t output anything) --socks4 HOST[:PORT] SOCKS4 proxy on given host + port --socks4a HOST[:PORT] SOCKS4a proxy on given host + port --socks5 HOST[:PORT] SOCKS5 proxy on given host + port --socks5-hostname HOST[:PORT] SOCKS5 proxy, pass host name to proxy --socks5-gssapi-service NAME SOCKS5 proxy service name for GSS-API --socks5-gssapi-nec Compatibility with NEC SOCKS5 server -Y, --speed-limit RATE Stop transfers below RATE for &apos;speed-time&apos; secs -y, --speed-time SECONDS Trigger &apos;speed-limit&apos; abort after SECONDS (default: 30) --ssl Try SSL/TLS (FTP, IMAP, POP3, SMTP) --ssl-reqd Require SSL/TLS (FTP, IMAP, POP3, SMTP) -2, --sslv2 Use SSLv2 (SSL) -3, --sslv3 Use SSLv3 (SSL) --ssl-allow-beast Allow security flaw to improve interop (SSL) --ssl-no-revoke Disable cert revocation checks (WinSSL) --stderr FILE Where to redirect stderr (use &quot;-&quot; for stdout) --tcp-nodelay Use the TCP_NODELAY option -t, --telnet-option OPT=VAL Set telnet option --tftp-blksize VALUE Set TFTP BLKSIZE option (must be &gt;512) -z, --time-cond TIME Transfer based on a time condition -1, --tlsv1 Use &gt;= TLSv1 (SSL) --tlsv1.0 Use TLSv1.0 (SSL) --tlsv1.1 Use TLSv1.1 (SSL) --tlsv1.2 Use TLSv1.2 (SSL) --trace FILE Write a debug trace to FILE --trace-ascii FILE Like --trace, but without hex output --trace-time Add time stamps to trace/verbose output --tr-encoding Request compressed transfer encoding (H) -T, --upload-file FILE Transfer FILE to destination --url URL URL to work with -B, --use-ascii Use ASCII/text transfer -u, --user USER[:PASSWORD] Server user and password --tlsuser USER TLS username --tlspassword STRING TLS password --tlsauthtype STRING TLS authentication type (default: SRP) --unix-socket FILE Connect through this Unix domain socket -A, --user-agent STRING Send User-Agent STRING to server (H) -v, --verbose Make the operation more talkative -V, --version Show version number and quit -w, --write-out FORMAT Use output FORMAT after completion --xattr Store metadata in extended file attributes -q Disable .curlrc (must be first parameter)]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC和WebAPI如何从Filter向Action中传递数据]]></title>
    <url>%2F2016%2F04%2F17%2Ftransfer-data-from-filter-to-action%2F</url>
    <content type="text"><![CDATA[MVC和WebAPI如何从Filter向Action中传递数据 需求最近在策划实现MVC项目中用户身份验证的功能时，考虑用MVC中的Filter过滤器来先从url链接中获取传递过来的token，在Filter中通过token获取用户的信息后，如果用户信息正确，则传递到Controller的Action中进行用户数据的操作。 那么，要如何从Filter中向Action中传递数据呢？ how to pass data from filter to controller? 注意：下面所提到的Filter都指实现ActionFilterAttribute的过滤器 MVC中 从Filter过滤器向Action中传递数据方法一 通过 RouteData 来传值12345//赋值：filterContext.RouteData.Values.Add(&quot;Tname&quot;,UName);//获取： var nm = RouteData.Values[&quot;Tname&quot;]; 测试通过。 详见： ASP.NET MVC Pass object from Custom Action Filter to Action - Stack Overflow 方法二 通过 ActionParameters 来传值另一种方法是通过 ActionParameters 来设置，但在Action中是通过添加参数获取值的： 1234//赋值： filterContext.ActionParameters.Add(&quot;number&quot;, Id);//获取： public ActionResult Index(int number, Person person) 详见： Manipulating Action Method Parameters - You’ve Been Haacked 通过测试，发现这种方法可以隐藏真实的Action方法： 比如：请求的链接是 http://localhost:47760/home/show?id=3&amp;name=abc而实际的Action为： 1public ActionResult Show(string aaa)&#123;&#125; 那么可以通过添加一个 ActionFilterAttribute 过滤器，并设置： 12this.Uname=getquerystring.name;filterContext.ActionParameters[&quot;aaa&quot;] = UName; 这样虽然url中请求的参数时id和name，而实际请求参数是aaa； 而实际的请求链接 http://localhost:47760/home/show?aaa=haha 也是可以访问的。 方法三 通过 HttpContext.Items 来传值1234//Filter中赋值： filterContext.HttpContext.Items[&quot;tname&quot;] = UName+&quot;2324&quot;;//Action中取值： var nm= HttpContext.Items[&quot;tname&quot;]; 测试通过。 通过测试发现好像这种方式比较合适。因为：可看到Items的解释为： 在派生类中重写时，获取一个键/值集合，该集合在 HTTP 请求过程中可以用于在模块与处理程序之间组织和共享数据。 详见： asp.net mvc - Accessing Action Filter&#39;s data in Controller Action - Stack Overflow WebAPI中从Filter向Action中传递数据如何从Filter向Action中传递数据？ 方法一 通过 Request.Properties 来传值1234//Filter中赋值： actionContext.Request.Properties[&quot;id&quot;] =&quot;134&quot;;//Action中获取： var id= Request.Properties[&quot;id&quot;]; 或： 123456//赋值: actionContext.Request.Properties.Add(&quot;mykey&quot;, myObject);//获取： object myObject;Request.Properties.TryGetValue(&quot;mykey&quot;, out myObject);//cast to MyType 测试通过。 详见： asp.net web api - WebApi: how to pass state from filter to controller? - Stack Overflow asp.net web api - Pass an object from ActionFilter.OnActionExecuting() to an ApiController - Stack Overflow 总结MVC 用 : 1filterContext.HttpContext.Items[UnitOfWorkRequestKey] = UnitOfWork; Web API 用 : 1actionContext.Request.Properties[UnitOfWorkRequestKey] = UnitOfWork; 详见： c# - Web API Action Filter - Controller.TempData equivalent? - Stack Overflow]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
        <tag>RestfulApi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web API中路由中加了action后其他get、post开头的方法如何直接访问]]></title>
    <url>%2F2016%2F04%2F17%2Fwebapi-action-url-extend%2F</url>
    <content type="text"><![CDATA[需求通常我们在访问Web API接口时，默认自带的Action方法为以下这些： 12345public IEnumerable&lt;string&gt; Get()public string Get(int id)public void Post([FromBody]string value)public void Put(int id, [FromBody]string value)public void Delete(int id) 默认的路由表规则为： WebApiConfig.cs文件 12345config.Routes.MapHttpRoute( name: &quot;DefaultApi&quot;, routeTemplate: &quot;api/&#123;controller&#125;/&#123;id&#125;&quot;, defaults: new &#123; id = RouteParameter.Optional &#125;); 匹配的Url为： 动作 HTTP方法 相对路径 获取全部 GET /api/products 指定 id 获取 GET /api/products/id 添加 POST /api/products 更新 PUT /api/products/id 删除 DELETE /api/products/id 特殊需求我们在同一个 Controller 中，有时候可能需要定义多个相同 Method 的 Action 方法，比如： 123public string Get(int id)public string GetList(string name)public string GetPeople(int id) 那么这种情况下，我们就要再添加一个 Route 路由规则，添加一个 {action} 的占位符： 12345 config.Routes.MapHttpRoute( name: &quot;DefaultApiAction&quot;, routeTemplate: &quot;api/&#123;controller&#125;/&#123;action&#125;/&#123;id&#125;&quot;, defaults: new &#123; id = RouteParameter.Optional &#125;); 但这样我们就不能再用之前的那种方式来直接访问默认的Get或Post等方法了，每个Url链接都要加上action名称： 123/api/products/get/api/products/getlist/api/products/post 这样的话我们就觉得反而更麻烦了。 解决方法那是不是有一种什么样的方法能让我们在添加多个相同类型的请求方法时，既能直接访问默认的方法，又能通过添加action名称来访问自定义添加的方法呢？ 其实，我们只要修改路由规则如下即可： 1234567891011121314151617181920using System.Net.Http;using System.Web.Http.Routing; //可用的路由表 config.Routes.MapHttpRoute(&quot;DefaultApiWithId&quot;, &quot;api/&#123;controller&#125;/&#123;id&#125;&quot;, new &#123; id = RouteParameter.Optional &#125;, new &#123; id = @&quot;\d+&quot; &#125;); config.Routes.MapHttpRoute(&quot;DefaultApiWithAction&quot;, &quot;api/&#123;controller&#125;/&#123;action&#125;&quot;); config.Routes.MapHttpRoute(&quot;DefaultApiGet&quot;, &quot;Api/&#123;controller&#125;&quot;, new &#123; action = &quot;Get&quot; &#125;, new &#123; httpMethod = new HttpMethodConstraint(HttpMethod.Get) &#125;); config.Routes.MapHttpRoute(&quot;DefaultApiPost&quot;, &quot;Api/&#123;controller&#125;&quot;, new &#123; action = &quot;Post&quot; &#125;, new &#123; httpMethod = new HttpMethodConstraint(HttpMethod.Post) &#125;); 详细说明见：wcf web api - Single controller with multiple GET methods in ASP.NET Web API - Stack Overflow 再啰嗦一句如果同一种请求方式下，有多个同类型的方法，会请求默认状态下的那个：比如 get方法： 12public string Get()public string GetTop() 如果请求：http://localhost:47760/api/product则访问到的是Get()方法，即使在顺序上GetTop()排在Get()方法前面。]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的计划任务-Crontab]]></title>
    <url>%2F2016%2F03%2F28%2Fthe-plan-task-in-linux-cronlib%2F</url>
    <content type="text"><![CDATA[Crontab 用于设置周期性被执行的任务的工具 检查cron服务检查crontab工具是否安装 1$ crontab -l 检查crond服务是启动 1$service crond status 注意: 在Ubuntu系统下,查看crontab服务是: service cron status 安装cron12$ sudo apt-get install vixie-cron$ sudo apt-get install crontabs 如果在输入crontab -l之后,提示”no crontab for root“的信息,则说明系统中没有设置crontab,需要先进行设置. crontab是一个文本文件，用来存放你要运行的命令。 执行命令crontab -e,会提示:1234no crontab for root - using an empty oneSelect an editor. ......... 这样的提示,然后选择一个编辑器(这里我选 vim:tiny)即可.然后会进入crontab编辑页面,在编辑页面中直接输入shift+:,然后输入wq保存,一个新的crontab就生成了.然后再执行crontab -l 就能看到刚刚编辑过的crontab文件了. 参考:Linux提示no crontab for root的解决办法Ubuntu下crontab命令的用法 实例执行crontab -e打开crontab文件 写入以下命令: 1*/1 * * * * date &gt;&gt; /tmp/log.txt 表示:每分钟将当前时间写入到tmp目录下的log.txt文件中 查看log.txt文件,执行命令: 1$ tail -f /tmp/log.txt 表示查看log.txt文件的最后几行 查看crontab服务运行状态: 1$ service cron status crontab 配置文件的格式1* * * * * COMMAND 1* 分钟 0~59 2* 小时 0~23 3* 日期 1~31 4* 月份 1~12 5* 星期 1-7 (0或者7表示星期天) 案例 每晚 21:30重启apache 130 21 * * * service httpd restart 每月 1 10 22日的4:45重启apache 145 4 1,10,22 * * service httpd restart 每月1到10日的4:45重启apache 145 4 1-10 * * service httpd restart 用-表示间隔 每隔2分钟重启Apache服务 12*/2 * * * * service httpd restart //偶数分钟内1-59/2 * * * * service httpd restart //奇数分钟内 晚上11点到早上7点之间,每隔一小时重启apache 10 23-7/1 * * * * service httpd retart 每天18点到23点之间每隔30分钟重启apache 120-59/30 18-23 * * * service httpd restart0,30 18-23 * * * service httpd restart 总结 * 表示任何时间都匹配 可以用 A,B,C 表示A或者B或者C时执行命令 可以用 A-B 表示A到B之间时执行命令 可以用 */A 表示每A分钟(小时等)执行一次命令 注意 第三和第五个域之间是”或”的关系:四月的第一个星期天早晨1时59分运行a.sh159 1 1-7 4 * test `date + \%w` -eq &amp;&amp; /root/a.sh Crontab格式 minute hour day month week command 其中： minute：表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 Crontab定时调用Python脚本 指定python脚本文件中的头信息 #!/bin/sh 相关链接 每天一个linux命令（50）：crontab命令 - peida - 博客园 crontab命令_Linux crontab 命令用法详解：提交和管理用户的需要周期性执行的任务 crontab 中 python 脚本执行失败的解决方法 | CoCo的小黑屋]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Crontab</tag>
      </tags>
  </entry>
</search>
